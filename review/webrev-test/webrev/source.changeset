# HG changeset patch
# User stuefe
# Date 1597217690 -7200
#      Wed Aug 12 09:34:50 2020 +0200
# Node ID 68d602154ae0e15edabd7ae9fa21ba98ba108743
# Parent  0d7947ba53894681c9bf55759d9c20ee3859e7bd
imported patch jep387-test.patch

diff --git a/src/hotspot/share/memory/metaspace/metaspace_test.cpp b/src/hotspot/share/memory/metaspace/metaspace_test.cpp
new file mode 100644
--- /dev/null
+++ b/src/hotspot/share/memory/metaspace/metaspace_test.cpp
@@ -0,0 +1,119 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+
+#include "memory/virtualspace.hpp"
+#include "memory/metaspace/virtualSpaceList.hpp"
+#include "memory/metaspace/chunkManager.hpp"
+#include "memory/metaspace/arenaGrowthPolicy.hpp"
+#include "memory/metaspace/commitLimiter.hpp"
+#include "memory/metaspace/metaspace_test.hpp"
+#include "memory/metaspace/metaspaceArena.hpp"
+#include "memory/metaspace/metaspaceContext.hpp"
+#include "memory/metaspace/runningCounters.hpp"
+#include "runtime/mutexLocker.hpp"
+#include "utilities/debug.hpp"
+#include "utilities/ostream.hpp"
+#include "utilities/globalDefinitions.hpp"
+
+namespace metaspace {
+
+///// MetaspaceTestArena //////
+
+MetaspaceTestArena::MetaspaceTestArena(Mutex* lock, MetaspaceArena* arena)
+  : _lock(lock), _arena(arena) {}
+
+MetaspaceTestArena::~MetaspaceTestArena() {
+  delete _arena;
+  delete _lock;
+}
+
+MetaWord* MetaspaceTestArena::allocate(size_t word_size) {
+  return _arena->allocate(word_size);
+}
+
+void MetaspaceTestArena::deallocate(MetaWord* p, size_t word_size) {
+  return _arena->deallocate(p, word_size);
+}
+
+///// MetaspaceTestArea //////
+
+MetaspaceTestContext::MetaspaceTestContext(const char* name, size_t commit_limit, size_t reserve_limit)
+  : _name(name), _reserve_limit(reserve_limit), _commit_limit(commit_limit),
+    _context(NULL),
+    _commit_limiter(commit_limit == 0 ? max_uintx : commit_limit), // commit_limit == 0 -> no limit
+    _used_words_counter()
+{
+  assert(is_aligned(reserve_limit, Metaspace::reserve_alignment_words()), "reserve_limit (" SIZE_FORMAT ") "
+                    "not aligned to metaspace reserve alignment (" SIZE_FORMAT ")",
+                    reserve_limit, Metaspace::reserve_alignment_words());
+  if (reserve_limit > 0) {
+    // have reserve limit -> non-expandable context
+    ReservedSpace rs(reserve_limit * BytesPerWord, Metaspace::reserve_alignment(), false);
+    _context = MetaspaceContext::create_nonexpandable_context(name, rs, &_commit_limiter);
+  } else {
+    // no reserve limit -> expandable vslist
+    _context = MetaspaceContext::create_expandable_context(name, &_commit_limiter);
+  }
+
+}
+
+MetaspaceTestContext::~MetaspaceTestContext() {
+  DEBUG_ONLY(verify(true);)
+  MutexLocker fcl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
+  delete _context;
+}
+
+// Create an arena, feeding off this area.
+MetaspaceTestArena* MetaspaceTestContext::create_arena(Metaspace::MetaspaceType type) {
+  const ArenaGrowthPolicy* growth_policy = ArenaGrowthPolicy::policy_for_space_type(type, false);
+  Mutex* lock = new Mutex(Monitor::native, "MetaspaceTestArea-lock", false, Monitor::_safepoint_check_never);
+  MetaspaceArena* arena = NULL;
+  {
+    MutexLocker ml(lock,  Mutex::_no_safepoint_check_flag);
+    arena = new MetaspaceArena(_context->cm(), growth_policy, lock, &_used_words_counter, _name);
+  }
+  return new MetaspaceTestArena(lock, arena);
+}
+
+void MetaspaceTestContext::purge_area() {
+  _context->cm()->purge();
+}
+
+#ifdef ASSERT
+void MetaspaceTestContext::verify(bool slow) const {
+  if (_context != NULL) {
+    _context->verify(slow);
+  }
+}
+#endif
+
+void MetaspaceTestContext::print_on(outputStream* st) const {
+  _context->print_on(st);
+}
+
+} // namespace metaspace
+
diff --git a/src/hotspot/share/memory/metaspace/metaspace_test.hpp b/src/hotspot/share/memory/metaspace/metaspace_test.hpp
new file mode 100644
--- /dev/null
+++ b/src/hotspot/share/memory/metaspace/metaspace_test.hpp
@@ -0,0 +1,120 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#ifndef SHARE_MEMORY_METASPACE_METASPACE_TEST_HPP
+#define SHARE_MEMORY_METASPACE_METASPACE_TEST_HPP
+
+
+#include "memory/allocation.hpp"
+#include "memory/metaspace.hpp"
+#include "memory/metaspace/commitLimiter.hpp"
+#include "memory/metaspace/counter.hpp"
+#include "memory/metaspace/metaspaceContext.hpp"
+#include "memory/virtualspace.hpp"
+#include "utilities/globalDefinitions.hpp"
+
+// This is just convenience classes for metaspace-related tests
+//  (jtreg, via whitebox API, and gtests)
+
+class ReservedSpace;
+class Mutex;
+class outputStream;
+
+namespace metaspace {
+
+class MetaspaceContext;
+class MetaspaceArena;
+
+
+// Wraps a MetaspaceTestArena with its own lock for testing purposes.
+class MetaspaceTestArena : public CHeapObj<mtInternal> {
+
+  Mutex* const _lock;
+  MetaspaceArena* const _arena;
+
+public:
+
+  const MetaspaceArena* arena() const {
+    return _arena;
+  }
+
+  MetaspaceTestArena(Mutex* lock, MetaspaceArena* arena);
+  ~MetaspaceTestArena();
+
+  MetaWord* allocate(size_t word_size);
+  void deallocate(MetaWord* p, size_t word_size);
+
+};
+
+
+// Wraps an instance of a MetaspaceContext together with some side objects for easy use in test beds (whitebox, gtests)
+class MetaspaceTestContext : public CHeapObj<mtInternal> {
+
+  const char* const _name;
+  const size_t _reserve_limit;
+  const size_t _commit_limit;
+
+  MetaspaceContext* _context;
+  CommitLimiter _commit_limiter;
+  SizeAtomicCounter _used_words_counter;
+
+public:
+
+  // Note: limit == 0 means unlimited
+  // Reserve limit > 0 simulates a non-expandable VirtualSpaceList (like CompressedClassSpace)
+  // Commit limit > 0 simulates a limit to max commitable space (like MaxMetaspaceSize)
+  MetaspaceTestContext(const char* name, size_t commit_limit = 0, size_t reserve_limit = 0);
+  ~MetaspaceTestContext();
+
+  // Create an arena, feeding off this area.
+  MetaspaceTestArena* create_arena(Metaspace::MetaspaceType type);
+
+  void purge_area();
+
+  // Accessors
+  const CommitLimiter& commit_limiter() const { return _commit_limiter; }
+  const VirtualSpaceList& vslist() const      { return *(_context->vslist()); }
+  ChunkManager& cm()                          { return *(_context->cm()); }
+
+  // Returns reserve- and commit limit we run the test with (in the real world,
+  // these would be equivalent to CompressedClassSpaceSize resp MaxMetaspaceSize)
+  size_t reserve_limit() const    { return _reserve_limit == 0 ? max_uintx : 0; }
+  size_t commit_limit() const     { return _commit_limit == 0 ? max_uintx : 0; }
+
+  // Convenience function to retrieve total committed/used words
+  size_t used_words() const       { return _used_words_counter.get(); }
+  size_t committed_words() const  { return _commit_limiter.committed_words(); }
+
+  DEBUG_ONLY(void verify(bool slow = false) const;)
+
+  void print_on(outputStream* st) const;
+
+};
+
+
+} // namespace metaspace
+
+#endif // SHARE_MEMORY_METASPACE_METASPACE_TEST_HPP
+
diff --git a/src/hotspot/share/prims/whitebox.cpp b/src/hotspot/share/prims/whitebox.cpp
--- a/src/hotspot/share/prims/whitebox.cpp
+++ b/src/hotspot/share/prims/whitebox.cpp
@@ -46,6 +46,7 @@
 #include "memory/heapShared.inline.hpp"
 #include "memory/metaspaceShared.hpp"
 #include "memory/metadataFactory.hpp"
+#include "memory/metaspace/metaspace_test.hpp"
 #include "memory/iterator.hpp"
 #include "memory/resourceArea.hpp"
 #include "memory/universe.hpp"
@@ -84,6 +85,7 @@
 #include "utilities/elfFile.hpp"
 #include "utilities/exceptions.hpp"
 #include "utilities/macros.hpp"
+#include "utilities/ostream.hpp"
 #if INCLUDE_CDS
 #include "prims/cdsoffsets.hpp"
 #endif // INCLUDE_CDS
@@ -1690,6 +1692,65 @@
   return Array<u1>::bytes_to_length(bytes);
 }
 
+///////////////
+// MetaspaceTestContext and MetaspaceTestArena
+WB_ENTRY(jlong, WB_CreateMetaspaceTestContext(JNIEnv* env, jobject wb, jlong commit_limit, jlong reserve_limit))
+  metaspace::MetaspaceTestContext* context =
+      new metaspace::MetaspaceTestContext("whitebox-metaspace-context", (size_t) commit_limit, (size_t) reserve_limit);
+  return (jlong)p2i(context);
+WB_END
+
+WB_ENTRY(void, WB_DestroyMetaspaceTestContext(JNIEnv* env, jobject wb, jlong context))
+  delete (metaspace::MetaspaceTestContext*) context;
+WB_END
+
+WB_ENTRY(void, WB_PurgeMetaspaceTestContext(JNIEnv* env, jobject wb, jlong context))
+  metaspace::MetaspaceTestContext* context0 = (metaspace::MetaspaceTestContext*) context;
+  context0->purge_area();
+WB_END
+
+WB_ENTRY(void, WB_PrintMetaspaceTestContext(JNIEnv* env, jobject wb, jlong context))
+  metaspace::MetaspaceTestContext* context0 = (metaspace::MetaspaceTestContext*) context;
+  context0->print_on(tty);
+WB_END
+
+WB_ENTRY(jlong, WB_GetTotalCommittedWordsInMetaspaceTestContext(JNIEnv* env, jobject wb, jlong context))
+  metaspace::MetaspaceTestContext* context0 = (metaspace::MetaspaceTestContext*) context;
+  return context0->committed_words();
+WB_END
+
+WB_ENTRY(jlong, WB_GetTotalUsedWordsInMetaspaceTestContext(JNIEnv* env, jobject wb, jlong context))
+  metaspace::MetaspaceTestContext* context0 = (metaspace::MetaspaceTestContext*) context;
+  return context0->used_words();
+WB_END
+
+WB_ENTRY(jlong, WB_CreateArenaInTestContext(JNIEnv* env, jobject wb, jlong context, jboolean is_micro))
+  const Metaspace::MetaspaceType type = is_micro ? Metaspace::ReflectionMetaspaceType : Metaspace::StandardMetaspaceType;
+  metaspace::MetaspaceTestContext* context0 = (metaspace::MetaspaceTestContext*) context;
+  return (jlong)p2i(context0->create_arena(type));
+WB_END
+
+WB_ENTRY(void, WB_DestroyMetaspaceTestArena(JNIEnv* env, jobject wb, jlong arena))
+  delete (metaspace::MetaspaceTestArena*) arena;
+WB_END
+
+WB_ENTRY(jlong, WB_AllocateFromMetaspaceTestArena(JNIEnv* env, jobject wb, jlong arena, jlong word_size))
+  metaspace::MetaspaceTestArena* arena0 = (metaspace::MetaspaceTestArena*) arena;
+  MetaWord* p = arena0->allocate((size_t) word_size);
+  return (jlong)p2i(p);
+WB_END
+
+WB_ENTRY(void, WB_DeallocateToMetaspaceTestArena(JNIEnv* env, jobject wb, jlong arena, jlong p, jlong word_size))
+  metaspace::MetaspaceTestArena* arena0 = (metaspace::MetaspaceTestArena*) arena;
+  arena0->deallocate((MetaWord*)p, (size_t) word_size);
+WB_END
+
+WB_ENTRY(jlong, WB_GetMaxMetaspaceAllocationSize(JNIEnv* env, jobject wb))
+  return (jlong) Metaspace::max_allocation_word_size() * BytesPerWord;
+WB_END
+
+//////////////
+
 WB_ENTRY(jlong, WB_AllocateMetaspace(JNIEnv* env, jobject wb, jobject class_loader, jlong size))
   if (size < 0) {
     THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(),
@@ -1706,15 +1767,6 @@
   return (jlong)(uintptr_t)metadata;
 WB_END
 
-WB_ENTRY(void, WB_FreeMetaspace(JNIEnv* env, jobject wb, jobject class_loader, jlong addr, jlong size))
-  oop class_loader_oop = JNIHandles::resolve(class_loader);
-  ClassLoaderData* cld = class_loader_oop != NULL
-      ? java_lang_ClassLoader::loader_data_acquire(class_loader_oop)
-      : ClassLoaderData::the_null_class_loader_data();
-
-  MetadataFactory::free_array(cld, (Array<u1>*)(uintptr_t)addr);
-WB_END
-
 WB_ENTRY(void, WB_DefineModule(JNIEnv* env, jobject o, jobject module, jboolean is_open,
                                 jstring version, jstring location, jobjectArray packages))
   Modules::define_module(module, is_open, version, location, packages, CHECK);
@@ -2435,8 +2487,6 @@
   {CC"readReservedMemory", CC"()V",                   (void*)&WB_ReadReservedMemory },
   {CC"allocateMetaspace",
      CC"(Ljava/lang/ClassLoader;J)J",                 (void*)&WB_AllocateMetaspace },
-  {CC"freeMetaspace",
-     CC"(Ljava/lang/ClassLoader;JJ)V",                (void*)&WB_FreeMetaspace },
   {CC"incMetaspaceCapacityUntilGC", CC"(J)J",         (void*)&WB_IncMetaspaceCapacityUntilGC },
   {CC"metaspaceCapacityUntilGC", CC"()J",             (void*)&WB_MetaspaceCapacityUntilGC },
   {CC"metaspaceReserveAlignment", CC"()J",            (void*)&WB_MetaspaceReserveAlignment },
@@ -2533,6 +2583,19 @@
   {CC"protectionDomainRemovedCount",   CC"()I",       (void*)&WB_ProtectionDomainRemovedCount },
   {CC"aotLibrariesCount", CC"()I",                    (void*)&WB_AotLibrariesCount },
   {CC"getKlassMetadataSize", CC"(Ljava/lang/Class;)I",(void*)&WB_GetKlassMetadataSize},
+
+  {CC"createMetaspaceTestContext", CC"(JJ)J",         (void*)&WB_CreateMetaspaceTestContext},
+  {CC"destroyMetaspaceTestContext", CC"(J)V",         (void*)&WB_DestroyMetaspaceTestContext},
+  {CC"purgeMetaspaceTestContext", CC"(J)V",           (void*)&WB_PurgeMetaspaceTestContext},
+  {CC"printMetaspaceTestContext", CC"(J)V",           (void*)&WB_PrintMetaspaceTestContext},
+  {CC"getTotalCommittedWordsInMetaspaceTestContext", CC"(J)J",(void*)&WB_GetTotalCommittedWordsInMetaspaceTestContext},
+  {CC"getTotalUsedWordsInMetaspaceTestContext", CC"(J)J", (void*)&WB_GetTotalUsedWordsInMetaspaceTestContext},
+  {CC"createArenaInTestContext", CC"(JZ)J",           (void*)&WB_CreateArenaInTestContext},
+  {CC"destroyMetaspaceTestArena", CC"(J)V",           (void*)&WB_DestroyMetaspaceTestArena},
+  {CC"allocateFromMetaspaceTestArena", CC"(JJ)J",     (void*)&WB_AllocateFromMetaspaceTestArena},
+  {CC"deallocateToMetaspaceTestArena", CC"(JJJ)V",    (void*)&WB_DeallocateToMetaspaceTestArena},
+  {CC"maxMetaspaceAllocationSize", CC"()J",           (void*)&WB_GetMaxMetaspaceAllocationSize},
+
 };
 
 
diff --git a/test/hotspot/gtest/memory/test_chunkManager.cpp b/test/hotspot/gtest/memory/test_chunkManager.cpp
deleted file mode 100644
--- a/test/hotspot/gtest/memory/test_chunkManager.cpp
+++ /dev/null
@@ -1,69 +0,0 @@
-/*
- * Copyright (c) 2016, 2018, Oracle and/or its affiliates. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- */
-
-#include "precompiled.hpp"
-#include "memory/metaspace/chunkManager.hpp"
-#include "memory/metaspace/metaspaceCommon.hpp"
-
-// The test function is only available in debug builds
-#ifdef ASSERT
-
-#include "unittest.hpp"
-
-using namespace metaspace;
-
-TEST(ChunkManager, list_index) {
-
-  // Test previous bug where a query for a humongous class metachunk,
-  // incorrectly matched the non-class medium metachunk size.
-  {
-    ChunkManager manager(true);
-
-    ASSERT_TRUE(MediumChunk > ClassMediumChunk) << "Precondition for test";
-
-    ChunkIndex index = manager.list_index(MediumChunk);
-
-    ASSERT_TRUE(index == HumongousIndex) <<
-        "Requested size is larger than ClassMediumChunk,"
-        " so should return HumongousIndex. Got index: " << index;
-  }
-
-  // Check the specified sizes as well.
-  {
-    ChunkManager manager(true);
-    ASSERT_TRUE(manager.list_index(ClassSpecializedChunk) == SpecializedIndex);
-    ASSERT_TRUE(manager.list_index(ClassSmallChunk) == SmallIndex);
-    ASSERT_TRUE(manager.list_index(ClassMediumChunk) == MediumIndex);
-    ASSERT_TRUE(manager.list_index(ClassMediumChunk + ClassSpecializedChunk) == HumongousIndex);
-  }
-  {
-    ChunkManager manager(false);
-    ASSERT_TRUE(manager.list_index(SpecializedChunk) == SpecializedIndex);
-    ASSERT_TRUE(manager.list_index(SmallChunk) == SmallIndex);
-    ASSERT_TRUE(manager.list_index(MediumChunk) == MediumIndex);
-    ASSERT_TRUE(manager.list_index(MediumChunk + SpecializedChunk) == HumongousIndex);
-  }
-
-}
-
-#endif // ASSERT
diff --git a/test/hotspot/gtest/memory/test_is_metaspace_obj.cpp b/test/hotspot/gtest/memory/test_is_metaspace_obj.cpp
deleted file mode 100644
--- a/test/hotspot/gtest/memory/test_is_metaspace_obj.cpp
+++ /dev/null
@@ -1,115 +0,0 @@
-/*
- * Copyright (c) 2016, 2018, Oracle and/or its affiliates. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- */
-
-#include "precompiled.hpp"
-#include "memory/allocation.inline.hpp"
-#include "memory/metaspace.hpp"
-#include "memory/metaspace/virtualSpaceList.hpp"
-#include "runtime/mutex.hpp"
-#include "runtime/mutexLocker.hpp"
-#include "runtime/os.hpp"
-#include "unittest.hpp"
-
-using namespace metaspace;
-
-
-// Test the cheerful multitude of metaspace-contains-functions.
-class MetaspaceIsMetaspaceObjTest : public ::testing::Test {
-  Mutex* _lock;
-  ClassLoaderMetaspace* _ms;
-
-public:
-
-  MetaspaceIsMetaspaceObjTest() : _lock(NULL), _ms(NULL) {}
-
-  virtual void SetUp() {
-  }
-
-  virtual void TearDown() {
-    delete _ms;
-    delete _lock;
-  }
-
-  void do_test(Metaspace::MetadataType mdType) {
-    _lock = new Mutex(Monitor::native, "gtest-IsMetaspaceObjTest-lock", false, Monitor::_safepoint_check_never);
-    {
-      MutexLocker ml(_lock, Mutex::_no_safepoint_check_flag);
-      _ms = new ClassLoaderMetaspace(_lock, Metaspace::StandardMetaspaceType);
-    }
-
-    const MetaspaceObj* p = (MetaspaceObj*) _ms->allocate(42, mdType);
-
-    // Test MetaspaceObj::is_metaspace_object
-    ASSERT_TRUE(MetaspaceObj::is_valid(p));
-
-    // A misaligned object shall not be recognized
-    const MetaspaceObj* p_misaligned = (MetaspaceObj*)((address)p) + 1;
-    ASSERT_FALSE(MetaspaceObj::is_valid(p_misaligned));
-
-    // Test VirtualSpaceList::contains and find_enclosing_space
-    VirtualSpaceList* list = Metaspace::space_list();
-    if (mdType == Metaspace::ClassType && Metaspace::using_class_space()) {
-      list = Metaspace::class_space_list();
-    }
-    ASSERT_TRUE(list->contains(p));
-    VirtualSpaceNode* const n = list->find_enclosing_space(p);
-    ASSERT_TRUE(n != NULL);
-    ASSERT_TRUE(n->contains(p));
-
-    // A misaligned pointer shall be recognized by list::contains
-    ASSERT_TRUE(list->contains((address)p) + 1);
-
-    // Now for some bogus values
-    ASSERT_FALSE(MetaspaceObj::is_valid((MetaspaceObj*)NULL));
-
-    // Should exercise various paths in MetaspaceObj::is_valid()
-    ASSERT_FALSE(MetaspaceObj::is_valid((MetaspaceObj*)1024));
-    ASSERT_FALSE(MetaspaceObj::is_valid((MetaspaceObj*)8192));
-
-    MetaspaceObj* p_stack = (MetaspaceObj*) &_lock;
-    ASSERT_FALSE(MetaspaceObj::is_valid(p_stack));
-
-    MetaspaceObj* p_heap = (MetaspaceObj*) os::malloc(41, mtInternal);
-    ASSERT_FALSE(MetaspaceObj::is_valid(p_heap));
-    os::free(p_heap);
-
-    // Test Metaspace::contains_xxx
-    ASSERT_TRUE(Metaspace::contains(p));
-    ASSERT_TRUE(Metaspace::contains_non_shared(p));
-
-    delete _ms;
-    _ms = NULL;
-    delete _lock;
-    _lock = NULL;
-  }
-
-};
-
-TEST_VM_F(MetaspaceIsMetaspaceObjTest, non_class_space) {
-  do_test(Metaspace::NonClassType);
-}
-
-TEST_VM_F(MetaspaceIsMetaspaceObjTest, class_space) {
-  do_test(Metaspace::ClassType);
-}
-
diff --git a/test/hotspot/gtest/memory/test_metachunk.cpp b/test/hotspot/gtest/memory/test_metachunk.cpp
deleted file mode 100644
--- a/test/hotspot/gtest/memory/test_metachunk.cpp
+++ /dev/null
@@ -1,98 +0,0 @@
-/*
- * Copyright (c) 2016, 2018, Oracle and/or its affiliates. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- */
-
-#include "precompiled.hpp"
-#include "memory/allocation.hpp"
-#include "memory/metaspace/metachunk.hpp"
-#include "unittest.hpp"
-#include "utilities/align.hpp"
-#include "utilities/copy.hpp"
-#include "utilities/debug.hpp"
-
-using namespace metaspace;
-
-class MetachunkTest {
- public:
-  static MetaWord* initial_top(Metachunk* metachunk) {
-    return metachunk->initial_top();
-  }
-  static MetaWord* top(Metachunk* metachunk) {
-    return metachunk->top();
-  }
-
-};
-
-TEST(Metachunk, basic) {
-  const ChunkIndex chunk_type = MediumIndex;
-  const bool is_class = false;
-  const size_t word_size = get_size_for_nonhumongous_chunktype(chunk_type, is_class);
-  // Allocate the chunk with correct alignment.
-  void* memory = malloc(word_size * BytesPerWord * 2);
-  ASSERT_TRUE(NULL != memory) << "Failed to malloc 2MB";
-
-  void* p_placement = align_up(memory, word_size * BytesPerWord);
-
-  Metachunk* metachunk = ::new (p_placement) Metachunk(chunk_type, is_class, word_size, NULL);
-
-  EXPECT_EQ((MetaWord*) metachunk, metachunk->bottom());
-  EXPECT_EQ((uintptr_t*) metachunk + metachunk->size(), metachunk->end());
-
-  // Check sizes
-  EXPECT_EQ(metachunk->size(), metachunk->word_size());
-  EXPECT_EQ(pointer_delta(metachunk->end(), metachunk->bottom(),
-                          sizeof (MetaWord)),
-            metachunk->word_size());
-
-  // Check usage
-  EXPECT_EQ(metachunk->used_word_size(), metachunk->overhead());
-  EXPECT_EQ(metachunk->word_size() - metachunk->used_word_size(),
-            metachunk->free_word_size());
-  EXPECT_EQ(MetachunkTest::top(metachunk), MetachunkTest::initial_top(metachunk));
-  EXPECT_TRUE(metachunk->is_empty());
-
-  // Allocate
-  size_t alloc_size = 64; // Words
-  EXPECT_TRUE(is_aligned(alloc_size, Metachunk::object_alignment()));
-
-  MetaWord* mem = metachunk->allocate(alloc_size);
-
-  // Check post alloc
-  EXPECT_EQ(MetachunkTest::initial_top(metachunk), mem);
-  EXPECT_EQ(MetachunkTest::top(metachunk), mem + alloc_size);
-  EXPECT_EQ(metachunk->overhead() + alloc_size, metachunk->used_word_size());
-  EXPECT_EQ(metachunk->word_size() - metachunk->used_word_size(),
-            metachunk->free_word_size());
-  EXPECT_FALSE(metachunk->is_empty());
-
-  // Clear chunk
-  metachunk->reset_empty();
-
-  // Check post clear
-  EXPECT_EQ(metachunk->used_word_size(), metachunk->overhead());
-  EXPECT_EQ(metachunk->word_size() - metachunk->used_word_size(),
-            metachunk->free_word_size());
-  EXPECT_EQ(MetachunkTest::top(metachunk), MetachunkTest::initial_top(metachunk));
-  EXPECT_TRUE(metachunk->is_empty());
-
-  free(memory);
-}
diff --git a/test/hotspot/gtest/memory/test_metaspace.cpp b/test/hotspot/gtest/memory/test_metaspace.cpp
deleted file mode 100644
--- a/test/hotspot/gtest/memory/test_metaspace.cpp
+++ /dev/null
@@ -1,86 +0,0 @@
-/*
- * Copyright (c) 2018, 2019, Oracle and/or its affiliates. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- */
-
-#include "precompiled.hpp"
-#include "memory/metaspace.hpp"
-#include "memory/metaspace/virtualSpaceList.hpp"
-#include "runtime/mutexLocker.hpp"
-#include "runtime/os.hpp"
-#include "unittest.hpp"
-
-using namespace metaspace;
-
-TEST_VM(MetaspaceUtils, reserved) {
-  size_t reserved = MetaspaceUtils::reserved_bytes();
-  EXPECT_GT(reserved, 0UL);
-
-  size_t reserved_metadata = MetaspaceUtils::reserved_bytes(Metaspace::NonClassType);
-  EXPECT_GT(reserved_metadata, 0UL);
-  EXPECT_LE(reserved_metadata, reserved);
-}
-
-TEST_VM(MetaspaceUtils, reserved_compressed_class_pointers) {
-  if (!UseCompressedClassPointers) {
-    return;
-  }
-  size_t reserved = MetaspaceUtils::reserved_bytes();
-  EXPECT_GT(reserved, 0UL);
-
-  size_t reserved_class = MetaspaceUtils::reserved_bytes(Metaspace::ClassType);
-  EXPECT_GT(reserved_class, 0UL);
-  EXPECT_LE(reserved_class, reserved);
-}
-
-TEST_VM(MetaspaceUtils, committed) {
-  size_t committed = MetaspaceUtils::committed_bytes();
-  EXPECT_GT(committed, 0UL);
-
-  size_t reserved  = MetaspaceUtils::reserved_bytes();
-  EXPECT_LE(committed, reserved);
-
-  size_t committed_metadata = MetaspaceUtils::committed_bytes(Metaspace::NonClassType);
-  EXPECT_GT(committed_metadata, 0UL);
-  EXPECT_LE(committed_metadata, committed);
-}
-
-TEST_VM(MetaspaceUtils, committed_compressed_class_pointers) {
-  if (!UseCompressedClassPointers) {
-    return;
-  }
-  size_t committed = MetaspaceUtils::committed_bytes();
-  EXPECT_GT(committed, 0UL);
-
-  size_t committed_class = MetaspaceUtils::committed_bytes(Metaspace::ClassType);
-  EXPECT_GT(committed_class, 0UL);
-  EXPECT_LE(committed_class, committed);
-}
-
-TEST_VM(MetaspaceUtils, virtual_space_list_large_chunk) {
-  VirtualSpaceList* vs_list = new VirtualSpaceList(os::vm_allocation_granularity());
-  MutexLocker cl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
-  // A size larger than VirtualSpaceSize (256k) and add one page to make it _not_ be
-  // vm_allocation_granularity aligned on Windows.
-  size_t large_size = (size_t)(2*256*K + (os::vm_page_size() / BytesPerWord));
-  large_size += (os::vm_page_size() / BytesPerWord);
-  vs_list->get_new_chunk(large_size, 0);
-}
diff --git a/test/hotspot/gtest/memory/test_metaspace_allocation.cpp b/test/hotspot/gtest/memory/test_metaspace_allocation.cpp
deleted file mode 100644
--- a/test/hotspot/gtest/memory/test_metaspace_allocation.cpp
+++ /dev/null
@@ -1,273 +0,0 @@
-/*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, SAP.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- */
-
-#include "precompiled.hpp"
-#include "memory/allocation.inline.hpp"
-#include "memory/metaspace.hpp"
-#include "runtime/mutex.hpp"
-#include "runtime/mutexLocker.hpp"
-#include "runtime/os.hpp"
-#include "utilities/align.hpp"
-#include "utilities/debug.hpp"
-#include "utilities/globalDefinitions.hpp"
-#include "utilities/ostream.hpp"
-#include "unittest.hpp"
-
-#define NUM_PARALLEL_METASPACES                 50
-#define MAX_PER_METASPACE_ALLOCATION_WORDSIZE   (512 * K)
-
-//#define DEBUG_VERBOSE true
-
-#ifdef DEBUG_VERBOSE
-
-struct chunkmanager_statistics_t {
-  int num_specialized_chunks;
-  int num_small_chunks;
-  int num_medium_chunks;
-  int num_humongous_chunks;
-};
-
-extern void test_metaspace_retrieve_chunkmanager_statistics(Metaspace::MetadataType mdType, chunkmanager_statistics_t* out);
-
-static void print_chunkmanager_statistics(outputStream* st, Metaspace::MetadataType mdType) {
-  chunkmanager_statistics_t stat;
-  test_metaspace_retrieve_chunkmanager_statistics(mdType, &stat);
-  st->print_cr("free chunks: %d / %d / %d / %d", stat.num_specialized_chunks, stat.num_small_chunks,
-               stat.num_medium_chunks, stat.num_humongous_chunks);
-}
-
-#endif
-
-struct chunk_geometry_t {
-  size_t specialized_chunk_word_size;
-  size_t small_chunk_word_size;
-  size_t medium_chunk_word_size;
-};
-
-extern void test_metaspace_retrieve_chunk_geometry(Metaspace::MetadataType mdType, chunk_geometry_t* out);
-
-
-class MetaspaceAllocationTest : public ::testing::Test {
-protected:
-
-  struct {
-    size_t allocated;
-    Mutex* lock;
-    ClassLoaderMetaspace* space;
-    bool is_empty() const { return allocated == 0; }
-    bool is_full() const { return allocated >= MAX_PER_METASPACE_ALLOCATION_WORDSIZE; }
-  } _spaces[NUM_PARALLEL_METASPACES];
-
-  chunk_geometry_t _chunk_geometry;
-
-  virtual void SetUp() {
-    ::memset(_spaces, 0, sizeof(_spaces));
-    test_metaspace_retrieve_chunk_geometry(Metaspace::NonClassType, &_chunk_geometry);
-  }
-
-  virtual void TearDown() {
-    for (int i = 0; i < NUM_PARALLEL_METASPACES; i ++) {
-      if (_spaces[i].space != NULL) {
-        delete _spaces[i].space;
-        delete _spaces[i].lock;
-      }
-    }
-  }
-
-  void create_space(int i) {
-    assert(i >= 0 && i < NUM_PARALLEL_METASPACES, "Sanity");
-    assert(_spaces[i].space == NULL && _spaces[i].allocated == 0, "Sanity");
-    if (_spaces[i].lock == NULL) {
-      _spaces[i].lock = new Mutex(Monitor::native, "gtest-MetaspaceAllocationTest-lock", false, Monitor::_safepoint_check_never);
-      ASSERT_TRUE(_spaces[i].lock != NULL);
-    }
-    // Let every ~10th space be a short-lived one to test different allocation patterns.
-    const Metaspace::MetaspaceType msType = (os::random() % 100 < 10) ?
-      Metaspace::ClassMirrorHolderMetaspaceType : Metaspace::StandardMetaspaceType;
-    {
-      // Pull lock during space creation, since this is what happens in the VM too
-      // (see ClassLoaderData::metaspace_non_null(), which we mimick here).
-      MutexLocker ml(_spaces[i].lock,  Mutex::_no_safepoint_check_flag);
-      _spaces[i].space = new ClassLoaderMetaspace(_spaces[i].lock, msType);
-    }
-    _spaces[i].allocated = 0;
-    ASSERT_TRUE(_spaces[i].space != NULL);
-  }
-
-  // Returns the index of a random space where index is [0..metaspaces) and which is
-  //   empty, non-empty or full.
-  // Returns -1 if no matching space exists.
-  enum fillgrade { fg_empty, fg_non_empty, fg_full };
-  int get_random_matching_space(int metaspaces, fillgrade fg) {
-    const int start_index = os::random() % metaspaces;
-    int i = start_index;
-    do {
-      if (fg == fg_empty && _spaces[i].is_empty()) {
-        return i;
-      } else if ((fg == fg_full && _spaces[i].is_full()) ||
-                 (fg == fg_non_empty && !_spaces[i].is_full() && !_spaces[i].is_empty())) {
-        return i;
-      }
-      i ++;
-      if (i == metaspaces) {
-        i = 0;
-      }
-    } while (i != start_index);
-    return -1;
-  }
-
-  int get_random_emtpy_space(int metaspaces) { return get_random_matching_space(metaspaces, fg_empty); }
-  int get_random_non_emtpy_space(int metaspaces) { return get_random_matching_space(metaspaces, fg_non_empty); }
-  int get_random_full_space(int metaspaces) { return get_random_matching_space(metaspaces, fg_full); }
-
-  void do_test(Metaspace::MetadataType mdType, int metaspaces, int phases, int allocs_per_phase,
-               float probability_for_large_allocations // 0.0-1.0
-  ) {
-    // Alternate between breathing in (allocating n blocks for a random Metaspace) and
-    // breathing out (deleting a random Metaspace). The intent is to stress the coalescation
-    // and splitting of free chunks.
-    int phases_done = 0;
-    bool allocating = true;
-    while (phases_done < phases) {
-      bool force_switch = false;
-      if (allocating) {
-        // Allocate space from metaspace, with a preference for completely empty spaces. This
-        // should provide a good mixture of metaspaces in the virtual space.
-        int index = get_random_emtpy_space(metaspaces);
-        if (index == -1) {
-          index = get_random_non_emtpy_space(metaspaces);
-        }
-        if (index == -1) {
-          // All spaces are full, switch to freeing.
-          force_switch = true;
-        } else {
-          // create space if it does not yet exist.
-          if (_spaces[index].space == NULL) {
-            create_space(index);
-          }
-          // Allocate a bunch of blocks from it. Mostly small stuff but mix in large allocations
-          //  to force humongous chunk allocations.
-          int allocs_done = 0;
-          while (allocs_done < allocs_per_phase && !_spaces[index].is_full()) {
-            size_t size = 0;
-            int r = os::random() % 1000;
-            if ((float)r < probability_for_large_allocations * 1000.0) {
-              size = (os::random() % _chunk_geometry.medium_chunk_word_size) + _chunk_geometry.medium_chunk_word_size;
-            } else {
-              size = os::random() % 64;
-            }
-            // Note: In contrast to space creation, no need to lock here. ClassLoaderMetaspace::allocate() will lock itself.
-            MetaWord* const p = _spaces[index].space->allocate(size, mdType);
-            if (p == NULL) {
-              // We very probably did hit the metaspace "until-gc" limit.
-#ifdef DEBUG_VERBOSE
-              tty->print_cr("OOM for " SIZE_FORMAT " words. ", size);
-#endif
-              // Just switch to deallocation and resume tests.
-              force_switch = true;
-              break;
-            } else {
-              _spaces[index].allocated += size;
-              allocs_done ++;
-            }
-          }
-        }
-      } else {
-        // freeing: find a metaspace and delete it, with preference for completely filled spaces.
-        int index = get_random_full_space(metaspaces);
-        if (index == -1) {
-          index = get_random_non_emtpy_space(metaspaces);
-        }
-        if (index == -1) {
-          force_switch = true;
-        } else {
-          assert(_spaces[index].space != NULL && _spaces[index].allocated > 0, "Sanity");
-          // Note: do not lock here. In the "wild" (the VM), we do not so either (see ~ClassLoaderData()).
-          delete _spaces[index].space;
-          _spaces[index].space = NULL;
-          _spaces[index].allocated = 0;
-        }
-      }
-
-      if (force_switch) {
-        allocating = !allocating;
-      } else {
-        // periodically switch between allocating and freeing, but prefer allocation because
-        // we want to intermingle allocations of multiple metaspaces.
-        allocating = os::random() % 5 < 4;
-      }
-      phases_done ++;
-#ifdef DEBUG_VERBOSE
-      int metaspaces_in_use = 0;
-      size_t total_allocated = 0;
-      for (int i = 0; i < metaspaces; i ++) {
-        if (_spaces[i].allocated > 0) {
-          total_allocated += _spaces[i].allocated;
-          metaspaces_in_use ++;
-        }
-      }
-      tty->print("%u:\tspaces: %d total words: " SIZE_FORMAT "\t\t\t", phases_done, metaspaces_in_use, total_allocated);
-      print_chunkmanager_statistics(tty, mdType);
-#endif
-    }
-#ifdef DEBUG_VERBOSE
-    tty->print_cr("Test finished. ");
-    MetaspaceUtils::print_metaspace_map(tty, mdType);
-    print_chunkmanager_statistics(tty, mdType);
-#endif
-  }
-};
-
-
-
-TEST_F(MetaspaceAllocationTest, chunk_geometry) {
-  ASSERT_GT(_chunk_geometry.specialized_chunk_word_size, (size_t) 0);
-  ASSERT_GT(_chunk_geometry.small_chunk_word_size, _chunk_geometry.specialized_chunk_word_size);
-  ASSERT_EQ(_chunk_geometry.small_chunk_word_size % _chunk_geometry.specialized_chunk_word_size, (size_t)0);
-  ASSERT_GT(_chunk_geometry.medium_chunk_word_size, _chunk_geometry.small_chunk_word_size);
-  ASSERT_EQ(_chunk_geometry.medium_chunk_word_size % _chunk_geometry.small_chunk_word_size, (size_t)0);
-}
-
-
-TEST_VM_F(MetaspaceAllocationTest, single_space_nonclass) {
-  do_test(Metaspace::NonClassType, 1, 1000, 100, 0);
-}
-
-TEST_VM_F(MetaspaceAllocationTest, single_space_class) {
-  do_test(Metaspace::ClassType, 1, 1000, 100, 0);
-}
-
-TEST_VM_F(MetaspaceAllocationTest, multi_space_nonclass) {
-  do_test(Metaspace::NonClassType, NUM_PARALLEL_METASPACES, 100, 1000, 0.0);
-}
-
-TEST_VM_F(MetaspaceAllocationTest, multi_space_class) {
-  do_test(Metaspace::ClassType, NUM_PARALLEL_METASPACES, 100, 1000, 0.0);
-}
-
-TEST_VM_F(MetaspaceAllocationTest, multi_space_nonclass_2) {
-  // many metaspaces, with humongous chunks mixed in.
-  do_test(Metaspace::NonClassType, NUM_PARALLEL_METASPACES, 100, 1000, .006f);
-}
-
diff --git a/test/hotspot/gtest/memory/test_spaceManager.cpp b/test/hotspot/gtest/memory/test_spaceManager.cpp
deleted file mode 100644
--- a/test/hotspot/gtest/memory/test_spaceManager.cpp
+++ /dev/null
@@ -1,74 +0,0 @@
-/*
- * Copyright (c) 2016, Oracle and/or its affiliates. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- */
-
-#include "precompiled.hpp"
-#include "memory/metaspace/spaceManager.hpp"
-
-using metaspace::SpaceManager;
-
-// The test function is only available in debug builds
-#ifdef ASSERT
-
-#include "unittest.hpp"
-
-
-static void test_adjust_initial_chunk_size(bool is_class) {
-  const size_t smallest = SpaceManager::smallest_chunk_size(is_class);
-  const size_t normal   = SpaceManager::small_chunk_size(is_class);
-  const size_t medium   = SpaceManager::medium_chunk_size(is_class);
-
-#define do_test(value, expected, is_class_value)                                 \
-    do {                                                                         \
-      size_t v = value;                                                          \
-      size_t e = expected;                                                       \
-      assert(SpaceManager::adjust_initial_chunk_size(v, (is_class_value)) == e,  \
-             "Expected: " SIZE_FORMAT " got: " SIZE_FORMAT, e, v);               \
-    } while (0)
-
-    // Smallest (specialized)
-    do_test(1,            smallest, is_class);
-    do_test(smallest - 1, smallest, is_class);
-    do_test(smallest,     smallest, is_class);
-
-    // Small
-    do_test(smallest + 1, normal, is_class);
-    do_test(normal - 1,   normal, is_class);
-    do_test(normal,       normal, is_class);
-
-    // Medium
-    do_test(normal + 1, medium, is_class);
-    do_test(medium - 1, medium, is_class);
-    do_test(medium,     medium, is_class);
-
-    // Humongous
-    do_test(medium + 1, medium + 1, is_class);
-
-#undef test_adjust_initial_chunk_size
-}
-
-TEST(SpaceManager, adjust_initial_chunk_size) {
-  test_adjust_initial_chunk_size(true);
-  test_adjust_initial_chunk_size(false);
-}
-
-#endif // ASSERT
diff --git a/test/hotspot/gtest/memory/test_virtualspace.cpp b/test/hotspot/gtest/memory/test_virtualspace.cpp
--- a/test/hotspot/gtest/memory/test_virtualspace.cpp
+++ b/test/hotspot/gtest/memory/test_virtualspace.cpp
@@ -28,6 +28,7 @@
 #include "utilities/align.hpp"
 #include "unittest.hpp"
 
+
 namespace {
   class MemoryReleaser {
     ReservedSpace* const _rs;
@@ -337,3 +338,6 @@
   EXPECT_NO_FATAL_FAILURE(test_virtual_space_actual_committed_space(10 * M, 5 * M,  Commit));
   EXPECT_NO_FATAL_FAILURE(test_virtual_space_actual_committed_space(10 * M, 10 * M, Commit));
 }
+
+
+
diff --git a/test/hotspot/gtest/metaspace/metaspaceTestContexts.cpp b/test/hotspot/gtest/metaspace/metaspaceTestContexts.cpp
new file mode 100644
--- /dev/null
+++ b/test/hotspot/gtest/metaspace/metaspaceTestContexts.cpp
@@ -0,0 +1,173 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+
+#include "precompiled.hpp"
+#include "metaspace/metaspaceTestsCommon.hpp"
+#include "metaspace/metaspaceTestContexts.hpp"
+
+using namespace metaspace::chunklevel;
+
+
+void ChunkTestsContext::checked_alloc_chunk_0(Metachunk** p_return_value, chunklevel_t preferred_level, chunklevel_t max_level,
+                                                      size_t min_committed_size) {
+
+  *p_return_value = NULL;
+
+  Metachunk* c = cm().get_chunk(preferred_level, max_level, min_committed_size);
+
+  if (c != NULL) {
+
+    ASSERT_LE(c->level(), max_level);
+    ASSERT_GE(c->level(), preferred_level);
+    ASSERT_GE(c->committed_words(), min_committed_size);
+    ASSERT_EQ(c->committed_words(), c->free_below_committed_words());
+    ASSERT_EQ(c->used_words(), (size_t)0);
+    ASSERT_TRUE(c->is_in_use());
+    ASSERT_FALSE(c->is_free());
+    ASSERT_FALSE(c->is_dead());
+    ASSERT_NULL(c->next());
+    ASSERT_NULL(c->prev());
+    if (c->level() == HIGHEST_CHUNK_LEVEL) {
+      ASSERT_TRUE(c->is_leaf_chunk());
+    } else {
+      ASSERT_FALSE(c->is_leaf_chunk());
+    }
+    if (c->level() == LOWEST_CHUNK_LEVEL) {
+      ASSERT_TRUE(c->is_root_chunk());
+    } else {
+      ASSERT_FALSE(c->is_root_chunk());
+    }
+    if (_num_chunks_allocated == 0) { // First chunk? We can make more assumptions
+      ASSERT_EQ(c->level(), preferred_level);
+      // Needs lock EXPECT_NULL(c->next_in_vs());
+      // Needs lock EXPECT_NULL(c->prev_in_vs());
+      ASSERT_TRUE(c->is_root_chunk() || c->is_leader());
+    }
+    _num_chunks_allocated ++;
+
+  }
+
+  *p_return_value = c;
+
+}
+
+// Test pattern established when allocating from the chunk with allocate_from_chunk_with_tests().
+void ChunkTestsContext::test_pattern(Metachunk* c, size_t word_size) {
+  check_range_for_pattern(c->base(), word_size, (uintx)c);
+}
+
+void ChunkTestsContext::return_chunk(Metachunk* c) {
+  test_pattern(c);
+  c->set_in_use(); // Forestall assert in cm
+  cm().return_chunk(c);
+}
+
+ void ChunkTestsContext::allocate_from_chunk(MetaWord** p_return_value, Metachunk* c, size_t word_size) {
+
+  size_t used_before = c->used_words();
+  size_t free_before = c->free_words();
+  size_t free_below_committed_before = c->free_below_committed_words();
+  const MetaWord* top_before = c->top();
+
+  MetaWord* p = c->allocate(word_size);
+  EXPECT_NOT_NULL(p);
+  EXPECT_EQ(c->used_words(), used_before + word_size);
+  EXPECT_EQ(c->free_words(), free_before - word_size);
+  EXPECT_EQ(c->free_below_committed_words(), free_below_committed_before - word_size);
+  EXPECT_EQ(c->top(), top_before + word_size);
+
+  // Old content should be preserved
+  test_pattern(c, used_before);
+
+  // Fill newly allocated range too
+  fill_range_with_pattern(p, word_size, (uintx)c);
+
+  *p_return_value = p;
+}
+
+void ChunkTestsContext::commit_chunk_with_test(Metachunk* c, size_t additional_size) {
+
+  size_t used_before = c->used_words();
+  size_t free_before = c->free_words();
+  const MetaWord* top_before = c->top();
+
+  c->set_in_use();
+  bool b = c->ensure_committed_additional(additional_size);
+  EXPECT_TRUE(b);
+
+  // We should have enough committed size now
+  EXPECT_GE(c->free_below_committed_words(), additional_size);
+
+  // used, free, top should be unchanged.
+  EXPECT_EQ(c->used_words(), used_before);
+  EXPECT_EQ(c->free_words(), free_before);
+  EXPECT_EQ(c->top(), top_before);
+
+  test_pattern(c, used_before);
+
+}
+
+void ChunkTestsContext::commit_chunk_expect_failure(Metachunk* c, size_t additional_size) {
+
+  size_t used_before = c->used_words();
+  size_t free_before = c->free_words();
+  size_t free_below_committed_before = c->free_below_committed_words();
+  const MetaWord* top_before = c->top();
+
+  c->set_in_use();
+  bool b = c->ensure_committed_additional(additional_size);
+  EXPECT_FALSE(b);
+
+  // Nothing should have changed
+  EXPECT_EQ(c->used_words(), used_before);
+  EXPECT_EQ(c->free_words(), free_before);
+  EXPECT_EQ(c->free_below_committed_words(), free_below_committed_before);
+  EXPECT_EQ(c->top(), top_before);
+
+  test_pattern(c, used_before);
+
+}
+
+void ChunkTestsContext::uncommit_chunk_with_test(Metachunk* c) {
+  if (c->word_size() >= Settings::commit_granule_words()) {
+    c->set_free();  // Forestall assert in uncommit
+    c->reset_used_words();
+    c->uncommit();
+
+    EXPECT_EQ(c->free_below_committed_words(), (size_t)0);
+    EXPECT_EQ(c->used_words(), (size_t)0);
+    EXPECT_EQ(c->free_words(), c->word_size());
+    EXPECT_EQ(c->top(), c->base());
+    EXPECT_TRUE(c->is_fully_uncommitted());
+  }
+}
+
+
+
+/////// SparseArray<T> ////////////////
+
+
+
diff --git a/test/hotspot/gtest/metaspace/metaspaceTestContexts.hpp b/test/hotspot/gtest/metaspace/metaspaceTestContexts.hpp
new file mode 100644
--- /dev/null
+++ b/test/hotspot/gtest/metaspace/metaspaceTestContexts.hpp
@@ -0,0 +1,123 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#ifndef GTEST_METASPACE_METASPACE_TESTHELPER_HPP
+#define GTEST_METASPACE_METASPACE_TESTHELPER_HPP
+
+#include "memory/allocation.hpp"
+#include "metaspace/metaspaceTestsCommon.hpp"
+
+using namespace metaspace::chunklevel;
+
+class MetaspaceTestContext : public metaspace::MetaspaceTestContext {
+public:
+  MetaspaceTestContext(size_t commit_limit = 0, size_t reserve_limit = 0)
+  : metaspace::MetaspaceTestContext("gtest-metaspace-context", commit_limit, reserve_limit)
+  {}
+};
+
+class ChunkTestsContext : public metaspace::MetaspaceTestContext {
+
+  int _num_chunks_allocated;
+
+  void checked_alloc_chunk_0(Metachunk** p_return_value, chunklevel_t preferred_level,
+                             chunklevel_t max_level, size_t min_committed_size);
+
+  // Test pattern established when allocating from the chunk with allocate_from_chunk_with_tests().
+  void test_pattern(Metachunk* c, size_t word_size);
+  void test_pattern(Metachunk* c) { test_pattern(c, c->used_words()); }
+
+public:
+
+  ChunkTestsContext(size_t commit_limit = 0, size_t reserve_limit = 0)
+    : metaspace::MetaspaceTestContext("metaspace-gtest-chunktestcontext", commit_limit, reserve_limit),
+      _num_chunks_allocated(0)
+  {}
+
+  /////
+
+  // Note: all test functions return void and return values are by pointer ref; this is awkward but otherwise we cannot
+  // use gtest ASSERT macros inside those functions.
+
+  // Allocate a chunk (you do not know if it will succeed).
+  void alloc_chunk(Metachunk** p_return_value, chunklevel_t preferred_level, chunklevel_t max_level, size_t min_committed_size) {
+    checked_alloc_chunk_0(p_return_value, preferred_level, max_level, min_committed_size);
+  }
+
+  // Allocate a chunk; do not expect success, but if it succeeds, test the chunk.
+  void alloc_chunk(Metachunk** p_return_value, chunklevel_t level) {
+    alloc_chunk(p_return_value, level, level, word_size_for_level(level));
+  }
+
+  // Allocate a chunk; it must succeed. Test the chunk.
+  void alloc_chunk_expect_success(Metachunk** p_return_value, chunklevel_t preferred_level, chunklevel_t max_level, size_t min_committed_size) {
+    checked_alloc_chunk_0(p_return_value, preferred_level, max_level, min_committed_size);
+    ASSERT_NOT_NULL(*p_return_value);
+  }
+
+  // Allocate a chunk; it must succeed. Test the chunk.
+  void alloc_chunk_expect_success(Metachunk** p_return_value, chunklevel_t level) {
+    alloc_chunk_expect_success(p_return_value, level, level, word_size_for_level(level));
+  }
+
+  // Allocate a chunk but expect it to fail.
+  void alloc_chunk_expect_failure(chunklevel_t preferred_level, chunklevel_t max_level, size_t min_committed_size) {
+    Metachunk* c = NULL;
+    checked_alloc_chunk_0(&c, preferred_level, max_level, min_committed_size);
+    ASSERT_NULL(c);
+  }
+
+  // Allocate a chunk but expect it to fail.
+  void alloc_chunk_expect_failure(chunklevel_t level) {
+    return alloc_chunk_expect_failure(level, level, word_size_for_level(level));
+  }
+
+  /////
+
+  void return_chunk(Metachunk* c);
+
+  /////
+
+  // Allocates from a chunk; also, fills allocated area with test pattern which will be tested with test_pattern().
+  void allocate_from_chunk(MetaWord** p_return_value, Metachunk* c, size_t word_size);
+
+  // Convenience function: allocate from chunk for when you don't care for the result pointer
+  void allocate_from_chunk(Metachunk* c, size_t word_size) {
+    MetaWord* dummy;
+    allocate_from_chunk(&dummy, c, word_size);
+  }
+
+  void commit_chunk_with_test(Metachunk* c, size_t additional_size);
+  void commit_chunk_expect_failure(Metachunk* c, size_t additional_size);
+
+  void uncommit_chunk_with_test(Metachunk* c);
+
+
+};
+
+
+#endif // GTEST_METASPACE_METASPACE_TESTHELPER_HPP
+
+
diff --git a/test/hotspot/gtest/metaspace/metaspaceTestsCommon.cpp b/test/hotspot/gtest/metaspace/metaspaceTestsCommon.cpp
new file mode 100644
--- /dev/null
+++ b/test/hotspot/gtest/metaspace/metaspaceTestsCommon.cpp
@@ -0,0 +1,103 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+
+#include "metaspaceTestsCommon.hpp"
+#include "metaspace/metaspace_rangehelpers.hpp"
+
+#include "utilities/debug.hpp"
+#include "utilities/globalDefinitions.hpp"
+
+
+void zap_range(MetaWord* p, size_t word_size) {
+  for (MetaWord* pzap = p; pzap < p + word_size; pzap += os::vm_page_size() / BytesPerWord) {
+    *pzap = (MetaWord)NOT_LP64(0xFEFEFEFE) LP64_ONLY(0xFEFEFEFEEFEFEFEFULL);
+  }
+}
+
+// Writes a uniqe pattern to p
+void mark_address(MetaWord* p, uintx pattern) {
+  MetaWord x = (MetaWord)((uintx) p ^ pattern);
+  *p = x;
+}
+
+// checks pattern at address
+void check_marked_address(const MetaWord* p, uintx pattern) {
+  MetaWord x = (MetaWord)((uintx) p ^ pattern);
+  EXPECT_EQ(*p, x);
+}
+
+// "fill_range_with_pattern" fills a range of heap words with pointers to itself.
+//
+// The idea is to fill a memory range with a pattern which is both marked clearly to the caller
+// and cannot be moved without becoming invalid.
+//
+// The filled range can be checked with check_range_for_pattern. One also can only check
+// a sub range of the original range.
+void fill_range_with_pattern(MetaWord* p, size_t word_size, uintx pattern) {
+  assert(word_size > 0 && p != NULL, "sanity");
+  for (MetaWord* p2 = p; p2 < p + word_size; p2 ++) {
+    mark_address(p2, pattern);
+  }
+}
+
+void check_range_for_pattern(const MetaWord* p, size_t word_size, uintx pattern) {
+  assert(p != NULL, "sanity");
+  const MetaWord* p2 = p;
+  while (p2 < p + word_size) {
+    check_marked_address(p2, pattern);
+    p2 ++;
+  }
+}
+
+
+// Similar to fill_range_with_pattern, but only marks start and end. This is optimized for cases
+// where fill_range_with_pattern just is too slow.
+// Use check_marked_range to check the range. In contrast to check_range_for_pattern, only the original
+// range can be checked.
+void mark_range(MetaWord* p, size_t word_size, uintx pattern) {
+  assert(word_size > 0 && p != NULL, "sanity");
+  mark_address(p, pattern);
+  mark_address(p + word_size - 1, pattern);
+}
+
+void check_marked_range(const MetaWord* p, size_t word_size, uintx pattern) {
+  assert(word_size > 0 && p != NULL, "sanity");
+  check_marked_address(p, pattern);
+  check_marked_address(p + word_size - 1, pattern);
+}
+
+void mark_range(MetaWord* p, size_t word_size) {
+  assert(word_size > 0 && p != NULL, "sanity");
+  uintx pattern = (uintx)p2i(p);
+  mark_range(p, word_size, pattern);
+}
+
+void check_marked_range(const MetaWord* p, size_t word_size) {
+  uintx pattern = (uintx)p2i(p);
+  check_marked_range(p, word_size, pattern);
+}
+
diff --git a/test/hotspot/gtest/metaspace/metaspaceTestsCommon.hpp b/test/hotspot/gtest/metaspace/metaspaceTestsCommon.hpp
new file mode 100644
--- /dev/null
+++ b/test/hotspot/gtest/metaspace/metaspaceTestsCommon.hpp
@@ -0,0 +1,273 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#ifndef GTEST_METASPACE_METASPACETESTCOMMON_HPP
+#define GTEST_METASPACE_METASPACETESTCOMMON_HPP
+
+#include "memory/allocation.hpp"
+
+
+#include "memory/metaspace/arenaGrowthPolicy.hpp"
+#include "memory/metaspace/binlist.hpp"
+#include "memory/metaspace/blocktree.hpp"
+#include "memory/metaspace/chunkHeaderPool.hpp"
+#include "memory/metaspace/chunkLevel.hpp"
+#include "memory/metaspace/chunkManager.hpp"
+#include "memory/metaspace/counter.hpp"
+#include "memory/metaspace/commitLimiter.hpp"
+#include "memory/metaspace/commitMask.hpp"
+#include "memory/metaspace/freeBlocks.hpp"
+#include "memory/metaspace/freeChunkList.hpp"
+#include "memory/metaspace/internStat.hpp"
+#include "memory/metaspace/metachunk.hpp"
+#include "memory/metaspace/metaspaceArena.hpp"
+#include "memory/metaspace/metaspaceCommon.hpp"
+#include "memory/metaspace/metaspaceEnums.hpp"
+#include "memory/metaspace/metaspaceStatistics.hpp"
+#include "memory/metaspace/metaspace_test.hpp"
+#include "memory/metaspace/virtualSpaceList.hpp"
+#include "memory/metaspace/settings.hpp"
+#include "runtime/mutexLocker.hpp"
+#include "runtime/os.hpp"
+
+#include "utilities/align.hpp"
+#include "utilities/debug.hpp"
+#include "utilities/globalDefinitions.hpp"
+
+#include "unittest.hpp"
+
+
+#include <stdio.h>
+
+
+//////////////////////////////////////////////////////////
+// handy aliases
+
+using metaspace::BinListImpl;
+using metaspace::BlockTree;
+using metaspace::ArenaGrowthPolicy;
+using metaspace::ChunkHeaderPool;
+using metaspace::ChunkManager;
+using metaspace::CommitLimiter;
+using metaspace::CommitMask;
+using metaspace::SizeCounter;
+using metaspace::SizeAtomicCounter;
+using metaspace::IntCounter;
+using metaspace::FreeBlocks;
+using metaspace::FreeChunkList;
+using metaspace::FreeChunkListVector;
+using metaspace::MemRangeCounter;
+using metaspace::Metachunk;
+using metaspace::MetachunkList;
+using metaspace::Settings;
+using metaspace::arena_stats_t;
+using metaspace::in_use_chunk_stats_t;
+using metaspace::cm_stats_t;
+using metaspace::SizeCounter;
+using metaspace::MetaspaceArena;
+using metaspace::VirtualSpaceList;
+using metaspace::VirtualSpaceNode;
+
+using metaspace::chunklevel_t;
+using namespace metaspace::chunklevel;
+
+
+/////////////////////////////////////////////////////////////////////
+// A little mockup to mimick and test the CommitMask in various tests
+
+class TestMap {
+  const size_t _len;
+  char* _arr;
+public:
+  TestMap(size_t len) : _len(len), _arr(NULL) {
+    _arr = NEW_C_HEAP_ARRAY(char, len, mtInternal);
+    memset(_arr, 0, _len);
+  }
+  ~TestMap() { FREE_C_HEAP_ARRAY(char, _arr); }
+
+  int get_num_set(size_t from, size_t to) const {
+    int result = 0;
+    for(size_t i = from; i < to; i ++) {
+      if (_arr[i] > 0) {
+        result ++;
+      }
+    }
+    return result;
+  }
+
+  size_t get_num_set() const { return get_num_set(0, _len); }
+
+  void set_range(size_t from, size_t to) {
+    memset(_arr + from, 1, to - from);
+  }
+
+  void clear_range(size_t from, size_t to) {
+    memset(_arr + from, 0, to - from);
+  }
+
+  bool at(size_t pos) const {
+    return _arr[pos] == 1;
+  }
+
+};
+
+
+///////////////////////////////////////////////////////////
+// Helper class for generating random allocation sizes
+class RandSizeGenerator {
+  const size_t _min; // [
+  const size_t _max; // )
+  const float _outlier_chance; // 0.0 -- 1.0
+  const size_t _outlier_min; // [
+  const size_t _outlier_max; // )
+public:
+  RandSizeGenerator(size_t min, size_t max)
+    : _min(min), _max(max), _outlier_chance(0.0), _outlier_min(min), _outlier_max(max)
+  {}
+
+  RandSizeGenerator(size_t min, size_t max, float outlier_chance, size_t outlier_min, size_t outlier_max)
+    : _min(min), _max(max), _outlier_chance(outlier_chance), _outlier_min(outlier_min), _outlier_max(outlier_max)
+  {}
+
+  size_t min() const { return _min; }
+  size_t max() const { return _max; }
+
+  size_t get() const {
+    size_t l1 = _min;
+    size_t l2 = _max;
+    int r = os::random() % 1000;
+    if ((float)r < _outlier_chance * 1000.0) {
+      l1 = _outlier_min;
+      l2 = _outlier_max;
+    }
+    const size_t d = l2 - l1;
+    return l1 + (os::random() % d);
+  }
+
+}; // end RandSizeGenerator
+
+size_t get_random_size(size_t min, size_t max);
+
+///////////////////////////////////////////////////////////
+// Function to test-access a memory range
+
+void zap_range(MetaWord* p, size_t word_size);
+
+// "fill_range_with_pattern" fills a range of heap words with pointers to itself.
+//
+// The idea is to fill a memory range with a pattern which is both marked clearly to the caller
+// and cannot be moved without becoming invalid.
+//
+// The filled range can be checked with check_range_for_pattern. One also can only check
+// a sub range of the original range.
+void fill_range_with_pattern(MetaWord* p, uintx pattern, size_t word_size);
+void check_range_for_pattern(const MetaWord* p, uintx pattern, size_t word_size);
+
+// Writes a uniqe pattern to p
+void mark_address(MetaWord* p, uintx pattern);
+// checks pattern at address
+void check_marked_address(const MetaWord* p, uintx pattern);
+
+// Similar to fill_range_with_pattern, but only marks start and end. This is optimized for cases
+// where fill_range_with_pattern just is too slow.
+// Use check_marked_range to check the range. In contrast to check_range_for_pattern, only the original
+// range can be checked.
+void mark_range(MetaWord* p, uintx pattern, size_t word_size);
+void check_marked_range(const MetaWord* p, uintx pattern, size_t word_size);
+
+void mark_range(MetaWord* p, size_t word_size);
+void check_marked_range(const MetaWord* p, size_t word_size);
+
+//////////////////////////////////////////////////////////
+// Some helpers to avoid typing out those annoying casts for NULL
+
+#define ASSERT_NOT_NULL(ptr)      ASSERT_NE((void*)NULL, (void*)ptr)
+#define ASSERT_NULL(ptr)          ASSERT_EQ((void*)NULL, (void*)ptr)
+#define EXPECT_NOT_NULL(ptr)      EXPECT_NE((void*)NULL, (void*)ptr)
+#define EXPECT_NULL(ptr)          EXPECT_EQ((void*)NULL, (void*)ptr)
+
+#define ASSERT_0(v)               ASSERT_EQ((intptr_t)0, (intptr_t)v)
+#define ASSERT_NOT_0(v)           ASSERT_NE((intptr_t)0, (intptr_t)v)
+#define EXPECT_0(v)               EXPECT_EQ((intptr_t)0, (intptr_t)v)
+#define EXPECT_NOT_0(v)           EXPECT_NE((intptr_t)0, (intptr_t)v)
+
+//////////////////////////////////////////////////////////
+// logging
+
+// Define "LOG_PLEASE" to switch on logging for a particular test before inclusion of this header.
+#ifdef LOG_PLEASE
+  #define LOG(...) { printf(__VA_ARGS__); printf("\n"); fflush(stdout); }
+#else
+  #define LOG(...)
+#endif
+
+//////////////////////////////////////////////////////////
+// Helper
+
+size_t get_workingset_size();
+
+// A simple preallocated buffer used to "feed" someone.
+// Mimicks chunk retirement leftover blocks.
+class FeederBuffer {
+
+  MetaWord* _buf;
+
+  // Buffer capacity in size of words.
+  const size_t _cap;
+
+  // Used words.
+  size_t _used;
+
+public:
+
+  FeederBuffer(size_t size) : _buf(NULL), _cap(size), _used(0) {
+    _buf = NEW_C_HEAP_ARRAY(MetaWord, _cap, mtInternal);
+  }
+
+  ~FeederBuffer() {
+    FREE_C_HEAP_ARRAY(MetaWord, _buf);
+  }
+
+  MetaWord* get(size_t word_size) {
+    if (_used + word_size > _cap) {
+      return NULL;
+    }
+    MetaWord* p = _buf + _used;
+    _used += word_size;
+    return p;
+  }
+
+  bool is_valid_pointer(MetaWord* p) const {
+    return p >= _buf && p < _buf + _used;
+  }
+
+  bool is_valid_range(MetaWord* p, size_t word_size) const {
+    return is_valid_pointer(p) &&
+           word_size > 0 ? is_valid_pointer(p + word_size - 1) : true;
+  }
+
+};
+
+#endif // GTEST_METASPACE_METASPACETESTCOMMON_HPP
diff --git a/test/hotspot/gtest/metaspace/metaspace_rangehelpers.hpp b/test/hotspot/gtest/metaspace/metaspace_rangehelpers.hpp
new file mode 100644
--- /dev/null
+++ b/test/hotspot/gtest/metaspace/metaspace_rangehelpers.hpp
@@ -0,0 +1,186 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#ifndef GTEST_METASPACE_METASPACE_RANGEHELPERS_HPP
+#define GTEST_METASPACE_METASPACE_RANGEHELPERS_HPP
+
+// We use ranges-of-things in these tests a lot so some helpers help
+// keeping the code small.
+
+#include "memory/allocation.hpp"
+#include "memory/metaspace/chunkLevel.hpp"
+#include "runtime/os.hpp"
+#include "utilities/align.hpp"
+#include "utilities/debug.hpp"
+#include "utilities/globalDefinitions.hpp"
+
+
+using metaspace::chunklevel_t;
+using namespace metaspace::chunklevel;
+
+
+// A range of numerical values.
+template <typename T, typename Td>
+class Range : public StackObj {
+
+  // start and size of range
+  T   _start;
+  Td  _size;
+
+  static Td random_uncapped_offset() {
+    if (sizeof(Td) > 4) {
+      return (Td)((uint64_t)os::random() * os::random());
+    } else {
+      return (Td)os::random();
+    }
+  }
+
+protected:
+
+  static void swap_if_needed(T& lo, T& hi) {
+    if (lo > hi) {
+      T v = lo;
+      lo = hi;
+      hi = v;
+    }
+  }
+
+public:
+
+  // Lowest value in range
+  T lowest() const      { return _start; }
+
+  // Highest value in range (including)
+  T highest() const     { return _start + (_size - 1); }
+
+  T start() const       { return _start; }
+  T end() const         { return _start + _size; }
+
+  // Number of values in range
+  Td size() const       { return _size; }
+
+  bool is_empty() const { return size() == 0; }
+
+  bool contains(T v) const {
+    return v >= _start && v < end();
+  }
+
+  bool contains(Range<T, Td> r) const {
+    return contains(r.lowest()) && contains(r.highest());
+  }
+
+  // Create a range from [start, end)
+  Range(T start, T end) : _start(start), _size(end - start) {
+    assert(end >= start, "start and end reversed");
+  }
+
+  // a range with a given size, starting at 0
+  Range(Td size) : _start(0), _size(size) {}
+
+  // Return a random offset
+  Td random_offset() const {
+    assert(!is_empty(), "Range too small");
+    Td v = random_uncapped_offset() % size();
+    return v;
+  }
+
+  // Return a random value within the range
+  T random_value() const {
+    assert(!is_empty(), "Range too small");
+    T v = _start + random_offset();
+    assert(contains(v), "Sanity");
+    return v;
+  }
+
+  // Return the head of this range up to but excluding <split_point>
+  Range<T, Td> head(Td split_point) const {
+    assert(_size >= split_point, "Sanity");
+    return Range<T, Td>(_start, _start + split_point);
+  }
+
+  // Return the tail of this range, starting at <split_point>
+  Range<T, Td> tail(Td split_point) const {
+    assert(_size > split_point, "Sanity");
+    return Range<T, Td>(_start + split_point, end());
+  }
+
+  // Return a non-empty random sub range.
+  Range<T, Td> random_subrange() const {
+    assert(size() > 1, "Range too small");
+    Td sz = MAX2((Td)1, random_offset());
+    return random_sized_subrange(sz);
+  }
+
+  // Return a subrange of given size at a random start position
+  Range<T, Td> random_sized_subrange(Td subrange_size) const {
+    assert(subrange_size > 0 && subrange_size < _size, "invalid size");
+    T start = head(_size - subrange_size).random_value();
+    return Range<T, Td>(start, start + subrange_size);
+  }
+
+  //// aligned ranges ////
+
+  bool range_is_aligned(Td alignment) const {
+    return is_aligned(_size, alignment) && is_aligned(_start, alignment);
+  }
+
+  // Return a non-empty aligned random sub range.
+  Range<T, Td> random_aligned_subrange(Td alignment) const {
+    assert(alignment > 0, "Sanity");
+    assert(range_is_aligned(alignment), "Outer range needs to be aligned"); // to keep matters simple
+    assert(_size >= alignment, "Outer range too small.");
+    Td sz = MAX2((Td)1, random_offset());
+    sz = align_up(sz, alignment);
+    return random_aligned_sized_subrange(sz, alignment);
+  }
+
+  // Return a subrange of given size at a random aligned start position
+  Range<T, Td> random_aligned_sized_subrange(Td subrange_size, Td alignment) const {
+    assert(alignment > 0, "Sanity");
+    assert(range_is_aligned(alignment), "Outer range needs to be aligned"); // to keep matters simple
+    assert(subrange_size > 0 && subrange_size <= _size &&
+           is_aligned(subrange_size, alignment), "invalid subrange size");
+    if (_size == subrange_size) {
+      return *this;
+    }
+    T start = head(_size - subrange_size).random_value();
+    start = align_down(start, alignment);
+    return Range<T, Td>(start, start + subrange_size);
+  }
+
+};
+
+typedef Range<int, int> IntRange;
+typedef Range<size_t, size_t> SizeRange;
+typedef Range<chunklevel_t, int> ChunkLevelRange;
+
+struct ChunkLevelRanges : public AllStatic {
+  static ChunkLevelRange small_chunks()  { return ChunkLevelRange(CHUNK_LEVEL_32K, CHUNK_LEVEL_1K + 1); }
+  static ChunkLevelRange medium_chunks() { return ChunkLevelRange(CHUNK_LEVEL_512K, CHUNK_LEVEL_32K + 1); }
+  static ChunkLevelRange large_chunks()  { return ChunkLevelRange(CHUNK_LEVEL_4M, CHUNK_LEVEL_512K + 1); }
+  static ChunkLevelRange all_chunks()    { return ChunkLevelRange(CHUNK_LEVEL_4M, CHUNK_LEVEL_1K + 1); }
+};
+
+#endif // GTEST_METASPACE_METASPACE_RANGEHELPERS_HPP
diff --git a/test/hotspot/gtest/metaspace/metaspace_sparsearray.hpp b/test/hotspot/gtest/metaspace/metaspace_sparsearray.hpp
new file mode 100644
--- /dev/null
+++ b/test/hotspot/gtest/metaspace/metaspace_sparsearray.hpp
@@ -0,0 +1,166 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#ifndef GTEST_METASPACE_SPARSEARRAY_HPP
+#define GTEST_METASPACE_SPARSEARRAY_HPP
+
+#include "memory/allocation.hpp"
+#include "runtime/os.hpp"
+#include "metaspace/metaspaceTestsCommon.hpp"
+#include "metaspace/metaspace_rangehelpers.hpp"
+
+
+/////// SparseArray<T> ////////////////
+
+// Throughout these tests we need to keep track of allocated items (ranges of metaspace memory, metachunks, ..)
+//  and be able to random-access them. Makes sense to have a helper for that.
+template <class T>
+class SparseArray : public StackObj {
+
+  T* const _slots;
+  const int _num;
+
+  // For convenience: a range covering all possible slot indices.
+  const IntRange _index_range;
+
+  bool contains(int index) const {
+    return _index_range.contains(index);
+  }
+
+  // Check slot intex for oob
+  void check_index(int i) const {
+    assert(contains(i), "Sanity");
+  }
+
+  // Swap the content of two slots.
+  void swap(int i1, int i2) {
+    check_index(i1);
+    check_index(i2);
+    T tmp = _slots[i1];
+    _slots[i1] = _slots[i2];
+    _slots[i2] = tmp;
+  }
+
+  enum condition_t { cond_null = 0, cond_non_null = 1, cond_dontcare = 2 };
+
+  // Helper for next_matching_slot
+  bool slot_matches(int slot, condition_t c) const {
+    switch(c) {
+    case cond_null:     return _slots[slot] == NULL;
+    case cond_non_null: return _slots[slot] != NULL;
+    case cond_dontcare: return true;
+    }
+    ShouldNotReachHere();
+    return false;
+  }
+
+  // Starting at (including) index, find the next matching slot. Returns index or -1 if none found.
+  int next_matching_slot(int slot, condition_t c) const {
+    while(slot < _num) {
+      if (slot_matches(slot, c)) {
+        return slot;
+      }
+      slot ++;
+    }
+    return -1;
+  }
+
+public:
+
+  SparseArray(int num)
+    : _slots(NEW_C_HEAP_ARRAY(T, num, mtInternal)),
+      _num(num),
+      _index_range(num)
+  {
+    for (int i = 0; i < _num; i ++) {
+      _slots[i] = NULL;
+    }
+  }
+
+  T at(int i)              { return _slots[i]; }
+  const T at(int i) const  { return _slots[i]; }
+  void set_at(int i, T e)  { _slots[i] = e; }
+
+  int size() const         { return _num; }
+
+  bool slot_is_null(int i) const                      { check_index(i); return _slots[i] == NULL; }
+
+  DEBUG_ONLY(void check_slot_is_null(int i) const     { assert(slot_is_null(i), "Slot %d is not null", i); })
+  DEBUG_ONLY(void check_slot_is_not_null(int i) const { assert(!slot_is_null(i), "Slot %d is null", i); })
+
+  // Shuffle all elements randomly
+  void shuffle() {
+    for (int i = 0; i < _num; i ++) {
+      swap(i, random_slot_index());
+    }
+  }
+
+  // Reverse elements
+  void reverse() {
+    for (int i = 0; i < _num / 2; i ++) {
+      swap(i, _num - i);
+    }
+  }
+
+  int first_slot() const            { return 0; }
+  int next_slot(int index) const    { return index == _index_range.highest() ? -1 : index + 1; }
+
+  int first_non_null_slot() const         { return next_matching_slot(0, cond_non_null); }
+  int next_non_null_slot(int index) const { return next_matching_slot(index + 1, cond_non_null); }
+
+  int first_null_slot() const             { return next_matching_slot(0, cond_null); }
+  int next_null_slot(int index) const     { return next_matching_slot(index + 1, cond_null); }
+
+  // Return a random slot index.
+  int random_slot_index() const {
+    return _index_range.random_value();
+  }
+
+  int random_non_null_slot_index() const {
+    int i = next_non_null_slot(_index_range.random_value());
+    if (i == -1) {
+      i = first_non_null_slot();
+    }
+    return i;
+  }
+
+  int random_null_slot_index() const {
+    int i = next_null_slot(_index_range.random_value());
+    if (i == -1) {
+      i = first_null_slot();
+    }
+    return i;
+  }
+
+  IntRange random_slot_range() const {
+    return _index_range.random_subrange();
+  }
+
+};
+
+
+#endif // GTEST_METASPACE_SPARSEARRAY_HPP
+
+
diff --git a/test/hotspot/gtest/metaspace/metaspace_testhelper.cpp b/test/hotspot/gtest/metaspace/metaspace_testhelper.cpp
new file mode 100644
--- /dev/null
+++ b/test/hotspot/gtest/metaspace/metaspace_testhelper.cpp
@@ -0,0 +1,178 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+
+#include "metaspace/metaspace_testhelper.hpp"
+
+using namespace metaspace::chunklevel;
+
+  // No reserve limit, and a commit limit.
+MetaspaceTestHelper::MetaspaceTestHelper(size_t commit_limit, size_t reserve_limit)
+: metaspace::MetaspaceTestContext("metaspace-gtest-context", commit_limit, reserve_limit),
+  _num_chunks_allocated(0)
+{
+}
+
+void MetaspaceTestHelper::checked_alloc_chunk_0(Metachunk** p_return_value, chunklevel_t preferred_level, chunklevel_t max_level,
+                                                      size_t min_committed_size) {
+
+  *p_return_value = NULL;
+
+  Metachunk* c = cm().get_chunk(preferred_level, max_level, min_committed_size);
+
+  if (c != NULL) {
+
+    ASSERT_LE(c->level(), max_level);
+    ASSERT_GE(c->level(), preferred_level);
+    ASSERT_GE(c->committed_words(), min_committed_size);
+    ASSERT_EQ(c->committed_words(), c->free_below_committed_words());
+    ASSERT_EQ(c->used_words(), (size_t)0);
+    ASSERT_TRUE(c->is_in_use());
+    ASSERT_FALSE(c->is_free());
+    ASSERT_FALSE(c->is_dead());
+    ASSERT_NULL(c->next());
+    ASSERT_NULL(c->prev());
+    if (c->level() == HIGHEST_CHUNK_LEVEL) {
+      ASSERT_TRUE(c->is_leaf_chunk());
+    } else {
+      ASSERT_FALSE(c->is_leaf_chunk());
+    }
+    if (c->level() == LOWEST_CHUNK_LEVEL) {
+      ASSERT_TRUE(c->is_root_chunk());
+    } else {
+      ASSERT_FALSE(c->is_root_chunk());
+    }
+    if (_num_chunks_allocated == 0) { // First chunk? We can make more assumptions
+      ASSERT_EQ(c->level(), preferred_level);
+      // Needs lock EXPECT_NULL(c->next_in_vs());
+      // Needs lock EXPECT_NULL(c->prev_in_vs());
+      ASSERT_TRUE(c->is_root_chunk() || c->is_leader());
+    }
+    _num_chunks_allocated ++;
+
+  }
+
+  *p_return_value = c;
+
+}
+
+// Test pattern established when allocating from the chunk with allocate_from_chunk_with_tests().
+void MetaspaceTestHelper::test_pattern(Metachunk* c, size_t word_size) {
+  check_range_for_pattern(c->base(), word_size, (uintx)c);
+}
+
+void MetaspaceTestHelper::return_chunk(Metachunk* c) {
+  test_pattern(c);
+  c->set_in_use(); // Forestall assert in cm
+  cm().return_chunk(c);
+}
+
+ void MetaspaceTestHelper::allocate_from_chunk(MetaWord** p_return_value, Metachunk* c, size_t word_size) {
+
+  size_t used_before = c->used_words();
+  size_t free_before = c->free_words();
+  size_t free_below_committed_before = c->free_below_committed_words();
+  const MetaWord* top_before = c->top();
+
+  MetaWord* p = c->allocate(word_size);
+  EXPECT_NOT_NULL(p);
+  EXPECT_EQ(c->used_words(), used_before + word_size);
+  EXPECT_EQ(c->free_words(), free_before - word_size);
+  EXPECT_EQ(c->free_below_committed_words(), free_below_committed_before - word_size);
+  EXPECT_EQ(c->top(), top_before + word_size);
+
+  // Old content should be preserved
+  test_pattern(c, used_before);
+
+  // Fill newly allocated range too
+  fill_range_with_pattern(p, word_size, (uintx)c);
+
+  *p_return_value = p;
+}
+
+void MetaspaceTestHelper::commit_chunk_with_test(Metachunk* c, size_t additional_size) {
+
+  size_t used_before = c->used_words();
+  size_t free_before = c->free_words();
+  const MetaWord* top_before = c->top();
+
+  c->set_in_use();
+  bool b = c->ensure_committed_additional(additional_size);
+  EXPECT_TRUE(b);
+
+  // We should have enough committed size now
+  EXPECT_GE(c->free_below_committed_words(), additional_size);
+
+  // used, free, top should be unchanged.
+  EXPECT_EQ(c->used_words(), used_before);
+  EXPECT_EQ(c->free_words(), free_before);
+  EXPECT_EQ(c->top(), top_before);
+
+  test_pattern(c, used_before);
+
+}
+
+void MetaspaceTestHelper::commit_chunk_expect_failure(Metachunk* c, size_t additional_size) {
+
+  size_t used_before = c->used_words();
+  size_t free_before = c->free_words();
+  size_t free_below_committed_before = c->free_below_committed_words();
+  const MetaWord* top_before = c->top();
+
+  c->set_in_use();
+  bool b = c->ensure_committed_additional(additional_size);
+  EXPECT_FALSE(b);
+
+  // Nothing should have changed
+  EXPECT_EQ(c->used_words(), used_before);
+  EXPECT_EQ(c->free_words(), free_before);
+  EXPECT_EQ(c->free_below_committed_words(), free_below_committed_before);
+  EXPECT_EQ(c->top(), top_before);
+
+  test_pattern(c, used_before);
+
+}
+
+void MetaspaceTestHelper::uncommit_chunk_with_test(Metachunk* c) {
+  if (c->word_size() >= Settings::commit_granule_words()) {
+    c->set_free();  // Forestall assert in uncommit
+    c->reset_used_words();
+    c->uncommit();
+
+    EXPECT_EQ(c->free_below_committed_words(), (size_t)0);
+    EXPECT_EQ(c->used_words(), (size_t)0);
+    EXPECT_EQ(c->free_words(), c->word_size());
+    EXPECT_EQ(c->top(), c->base());
+    EXPECT_TRUE(c->is_fully_uncommitted());
+  }
+}
+
+
+
+/////// SparseArray<T> ////////////////
+
+
+
diff --git a/test/hotspot/gtest/metaspace/metaspace_testhelper.hpp b/test/hotspot/gtest/metaspace/metaspace_testhelper.hpp
new file mode 100644
--- /dev/null
+++ b/test/hotspot/gtest/metaspace/metaspace_testhelper.hpp
@@ -0,0 +1,114 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#ifndef GTEST_METASPACE_METASPACE_TESTHELPER_HPP
+#define GTEST_METASPACE_METASPACE_TESTHELPER_HPP
+
+#include "memory/allocation.hpp"
+#include "metaspace/metaspaceTestsCommon.hpp"
+
+using namespace metaspace::chunklevel;
+
+class MetaspaceTestHelper : public metaspace::MetaspaceTestContext {
+
+  int _num_chunks_allocated;
+
+  void checked_alloc_chunk_0(Metachunk** p_return_value, chunklevel_t preferred_level,
+                             chunklevel_t max_level, size_t min_committed_size);
+
+public:
+
+  // Note: limit = 0 means unlimited
+  MetaspaceTestHelper(size_t commit_limit = 0, size_t reserve_limit = 0);
+
+  /////
+
+  // Note: all test functions return void and return values are by pointer ref; this is awkward but otherwise we cannot
+  // use gtest ASSERT macros inside those functions.
+
+  // Allocate a chunk (you do not know if it will succeed).
+  void alloc_chunk(Metachunk** p_return_value, chunklevel_t preferred_level, chunklevel_t max_level, size_t min_committed_size) {
+    checked_alloc_chunk_0(p_return_value, preferred_level, max_level, min_committed_size);
+  }
+
+  // Allocate a chunk; do not expect success, but if it succeeds, test the chunk.
+  void alloc_chunk(Metachunk** p_return_value, chunklevel_t level) {
+    alloc_chunk(p_return_value, level, level, word_size_for_level(level));
+  }
+
+  // Allocate a chunk; it must succeed. Test the chunk.
+  void alloc_chunk_expect_success(Metachunk** p_return_value, chunklevel_t preferred_level, chunklevel_t max_level, size_t min_committed_size) {
+    checked_alloc_chunk_0(p_return_value, preferred_level, max_level, min_committed_size);
+    ASSERT_NOT_NULL(*p_return_value);
+  }
+
+  // Allocate a chunk; it must succeed. Test the chunk.
+  void alloc_chunk_expect_success(Metachunk** p_return_value, chunklevel_t level) {
+    alloc_chunk_expect_success(p_return_value, level, level, word_size_for_level(level));
+  }
+
+  // Allocate a chunk but expect it to fail.
+  void alloc_chunk_expect_failure(chunklevel_t preferred_level, chunklevel_t max_level, size_t min_committed_size) {
+    Metachunk* c = NULL;
+    checked_alloc_chunk_0(&c, preferred_level, max_level, min_committed_size);
+    ASSERT_NULL(c);
+  }
+
+  // Allocate a chunk but expect it to fail.
+  void alloc_chunk_expect_failure(chunklevel_t level) {
+    return alloc_chunk_expect_failure(level, level, word_size_for_level(level));
+  }
+
+  /////
+
+  void return_chunk(Metachunk* c);
+
+  /////
+
+  // Allocates from a chunk; also, fills allocated area with test pattern which will be tested with test_pattern().
+  void allocate_from_chunk(MetaWord** p_return_value, Metachunk* c, size_t word_size);
+
+  // Convenience function: allocate from chunk for when you don't care for the result pointer
+  void allocate_from_chunk(Metachunk* c, size_t word_size) {
+    MetaWord* dummy;
+    allocate_from_chunk(&dummy, c, word_size);
+  }
+
+  // Test pattern established when allocating from the chunk with allocate_from_chunk_with_tests().
+  void test_pattern(Metachunk* c, size_t word_size);
+  void test_pattern(Metachunk* c) { test_pattern(c, c->used_words()); }
+
+  void commit_chunk_with_test(Metachunk* c, size_t additional_size);
+  void commit_chunk_expect_failure(Metachunk* c, size_t additional_size);
+
+  void uncommit_chunk_with_test(Metachunk* c);
+
+
+};
+
+
+#endif // GTEST_METASPACE_METASPACE_TESTHELPER_HPP
+
+
diff --git a/test/hotspot/gtest/metaspace/test_arenagrowthpolicy.cpp b/test/hotspot/gtest/metaspace/test_arenagrowthpolicy.cpp
new file mode 100644
--- /dev/null
+++ b/test/hotspot/gtest/metaspace/test_arenagrowthpolicy.cpp
@@ -0,0 +1,71 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+
+//#define LOG_PLEASE
+
+#include "metaspaceTestsCommon.hpp"
+
+static void test_arena_growth_policy(Metaspace::MetaspaceType spacetype, bool is_class) {
+
+  const ArenaGrowthPolicy* a =
+      ArenaGrowthPolicy::policy_for_space_type((Metaspace::MetaspaceType)spacetype, is_class);
+
+  // initial level
+  chunklevel_t lvl = a->get_level_at_step(0);
+  ASSERT_TRUE(is_valid_level(lvl));
+  if (spacetype != Metaspace::BootMetaspaceType) {
+    // All types save boot loader should start with small or very small chunks
+    ASSERT_GE(lvl, CHUNK_LEVEL_4K);
+  }
+
+  for (int step = 1; step < 100; step ++) {
+    chunklevel_t lvl2 = a->get_level_at_step(step);
+    ASSERT_TRUE(is_valid_level(lvl2));
+    // limit steepness: no growth allowed beyond last chunksize * 2
+    ASSERT_LE(word_size_for_level(lvl2), word_size_for_level(lvl) * 2);
+    lvl = lvl2;
+  }
+}
+
+#define DEFINE_GROWTH_POLICY_TEST(spacetype, is_class) \
+TEST_VM(metaspace, arena_growth_policy_##spacetype##_##is_class) { \
+	test_arena_growth_policy(Metaspace::spacetype, is_class); \
+}
+
+DEFINE_GROWTH_POLICY_TEST(ReflectionMetaspaceType, true)
+DEFINE_GROWTH_POLICY_TEST(ReflectionMetaspaceType, false)
+DEFINE_GROWTH_POLICY_TEST(ClassMirrorHolderMetaspaceType, true)
+DEFINE_GROWTH_POLICY_TEST(ClassMirrorHolderMetaspaceType, false)
+DEFINE_GROWTH_POLICY_TEST(StandardMetaspaceType, true)
+DEFINE_GROWTH_POLICY_TEST(StandardMetaspaceType, false)
+DEFINE_GROWTH_POLICY_TEST(BootMetaspaceType, true)
+DEFINE_GROWTH_POLICY_TEST(BootMetaspaceType, false)
+
+
+
+
+
diff --git a/test/hotspot/gtest/metaspace/test_binlist.cpp b/test/hotspot/gtest/metaspace/test_binlist.cpp
new file mode 100644
--- /dev/null
+++ b/test/hotspot/gtest/metaspace/test_binlist.cpp
@@ -0,0 +1,232 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+
+//#define LOG_PLEASE
+
+#include "metaspaceTestsCommon.hpp"
+
+
+#define CHECK_BL_CONTENT(bl, expected_num, expected_size) { \
+  EXPECT_EQ(bl.count(), (unsigned)expected_num); \
+  EXPECT_EQ(bl.total_size(), (size_t)expected_size); \
+  if (expected_num == 0) { \
+    EXPECT_TRUE(bl.is_empty()); \
+  } else { \
+    EXPECT_FALSE(bl.is_empty()); \
+  } \
+}
+
+
+template <class BINLISTTYPE>
+struct BinListBasicTest {
+
+  static const size_t minws;
+  static const size_t maxws;
+
+  static void basic_test() {
+
+    BINLISTTYPE bl;
+
+    CHECK_BL_CONTENT(bl, 0, 0);
+
+    MetaWord arr[1000];
+
+    size_t innocous_size = minws + ((maxws - minws) / 2);
+
+    // Try to get a block from an empty list.
+    size_t real_size = 4711;
+    MetaWord* p = bl.get_block(innocous_size, &real_size);
+    EXPECT_EQ(p, (MetaWord*)NULL);
+    EXPECT_EQ((size_t)0, real_size);
+
+    // Add a block...
+    bl.add_block(arr, innocous_size);
+    CHECK_BL_CONTENT(bl, 1, innocous_size);
+    DEBUG_ONLY(bl.verify();)
+
+    // And retrieve it.
+    real_size = 4711;
+    p = bl.get_block(innocous_size, &real_size);
+    EXPECT_EQ(p, arr);
+    EXPECT_EQ((size_t)innocous_size, real_size);
+    CHECK_BL_CONTENT(bl, 0, 0);
+    DEBUG_ONLY(bl.verify();)
+
+  }
+
+  static void basic_test_2() {
+
+    BINLISTTYPE bl;
+
+    CHECK_BL_CONTENT(bl, 0, 0);
+
+    MetaWord arr[1000];
+
+    for (size_t s1 = minws; s1 < maxws; s1 ++) {
+      for (size_t s2 = minws; s2 < maxws; s2 ++) {
+
+        bl.add_block(arr, s1);
+        CHECK_BL_CONTENT(bl, 1, s1);
+        DEBUG_ONLY(bl.verify();)
+
+        size_t real_size = 4711;
+        MetaWord* p = bl.get_block(s2, &real_size);
+        if (s1 >= s2) {
+          EXPECT_EQ(p, arr);
+          EXPECT_EQ((size_t)s1, real_size);
+          CHECK_BL_CONTENT(bl, 0, 0);
+          DEBUG_ONLY(bl.verify();)
+        } else {
+          EXPECT_EQ(p, (MetaWord*)NULL);
+          EXPECT_EQ((size_t)0, real_size);
+          CHECK_BL_CONTENT(bl, 1, s1);
+          DEBUG_ONLY(bl.verify();)
+          // drain bl
+          p = bl.get_block(minws, &real_size);
+          EXPECT_EQ(p, arr);
+          EXPECT_EQ((size_t)s1, real_size);
+          CHECK_BL_CONTENT(bl, 0, 0);
+        }
+      }
+    }
+  }
+
+  static void random_test() {
+
+    BINLISTTYPE bl[2];
+    MemRangeCounter cnt[2];
+
+#define CHECK_COUNTERS \
+  ASSERT_EQ(cnt[0].count(), bl[0].count()); \
+  ASSERT_EQ(cnt[1].count(), bl[1].count()); \
+  ASSERT_EQ(cnt[0].total_size(), bl[0].total_size()); \
+  ASSERT_EQ(cnt[1].total_size(), bl[1].total_size());
+
+    FeederBuffer fb(1024);
+    RandSizeGenerator rgen(minws, maxws);
+
+    // feed all
+    int which = 0;
+    for (;;) {
+      size_t s = rgen.get();
+      MetaWord* p = fb.get(s);
+      if (p != NULL) {
+        bl[which].add_block(p, s);
+        cnt[which].add(s);
+        which = which == 0 ? 1 : 0;
+      } else {
+        break;
+      }
+    }
+
+    CHECK_COUNTERS;
+    DEBUG_ONLY(bl[0].verify();)
+    DEBUG_ONLY(bl[1].verify();)
+
+    // play pingpong
+    for (int iter = 0; iter < 1000; iter ++) {
+      size_t s = rgen.get();
+      int taker = iter % 2;
+      int giver = taker == 0 ? 1 : 0;
+
+      size_t real_size = 4711;
+      MetaWord* p = bl[giver].get_block(s, &real_size);
+      if (p != NULL) {
+
+        ASSERT_TRUE(fb.is_valid_range(p, real_size));
+        ASSERT_GE(real_size, s);
+        cnt[giver].sub(real_size);
+
+        bl[taker].add_block(p, real_size);
+        cnt[taker].add(real_size);
+
+      } else {
+        ASSERT_EQ(real_size, (size_t)NULL);
+      }
+
+      CHECK_COUNTERS;
+
+    }
+
+    CHECK_COUNTERS;
+    DEBUG_ONLY(bl[0].verify();)
+    DEBUG_ONLY(bl[1].verify();)
+
+    // drain both lists.
+    for (int which = 0; which < 2; which ++) {
+      size_t last_size = 0;
+      while (bl[which].is_empty() == false) {
+
+        size_t real_size = 4711;
+        MetaWord* p = bl[which].get_block(minws, &real_size);
+
+        ASSERT_NE(p, (MetaWord*) NULL);
+        ASSERT_GE(real_size, minws);
+        ASSERT_TRUE(fb.is_valid_range(p, real_size));
+
+        // This must hold true since we always return the smallest fit.
+        ASSERT_GE(real_size, last_size);
+        if (real_size > last_size) {
+          last_size = real_size;
+        }
+
+        cnt[which].sub(real_size);
+
+        CHECK_COUNTERS;
+      }
+    }
+
+
+  }
+};
+
+template <typename BINLISTTYPE> const size_t BinListBasicTest<BINLISTTYPE>::minws = BINLISTTYPE::minimal_word_size;
+template <typename BINLISTTYPE> const size_t BinListBasicTest<BINLISTTYPE>::maxws = BINLISTTYPE::maximal_word_size;
+
+
+TEST_VM(metaspace, BinList_basic_8)   { BinListBasicTest<metaspace::BinList8>::basic_test(); }
+TEST_VM(metaspace, BinList_basic_16)  { BinListBasicTest<metaspace::BinList16>::basic_test(); }
+TEST_VM(metaspace, BinList_basic_32)  { BinListBasicTest<metaspace::BinList32>::basic_test(); }
+//TEST_VM(metaspace, BinList_basic_64)  { BinListBasicTest<metaspace::BinList64>::basic_test(); }
+
+TEST_VM(metaspace, BinList_basic_1331)   { BinListBasicTest< metaspace::BinListImpl<13, 31> >::basic_test(); }
+TEST_VM(metaspace, BinList_basic_131)   { BinListBasicTest< metaspace::BinListImpl<13, 1> >::basic_test(); }
+
+TEST_VM(metaspace, BinList_basic2_8)   { BinListBasicTest<metaspace::BinList8>::basic_test_2(); }
+TEST_VM(metaspace, BinList_basic2_16)  { BinListBasicTest<metaspace::BinList16>::basic_test_2(); }
+TEST_VM(metaspace, BinList_basic2_32)  { BinListBasicTest<metaspace::BinList32>::basic_test_2(); }
+
+TEST_VM(metaspace, BinList_basic2_1331)   { BinListBasicTest< metaspace::BinListImpl<13, 31> >::basic_test_2(); }
+TEST_VM(metaspace, BinList_basic2_131)   { BinListBasicTest< metaspace::BinListImpl<13, 1> >::basic_test_2(); }
+
+TEST_VM(metaspace, BinList_random_test_8)   { BinListBasicTest<metaspace::BinList8>::random_test(); }
+TEST_VM(metaspace, BinList_random_test_16)  { BinListBasicTest<metaspace::BinList16>::random_test(); }
+TEST_VM(metaspace, BinList_random_test_32)  { BinListBasicTest<metaspace::BinList32>::random_test(); }
+
+TEST_VM(metaspace, BinList_random_test_1331)   { BinListBasicTest< metaspace::BinListImpl<13, 31> >::random_test(); }
+TEST_VM(metaspace, BinList_random_test_131)   { BinListBasicTest< metaspace::BinListImpl<13, 1> >::random_test(); }
+
diff --git a/test/hotspot/gtest/metaspace/test_blocktree.cpp b/test/hotspot/gtest/metaspace/test_blocktree.cpp
new file mode 100644
--- /dev/null
+++ b/test/hotspot/gtest/metaspace/test_blocktree.cpp
@@ -0,0 +1,364 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+
+//#define LOG_PLEASE
+
+#include "metaspaceTestsCommon.hpp"
+
+
+#define CHECK_BT_CONTENT(bt, expected_num, expected_size) { \
+  EXPECT_EQ(bt.count(), (unsigned)expected_num); \
+  EXPECT_EQ(bt.total_size(), (size_t)expected_size); \
+  if (expected_num == 0) { \
+    EXPECT_TRUE(bt.is_empty()); \
+  } else { \
+    EXPECT_FALSE(bt.is_empty()); \
+  } \
+}
+
+TEST_VM(metaspace, BlockTree_basic) {
+
+  BlockTree bt;
+  CHECK_BT_CONTENT(bt, 0, 0);
+
+  size_t real_size = 0;
+  MetaWord* p = NULL;
+  MetaWord arr[10000];
+
+  const size_t minws = BlockTree::minimal_word_size;
+  const size_t maxws = 4096;
+
+  // get_block from empty tree should yield nothing
+  p = bt.get_block(minws, &real_size);
+  EXPECT_EQ(p, (MetaWord*)NULL);
+  EXPECT_EQ(real_size, (size_t)0);
+  CHECK_BT_CONTENT(bt, 0, 0);
+
+  // Add some blocks and retrieve them right away.
+  size_t sizes[] = {
+      minws + 10,
+      maxws - 10,
+      minws, // smallest possible
+      maxws - 1, // largest possible
+      0
+  };
+
+  for (int i = 0; sizes[i] > 0; i ++) {
+    bt.add_block(arr, sizes[i]);
+    CHECK_BT_CONTENT(bt, 1, sizes[i]);
+
+    DEBUG_ONLY(bt.verify();)
+
+    MetaWord* p = bt.get_block(sizes[i], &real_size);
+    EXPECT_EQ(p, arr);
+    EXPECT_EQ(real_size, (size_t)sizes[i]);
+    CHECK_BT_CONTENT(bt, 0, 0);
+  }
+
+}
+
+TEST_VM(metaspace, BlockTree_closest_fit) {
+
+  // Test the fact that getting blocks should always return the closest fit
+  BlockTree bt;
+  FeederBuffer fb(10000);
+
+  const size_t minws = BlockTree::minimal_word_size;
+  const size_t maxws = 256;
+
+  size_t sizes[] = {
+      minws + 9,
+      minws + 3,
+      minws + 9,
+      minws,
+      minws + 8,
+      maxws - 2,
+      minws,
+      maxws - 1,
+      0
+  };
+
+  size_t size_added = 0;
+  int num_added = 0;
+
+  for (int i = 0; sizes[i] > 0; i ++) {
+    const size_t s = sizes[i];
+    MetaWord* p = fb.get(s);
+    bt.add_block(p, s);
+    num_added ++; size_added += s;
+    CHECK_BT_CONTENT(bt, num_added, size_added);
+  }
+
+  DEBUG_ONLY(bt.verify();)
+
+  size_t last_size = 0;
+  while (bt.is_empty() == false) {
+    size_t real_size = 0;
+    MetaWord* p = bt.get_block(minws, &real_size);
+    EXPECT_TRUE(fb.is_valid_range(p, real_size));
+
+    EXPECT_GE(real_size, last_size);
+    last_size = real_size;
+
+    num_added --;
+    size_added -= real_size;
+    CHECK_BT_CONTENT(bt, num_added, size_added);
+  }
+
+  CHECK_BT_CONTENT(bt, 0, 0);
+
+}
+
+
+TEST_VM(metaspace, BlockTree_basic_siblings)
+{
+  BlockTree bt;
+  CHECK_BT_CONTENT(bt, 0, 0);
+
+  const size_t minws = BlockTree::minimal_word_size;
+  const size_t maxws = 256;
+  const size_t test_size = minws + 17;
+  const int num = 10;
+
+  MetaWord* arr = NEW_C_HEAP_ARRAY(MetaWord, num * test_size, mtInternal);
+
+  for (int i = 0; i < num; i ++) {
+    bt.add_block(arr + (i * test_size), test_size);
+    CHECK_BT_CONTENT(bt, i + 1, (i + 1) * test_size);
+  }
+
+  DEBUG_ONLY(bt.verify();)
+
+  for (int i = num; i > 0; i --) {
+    size_t real_size = 4711;
+    MetaWord* p = bt.get_block(test_size, &real_size);
+    EXPECT_LT(p, arr + num * test_size);
+    EXPECT_GE(p, arr);
+    EXPECT_EQ(real_size, (size_t)test_size);
+    CHECK_BT_CONTENT(bt, i - 1, (i - 1) * test_size);
+  }
+
+  FREE_C_HEAP_ARRAY(MetaWord, arr);
+}
+
+class BlockTreeTest {
+
+  FeederBuffer _fb;
+
+  BlockTree _bt[2];
+  MemRangeCounter _cnt[2];
+
+  RandSizeGenerator _rgen;
+
+#define CHECK_COUNTERS \
+		CHECK_BT_CONTENT(_bt[0], _cnt[0].count(), _cnt[0].total_size()) \
+    CHECK_BT_CONTENT(_bt[1], _cnt[1].count(), _cnt[1].total_size())
+
+#define CHECK_COUNTERS_ARE_0 \
+    CHECK_BT_CONTENT(_bt[0], 0, 0) \
+    CHECK_BT_CONTENT(_bt[1], 0, 0)
+
+#ifdef ASSERT
+  void verify_trees() {
+    _bt[0].verify();
+    _bt[1].verify();
+  }
+#endif
+
+  enum feeding_pattern_t {
+    scatter = 1,
+    left_right = 2,
+    right_left = 3
+  };
+
+  void feed_all(feeding_pattern_t feeding_pattern) {
+
+    // Feed the whole feaderbuffer space to the trees.
+    MetaWord* p = NULL;
+    unsigned added = 0;
+
+    // If we feed in small graining, we cap the number of blocks to limit test duration.
+    const unsigned max_blocks = 2000;
+
+    size_t old_feeding_size = feeding_pattern == right_left ? _rgen.max() : _rgen.min();
+    do {
+      size_t s = 0;
+      switch (feeding_pattern) {
+      case scatter:
+        // fill completely random
+        s =_rgen.get();
+        break;
+      case left_right:
+        // fill in ascending order to annoy trees.
+        s = MIN2(_rgen.get(), old_feeding_size);
+        old_feeding_size = s;
+        break;
+      case right_left:
+        // same, but descending.
+        s = MAX2(_rgen.get(), old_feeding_size);
+        old_feeding_size = s;
+        break;
+      }
+
+      p = _fb.get(s);
+      if (p != NULL) {
+        int which = added % 2;
+        added ++;
+        _bt[which].add_block(p, s);
+        _cnt[which].add(s);
+        CHECK_COUNTERS
+      }
+      DEBUG_ONLY(verify_trees();)
+      CHECK_COUNTERS;
+    } while (p != NULL && added < max_blocks);
+
+    // Trees should be populated in a balanced way, and not empty
+    EXPECT_TRUE( _bt[0].count() == _bt[1].count() ||
+                (_bt[0].count() == _bt[1].count() + 1 && _bt[0].count() > 0));
+
+  }
+
+  void ping_pong_loop(int iterations) {
+
+    // We loop and in each iteration randomly retrieve a block from one tree and add it to another.
+    for (int i = 0; i < iterations; i ++) {
+      int taker = 0;
+      int giver = 1;
+      if ((os::random() % 10) > 5) {
+        giver = 0; taker = 1;
+      }
+      size_t s =_rgen.get();
+      size_t real_size = 0;
+      MetaWord* p = _bt[giver].get_block(s, &real_size);
+      if (p == NULL) {
+        // Todo: check that bt really has no larger block than this.
+      } else {
+        ASSERT_TRUE(_fb.is_valid_range(p, real_size));
+        ASSERT_GE(real_size, s);
+        _bt[taker].add_block(p, real_size);
+        _cnt[giver].sub(real_size);
+        _cnt[taker].add(real_size);
+        CHECK_COUNTERS;
+      }
+
+#ifdef ASSERT
+      if (true) {//i % 1000 == 0) {
+        verify_trees();
+      }
+#endif
+    }
+  }
+
+  // Drain the trees. While draining, observe the order of the drained items.
+  void drain_all() {
+
+    for (int which = 0; which < 2; which ++) {
+      BlockTree* bt = _bt + which;
+      size_t last_size = 0;
+      while(!bt->is_empty()) {
+
+        // We only query for the minimal size. Actually returned size should be
+        // monotonously growing since get_block should always return the closest fit.
+        size_t real_size = 4711;
+        MetaWord* p = bt->get_block(BlockTree::minimal_word_size, &real_size);
+        ASSERT_TRUE(_fb.is_valid_range(p, real_size));
+
+        ASSERT_GE(real_size, last_size);
+        last_size = real_size;
+
+        _cnt[which].sub(real_size);
+        CHECK_COUNTERS;
+
+#ifdef ASSERT
+        if (true) {//i % 1000 == 0) {
+          bt->verify();
+        }
+#endif
+      }
+    }
+
+  }
+
+  void test(feeding_pattern_t feeding_pattern) {
+
+    CHECK_COUNTERS_ARE_0
+
+    feed_all(feeding_pattern);
+
+    LOG("Blocks in circulation: bt1=%d:" SIZE_FORMAT ", bt2=%d:" SIZE_FORMAT ".",
+        _bt[0].count(), _bt[0].total_size(),
+        _bt[1].count(), _bt[1].total_size());
+
+    ping_pong_loop(2000);
+
+    LOG("After Pingpong: bt1=%d:" SIZE_FORMAT ", bt2=%d:" SIZE_FORMAT ".",
+        _bt[0].count(), _bt[0].total_size(),
+        _bt[1].count(), _bt[1].total_size());
+
+    drain_all();
+
+    CHECK_COUNTERS_ARE_0
+  }
+
+
+public:
+
+  BlockTreeTest(size_t min_word_size, size_t max_word_size) :
+    _fb(2 * M),
+    _bt(),
+    _rgen(min_word_size, max_word_size)
+  {
+    CHECK_COUNTERS;
+    DEBUG_ONLY(verify_trees();)
+  }
+
+
+  void test_scatter()      { test(scatter); }
+  void test_right_left()   { test(right_left); }
+  void test_left_right()   { test(left_right); }
+
+};
+
+#define DO_TEST(name, feedingpattern, min, max) \
+		TEST_VM(metaspace, BlockTree_##name##_##feedingpattern) { \
+      BlockTreeTest btt(min, max); \
+      btt.test_##feedingpattern(); \
+    }
+
+#define DO_TEST_ALL_PATTERNS(name, min, max) \
+  DO_TEST(name, scatter, min, max) \
+  DO_TEST(name, right_left, min, max) \
+  DO_TEST(name, left_right, min, max)
+
+
+DO_TEST_ALL_PATTERNS(wide, BlockTree::minimal_word_size, 128 * K);
+DO_TEST_ALL_PATTERNS(narrow, BlockTree::minimal_word_size, 16)
+DO_TEST_ALL_PATTERNS(129, BlockTree::minimal_word_size, 129)
+DO_TEST_ALL_PATTERNS(4K, BlockTree::minimal_word_size, 4*K)
+
+
+
diff --git a/test/hotspot/gtest/metaspace/test_chunkManager.cpp b/test/hotspot/gtest/metaspace/test_chunkManager.cpp
new file mode 100644
--- /dev/null
+++ b/test/hotspot/gtest/metaspace/test_chunkManager.cpp
@@ -0,0 +1,294 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+
+//#define LOG_PLEASE
+
+#include "metaspace/metaspace_sparsearray.hpp"
+#include "metaspace/metaspaceTestsCommon.hpp"
+#include "metaspace/metaspaceTestContexts.hpp"
+
+
+
+class ChunkManagerRandomChunkAllocTest {
+
+  static const size_t max_footprint_words = 8 * M;
+
+  ChunkTestsContext _helper;
+
+  // All allocated live chunks
+  typedef SparseArray<Metachunk*> SparseArrayOfChunks;
+  SparseArrayOfChunks _chunks;
+
+  const ChunkLevelRange _chunklevel_range;
+  const float _commit_factor;
+
+  // Depending on a probability pattern, come up with a reasonable limit to number of live chunks
+  static int max_num_live_chunks(ChunkLevelRange r, float commit_factor) {
+    // Assuming we allocate only the largest type of chunk, committed to the fullest commit factor,
+    // how many chunks can we accomodate before hitting max_footprint_words?
+    const size_t largest_chunk_size = word_size_for_level(r.lowest());
+    int max_chunks = (max_footprint_words * commit_factor) / largest_chunk_size;
+    // .. but cap at (min) 50 and (max) 1000
+    max_chunks = MIN2(1000, max_chunks);
+    max_chunks = MAX2(50, max_chunks);
+    return max_chunks;
+  }
+
+  // Return true if, after an allocation error happened, a reserve error seems likely.
+  bool could_be_reserve_error() {
+    return _helper.vslist().is_full();
+  }
+
+  // Return true if, after an allocation error happened, a commit error seems likely.
+  bool could_be_commit_error(size_t additional_word_size) {
+
+    // could it be commit limit hit?
+
+    if (Settings::new_chunks_are_fully_committed()) {
+      // For all we know we may have just failed to fully-commit a new root chunk.
+      additional_word_size = MAX_CHUNK_WORD_SIZE;
+    }
+
+    // Note that this is difficult to verify precisely, since there are
+    // several layers of truth:
+    // a) at the lowest layer (RootChunkArea) we have a bitmap of committed granules;
+    // b) at the vslist layer, we keep running counters of committed/reserved words;
+    // c) at the chunk layer, we keep a commit watermark (committed_words).
+    //
+    // (a) should mirror reality.
+    // (a) and (b) should be precisely in sync. This is tested by
+    // VirtualSpaceList::verify().
+    // (c) can be, by design, imprecise (too low).
+    //
+    // Here, I check (b) and trust it to be correct. We also call vslist::verify().
+    DEBUG_ONLY(_helper.verify();)
+
+    const size_t commit_add = align_up(additional_word_size, Settings::commit_granule_words());
+    if (_helper.commit_limit() <= (commit_add + _helper.vslist().committed_words())) {
+      return true;
+    }
+
+    return false;
+
+  }
+
+  // Given a chunk level and a factor, return a random commit size.
+  static size_t random_committed_words(chunklevel_t lvl, float commit_factor) {
+    const size_t sz = word_size_for_level(lvl) * commit_factor;
+    if (sz < 2) {
+      return 0;
+    }
+    return MIN2(SizeRange(sz).random_value(), sz);
+  }
+
+
+  //// Chunk allocation ////
+
+  // Given an slot index, allocate a random chunk and set it into that slot. Slot must be empty.
+  // Returns false if allocation fails.
+  bool allocate_random_chunk_at(int slot) {
+
+    DEBUG_ONLY(_chunks.check_slot_is_null(slot);)
+
+    const ChunkLevelRange r = _chunklevel_range.random_subrange();
+    const chunklevel_t pref_level = r.lowest();
+    const chunklevel_t max_level = r.highest();
+    const size_t min_committed = random_committed_words(max_level, _commit_factor);
+
+    Metachunk* c = NULL;
+    _helper.alloc_chunk(&c, r.lowest(), r.highest(), min_committed);
+    if (c == NULL) {
+      EXPECT_TRUE(could_be_reserve_error() ||
+                  could_be_commit_error(min_committed));
+      LOG("Alloc chunk at %d failed.", slot);
+      return false;
+    }
+
+    _chunks.set_at(slot, c);
+
+    LOG("Allocated chunk at %d: " METACHUNK_FORMAT ".", slot, METACHUNK_FORMAT_ARGS(c));
+
+    return true;
+
+  }
+
+  // Allocates a random number of random chunks
+  bool allocate_random_chunks() {
+    int to_alloc = 1 + IntRange(MAX2(1, _chunks.size() / 8)).random_value();
+    bool success = true;
+    int slot = _chunks.first_null_slot();
+    while (to_alloc > 0 && slot != -1 && success) {
+      success = allocate_random_chunk_at(slot);
+      slot = _chunks.next_null_slot(slot);
+      to_alloc --;
+    }
+    return success && to_alloc == 0;
+  }
+
+  bool fill_all_slots_with_random_chunks() {
+    bool success = true;
+    for (int slot = _chunks.first_null_slot();
+         slot != -1 && success; slot = _chunks.next_null_slot(slot)) {
+      success = allocate_random_chunk_at(slot);
+    }
+    return success;
+  }
+
+  //// Chunk return ////
+
+  // Given an slot index, return the chunk in that slot to the chunk manager.
+  void return_chunk_at(int slot) {
+    Metachunk* c = _chunks.at(slot);
+    LOG("Returning chunk at %d: " METACHUNK_FORMAT ".", slot, METACHUNK_FORMAT_ARGS(c));
+    _helper.return_chunk(c);
+    _chunks.set_at(slot, NULL);
+  }
+
+  // return a random number of chunks (at most a quarter of the full slot range)
+  void return_random_chunks() {
+    int to_free = 1 + IntRange(MAX2(1, _chunks.size() / 8)).random_value();
+    int index = _chunks.first_non_null_slot();
+    while (to_free > 0 && index != -1) {
+      return_chunk_at(index);
+      index = _chunks.next_non_null_slot(index);
+      to_free --;
+    }
+  }
+
+  void return_all_chunks() {
+    for (int slot = _chunks.first_non_null_slot();
+         slot != -1; slot = _chunks.next_non_null_slot(slot)) {
+      return_chunk_at(slot);
+    }
+  }
+
+  // adjust test if we change levels
+  STATIC_ASSERT(HIGHEST_CHUNK_LEVEL == CHUNK_LEVEL_1K);
+  STATIC_ASSERT(LOWEST_CHUNK_LEVEL == CHUNK_LEVEL_4M);
+
+  void one_test() {
+
+    fill_all_slots_with_random_chunks();
+    _chunks.shuffle();
+
+    IntRange rand(100);
+
+    for (int j = 0; j < 1000; j ++) {
+
+      bool force_alloc = false;
+      bool force_free = true;
+
+      bool do_alloc =
+          force_alloc ? true :
+              (force_free ? false : rand.random_value() >= 50);
+      force_alloc = force_free = false;
+
+      if (do_alloc) {
+        if (!allocate_random_chunks()) {
+          force_free = true;
+        }
+      } else {
+        return_random_chunks();
+      }
+
+      _chunks.shuffle();
+
+    }
+
+    return_all_chunks();
+
+  }
+
+
+public:
+
+  // A test with no limits
+  ChunkManagerRandomChunkAllocTest(ChunkLevelRange r, float commit_factor)
+    : _helper(),
+      _chunks(max_num_live_chunks(r, commit_factor)),
+      _chunklevel_range(r),
+      _commit_factor(commit_factor)
+  {}
+
+  // A test with no reserve limit but commit limit
+  ChunkManagerRandomChunkAllocTest(size_t commit_limit,
+                                   ChunkLevelRange r, float commit_factor)
+    : _helper(commit_limit),
+      _chunks(max_num_live_chunks(r, commit_factor)),
+      _chunklevel_range(r),
+      _commit_factor(commit_factor)
+  {}
+
+  // A test with both reserve and commit limit
+  // ChunkManagerRandomChunkAllocTest(size_t commit_limit, size_t reserve_limit,
+  //                                  ChunkLevelRange r, float commit_factor)
+  // : _helper(commit_limit, reserve_limit),
+  // _chunks(max_num_live_chunks(r, commit_factor)),
+  // _chunklevel_range(r),
+  // _commit_factor(commit_factor)
+  // {}
+
+
+  void do_tests() {
+    const int num_runs = 5;
+    for (int n = 0; n < num_runs; n ++) {
+      one_test();
+    }
+  }
+
+};
+
+#define DEFINE_TEST(name, range, commit_factor) \
+TEST_VM(metaspace, chunkmanager_##name) { \
+	ChunkManagerRandomChunkAllocTest test(range, commit_factor); \
+	test.do_tests(); \
+}
+
+DEFINE_TEST(test_nolimit_1, ChunkLevelRanges::small_chunks(), 0.0f)
+DEFINE_TEST(test_nolimit_2, ChunkLevelRanges::small_chunks(), 0.5f)
+DEFINE_TEST(test_nolimit_3, ChunkLevelRanges::small_chunks(), 1.0f)
+
+DEFINE_TEST(test_nolimit_4, ChunkLevelRanges::all_chunks(), 0.0f)
+DEFINE_TEST(test_nolimit_5, ChunkLevelRanges::all_chunks(), 0.5f)
+DEFINE_TEST(test_nolimit_6, ChunkLevelRanges::all_chunks(), 1.0f)
+
+#define DEFINE_TEST_2(name, range, commit_factor) \
+TEST_VM(metaspace, chunkmanager_##name) { \
+  const size_t commit_limit = 256 * K; \
+  ChunkManagerRandomChunkAllocTest test(commit_limit, range, commit_factor); \
+  test.do_tests(); \
+}
+
+DEFINE_TEST_2(test_with_limit_1, ChunkLevelRanges::small_chunks(), 0.0f)
+DEFINE_TEST_2(test_with_limit_2, ChunkLevelRanges::small_chunks(), 0.5f)
+DEFINE_TEST_2(test_with_limit_3, ChunkLevelRanges::small_chunks(), 1.0f)
+
+DEFINE_TEST_2(test_with_limit_4, ChunkLevelRanges::all_chunks(), 0.0f)
+DEFINE_TEST_2(test_with_limit_5, ChunkLevelRanges::all_chunks(), 0.5f)
+DEFINE_TEST_2(test_with_limit_6, ChunkLevelRanges::all_chunks(), 1.0f)
+
+
diff --git a/test/hotspot/gtest/metaspace/test_chunkManager_stress.cpp b/test/hotspot/gtest/metaspace/test_chunkManager_stress.cpp
new file mode 100644
--- /dev/null
+++ b/test/hotspot/gtest/metaspace/test_chunkManager_stress.cpp
@@ -0,0 +1,293 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+
+//#define LOG_PLEASE
+
+#include "metaspace/metaspace_sparsearray.hpp"
+#include "metaspace/metaspaceTestsCommon.hpp"
+#include "metaspace/metaspaceTestContexts.hpp"
+
+
+class ChunkManagerRandomChunkAllocTest {
+
+  static const size_t max_footprint_words = 8 * M;
+
+  ChunkTestsContext _helper;
+
+  // All allocated live chunks
+  typedef SparseArray<Metachunk*> SparseArrayOfChunks;
+  SparseArrayOfChunks _chunks;
+
+  const ChunkLevelRange _chunklevel_range;
+  const float _commit_factor;
+
+  // Depending on a probability pattern, come up with a reasonable limit to number of live chunks
+  static int max_num_live_chunks(ChunkLevelRange r, float commit_factor) {
+    // Assuming we allocate only the largest type of chunk, committed to the fullest commit factor,
+    // how many chunks can we accomodate before hitting max_footprint_words?
+    const size_t largest_chunk_size = word_size_for_level(r.lowest());
+    int max_chunks = (max_footprint_words * commit_factor) / largest_chunk_size;
+    // .. but cap at (min) 50 and (max) 1000
+    max_chunks = MIN2(1000, max_chunks);
+    max_chunks = MAX2(50, max_chunks);
+    return max_chunks;
+  }
+
+  // Return true if, after an allocation error happened, a reserve error seems likely.
+  bool could_be_reserve_error() {
+    return _helper.vslist().is_full();
+  }
+
+  // Return true if, after an allocation error happened, a commit error seems likely.
+  bool could_be_commit_error(size_t additional_word_size) {
+
+    // could it be commit limit hit?
+
+    if (Settings::new_chunks_are_fully_committed()) {
+      // For all we know we may have just failed to fully-commit a new root chunk.
+      additional_word_size = MAX_CHUNK_WORD_SIZE;
+    }
+
+    // Note that this is difficult to verify precisely, since there are
+    // several layers of truth:
+    // a) at the lowest layer (RootChunkArea) we have a bitmap of committed granules;
+    // b) at the vslist layer, we keep running counters of committed/reserved words;
+    // c) at the chunk layer, we keep a commit watermark (committed_words).
+    //
+    // (a) should mirror reality.
+    // (a) and (b) should be precisely in sync. This is tested by
+    // VirtualSpaceList::verify().
+    // (c) can be, by design, imprecise (too low).
+    //
+    // Here, I check (b) and trust it to be correct. We also call vslist::verify().
+    DEBUG_ONLY(_helper.verify();)
+
+    const size_t commit_add = align_up(additional_word_size, Settings::commit_granule_words());
+    if (_helper.commit_limit() <= (commit_add + _helper.vslist().committed_words())) {
+      return true;
+    }
+
+    return false;
+
+  }
+
+  // Given a chunk level and a factor, return a random commit size.
+  static size_t random_committed_words(chunklevel_t lvl, float commit_factor) {
+    const size_t sz = word_size_for_level(lvl) * commit_factor;
+    if (sz < 2) {
+      return 0;
+    }
+    return MIN2(SizeRange(sz).random_value(), sz);
+  }
+
+
+  //// Chunk allocation ////
+
+  // Given an slot index, allocate a random chunk and set it into that slot. Slot must be empty.
+  // Returns false if allocation fails.
+  bool allocate_random_chunk_at(int slot) {
+
+    DEBUG_ONLY(_chunks.check_slot_is_null(slot);)
+
+    const ChunkLevelRange r = _chunklevel_range.random_subrange();
+    const chunklevel_t pref_level = r.lowest();
+    const chunklevel_t max_level = r.highest();
+    const size_t min_committed = random_committed_words(max_level, _commit_factor);
+
+    Metachunk* c = NULL;
+    _helper.alloc_chunk(&c, r.lowest(), r.highest(), min_committed);
+    if (c == NULL) {
+      EXPECT_TRUE(could_be_reserve_error() ||
+                  could_be_commit_error(min_committed));
+      LOG("Alloc chunk at %d failed.", slot);
+      return false;
+    }
+
+    _chunks.set_at(slot, c);
+
+    LOG("Allocated chunk at %d: " METACHUNK_FORMAT ".", slot, METACHUNK_FORMAT_ARGS(c));
+
+    return true;
+
+  }
+
+  // Allocates a random number of random chunks
+  bool allocate_random_chunks() {
+    int to_alloc = 1 + IntRange(MAX2(1, _chunks.size() / 8)).random_value();
+    bool success = true;
+    int slot = _chunks.first_null_slot();
+    while (to_alloc > 0 && slot != -1 && success) {
+      success = allocate_random_chunk_at(slot);
+      slot = _chunks.next_null_slot(slot);
+      to_alloc --;
+    }
+    return success && to_alloc == 0;
+  }
+
+  bool fill_all_slots_with_random_chunks() {
+    bool success = true;
+    for (int slot = _chunks.first_null_slot();
+         slot != -1 && success; slot = _chunks.next_null_slot(slot)) {
+      success = allocate_random_chunk_at(slot);
+    }
+    return success;
+  }
+
+  //// Chunk return ////
+
+  // Given an slot index, return the chunk in that slot to the chunk manager.
+  void return_chunk_at(int slot) {
+    Metachunk* c = _chunks.at(slot);
+    LOG("Returning chunk at %d: " METACHUNK_FORMAT ".", slot, METACHUNK_FORMAT_ARGS(c));
+    _helper.return_chunk(c);
+    _chunks.set_at(slot, NULL);
+  }
+
+  // return a random number of chunks (at most a quarter of the full slot range)
+  void return_random_chunks() {
+    int to_free = 1 + IntRange(MAX2(1, _chunks.size() / 8)).random_value();
+    int index = _chunks.first_non_null_slot();
+    while (to_free > 0 && index != -1) {
+      return_chunk_at(index);
+      index = _chunks.next_non_null_slot(index);
+      to_free --;
+    }
+  }
+
+  void return_all_chunks() {
+    for (int slot = _chunks.first_non_null_slot();
+         slot != -1; slot = _chunks.next_non_null_slot(slot)) {
+      return_chunk_at(slot);
+    }
+  }
+
+  // adjust test if we change levels
+  STATIC_ASSERT(HIGHEST_CHUNK_LEVEL == CHUNK_LEVEL_1K);
+  STATIC_ASSERT(LOWEST_CHUNK_LEVEL == CHUNK_LEVEL_4M);
+
+  void one_test() {
+
+    fill_all_slots_with_random_chunks();
+    _chunks.shuffle();
+
+    IntRange rand(100);
+
+    for (int j = 0; j < 1000; j ++) {
+
+      bool force_alloc = false;
+      bool force_free = true;
+
+      bool do_alloc =
+          force_alloc ? true :
+              (force_free ? false : rand.random_value() >= 50);
+      force_alloc = force_free = false;
+
+      if (do_alloc) {
+        if (!allocate_random_chunks()) {
+          force_free = true;
+        }
+      } else {
+        return_random_chunks();
+      }
+
+      _chunks.shuffle();
+
+    }
+
+    return_all_chunks();
+
+  }
+
+
+public:
+
+  // A test with no limits
+  ChunkManagerRandomChunkAllocTest(ChunkLevelRange r, float commit_factor)
+    : _helper(),
+      _chunks(max_num_live_chunks(r, commit_factor)),
+      _chunklevel_range(r),
+      _commit_factor(commit_factor)
+  {}
+
+  // A test with no reserve limit but commit limit
+  ChunkManagerRandomChunkAllocTest(size_t commit_limit,
+                                   ChunkLevelRange r, float commit_factor)
+    : _helper(commit_limit),
+      _chunks(max_num_live_chunks(r, commit_factor)),
+      _chunklevel_range(r),
+      _commit_factor(commit_factor)
+  {}
+
+  // A test with both reserve and commit limit
+  // ChunkManagerRandomChunkAllocTest(size_t commit_limit, size_t reserve_limit,
+  //                                  ChunkLevelRange r, float commit_factor)
+  // : _helper(commit_limit, reserve_limit),
+  // _chunks(max_num_live_chunks(r, commit_factor)),
+  // _chunklevel_range(r),
+  // _commit_factor(commit_factor)
+  // {}
+
+
+  void do_tests() {
+    const int num_runs = 5;
+    for (int n = 0; n < num_runs; n ++) {
+      one_test();
+    }
+  }
+
+};
+
+#define DEFINE_TEST(name, range, commit_factor) \
+TEST_VM(metaspace, chunkmanager_random_alloc_##name) { \
+	ChunkManagerRandomChunkAllocTest test(range, commit_factor); \
+	test.do_tests(); \
+}
+
+DEFINE_TEST(test_nolimit_1, ChunkLevelRanges::small_chunks(), 0.0f)
+DEFINE_TEST(test_nolimit_2, ChunkLevelRanges::small_chunks(), 0.5f)
+DEFINE_TEST(test_nolimit_3, ChunkLevelRanges::small_chunks(), 1.0f)
+
+DEFINE_TEST(test_nolimit_4, ChunkLevelRanges::all_chunks(), 0.0f)
+DEFINE_TEST(test_nolimit_5, ChunkLevelRanges::all_chunks(), 0.5f)
+DEFINE_TEST(test_nolimit_6, ChunkLevelRanges::all_chunks(), 1.0f)
+
+#define DEFINE_TEST_2(name, range, commit_factor) \
+TEST_VM(metaspace, chunkmanager_random_alloc_##name) { \
+  const size_t commit_limit = 256 * K; \
+  ChunkManagerRandomChunkAllocTest test(commit_limit, range, commit_factor); \
+  test.do_tests(); \
+}
+
+DEFINE_TEST_2(test_with_limit_1, ChunkLevelRanges::small_chunks(), 0.0f)
+DEFINE_TEST_2(test_with_limit_2, ChunkLevelRanges::small_chunks(), 0.5f)
+DEFINE_TEST_2(test_with_limit_3, ChunkLevelRanges::small_chunks(), 1.0f)
+
+DEFINE_TEST_2(test_with_limit_4, ChunkLevelRanges::all_chunks(), 0.0f)
+DEFINE_TEST_2(test_with_limit_5, ChunkLevelRanges::all_chunks(), 0.5f)
+DEFINE_TEST_2(test_with_limit_6, ChunkLevelRanges::all_chunks(), 1.0f)
+
+
diff --git a/test/hotspot/gtest/metaspace/test_chunkheaderpool.cpp b/test/hotspot/gtest/metaspace/test_chunkheaderpool.cpp
new file mode 100644
--- /dev/null
+++ b/test/hotspot/gtest/metaspace/test_chunkheaderpool.cpp
@@ -0,0 +1,148 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+
+#include "metaspaceTestsCommon.hpp"
+
+class ChunkHeaderPoolTest {
+
+  static const size_t max_cap = 0x1000;
+
+  ChunkHeaderPool _pool;
+
+  // Array of the same size as the pool max capacity; holds the allocated elements.
+  Metachunk* _elems[max_cap];
+  SizeCounter _num_allocated;
+
+  void attempt_free_at(size_t index) {
+
+    LOG("attempt_free_at " SIZE_FORMAT ".", index);
+
+    if (_elems[index] == NULL) {
+      return;
+    }
+
+    _pool.return_chunk_header(_elems[index]);
+    _elems[index] = NULL;
+
+    _num_allocated.decrement();
+    DEBUG_ONLY(_num_allocated.check(_pool.used());)
+
+    DEBUG_ONLY(_pool.verify(true);)
+
+  }
+
+  void attempt_allocate_at(size_t index) {
+
+    LOG("attempt_allocate_at " SIZE_FORMAT ".", index);
+
+    if (_elems[index] != NULL) {
+      return;
+    }
+
+    Metachunk* c = _pool.allocate_chunk_header();
+    EXPECT_NOT_NULL(c);
+    _elems[index] = c;
+    c->set_free();
+
+    _num_allocated.increment();
+    DEBUG_ONLY(_num_allocated.check(_pool.used());)
+
+    DEBUG_ONLY(_pool.verify(true);)
+  }
+
+  void attempt_allocate_or_free_at(size_t index) {
+    if (_elems[index] == NULL) {
+      attempt_allocate_at(index);
+    } else {
+      attempt_free_at(index);
+    }
+  }
+
+  // Randomly allocate from the pool and free. Slight preference for allocation.
+  void test_random_alloc_free(int num_iterations) {
+
+    for (int iter = 0; iter < num_iterations; iter ++) {
+      size_t index = (size_t)os::random() % max_cap;
+      attempt_allocate_or_free_at(index);
+    }
+
+    DEBUG_ONLY(_pool.verify(true);)
+
+  }
+
+  static void test_once() {
+    ChunkHeaderPoolTest test;
+    test.test_random_alloc_free(100);
+  }
+
+
+public:
+
+  ChunkHeaderPoolTest() : _pool() {
+    memset(_elems, 0, sizeof(_elems));
+  }
+
+  static void run_tests() {
+    for (int i = 0; i < 1000; i ++) {
+      test_once();
+    }
+  }
+
+};
+
+TEST_VM(metaspace, chunk_header_pool_basics) {
+
+  ChunkHeaderPool pool;
+  EXPECT_EQ(pool.used(), (int)0);
+  EXPECT_EQ(pool.freelist_size(), (int)0);
+
+  Metachunk* header = pool.allocate_chunk_header();
+  EXPECT_NOT_NULL(header);
+  EXPECT_EQ(pool.used(), 1);
+  EXPECT_EQ(pool.freelist_size(), (int)0);
+
+  header->set_free();
+  pool.return_chunk_header(header);
+  EXPECT_EQ(pool.used(), (int)0);
+  EXPECT_EQ(pool.freelist_size(), 1);
+
+  header = pool.allocate_chunk_header();
+  EXPECT_NOT_NULL(header);
+  EXPECT_EQ(pool.used(), 1);
+  EXPECT_EQ(pool.freelist_size(), (int)0);
+
+  header->set_free();
+  pool.return_chunk_header(header);
+  EXPECT_EQ(pool.used(), (int)0);
+  EXPECT_EQ(pool.freelist_size(), 1);
+
+}
+
+
+TEST_VM(metaspace, chunk_header_pool) {
+  ChunkHeaderPoolTest::run_tests();
+}
diff --git a/test/hotspot/gtest/metaspace/test_commitmask.cpp b/test/hotspot/gtest/metaspace/test_commitmask.cpp
new file mode 100644
--- /dev/null
+++ b/test/hotspot/gtest/metaspace/test_commitmask.cpp
@@ -0,0 +1,346 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+#include "runtime/os.hpp"
+
+#include "metaspaceTestsCommon.hpp"
+#include "metaspace/metaspace_rangehelpers.hpp"
+
+static int get_random(int limit) { return os::random() % limit; }
+
+class CommitMaskTest {
+  const MetaWord* const _base;
+  const size_t _word_size;
+
+  CommitMask _mask;
+
+  void verify_mask() {
+    // Note: we omit the touch test since we operate on fictional
+    // memory
+    DEBUG_ONLY(_mask.verify(false);)
+  }
+
+  // Return a random sub range within [_base.._base + word_size),
+  // aligned to granule size
+  const MetaWord* calc_random_subrange(size_t* p_word_size) {
+    size_t l1 = get_random((int)_word_size);
+    size_t l2 = get_random((int)_word_size);
+    if (l1 > l2) {
+      size_t l = l1;
+      l1 = l2;
+      l2 = l;
+    }
+    l1 = align_down(l1, Settings::commit_granule_words());
+    l2 = align_up(l2, Settings::commit_granule_words());
+
+    const MetaWord* p = _base + l1;
+    const size_t len = l2 - l1;
+
+    assert(p >= _base && p + len <= _base + _word_size,
+           "Sanity");
+    *p_word_size = len;
+
+    return p;
+  }
+
+  void test1() {
+
+    LOG("test1");
+
+    // Commit everything
+    size_t prior_committed = _mask.mark_range_as_committed(_base, _word_size);
+    verify_mask();
+    ASSERT_LE(prior_committed, _word_size); // We do not really know
+
+    // Commit everything again, should be a noop
+    prior_committed = _mask.mark_range_as_committed(_base, _word_size);
+    verify_mask();
+    ASSERT_EQ(prior_committed, _word_size);
+
+    ASSERT_EQ(_mask.get_committed_size(),
+              _word_size);
+    ASSERT_EQ(_mask.get_committed_size_in_range(_base, _word_size),
+              _word_size);
+
+    for (const MetaWord* p = _base; p < _base + _word_size; p ++) {
+      ASSERT_TRUE(_mask.is_committed_address(p));
+    }
+
+    // Now make an uncommitted hole
+    size_t sr_word_size;
+    const MetaWord* sr_base = calc_random_subrange(&sr_word_size);
+    LOG("subrange " PTR_FORMAT "-" PTR_FORMAT ".",
+        p2i(sr_base), p2i(sr_base + sr_word_size));
+
+    size_t prior_uncommitted =
+        _mask.mark_range_as_uncommitted(sr_base, sr_word_size);
+    verify_mask();
+    ASSERT_EQ(prior_uncommitted, (size_t)0);
+
+    // Again, for fun, should be a noop now.
+    prior_uncommitted = _mask.mark_range_as_uncommitted(sr_base, sr_word_size);
+    verify_mask();
+    ASSERT_EQ(prior_uncommitted, sr_word_size);
+
+    ASSERT_EQ(_mask.get_committed_size_in_range(sr_base, sr_word_size),
+              (size_t)0);
+    ASSERT_EQ(_mask.get_committed_size(),
+              _word_size - sr_word_size);
+    ASSERT_EQ(_mask.get_committed_size_in_range(_base, _word_size),
+              _word_size - sr_word_size);
+    for (const MetaWord* p = _base; p < _base + _word_size; p ++) {
+      if (p >= sr_base && p < sr_base + sr_word_size) {
+        ASSERT_FALSE(_mask.is_committed_address(p));
+      } else {
+        ASSERT_TRUE(_mask.is_committed_address(p));
+      }
+    }
+
+    // Recommit whole range
+    prior_committed = _mask.mark_range_as_committed(_base, _word_size);
+    verify_mask();
+    ASSERT_EQ(prior_committed, _word_size - sr_word_size);
+
+    ASSERT_EQ(_mask.get_committed_size_in_range(sr_base, sr_word_size),
+              sr_word_size);
+    ASSERT_EQ(_mask.get_committed_size(),
+              _word_size);
+    ASSERT_EQ(_mask.get_committed_size_in_range(_base, _word_size),
+              _word_size);
+    for (const MetaWord* p = _base; p < _base + _word_size; p ++) {
+      ASSERT_TRUE(_mask.is_committed_address(p));
+    }
+
+  }
+
+  void test2() {
+
+    LOG("test2");
+
+    // Uncommit everything
+    size_t prior_uncommitted = _mask.mark_range_as_uncommitted(_base, _word_size);
+    verify_mask();
+    ASSERT_LE(prior_uncommitted, _word_size);
+
+    // Uncommit everything again, should be a noop
+    prior_uncommitted = _mask.mark_range_as_uncommitted(_base, _word_size);
+    verify_mask();
+    ASSERT_EQ(prior_uncommitted, _word_size);
+
+    ASSERT_EQ(_mask.get_committed_size(),
+        (size_t)0);
+    ASSERT_EQ(_mask.get_committed_size_in_range(_base, _word_size),
+        (size_t)0);
+
+    // Now make an committed region
+    size_t sr_word_size;
+    const MetaWord* sr_base = calc_random_subrange(&sr_word_size);
+    LOG("subrange " PTR_FORMAT "-" PTR_FORMAT ".",
+        p2i(sr_base), p2i(sr_base + sr_word_size));
+
+    ASSERT_EQ(_mask.get_committed_size_in_range(sr_base, sr_word_size),
+              (size_t)0);
+    for (const MetaWord* p = _base; p < _base + _word_size; p ++) {
+      ASSERT_FALSE(_mask.is_committed_address(p));
+    }
+
+    size_t prior_committed = _mask.mark_range_as_committed(sr_base, sr_word_size);
+    verify_mask();
+    ASSERT_EQ(prior_committed, (size_t)0);
+
+    // Again, for fun, should be a noop now.
+    prior_committed = _mask.mark_range_as_committed(sr_base, sr_word_size);
+    verify_mask();
+    ASSERT_EQ(prior_committed, sr_word_size);
+
+    ASSERT_EQ(_mask.get_committed_size_in_range(sr_base, sr_word_size),
+        sr_word_size);
+    ASSERT_EQ(_mask.get_committed_size(),
+        sr_word_size);
+    ASSERT_EQ(_mask.get_committed_size_in_range(_base, _word_size),
+        sr_word_size);
+    for (const MetaWord* p = _base; p < _base + _word_size; p ++) {
+      if (p >= sr_base && p < sr_base + sr_word_size) {
+        ASSERT_TRUE(_mask.is_committed_address(p));
+      } else {
+        ASSERT_FALSE(_mask.is_committed_address(p));
+      }
+    }
+
+    // Re-uncommit whole range
+    prior_uncommitted = _mask.mark_range_as_uncommitted(_base, _word_size);
+    verify_mask();
+    ASSERT_EQ(prior_uncommitted, _word_size - sr_word_size);
+
+    EXPECT_EQ(_mask.get_committed_size_in_range(sr_base, sr_word_size),
+        (size_t)0);
+    EXPECT_EQ(_mask.get_committed_size(),
+        (size_t)0);
+    EXPECT_EQ(_mask.get_committed_size_in_range(_base, _word_size),
+        (size_t)0);
+    for (const MetaWord* p = _base; p < _base + _word_size; p ++) {
+      ASSERT_FALSE(_mask.is_committed_address(p));
+    }
+
+  }
+
+
+  void test3() {
+
+    // arbitrary ranges are set and cleared and compared with the test map
+    TestMap map(_word_size);
+
+    _mask.clear_large();
+
+    for (int run = 0; run < 100; run ++) {
+
+      // A random range
+      SizeRange r = SizeRange(_word_size).random_aligned_subrange(Settings::commit_granule_words());
+
+      if (os::random() % 100 < 50) {
+        _mask.mark_range_as_committed(_base + r.lowest(), r.size());
+        map.set_range(r.lowest(), r.end());
+      } else {
+        _mask.mark_range_as_uncommitted(_base + r.lowest(), r.size());
+        map.clear_range(r.lowest(), r.end());
+      }
+
+      ASSERT_EQ(_mask.get_committed_size(), (size_t)map.get_num_set());
+
+      ASSERT_EQ(_mask.get_committed_size_in_range(_base + r.lowest(), r.size()),
+                (size_t)map.get_num_set(r.lowest(), r.end()));
+
+    }
+
+  }
+
+
+public:
+
+  CommitMaskTest(const MetaWord* base, size_t size)
+    : _base(base), _word_size(size), _mask(base, size)
+  {}
+
+  void test() {
+    LOG("mask range: " PTR_FORMAT "-" PTR_FORMAT
+         " (" SIZE_FORMAT " words).",
+         p2i(_base), p2i(_base + _word_size), _word_size);
+    for (int i = 0; i < 5; i ++) {
+      test1(); test2(); test3();
+    }
+  }
+
+
+};
+
+TEST_VM(metaspace, commit_mask_basics) {
+
+  const MetaWord* const base = (const MetaWord*) 0x100000;
+
+  CommitMask mask1(base, Settings::commit_granule_words());
+  ASSERT_EQ(mask1.size(), (BitMap::idx_t)1);
+
+  CommitMask mask2(base, Settings::commit_granule_words() * 4);
+  ASSERT_EQ(mask2.size(), (BitMap::idx_t)4);
+
+  CommitMask mask3(base, Settings::commit_granule_words() * 43);
+  ASSERT_EQ(mask3.size(), (BitMap::idx_t)43);
+
+  mask3.mark_range_as_committed(base, Settings::commit_granule_words());
+  mask3.mark_range_as_committed(base + (Settings::commit_granule_words() * 42), Settings::commit_granule_words());
+
+  ASSERT_EQ(mask3.at(0), 1);
+  for (int i = 1; i < 42; i ++) {
+    ASSERT_EQ(mask3.at(i), 0);
+  }
+  ASSERT_EQ(mask3.at(42), 1);
+
+}
+
+TEST_VM(metaspace, commit_mask_small) {
+
+  const MetaWord* const base = (const MetaWord*) 0x100000;
+
+  CommitMaskTest test(base, Settings::commit_granule_words());
+  test.test();
+
+}
+
+TEST_VM(metaspace, commit_mask_range) {
+
+  const MetaWord* const base = (const MetaWord*) 0x100000;
+  const size_t len = Settings::commit_granule_words() * 4;
+  const MetaWord* const end = base + len;
+  CommitMask mask(base, len);
+
+  LOG("total range: " PTR_FORMAT "-" PTR_FORMAT "\n", p2i(base), p2i(end));
+
+  size_t l = mask.mark_range_as_committed(base, len);
+  ASSERT_LE(l, len);
+
+  for (const MetaWord* p = base; p <= end - Settings::commit_granule_words();
+       p += Settings::commit_granule_words()) {
+    for (const MetaWord* p2 = p + Settings::commit_granule_words();
+         p2 <= end; p2 += Settings::commit_granule_words()) {
+      LOG(PTR_FORMAT "-" PTR_FORMAT "\n", p2i(p), p2i(p2));
+      EXPECT_EQ(mask.get_committed_size_in_range(p, p2 - p),
+                (size_t)(p2 - p));
+    }
+  }
+
+  l = mask.mark_range_as_uncommitted(base, len);
+  ASSERT_EQ(l, (size_t)0);
+
+  for (const MetaWord* p = base; p <= end - Settings::commit_granule_words();
+       p += Settings::commit_granule_words()) {
+    for (const MetaWord* p2 = p + Settings::commit_granule_words();
+         p2 <= end; p2 += Settings::commit_granule_words()) {
+      LOG(PTR_FORMAT "-" PTR_FORMAT "\n", p2i(p), p2i(p2));
+      EXPECT_EQ(mask.get_committed_size_in_range(p, p2 - p),
+                (size_t)(0));
+    }
+  }
+
+}
+
+
+TEST_VM(metaspace, commit_mask_random) {
+
+  for (int i = 0; i < 5; i ++) {
+
+    // make up a range out of thin air
+    const MetaWord* const base =
+        align_down( (const MetaWord*) ((uintptr_t) os::random() * os::random()),
+                    Settings::commit_granule_bytes());
+    const size_t len = align_up( 1 + (os::random() % M),
+                    Settings::commit_granule_words());
+
+    CommitMaskTest test(base, len);
+    test.test();
+
+  }
+
+}
diff --git a/test/hotspot/gtest/metaspace/test_freeblocks.cpp b/test/hotspot/gtest/metaspace/test_freeblocks.cpp
new file mode 100644
--- /dev/null
+++ b/test/hotspot/gtest/metaspace/test_freeblocks.cpp
@@ -0,0 +1,232 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+
+//#define LOG_PLEASE
+
+#include "metaspaceTestsCommon.hpp"
+
+#define CHECK_CONTENT(fb, num_blocks_expected, word_size_expected) \
+{ \
+  if (word_size_expected > 0) { \
+    EXPECT_FALSE(fb.is_empty()); \
+  } else { \
+    EXPECT_TRUE(fb.is_empty()); \
+  } \
+  EXPECT_EQ(fb.total_size(), (size_t)word_size_expected); \
+  EXPECT_EQ(fb.count(), (int)num_blocks_expected); \
+}
+
+class FreeBlocksTest {
+
+  FeederBuffer _fb;
+  FreeBlocks _freeblocks;
+
+  // random generator for block feeding
+  RandSizeGenerator _rgen_feeding;
+
+  // random generator for allocations (and, hence, deallocations)
+  RandSizeGenerator _rgen_allocations;
+
+  SizeCounter _allocated_words;
+
+  struct allocation_t {
+    allocation_t* next;
+    size_t word_size;
+    MetaWord* p;
+  };
+
+  // Array of the same size as the pool max capacity; holds the allocated elements.
+  allocation_t* _allocations;
+
+  int _num_allocs;
+  int _num_deallocs;
+  int _num_feeds;
+
+  bool feed_some() {
+    size_t word_size = _rgen_feeding.get();
+    MetaWord* p = _fb.get(word_size);
+    if (p != NULL) {
+      _freeblocks.add_block(p, word_size);
+      return true;
+    }
+    return false;
+  }
+
+  void deallocate_top() {
+
+    allocation_t* a = _allocations;
+    if (a != NULL) {
+      _allocations = a->next;
+      check_marked_range(a->p, a->word_size);
+      _freeblocks.add_block(a->p, a->word_size);
+      delete a;
+      DEBUG_ONLY(_freeblocks.verify();)
+    }
+  }
+
+  bool allocate() {
+
+    size_t word_size = MAX2(_rgen_allocations.get(), _freeblocks.minimal_word_size);
+    MetaWord* p = _freeblocks.get_block(word_size);
+    if (p != NULL) {
+      _allocated_words.increment_by(word_size);
+      allocation_t* a = new allocation_t;
+      a->p = p; a->word_size = word_size;
+      a->next = _allocations;
+      _allocations = a;
+      DEBUG_ONLY(_freeblocks.verify();)
+      mark_range(p, word_size);
+      return true;
+    }
+    return false;
+  }
+
+  void test_all_marked_ranges() {
+    for (allocation_t* a = _allocations; a != NULL; a = a->next) {
+      check_marked_range(a->p, a->word_size);
+    }
+  }
+
+  void test_loop() {
+    // We loop and in each iteration execute one of three operations:
+    // - allocation from lom
+    // - deallocation to lom of a previously allocated block
+    // - feeding a new larger block into the lom (mimicks chunk retiring)
+    // When we have fed all large blocks into the lom (feedbuffer empty), we
+    //  switch to draining the lom completely (only allocs)
+    bool forcefeed = false;
+    bool draining = false;
+    bool stop = false;
+    int iter = 100000; // safety stop
+    while (!stop && iter > 0) {
+      iter --;
+      int surprise = (int)os::random() % 10;
+      if (!draining && (surprise >= 7 || forcefeed)) {
+        forcefeed = false;
+        if (feed_some()) {
+          _num_feeds ++;
+        } else {
+          // We fed all input memory into the LOM. Now lets proceed until the lom is drained.
+          draining = true;
+        }
+      } else if (!draining && surprise < 1) {
+        deallocate_top();
+        _num_deallocs ++;
+      } else {
+        if (allocate()) {
+          _num_allocs ++;
+        } else {
+          if (draining) {
+            stop = _freeblocks.total_size() < 512;
+          } else {
+            forcefeed = true;
+          }
+        }
+      }
+      if ((iter % 1000) == 0) {
+        DEBUG_ONLY(_freeblocks.verify();)
+        test_all_marked_ranges();
+        LOG("a %d (" SIZE_FORMAT "), d %d, f %d", _num_allocs, _allocated_words.get(), _num_deallocs, _num_feeds);
+#ifdef LOG_PLEASE
+        _freeblocks.print(tty, true);
+        tty->cr();
+#endif
+      }
+    }
+
+    // Drain
+
+
+  }
+
+
+
+public:
+
+  FreeBlocksTest(size_t avg_alloc_size) :
+    _fb(512 * K), _freeblocks(),
+    _rgen_feeding(128, 4096),
+    _rgen_allocations(avg_alloc_size / 4, avg_alloc_size * 2, 0.01f, avg_alloc_size / 3, avg_alloc_size * 30),
+    _allocations(NULL),
+    _num_allocs(0), _num_deallocs(0), _num_feeds(0)
+  {
+    CHECK_CONTENT(_freeblocks, 0, 0);
+    // some initial feeding
+    _freeblocks.add_block(_fb.get(1024), 1024);
+    CHECK_CONTENT(_freeblocks, 1, 1024);
+  }
+
+
+  static void test_small_allocations() {
+    FreeBlocksTest test(10);
+    test.test_loop();
+  }
+
+  static void test_medium_allocations() {
+    FreeBlocksTest test(30);
+    test.test_loop();
+  }
+
+  static void test_large_allocations() {
+    FreeBlocksTest test(150);
+    test.test_loop();
+  }
+
+
+};
+
+
+TEST_VM(metaspace, freeblocks_basics) {
+
+  FreeBlocks lom;
+  MetaWord tmp[1024];
+  CHECK_CONTENT(lom, 0, 0);
+
+  lom.add_block(tmp, 1024);
+  DEBUG_ONLY(lom.verify();)
+  ASSERT_FALSE(lom.is_empty());
+  CHECK_CONTENT(lom, 1, 1024);
+
+  MetaWord* p = lom.get_block(1024);
+  EXPECT_EQ(p, tmp);
+  DEBUG_ONLY(lom.verify();)
+  CHECK_CONTENT(lom, 0, 0);
+
+}
+
+TEST_VM(metaspace, freeblocks_small) {
+  FreeBlocksTest::test_small_allocations();
+}
+
+TEST_VM(metaspace, freeblocks_medium) {
+  FreeBlocksTest::test_medium_allocations();
+}
+
+TEST_VM(metaspace, freeblocks_large) {
+  FreeBlocksTest::test_large_allocations();
+}
+
diff --git a/test/hotspot/gtest/metaspace/test_internstats.cpp b/test/hotspot/gtest/metaspace/test_internstats.cpp
new file mode 100644
--- /dev/null
+++ b/test/hotspot/gtest/metaspace/test_internstats.cpp
@@ -0,0 +1,45 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+
+//#define LOG_PLEASE
+
+#include "metaspaceTestsCommon.hpp"
+#include "memory/metaspace/internStat.hpp"
+
+// Very simple test, since the VM is fired up we should see a little
+// Metaspace activity already which should show up in the stats.
+TEST_VM(metaspace, internstats) {
+
+  DEBUG_ONLY(ASSERT_GT(metaspace::InternalStats::num_allocs(), (uint64_t)0);)
+
+  ASSERT_GT(metaspace::InternalStats::num_arena_births(), (uint64_t)0);
+  ASSERT_GT(metaspace::InternalStats::num_vsnodes_births(), (uint64_t)0);
+  ASSERT_GT(metaspace::InternalStats::num_space_committed(), (uint64_t)0);
+  ASSERT_GT(metaspace::InternalStats::num_chunks_taken_from_freelist(), (uint64_t)0);
+
+}
+
diff --git a/test/hotspot/gtest/metaspace/test_is_metaspace_obj.cpp b/test/hotspot/gtest/metaspace/test_is_metaspace_obj.cpp
new file mode 100644
--- /dev/null
+++ b/test/hotspot/gtest/metaspace/test_is_metaspace_obj.cpp
@@ -0,0 +1,114 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+
+#include "memory/allocation.inline.hpp"
+#include "memory/metaspace.hpp"
+#include "memory/metaspace/virtualSpaceList.hpp"
+#include "runtime/mutex.hpp"
+#include "runtime/mutexLocker.hpp"
+#include "runtime/os.hpp"
+#include "unittest.hpp"
+
+using namespace metaspace;
+
+
+
+// Test the cheerful multitude of metaspace-contains-functions.
+class MetaspaceIsMetaspaceObjTest {
+  Mutex* _lock;
+  ClassLoaderMetaspace* _ms;
+
+public:
+
+  MetaspaceIsMetaspaceObjTest() : _lock(NULL), _ms(NULL) {}
+  ~MetaspaceIsMetaspaceObjTest() {
+    delete _ms;
+    delete _lock;
+  }
+
+  void do_test(Metaspace::MetadataType mdType) {
+    _lock = new Mutex(Monitor::native, "gtest-IsMetaspaceObjTest-lock", false, Monitor::_safepoint_check_never);
+    {
+      MutexLocker ml(_lock, Mutex::_no_safepoint_check_flag);
+      _ms = new ClassLoaderMetaspace(_lock, Metaspace::StandardMetaspaceType);
+    }
+
+    const MetaspaceObj* p = (MetaspaceObj*) _ms->allocate(42, mdType);
+
+    // Test MetaspaceObj::is_metaspace_object
+    ASSERT_TRUE(MetaspaceObj::is_valid(p));
+
+    // A misaligned object shall not be recognized
+    const MetaspaceObj* p_misaligned = (MetaspaceObj*)((address)p) + 1;
+    ASSERT_FALSE(MetaspaceObj::is_valid(p_misaligned));
+
+    // Test VirtualSpaceList::contains
+    const VirtualSpaceList* const vslist =
+        (mdType == Metaspace::ClassType && Metaspace::using_class_space()) ?
+         VirtualSpaceList::vslist_class() : VirtualSpaceList::vslist_nonclass();
+
+    ASSERT_TRUE(vslist->contains((MetaWord*)p));
+
+    // A misaligned pointer shall still be recognized by list::contains
+    ASSERT_TRUE(vslist->contains((MetaWord*)((address)p) + 1));
+
+    // Now for some bogus values
+    ASSERT_FALSE(MetaspaceObj::is_valid((MetaspaceObj*)NULL));
+
+    // Should exercise various paths in MetaspaceObj::is_valid()
+    ASSERT_FALSE(MetaspaceObj::is_valid((MetaspaceObj*)1024));
+    ASSERT_FALSE(MetaspaceObj::is_valid((MetaspaceObj*)8192));
+
+    MetaspaceObj* p_stack = (MetaspaceObj*) &_lock;
+    ASSERT_FALSE(MetaspaceObj::is_valid(p_stack));
+
+    MetaspaceObj* p_heap = (MetaspaceObj*) os::malloc(41, mtInternal);
+    ASSERT_FALSE(MetaspaceObj::is_valid(p_heap));
+    os::free(p_heap);
+
+    // Test Metaspace::contains_xxx
+    ASSERT_TRUE(Metaspace::contains(p));
+    ASSERT_TRUE(Metaspace::contains_non_shared(p));
+
+    delete _ms;
+    _ms = NULL;
+    delete _lock;
+    _lock = NULL;
+  }
+
+};
+
+TEST_VM(metaspace, is_metaspace_obj_non_class) {
+  MetaspaceIsMetaspaceObjTest test;
+  test.do_test(Metaspace::NonClassType);
+}
+
+TEST_VM(metaspace, is_metaspace_obj_class) {
+  MetaspaceIsMetaspaceObjTest test;
+  test.do_test(Metaspace::ClassType);
+}
+
diff --git a/test/hotspot/gtest/metaspace/test_metachunk.cpp b/test/hotspot/gtest/metaspace/test_metachunk.cpp
new file mode 100644
--- /dev/null
+++ b/test/hotspot/gtest/metaspace/test_metachunk.cpp
@@ -0,0 +1,412 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+#include "metaspace/metaspaceTestsCommon.hpp"
+#include "metaspace/metaspaceTestContexts.hpp"
+#include "runtime/mutexLocker.hpp"
+
+using namespace metaspace::chunklevel;
+
+// Test ChunkManager::get_chunk
+TEST_VM(metaspace, get_chunk) {
+
+  ChunkTestsContext helper(8 * M);
+  Metachunk* c = NULL;
+
+  for (chunklevel_t pref_lvl = LOWEST_CHUNK_LEVEL; pref_lvl <= HIGHEST_CHUNK_LEVEL; pref_lvl ++) {
+
+    for (chunklevel_t max_lvl = pref_lvl; max_lvl <= HIGHEST_CHUNK_LEVEL; max_lvl ++) {
+
+      for (size_t min_committed_words = Settings::commit_granule_words();
+           min_committed_words <= word_size_for_level(max_lvl); min_committed_words *= 2) {
+        helper.alloc_chunk_expect_success(&c, pref_lvl, max_lvl, min_committed_words);
+        helper.return_chunk(c);
+      }
+    }
+  }
+}
+
+// Test ChunkManager::get_chunk, but with a commit limit.
+TEST_VM(metaspace, get_chunk_with_commit_limit) {
+
+  const size_t commit_limit_words = 1 * M;
+  ChunkTestsContext helper(commit_limit_words);
+  Metachunk* c = NULL;
+
+  for (chunklevel_t pref_lvl = LOWEST_CHUNK_LEVEL; pref_lvl <= HIGHEST_CHUNK_LEVEL; pref_lvl ++) {
+
+    for (chunklevel_t max_lvl = pref_lvl; max_lvl <= HIGHEST_CHUNK_LEVEL; max_lvl ++) {
+
+      for (size_t min_committed_words = Settings::commit_granule_words();
+           min_committed_words <= word_size_for_level(max_lvl); min_committed_words *= 2) {
+
+        if (min_committed_words <= commit_limit_words) {
+          helper.alloc_chunk_expect_success(&c, pref_lvl, max_lvl, min_committed_words);
+          helper.return_chunk(c);
+        } else {
+          helper.alloc_chunk_expect_failure(pref_lvl, max_lvl, min_committed_words);
+        }
+
+      }
+    }
+  }
+}
+
+// Test that recommitting the used portion of a chunk will preserve the original content.
+TEST_VM(metaspace, get_chunk_recommit) {
+
+  ChunkTestsContext helper;
+  Metachunk* c = NULL;
+  helper.alloc_chunk_expect_success(&c, ROOT_CHUNK_LEVEL, ROOT_CHUNK_LEVEL, 0);
+  helper.uncommit_chunk_with_test(c);
+
+  helper.commit_chunk_with_test(c, Settings::commit_granule_words());
+  helper.allocate_from_chunk(c, Settings::commit_granule_words());
+
+  c->ensure_committed(Settings::commit_granule_words());
+  check_range_for_pattern(c->base(), c->used_words(), (uintx)c);
+
+  c->ensure_committed(Settings::commit_granule_words() * 2);
+  check_range_for_pattern(c->base(), c->used_words(), (uintx)c);
+
+  helper.return_chunk(c);
+
+}
+
+// Test ChunkManager::get_chunk, but with a reserve limit.
+// (meaning, the underlying VirtualSpaceList cannot expand, like compressed class space).
+TEST_VM(metaspace, get_chunk_with_reserve_limit) {
+
+  const size_t reserve_limit_words = word_size_for_level(ROOT_CHUNK_LEVEL);
+  const size_t commit_limit_words = 1024 * M; // just very high
+  ChunkTestsContext helper(commit_limit_words, reserve_limit_words);
+
+  // Reserve limit works at root chunk size granularity: if the chunk manager cannot satisfy
+  //  a request for a chunk from its freelists, it will acquire a new root chunk from the
+  //  underlying virtual space list. If that list is full and cannot be expanded (think ccs)
+  //  we should get an error.
+  // Testing this is simply testing a chunk allocation which should cause allocation of a new
+  //  root chunk.
+
+  // Cause allocation of the firstone root chunk, should still work:
+  Metachunk* c = NULL;
+  helper.alloc_chunk_expect_success(&c, HIGHEST_CHUNK_LEVEL);
+
+  // and this should need a new root chunk and hence fail:
+  helper.alloc_chunk_expect_failure(ROOT_CHUNK_LEVEL);
+
+  helper.return_chunk(c);
+
+}
+
+// Test MetaChunk::allocate
+TEST_VM(metaspace, chunk_allocate_full) {
+
+  ChunkTestsContext helper;
+
+  for (chunklevel_t lvl = LOWEST_CHUNK_LEVEL; lvl <= HIGHEST_CHUNK_LEVEL; lvl ++) {
+    Metachunk* c = NULL;
+    helper.alloc_chunk_expect_success(&c, lvl);
+    helper.allocate_from_chunk(c, c->word_size());
+    helper.return_chunk(c);
+  }
+
+}
+
+// Test MetaChunk::allocate
+TEST_VM(metaspace, chunk_allocate_random) {
+
+  ChunkTestsContext helper;
+
+  for (chunklevel_t lvl = LOWEST_CHUNK_LEVEL; lvl <= HIGHEST_CHUNK_LEVEL; lvl ++) {
+
+    Metachunk* c = NULL;
+    helper.alloc_chunk_expect_success(&c, lvl);
+    helper.uncommit_chunk_with_test(c); // start out fully uncommitted
+
+    RandSizeGenerator rgen(1, c->word_size() / 30);
+    bool stop = false;
+
+    while (!stop) {
+      const size_t s = rgen.get();
+      if (s <= c->free_words()) {
+        helper.commit_chunk_with_test(c, s);
+        helper.allocate_from_chunk(c, s);
+      } else {
+        stop = true;
+      }
+
+    }
+    helper.return_chunk(c);
+
+  }
+
+}
+
+TEST_VM(metaspace, chunk_buddy_stuff) {
+
+  for (chunklevel_t l = ROOT_CHUNK_LEVEL + 1; l <= HIGHEST_CHUNK_LEVEL; l ++) {
+
+    ChunkTestsContext helper;
+
+    // Allocate two chunks; since we know the first chunk is the first in its area,
+    // it has to be a leader, and the next one of the same size its buddy.
+
+    // (Note: strictly speaking the ChunkManager does not promise any placement but
+    //  we know how the placement works so these tests make sense).
+
+    Metachunk* c1 = NULL;
+    helper.alloc_chunk(&c1, CHUNK_LEVEL_1K);
+    EXPECT_TRUE(c1->is_leader());
+
+    Metachunk* c2 = NULL;
+    helper.alloc_chunk(&c2, CHUNK_LEVEL_1K);
+    EXPECT_FALSE(c2->is_leader());
+
+    // buddies are adjacent in memory
+    // (next/prev_in_vs needs lock)
+    {
+      MutexLocker fcl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
+      EXPECT_EQ(c1->next_in_vs(), c2);
+      EXPECT_EQ(c1->end(), c2->base());
+      EXPECT_NULL(c1->prev_in_vs()); // since we know this is the first in the area
+      EXPECT_EQ(c2->prev_in_vs(), c1);
+    }
+
+    helper.return_chunk(c1);
+    helper.return_chunk(c2);
+
+  }
+
+}
+
+
+TEST_VM(metaspace, chunk_allocate_with_commit_limit) {
+
+  // This test does not make sense if commit-on-demand is off
+  if (Settings::new_chunks_are_fully_committed()) {
+    return;
+  }
+
+  const size_t granule_sz = Settings::commit_granule_words();
+  const size_t commit_limit = granule_sz * 3;
+  ChunkTestsContext helper(commit_limit);
+
+  // A big chunk, but uncommitted.
+  Metachunk* c = NULL;
+  helper.alloc_chunk_expect_success(&c, ROOT_CHUNK_LEVEL, ROOT_CHUNK_LEVEL, 0);
+  helper.uncommit_chunk_with_test(c); // ... just to make sure.
+
+  // first granule...
+  helper.commit_chunk_with_test(c, granule_sz);
+  helper.allocate_from_chunk(c, granule_sz);
+
+  // second granule...
+  helper.commit_chunk_with_test(c, granule_sz);
+  helper.allocate_from_chunk(c, granule_sz);
+
+  // third granule...
+  helper.commit_chunk_with_test(c, granule_sz);
+  helper.allocate_from_chunk(c, granule_sz);
+
+  // This should fail now.
+  helper.commit_chunk_expect_failure(c, granule_sz);
+
+  helper.return_chunk(c);
+
+}
+
+// Test splitting a chunk
+TEST_VM(metaspace, chunk_split_and_merge) {
+
+  // Split works like this:
+  //
+  //  ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ----
+  // |                                  A                                            |
+  //  ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ----
+  //
+  //  ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ----
+  // | A' | b  |    c    |         d         |                   e                   |
+  //  ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ----
+  //
+  // A original chunk (A) is split to form a target chunk (A') and as a result splinter
+  // chunks form (b..e). A' is the leader of the (A',b) pair, which is the leader of the
+  // ((A',b), c) pair and so on. In other words, A' will be a leader chunk, all splinter
+  // chunks are follower chunks.
+  //
+  // Merging reverses this operation:
+  //
+  //  ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ----
+  // | A  | b  |    c    |         d         |                   e                   |
+  //  ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ----
+  //
+  //  ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ----
+  // |                                  A'                                           |
+  //  ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ----
+  //
+  // (A) will be merged with its buddy b, (A+b) with its buddy c and so on. The result
+  // chunk is A'.
+  // Note that merging also works, of course, if we were to start the merge at (b) (so,
+  // with a follower chunk, not a leader). Also, at any point in the merge
+  // process we may arrive at a follower chunk. So, the fact that in this test
+  // we only expect a leader merge is a feature of the test, and of the fact that we
+  // start each split test with a fresh MetaspaceTestHelper.
+
+  // Note: Splitting and merging chunks is usually done from within the ChunkManager and
+  //  subject to a lot of assumptions and hence asserts. Here, we have to explicitly use
+  //  VirtualSpaceNode::split/::merge and therefore have to observe rules:
+  // - both split and merge expect free chunks, so state has to be "free"
+  // - but that would trigger the "ideally merged" assertion in the RootChunkArea, so the
+  //   original chunk has to be a root chunk, we cannot just split any chunk manually.
+  // - Also, after the split we have to completely re-merge to avoid triggering asserts
+  //   in ~RootChunkArea()
+  // - finally we have to lock manually
+
+  ChunkTestsContext helper;
+
+  const chunklevel_t orig_lvl = ROOT_CHUNK_LEVEL;
+  for (chunklevel_t target_lvl = orig_lvl + 1; target_lvl <= HIGHEST_CHUNK_LEVEL; target_lvl ++) {
+
+    // Split a fully committed chunk. The resulting chunk should be fully
+    //  committed as well, and have its content preserved.
+    Metachunk* c = NULL;
+    helper.alloc_chunk_expect_success(&c, orig_lvl);
+
+    // We allocate from this chunk to be able to completely paint the payload.
+    helper.allocate_from_chunk(c, c->word_size());
+
+    const uintx canary = os::random();
+    fill_range_with_pattern(c->base(), c->word_size(), canary);
+
+    FreeChunkListVector splinters;
+
+    {
+      // Splitting/Merging chunks is usually done by the chunkmanager, and no explicit
+      // outside API exists. So we split/merge chunks via the underlying vs node, directly.
+      // This means that we have to go through some extra hoops to not trigger any asserts.
+      MutexLocker fcl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
+      c->reset_used_words();
+      c->set_free();
+      c->vsnode()->split(target_lvl, c, &splinters);
+    }
+
+    DEBUG_ONLY(helper.verify();)
+
+    EXPECT_EQ(c->level(), target_lvl);
+    EXPECT_TRUE(c->is_fully_committed());
+    EXPECT_FALSE(c->is_root_chunk());
+    EXPECT_TRUE(c->is_leader());
+
+    check_range_for_pattern(c->base(), c->word_size(), canary);
+
+    // I expect splinter chunks (one for each splinter level:
+    //  e.g. splitting a 1M chunk to get a 64K chunk should yield splinters: [512K, 256K, 128K, 64K]
+    for (chunklevel_t l = LOWEST_CHUNK_LEVEL; l < HIGHEST_CHUNK_LEVEL; l ++) {
+      const Metachunk* c2 = splinters.first_at_level(l);
+      if (l > orig_lvl && l <= target_lvl) {
+        EXPECT_NOT_NULL(c2);
+        EXPECT_EQ(c2->level(), l);
+        EXPECT_TRUE(c2->is_free());
+        EXPECT_TRUE(!c2->is_leader());
+        DEBUG_ONLY(c2->verify(false));
+        check_range_for_pattern(c2->base(), c2->word_size(), canary);
+      } else {
+        EXPECT_NULL(c2);
+      }
+    }
+
+    // Revert the split by using merge. This should result in all splinters coalescing
+    // to one chunk.
+    {
+      MutexLocker fcl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
+      Metachunk* merged = c->vsnode()->merge(c, &splinters);
+
+      // the merged chunk should occupy the same address as the splinter
+      // since it should have been the leader in the split.
+      EXPECT_EQ(merged, c);
+      EXPECT_TRUE(merged->is_root_chunk() || merged->is_leader());
+
+      // Splitting should have arrived at the original chunk since none of the splinters are in use.
+      EXPECT_EQ(c->level(), orig_lvl);
+
+      // All splinters should have been removed from the list
+      EXPECT_EQ(splinters.num_chunks(), 0);
+    }
+
+    helper.return_chunk(c);
+
+  }
+
+}
+
+TEST_VM(metaspace, chunk_enlarge_in_place) {
+
+  ChunkTestsContext helper;
+
+  // Starting with the smallest chunk size, attempt to enlarge the chunk in place until we arrive
+  // at root chunk size. Since the state is clean, this should work.
+
+  Metachunk* c = NULL;
+  helper.alloc_chunk_expect_success(&c, HIGHEST_CHUNK_LEVEL);
+
+  chunklevel_t l = c->level();
+
+  while (l != ROOT_CHUNK_LEVEL) {
+
+    // commit and allocate from chunk to pattern it...
+    const size_t original_chunk_size = c->word_size();
+    helper.commit_chunk_with_test(c, c->free_words());
+    helper.allocate_from_chunk(c, c->free_words());
+
+    size_t used_before = c->used_words();
+    size_t free_before = c->free_words();
+    size_t free_below_committed_before = c->free_below_committed_words();
+    const MetaWord* top_before = c->top();
+
+    EXPECT_TRUE(helper.cm().attempt_enlarge_chunk(c));
+    EXPECT_EQ(l - 1, c->level());
+    EXPECT_EQ(c->word_size(), original_chunk_size * 2);
+
+    // Used words should not have changed
+    EXPECT_EQ(c->used_words(), used_before);
+    EXPECT_EQ(c->top(), top_before);
+
+    // free words should be expanded by the old size (since old chunk is doubled in size)
+    EXPECT_EQ(c->free_words(), free_before + original_chunk_size);
+
+    // free below committed can be larger but never smaller
+    EXPECT_GE(c->free_below_committed_words(), free_below_committed_before);
+
+    // Old content should be preserved
+    check_range_for_pattern(c->base(), original_chunk_size, (uintx)c);
+
+    l = c->level();
+  }
+
+  helper.return_chunk(c);
+
+}
+
diff --git a/test/hotspot/gtest/metaspace/test_metachunklist.cpp b/test/hotspot/gtest/metaspace/test_metachunklist.cpp
new file mode 100644
--- /dev/null
+++ b/test/hotspot/gtest/metaspace/test_metachunklist.cpp
@@ -0,0 +1,140 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+
+//#define LOG_PLEASE
+#include "metaspace/metaspaceTestsCommon.hpp"
+#include "metaspace/metaspaceTestContexts.hpp"
+#include "metaspace/metaspace_rangehelpers.hpp"
+
+TEST_VM(metaspace, metachunklist) {
+
+  ChunkTestsContext helper;
+
+  MetachunkList lst;
+
+  Metachunk* chunks[10];
+  size_t total_size = 0;
+
+  for (int i = 0; i < 10; i ++) {
+    Metachunk* c = NULL;
+    helper.alloc_chunk_expect_success(&c, ChunkLevelRanges::all_chunks().random_value());
+    chunks[i] = c;
+    total_size += c->committed_words();
+
+    lst.add(c);
+    EXPECT_EQ(lst.first(), c);
+
+    Metachunk* c2 = lst.remove_first();
+    EXPECT_EQ(c, c2);
+
+    EXPECT_EQ(lst.count(), i);
+    lst.add(c);
+    EXPECT_EQ(lst.count(), i + 1);
+    EXPECT_EQ(lst.calc_committed_word_size(), total_size);
+
+  }
+
+  for (int i = 0; i < 10; i ++) {
+    DEBUG_ONLY(EXPECT_TRUE(lst.contains(chunks[i]));)
+  }
+
+  for (int i = 0; i < 10; i ++) {
+    Metachunk* c = lst.remove_first();
+    DEBUG_ONLY(EXPECT_FALSE(lst.contains(c));)
+    helper.return_chunk(c);
+  }
+
+  EXPECT_EQ(lst.count(), 0);
+  EXPECT_EQ(lst.calc_committed_word_size(), (size_t)0);
+
+}
+
+
+TEST_VM(metaspace, freechunklist) {
+
+  ChunkTestsContext helper;
+
+  FreeChunkListVector lst;
+
+  MemRangeCounter cnt;
+  MemRangeCounter committed_cnt;
+
+  // Add random chunks to list and check the counter apis (word_size, commited_word_size, num_chunks)
+  // Make every other chunk randomly uncommitted, and later we check that committed chunks are sorted in at the front
+  // of the lists.
+  for (int i = 0; i < 100; i ++) {
+    Metachunk* c = NULL;
+    helper.alloc_chunk_expect_success(&c, ChunkLevelRanges::all_chunks().random_value());
+    bool uncommitted_chunk = i % 3;
+    if (uncommitted_chunk) {
+      helper.uncommit_chunk_with_test(c);
+      c->set_in_use();
+    }
+
+    lst.add(c);
+
+    LOG("->" METACHUNK_FULL_FORMAT, METACHUNK_FULL_FORMAT_ARGS(c));
+
+    cnt.add(c->word_size());
+    committed_cnt.add(c->committed_words());
+
+    EXPECT_EQ(lst.num_chunks(), (int)cnt.count());
+    EXPECT_EQ(lst.word_size(), cnt.total_size());
+    EXPECT_EQ(lst.committed_word_size(), committed_cnt.total_size());
+  }
+
+  // Drain each list separately
+  for (chunklevel_t lvl = LOWEST_CHUNK_LEVEL; lvl <= HIGHEST_CHUNK_LEVEL; lvl ++) {
+    Metachunk* c = lst.remove_first(lvl);
+    bool found_uncommitted = false;
+    while (c != NULL) {
+
+      LOG("<-" METACHUNK_FULL_FORMAT, METACHUNK_FULL_FORMAT_ARGS(c));
+
+      // Within a level, no committed chunk should follow an uncommitted chunk:
+      if (found_uncommitted) {
+        EXPECT_TRUE(c->is_fully_uncommitted());
+      } else {
+        found_uncommitted = c->is_fully_uncommitted();
+      }
+
+      cnt.sub(c->word_size());
+      committed_cnt.sub(c->committed_words());
+
+      EXPECT_EQ(lst.num_chunks(), (int)cnt.count());
+      EXPECT_EQ(lst.word_size(), cnt.total_size());
+      EXPECT_EQ(lst.committed_word_size(), committed_cnt.total_size());
+
+      helper.return_chunk(c);
+
+      c = lst.remove_first(lvl);
+    }
+  }
+
+  // TODO
+}
+
diff --git a/test/hotspot/gtest/metaspace/test_metaspaceUtils.cpp b/test/hotspot/gtest/metaspace/test_metaspaceUtils.cpp
new file mode 100644
--- /dev/null
+++ b/test/hotspot/gtest/metaspace/test_metaspaceUtils.cpp
@@ -0,0 +1,75 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+#include "memory/metaspace.hpp"
+#include "unittest.hpp"
+
+
+TEST_VM(MetaspaceUtils, reserved) {
+  size_t reserved = MetaspaceUtils::reserved_bytes();
+  EXPECT_GT(reserved, 0UL);
+
+  size_t reserved_metadata = MetaspaceUtils::reserved_bytes(Metaspace::NonClassType);
+  EXPECT_GT(reserved_metadata, 0UL);
+  EXPECT_LE(reserved_metadata, reserved);
+}
+
+TEST_VM(MetaspaceUtils, reserved_compressed_class_pointers) {
+  if (!UseCompressedClassPointers) {
+    return;
+  }
+  size_t reserved = MetaspaceUtils::reserved_bytes();
+  EXPECT_GT(reserved, 0UL);
+
+  size_t reserved_class = MetaspaceUtils::reserved_bytes(Metaspace::ClassType);
+  EXPECT_GT(reserved_class, 0UL);
+  EXPECT_LE(reserved_class, reserved);
+}
+
+TEST_VM(MetaspaceUtils, committed) {
+  size_t committed = MetaspaceUtils::committed_bytes();
+  EXPECT_GT(committed, 0UL);
+
+  size_t reserved  = MetaspaceUtils::reserved_bytes();
+  EXPECT_LE(committed, reserved);
+
+  size_t committed_metadata = MetaspaceUtils::committed_bytes(Metaspace::NonClassType);
+  EXPECT_GT(committed_metadata, 0UL);
+  EXPECT_LE(committed_metadata, committed);
+}
+
+TEST_VM(MetaspaceUtils, committed_compressed_class_pointers) {
+  if (!UseCompressedClassPointers) {
+    return;
+  }
+  size_t committed = MetaspaceUtils::committed_bytes();
+  EXPECT_GT(committed, 0UL);
+
+  size_t committed_class = MetaspaceUtils::committed_bytes(Metaspace::ClassType);
+  EXPECT_GT(committed_class, 0UL);
+  EXPECT_LE(committed_class, committed);
+}
+
diff --git a/test/hotspot/gtest/metaspace/test_metaspace_counters.cpp b/test/hotspot/gtest/metaspace/test_metaspace_counters.cpp
new file mode 100644
--- /dev/null
+++ b/test/hotspot/gtest/metaspace/test_metaspace_counters.cpp
@@ -0,0 +1,48 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+
+//#define LOG_PLEASE
+
+#include "classfile/classLoaderData.hpp"
+#include "metaspaceTestsCommon.hpp"
+#include "metaspace_rangehelpers.hpp"
+#include "threadHelper.inline.hpp"
+
+
+TEST_VM(metaspace, counters_basic)   {
+
+  IntCounter cnt;
+  ASSERT_0(cnt.get());
+  cnt.increment();
+  ASSERT_EQ(cnt.get(), (unsigned)1);
+  cnt.increment_by(100);
+  ASSERT_EQ(cnt.get(), (unsigned)101);
+  cnt.decrement_by(101);
+  ASSERT_0(cnt.get());
+
+}
+
diff --git a/test/hotspot/gtest/metaspace/test_metaspace_misc.cpp b/test/hotspot/gtest/metaspace/test_metaspace_misc.cpp
new file mode 100644
--- /dev/null
+++ b/test/hotspot/gtest/metaspace/test_metaspace_misc.cpp
@@ -0,0 +1,107 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+
+// #define LOG_PLEASE
+
+#include "classfile/classLoaderData.hpp"
+#include "metaspaceTestsCommon.hpp"
+#include "utilities/powerOfTwo.hpp"
+
+
+TEST_VM(metaspace, misc_sizes)   {
+
+  // Test test common sizes (seems primitive but breaks surprisingly often during development
+  //  because of word vs byte confusion)
+  // Adjust this test if numbers change.
+  ASSERT_TRUE(Settings::commit_granule_bytes() == 16 * K ||
+              Settings::commit_granule_bytes() == 64 * K);
+  ASSERT_EQ(Settings::commit_granule_bytes(), Metaspace::commit_alignment());
+  ASSERT_TRUE(is_aligned(Settings::virtual_space_node_default_word_size(),
+              metaspace::chunklevel::MAX_CHUNK_WORD_SIZE));
+  ASSERT_EQ(Settings::virtual_space_node_default_word_size(),
+            metaspace::chunklevel::MAX_CHUNK_WORD_SIZE * 2);
+  ASSERT_EQ(Settings::virtual_space_node_reserve_alignment_words(),
+            Metaspace::reserve_alignment_words());
+
+}
+
+
+TEST_VM(metaspace, misc_max_alloc_size)   {
+
+  // Make sure we can allocate what we promise to allocate
+  const size_t sz = Metaspace::max_allocation_word_size();
+  ClassLoaderData* cld = ClassLoaderData::the_null_class_loader_data();
+  MetaWord* p = cld->metaspace_non_null()->allocate(sz, Metaspace::NonClassType);
+  ASSERT_NOT_NULL(p);
+  cld->metaspace_non_null()->deallocate(p, sz, false);
+
+}
+
+TEST_VM(metaspace, chunklevel_utils)   {
+
+  LOG(SIZE_FORMAT, MAX_CHUNK_BYTE_SIZE);
+  LOG(SIZE_FORMAT, MIN_CHUNK_BYTE_SIZE);
+  LOG(SIZE_FORMAT, MIN_CHUNK_WORD_SIZE);
+  LOG(SIZE_FORMAT, MAX_CHUNK_WORD_SIZE);
+  LOG(SIZE_FORMAT, MAX_CHUNK_BYTE_SIZE);
+  LOG("%u", (unsigned)ROOT_CHUNK_LEVEL);
+  LOG("%u", (unsigned)HIGHEST_CHUNK_LEVEL);
+  LOG("%u", (unsigned)LOWEST_CHUNK_LEVEL);
+
+  static const chunklevel_t INVALID_CHUNK_LEVEL    = (chunklevel_t) -1;
+
+  EXPECT_TRUE(is_power_of_2(MAX_CHUNK_WORD_SIZE));
+  EXPECT_TRUE(is_power_of_2(MIN_CHUNK_WORD_SIZE));
+
+  EXPECT_TRUE(is_valid_level(LOWEST_CHUNK_LEVEL));
+  EXPECT_TRUE(is_valid_level(HIGHEST_CHUNK_LEVEL));
+  EXPECT_FALSE(is_valid_level(HIGHEST_CHUNK_LEVEL + 1));
+  EXPECT_FALSE(is_valid_level(LOWEST_CHUNK_LEVEL - 1));
+
+  EXPECT_EQ(word_size_for_level(ROOT_CHUNK_LEVEL), MAX_CHUNK_WORD_SIZE);
+  EXPECT_EQ(word_size_for_level(HIGHEST_CHUNK_LEVEL), MIN_CHUNK_WORD_SIZE);
+
+  EXPECT_EQ(word_size_for_level(CHUNK_LEVEL_4K), (4 * K) / BytesPerWord);
+  EXPECT_EQ(word_size_for_level(CHUNK_LEVEL_64K), (64 * K) / BytesPerWord);
+
+  EXPECT_EQ(level_fitting_word_size(0), HIGHEST_CHUNK_LEVEL);
+  EXPECT_EQ(level_fitting_word_size(1), HIGHEST_CHUNK_LEVEL);
+  EXPECT_EQ(level_fitting_word_size(MIN_CHUNK_WORD_SIZE), HIGHEST_CHUNK_LEVEL);
+  EXPECT_EQ(level_fitting_word_size(MIN_CHUNK_WORD_SIZE + 1), HIGHEST_CHUNK_LEVEL - 1);
+
+  EXPECT_EQ(level_fitting_word_size(MAX_CHUNK_WORD_SIZE), ROOT_CHUNK_LEVEL);
+  EXPECT_EQ(level_fitting_word_size(MAX_CHUNK_WORD_SIZE - 1), ROOT_CHUNK_LEVEL);
+  EXPECT_EQ(level_fitting_word_size((MAX_CHUNK_WORD_SIZE / 2) + 1), ROOT_CHUNK_LEVEL);
+  EXPECT_EQ(level_fitting_word_size(MAX_CHUNK_WORD_SIZE / 2), ROOT_CHUNK_LEVEL + 1);
+
+  EXPECT_EQ(level_fitting_word_size(8 * K), CHUNK_LEVEL_64K);
+  EXPECT_EQ(level_fitting_word_size(8 * K + 13), CHUNK_LEVEL_64K - 1);
+  EXPECT_EQ(level_fitting_word_size(8 * K - 13), CHUNK_LEVEL_64K);
+
+
+}
+
diff --git a/test/hotspot/gtest/metaspace/test_metaspacearena.cpp b/test/hotspot/gtest/metaspace/test_metaspacearena.cpp
new file mode 100644
--- /dev/null
+++ b/test/hotspot/gtest/metaspace/test_metaspacearena.cpp
@@ -0,0 +1,607 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+
+//#define LOG_PLEASE
+
+#include "metaspace/metaspaceTestsCommon.hpp"
+#include "metaspace/metaspaceTestContexts.hpp"
+#include "metaspace/metaspace_sparsearray.hpp"
+#include "utilities/ostream.hpp"
+
+
+// TODO: this class is very similar to MetaspaceArenaTestBed in test_metaspacearena_stress.cpp.
+// should be unified.
+class MetaspaceArenaTestHelper {
+
+  MetaspaceTestContext& _helper;
+
+  Mutex* _lock;
+  const ArenaGrowthPolicy* _growth_policy;
+  SizeAtomicCounter _used_words_counter;
+  MetaspaceArena* _arena;
+
+public:
+
+  MetaspaceArenaTestHelper(MetaspaceTestContext& helper, Metaspace::MetaspaceType space_type, bool is_class,
+                         const char* name = "gtest-MetaspaceArena")
+    : _helper(helper),
+      _lock(NULL),
+      _growth_policy(NULL),
+      _used_words_counter(),
+      _arena(NULL)
+  {
+    _growth_policy = ArenaGrowthPolicy::policy_for_space_type(space_type, is_class);
+    _lock = new Mutex(Monitor::native, "gtest-MetaspaceArenaTest-lock", false, Monitor::_safepoint_check_never);
+    // Lock during space creation, since this is what happens in the VM too
+    //  (see ClassLoaderData::metaspace_non_null(), which we mimick here).
+    {
+      MutexLocker ml(_lock,  Mutex::_no_safepoint_check_flag);
+      _arena = new MetaspaceArena(&_helper.cm(), _growth_policy, _lock, &_used_words_counter, name);
+    }
+    DEBUG_ONLY(_arena->verify(true));
+  }
+
+  ~MetaspaceArenaTestHelper() {
+    delete_arena_with_tests();
+    delete _lock;
+  }
+
+  const CommitLimiter& limiter() const { return _helper.commit_limiter(); }
+  MetaspaceArena* arena() const { return _arena; }
+  SizeAtomicCounter& used_words_counter() { return _used_words_counter; }
+
+  // Note: all test functions return void due to gtests limitation that we cannot use ASSERT
+  // in non-void returning tests.
+
+  void delete_arena_with_tests() {
+    if (_arena != NULL) {
+      size_t used_words_before = _used_words_counter.get();
+      size_t committed_words_before = limiter().committed_words();
+      DEBUG_ONLY(_arena->verify(true));
+      delete _arena;
+      _arena = NULL;
+      size_t used_words_after = _used_words_counter.get();
+      size_t committed_words_after = limiter().committed_words();
+      ASSERT_0(used_words_after);
+      if (Settings::uncommit_free_chunks()) {
+        ASSERT_LE(committed_words_after, committed_words_before);
+      } else {
+        ASSERT_EQ(committed_words_after, committed_words_before);
+      }
+    }
+  }
+
+  void usage_numbers_with_test(size_t* p_used, size_t* p_committed, size_t* p_capacity) const {
+    _arena->usage_numbers(p_used, p_committed, p_capacity);
+    if (p_used != NULL) {
+      if (p_committed != NULL) {
+        ASSERT_GE(*p_committed, *p_used);
+      }
+      // Since we own the used words counter, it should reflect our usage number 1:1
+      ASSERT_EQ(_used_words_counter.get(), *p_used);
+    }
+    if (p_committed != NULL && p_capacity != NULL) {
+      ASSERT_GE(*p_capacity, *p_committed);
+    }
+  }
+
+  // Allocate; caller expects success; return pointer in *p_return_value
+  void allocate_from_arena_with_tests_expect_success(MetaWord** p_return_value, size_t word_size) {
+    allocate_from_arena_with_tests(p_return_value, word_size);
+    ASSERT_NOT_NULL(*p_return_value);
+  }
+
+  // Allocate; caller expects success but is not interested in return value
+  void allocate_from_arena_with_tests_expect_success(size_t word_size) {
+    MetaWord* dummy = NULL;
+    allocate_from_arena_with_tests_expect_success(&dummy, word_size);
+  }
+
+  // Allocate; caller expects failure
+  void allocate_from_arena_with_tests_expect_failure(size_t word_size) {
+    MetaWord* dummy = NULL;
+    allocate_from_arena_with_tests(&dummy, word_size);
+    ASSERT_NULL(dummy);
+  }
+
+  // Allocate; it may or may not work; return value in *p_return_value
+  void allocate_from_arena_with_tests(MetaWord** p_return_value, size_t word_size) {
+
+    // Note: usage_numbers walks all chunks in use and counts.
+    size_t used = 0, committed = 0, capacity = 0;
+    usage_numbers_with_test(&used, &committed, &capacity);
+
+    size_t possible_expansion = limiter().possible_expansion_words();
+
+    MetaWord* p = _arena->allocate(word_size);
+
+    SOMETIMES(DEBUG_ONLY(_arena->verify(true);))
+
+    size_t used2 = 0, committed2 = 0, capacity2 = 0;
+    usage_numbers_with_test(&used2, &committed2, &capacity2);
+
+    if (p == NULL) {
+      // Allocation failed.
+      if (Settings::new_chunks_are_fully_committed()) {
+        ASSERT_LT(possible_expansion, MAX_CHUNK_WORD_SIZE);
+      } else {
+        ASSERT_LT(possible_expansion, word_size);
+      }
+
+      ASSERT_EQ(used, used2);
+      ASSERT_EQ(committed, committed2);
+      ASSERT_EQ(capacity, capacity2);
+    } else {
+      // Allocation succeeded. Should be correctly aligned.
+      ASSERT_TRUE(is_aligned(p, sizeof(MetaWord)));
+      // used: may go up or may not (since our request may have been satisfied from the freeblocklist
+      //   whose content already counts as used).
+      // committed: may go up, may not
+      // capacity: ditto
+      ASSERT_GE(used2, used);
+      ASSERT_GE(committed2, committed);
+      ASSERT_GE(capacity2, capacity);
+    }
+
+    *p_return_value = p;
+  }
+
+  // Allocate; it may or may not work; but caller does not care for the result value
+  void allocate_from_arena_with_tests(size_t word_size) {
+    MetaWord* dummy = NULL;
+    allocate_from_arena_with_tests(&dummy, word_size);
+  }
+
+
+  void deallocate_with_tests(MetaWord* p, size_t word_size) {
+    size_t used = 0, committed = 0, capacity = 0;
+    usage_numbers_with_test(&used, &committed, &capacity);
+
+    _arena->deallocate(p, word_size);
+
+    SOMETIMES(DEBUG_ONLY(_arena->verify(true);))
+
+    size_t used2 = 0, committed2 = 0, capacity2 = 0;
+    usage_numbers_with_test(&used2, &committed2, &capacity2);
+
+    // Nothing should have changed. Deallocated blocks are added to the free block list
+    // which still counts as used.
+    ASSERT_EQ(used2, used);
+    ASSERT_EQ(committed2, committed);
+    ASSERT_EQ(capacity2, capacity);
+  }
+
+
+};
+
+
+static void test_basics(size_t commit_limit, bool is_micro) {
+  MetaspaceTestContext msthelper(commit_limit);
+  MetaspaceArenaTestHelper helper(msthelper, is_micro ? Metaspace::ReflectionMetaspaceType : Metaspace::StandardMetaspaceType, false);
+
+  helper.allocate_from_arena_with_tests(1);
+  helper.allocate_from_arena_with_tests(128);
+  helper.allocate_from_arena_with_tests(128 * K);
+  helper.allocate_from_arena_with_tests(1);
+  helper.allocate_from_arena_with_tests(128);
+  helper.allocate_from_arena_with_tests(128 * K);
+}
+
+TEST_VM(metaspace, MetaspaceArena_basics_micro_nolimit) {
+  test_basics(max_uintx, true);
+}
+
+TEST_VM(metaspace, MetaspaceArena_basics_micro_limit) {
+  test_basics(256 * K, true);
+}
+
+TEST_VM(metaspace, MetaspaceArena_basics_standard_nolimit) {
+  test_basics(max_uintx, false);
+}
+
+TEST_VM(metaspace, MetaspaceArena_basics_standard_limit) {
+  test_basics(256 * K, false);
+}
+
+
+// Test: in a single undisturbed MetaspaceArena (so, we should have chunks enlarged in place)
+// we allocate a small amount, then the full amount possible. The sum of first and second
+// allocation bring us above root chunk size. This should work - chunk enlargement should
+// fail and a new root chunk should be allocated instead.
+TEST_VM(metaspace, MetaspaceArena_test_enlarge_in_place) {
+
+  if (Settings::use_allocation_guard()) {
+    return;
+  }
+
+  MetaspaceTestContext msthelper;
+  MetaspaceArenaTestHelper helper(msthelper, Metaspace::StandardMetaspaceType, false);
+  helper.allocate_from_arena_with_tests_expect_success(1);
+  helper.allocate_from_arena_with_tests_expect_success(MAX_CHUNK_WORD_SIZE);
+  helper.allocate_from_arena_with_tests_expect_success(MAX_CHUNK_WORD_SIZE / 2);
+  helper.allocate_from_arena_with_tests_expect_success(MAX_CHUNK_WORD_SIZE);
+}
+
+// Test allocating from smallest to largest chunk size, and one step beyond.
+// The first n allocations should happen in place, the ladder should open a new chunk.
+TEST_VM(metaspace, MetaspaceArena_test_enlarge_in_place_ladder_1) {
+
+  if (Settings::use_allocation_guard()) {
+    return;
+  }
+
+  MetaspaceTestContext msthelper;
+  MetaspaceArenaTestHelper helper(msthelper, Metaspace::StandardMetaspaceType, false);
+  size_t size = MIN_CHUNK_WORD_SIZE;
+  while (size <= MAX_CHUNK_WORD_SIZE) {
+    helper.allocate_from_arena_with_tests_expect_success(size);
+    size *= 2;
+  }
+  helper.allocate_from_arena_with_tests_expect_success(MAX_CHUNK_WORD_SIZE);
+}
+
+// Same as MetaspaceArena_test_enlarge_in_place_ladder_1, but increase in *4 step size;
+// this way chunk-in-place-enlargement does not work and we should have new chunks at each allocation.
+TEST_VM(metaspace, MetaspaceArena_test_enlarge_in_place_ladder_2) {
+
+  if (Settings::use_allocation_guard()) {
+    return;
+  }
+
+  MetaspaceTestContext msthelper;
+  MetaspaceArenaTestHelper helper(msthelper, Metaspace::StandardMetaspaceType, false);
+  size_t size = MIN_CHUNK_WORD_SIZE;
+  while (size <= MAX_CHUNK_WORD_SIZE) {
+    helper.allocate_from_arena_with_tests_expect_success(size);
+    size *= 4;
+  }
+  helper.allocate_from_arena_with_tests_expect_success(MAX_CHUNK_WORD_SIZE);
+}
+
+// Test the MetaspaceArenas' free block list:
+// Allocate, deallocate, then allocate the same block again. The second allocate should
+// reuse the deallocated block.
+TEST_VM(metaspace, MetaspaceArena_deallocate) {
+  if (Settings::use_allocation_guard()) {
+    return;
+  }
+  for (size_t s = 2; s <= MAX_CHUNK_WORD_SIZE; s *= 2) {
+    MetaspaceTestContext msthelper;
+    MetaspaceArenaTestHelper helper(msthelper, Metaspace::StandardMetaspaceType, false);
+
+    MetaWord* p1 = NULL;
+    helper.allocate_from_arena_with_tests_expect_success(&p1, s);
+
+    size_t used1 = 0, capacity1 = 0;
+    helper.usage_numbers_with_test(&used1, NULL, &capacity1);
+    ASSERT_EQ(used1, s);
+
+    helper.deallocate_with_tests(p1, s);
+
+    size_t used2 = 0, capacity2 = 0;
+    helper.usage_numbers_with_test(&used2, NULL, &capacity2);
+    ASSERT_EQ(used1, used2);
+    ASSERT_EQ(capacity2, capacity2);
+
+    MetaWord* p2 = NULL;
+    helper.allocate_from_arena_with_tests_expect_success(&p2, s);
+
+    size_t used3 = 0, capacity3 = 0;
+    helper.usage_numbers_with_test(&used3, NULL, &capacity3);
+    ASSERT_EQ(used3, used2);
+    ASSERT_EQ(capacity3, capacity2);
+
+    // Actually, we should get the very same allocation back
+    ASSERT_EQ(p1, p2);
+  }
+}
+
+static void test_recover_from_commit_limit_hit() {
+
+  if (Settings::new_chunks_are_fully_committed()) {
+    return; // This would throw off the commit counting in this test.
+  }
+
+  // Test:
+  // - Multiple MetaspaceArena allocate (operating under the same commit limiter).
+  // - One, while attempting to commit parts of its current chunk on demand,
+  //   triggers the limit and cannot commit its chunk further.
+  // - We release the other MetaspaceArena - its content is put back to the
+  //   freelists.
+  // - We re-attempt allocation from the first manager. It should now succeed.
+  //
+  // This means if the first MetaspaceArena may have to let go of its current chunk and
+  // retire it and take a fresh chunk from the freelist.
+
+  const size_t commit_limit = Settings::commit_granule_words() * 10;
+  MetaspaceTestContext msthelper(commit_limit);
+
+  // The first MetaspaceArena mimicks a micro loader. This will fill the free
+  //  chunk list with very small chunks. We allocate from them in an interleaved
+  //  way to cause fragmentation.
+  MetaspaceArenaTestHelper helper1(msthelper, Metaspace::ReflectionMetaspaceType, false);
+  MetaspaceArenaTestHelper helper2(msthelper, Metaspace::ReflectionMetaspaceType, false);
+
+  // This MetaspaceArena should hit the limit. We use BootMetaspaceType here since
+  // it gets a large initial chunk which is committed
+  // on demand and we are likely to hit a commit limit while trying to expand it.
+  MetaspaceArenaTestHelper helper3(msthelper, Metaspace::BootMetaspaceType, false);
+
+  // Allocate space until we have below two but above one granule left
+  size_t allocated_from_1_and_2 = 0;
+  while (msthelper.commit_limiter().possible_expansion_words() >= Settings::commit_granule_words() * 2 &&
+      allocated_from_1_and_2 < commit_limit) {
+    helper1.allocate_from_arena_with_tests_expect_success(1);
+    helper2.allocate_from_arena_with_tests_expect_success(1);
+    allocated_from_1_and_2 += 2;
+  }
+
+  // Now, allocating from helper3, creep up on the limit
+  size_t allocated_from_3 = 0;
+  MetaWord* p = NULL;
+  while ( (helper3.allocate_from_arena_with_tests(&p, 1), p != NULL) &&
+         ++allocated_from_3 < Settings::commit_granule_words() * 2);
+
+  EXPECT_LE(allocated_from_3, Settings::commit_granule_words() * 2);
+
+  // We expect the freelist to be empty of committed space...
+  EXPECT_0(msthelper.cm().total_committed_word_size());
+
+  //msthelper.cm().print_on(tty);
+
+  // Release the first MetaspaceArena.
+  helper1.delete_arena_with_tests();
+
+  //msthelper.cm().print_on(tty);
+
+  // Should have populated the freelist with committed space
+  // We expect the freelist to be empty of committed space...
+  EXPECT_GT(msthelper.cm().total_committed_word_size(), (size_t)0);
+
+  // Repeat allocation from helper3, should now work.
+  helper3.allocate_from_arena_with_tests_expect_success(1);
+
+}
+
+
+TEST_VM(metaspace, MetaspaceArena_recover_from_limit_hit) {
+  test_recover_from_commit_limit_hit();
+}
+
+static void test_controlled_growth(Metaspace::MetaspaceType type, bool is_class,
+                                   size_t expected_starting_capacity,
+                                   bool test_in_place_enlargement)
+{
+
+  if (Settings::use_allocation_guard()) {
+    return;
+  }
+
+  // From a MetaspaceArena in a clean room allocate tiny amounts;
+  // watch it grow. Used/committed/capacity should not grow in
+  // large jumps. Also, different types of MetaspaceArena should
+  // have different initial capacities.
+
+  MetaspaceTestContext msthelper;
+  MetaspaceArenaTestHelper smhelper(msthelper, type, is_class, "Grower");
+
+  MetaspaceArenaTestHelper smhelper_harrasser(msthelper, Metaspace::ReflectionMetaspaceType, true, "Harasser");
+
+  size_t used = 0, committed = 0, capacity = 0;
+  const size_t alloc_words = 16;
+
+  smhelper.arena()->usage_numbers(&used, &committed, &capacity);
+  ASSERT_0(used);
+  ASSERT_0(committed);
+  ASSERT_0(capacity);
+
+  ///// First allocation //
+
+  smhelper.allocate_from_arena_with_tests_expect_success(alloc_words);
+
+  smhelper.arena()->usage_numbers(&used, &committed, &capacity);
+
+  ASSERT_EQ(used, alloc_words);
+  ASSERT_GE(committed, used);
+  ASSERT_GE(capacity, committed);
+
+  ASSERT_EQ(capacity, expected_starting_capacity);
+
+  if (!(Settings::new_chunks_are_fully_committed() && type == Metaspace::BootMetaspaceType)) {
+    // Initial commit charge for the whole context should be one granule
+    ASSERT_EQ(msthelper.committed_words(), Settings::commit_granule_words());
+    // Initial commit number for the arena should be less since - apart from boot loader - no
+    //  space type has large initial chunks.
+    ASSERT_LE(committed, Settings::commit_granule_words());
+  }
+
+  ///// subsequent allocations //
+
+  DEBUG_ONLY(const uintx num_chunk_enlarged = metaspace::InternalStats::num_chunks_enlarged();)
+
+  size_t words_allocated = 0;
+  int num_allocated = 0;
+  const size_t safety = MAX_CHUNK_WORD_SIZE * 1.2;
+  size_t highest_capacity_jump = capacity;
+  int num_capacity_jumps = 0;
+
+  while (words_allocated < safety && num_capacity_jumps < 15) {
+
+    // if we want to test growth with in-place chunk enlargement, leave MetaspaceArena
+    // undisturbed; it will have all the place to grow. Otherwise allocate from a little
+    // side arena to increase fragmentation.
+    // (Note that this does not completely prevent in-place chunk enlargement but makes it
+    //  rather improbable)
+    if (!test_in_place_enlargement) {
+      smhelper_harrasser.allocate_from_arena_with_tests_expect_success(alloc_words * 2);
+    }
+
+    smhelper.allocate_from_arena_with_tests_expect_success(alloc_words);
+    words_allocated += alloc_words;
+    num_allocated ++;
+
+    size_t used2 = 0, committed2 = 0, capacity2 = 0;
+
+    smhelper.arena()->usage_numbers(&used2, &committed2, &capacity2);
+
+    // used should not grow larger than what we allocated, plus possible overhead.
+    ASSERT_GE(used2, used);
+    ASSERT_LE(used2, used + alloc_words * 2);
+    ASSERT_LE(used2, words_allocated + 100);
+    used = used2;
+
+    // A jump in committed words should not be larger than commit granule size.
+    // It can be smaller, since the current chunk of the MetaspaceArena may be
+    // smaller than a commit granule.
+    // (Note: unless root chunks are born fully committed)
+    ASSERT_GE(committed2, used2);
+    ASSERT_GE(committed2, committed);
+    const size_t committed_jump = committed2 - committed;
+    if (committed_jump > 0 && !Settings::new_chunks_are_fully_committed()) {
+      ASSERT_LE(committed_jump, Settings::commit_granule_words());
+    }
+    committed = committed2;
+
+    // Capacity jumps: Test that arenas capacity does not grow too fast.
+    ASSERT_GE(capacity2, committed2);
+    ASSERT_GE(capacity2, capacity);
+    const size_t capacity_jump = capacity2 - capacity;
+    if (capacity_jump > 0) {
+      LOG(">" SIZE_FORMAT "->" SIZE_FORMAT "(+" SIZE_FORMAT ")", capacity, capacity2, capacity_jump)
+      if (capacity_jump > highest_capacity_jump) {
+        /* Disabled for now since this is rather shaky. The way it is tested makes it too dependent
+         * on allocation history. Need to rethink this.
+        ASSERT_LE(capacity_jump, highest_capacity_jump * 2);
+        ASSERT_GE(capacity_jump, MIN_CHUNK_WORD_SIZE);
+        ASSERT_LE(capacity_jump, MAX_CHUNK_WORD_SIZE);
+        */
+        highest_capacity_jump = capacity_jump;
+      }
+      num_capacity_jumps ++;
+    }
+
+    capacity = capacity2;
+
+  }
+
+  // After all this work, we should see an increase in number of chunk-in-place-enlargements
+  //  (this especially is vulnerable to regression: the decisions of when to do in-place-enlargements are somewhat
+  //   complicated, see MetaspaceArena::attempt_enlarge_current_chunk())
+#ifdef ASSERT
+  if (test_in_place_enlargement) {
+    const uintx num_chunk_enlarged_2 = metaspace::InternalStats::num_chunks_enlarged();
+    ASSERT_GT(num_chunk_enlarged_2, num_chunk_enlarged);
+  }
+#endif
+}
+
+// these numbers have to be in sync with arena policy numbers (see memory/metaspace/arenaGrowthPolicy.cpp)
+TEST_VM(metaspace, MetaspaceArena_growth_refl_c_inplace) {
+  test_controlled_growth(Metaspace::ReflectionMetaspaceType, true,
+                         word_size_for_level(CHUNK_LEVEL_1K), true);
+}
+
+TEST_VM(metaspace, MetaspaceArena_growth_refl_c_not_inplace) {
+  test_controlled_growth(Metaspace::ReflectionMetaspaceType, true,
+                         word_size_for_level(CHUNK_LEVEL_1K), false);
+}
+
+TEST_VM(metaspace, MetaspaceArena_growth_anon_c_inplace) {
+  test_controlled_growth(Metaspace::ClassMirrorHolderMetaspaceType, true,
+                         word_size_for_level(CHUNK_LEVEL_1K), true);
+}
+
+TEST_VM(metaspace, MetaspaceArena_growth_anon_c_not_inplace) {
+  test_controlled_growth(Metaspace::ClassMirrorHolderMetaspaceType, true,
+                         word_size_for_level(CHUNK_LEVEL_1K), false);
+}
+
+TEST_VM(metaspace, MetaspaceArena_growth_standard_c_inplace) {
+  test_controlled_growth(Metaspace::StandardMetaspaceType, true,
+                         word_size_for_level(CHUNK_LEVEL_2K), true);
+}
+
+TEST_VM(metaspace, MetaspaceArena_growth_standard_c_not_inplace) {
+  test_controlled_growth(Metaspace::StandardMetaspaceType, true,
+                         word_size_for_level(CHUNK_LEVEL_2K), false);
+}
+
+/* Disabled growth tests for BootMetaspaceType: there, the growth steps are too rare,
+ * and too large, to make any reliable guess as toward chunks get enlarged in place.
+TEST_VM(metaspace, MetaspaceArena_growth_boot_c_inplace) {
+  test_controlled_growth(Metaspace::BootMetaspaceType, true,
+                         word_size_for_level(CHUNK_LEVEL_1M), true);
+}
+
+TEST_VM(metaspace, MetaspaceArena_growth_boot_c_not_inplace) {
+  test_controlled_growth(Metaspace::BootMetaspaceType, true,
+                         word_size_for_level(CHUNK_LEVEL_1M), false);
+}
+*/
+
+TEST_VM(metaspace, MetaspaceArena_growth_refl_nc_inplace) {
+  test_controlled_growth(Metaspace::ReflectionMetaspaceType, false,
+                         word_size_for_level(CHUNK_LEVEL_2K), true);
+}
+
+TEST_VM(metaspace, MetaspaceArena_growth_refl_nc_not_inplace) {
+  test_controlled_growth(Metaspace::ReflectionMetaspaceType, false,
+                         word_size_for_level(CHUNK_LEVEL_2K), false);
+}
+
+TEST_VM(metaspace, MetaspaceArena_growth_anon_nc_inplace) {
+  test_controlled_growth(Metaspace::ClassMirrorHolderMetaspaceType, false,
+                         word_size_for_level(CHUNK_LEVEL_1K), true);
+}
+
+TEST_VM(metaspace, MetaspaceArena_growth_anon_nc_not_inplace) {
+  test_controlled_growth(Metaspace::ClassMirrorHolderMetaspaceType, false,
+                         word_size_for_level(CHUNK_LEVEL_1K), false);
+}
+
+TEST_VM(metaspace, MetaspaceArena_growth_standard_nc_inplace) {
+  test_controlled_growth(Metaspace::StandardMetaspaceType, false,
+                         word_size_for_level(CHUNK_LEVEL_4K), true);
+}
+
+TEST_VM(metaspace, MetaspaceArena_growth_standard_nc_not_inplace) {
+  test_controlled_growth(Metaspace::StandardMetaspaceType, false,
+                         word_size_for_level(CHUNK_LEVEL_4K), false);
+}
+
+/* Disabled growth tests for BootMetaspaceType: there, the growth steps are too rare,
+ * and too large, to make any reliable guess as toward chunks get enlarged in place.
+TEST_VM(metaspace, MetaspaceArena_growth_boot_nc_inplace) {
+  test_controlled_growth(Metaspace::BootMetaspaceType, false,
+                         word_size_for_level(CHUNK_LEVEL_4M), true);
+}
+
+TEST_VM(metaspace, MetaspaceArena_growth_boot_nc_not_inplace) {
+  test_controlled_growth(Metaspace::BootMetaspaceType, false,
+                         word_size_for_level(CHUNK_LEVEL_4M), false);
+}
+*/
diff --git a/test/hotspot/gtest/metaspace/test_metaspacearena_stress.cpp b/test/hotspot/gtest/metaspace/test_metaspacearena_stress.cpp
new file mode 100644
--- /dev/null
+++ b/test/hotspot/gtest/metaspace/test_metaspacearena_stress.cpp
@@ -0,0 +1,437 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+
+//#define LOG_PLEASE
+#include "metaspace/metaspaceTestsCommon.hpp"
+#include "metaspace/metaspaceTestContexts.hpp"
+#include "metaspace/metaspace_sparsearray.hpp"
+
+// Little randomness helper
+static bool fifty_fifty() {
+  return IntRange(100).random_value() < 50;
+}
+
+// See metaspaceArena.cpp : needed for predicting commit sizes.
+namespace metaspace {
+  extern size_t get_raw_word_size_for_requested_word_size(size_t net_word_size);
+}
+
+// A MetaspaceArenaTestBed contains a single MetaspaceArena and its lock.
+// It keeps track of allocations done from this MetaspaceArena.
+class MetaspaceArenaTestBed : public CHeapObj<mtInternal> {
+
+  MetaspaceArena* _arena;
+
+  Mutex* _lock;
+
+  const SizeRange _allocation_range;
+  size_t _size_of_last_failed_allocation;
+
+  // We keep track of all allocations done thru the MetaspaceArena to
+  // later check for overwriters.
+  struct allocation_t {
+    allocation_t* next;
+    MetaWord* p; // NULL if deallocated
+    size_t word_size;
+    void mark() {
+      mark_range(p, word_size);
+    }
+    void verify() const {
+      if (p != NULL) {
+        check_marked_range(p, word_size);
+      }
+    }
+  };
+
+  allocation_t* _allocations;
+
+  // We count how much we did allocate and deallocate
+  MemRangeCounter _alloc_count;
+  MemRangeCounter _dealloc_count;
+
+  // Check statistics returned by MetaspaceArena::add_to_statistics() against what
+  // we know we allocated. This is a bit flaky since MetaspaceArena has internal
+  // overhead.
+  void verify_arena_statistics() const {
+
+    arena_stats_t stats;
+    _arena->add_to_statistics(&stats);
+    in_use_chunk_stats_t in_use_stats = stats.totals();
+
+    assert(_dealloc_count.total_size() <= _alloc_count.total_size() &&
+           _dealloc_count.count() <= _alloc_count.count(), "Sanity");
+
+    // Check consistency of stats
+    ASSERT_GE(in_use_stats.word_size, in_use_stats.committed_words);
+    ASSERT_EQ(in_use_stats.committed_words,
+              in_use_stats.used_words + in_use_stats.free_words + in_use_stats.waste_words);
+    ASSERT_GE(in_use_stats.used_words, stats.free_blocks_word_size);
+
+    // Note: reasons why the outside alloc counter and the inside used counter can differ:
+    // - alignment/padding of allocations
+    // - inside used counter contains blocks in free list
+    // - free block list splinter threshold
+
+    // Since what we deallocated may have been given back to us in a following allocation,
+    // we only know fore sure we allocated what we did not give back.
+    const size_t at_least_allocated = _alloc_count.total_size() - _dealloc_count.total_size();
+
+    // At most we allocated this:
+    const size_t max_word_overhead_per_alloc = 4;
+    const size_t at_most_allocated = _alloc_count.total_size() + max_word_overhead_per_alloc * _alloc_count.count();
+
+    ASSERT_LE(at_least_allocated, in_use_stats.used_words - stats.free_blocks_word_size);
+    ASSERT_GE(at_most_allocated, in_use_stats.used_words - stats.free_blocks_word_size);
+
+  }
+
+public:
+
+  MetaspaceArena* arena() { return _arena; }
+
+  MetaspaceArenaTestBed(ChunkManager* cm, const ArenaGrowthPolicy* alloc_sequence,
+                      SizeAtomicCounter* used_words_counter, SizeRange allocation_range)
+    : _arena(NULL),
+      _lock(NULL),
+      _allocation_range(allocation_range),
+      _size_of_last_failed_allocation(0),
+      _allocations(NULL),
+      _alloc_count(), _dealloc_count()
+  {
+    _lock = new Mutex(Monitor::native, "gtest-MetaspaceArenaTestBed-lock", false, Monitor::_safepoint_check_never);
+    // Lock during space creation, since this is what happens in the VM too
+    //  (see ClassLoaderData::metaspace_non_null(), which we mimick here).
+    MutexLocker ml(_lock,  Mutex::_no_safepoint_check_flag);
+    _arena = new MetaspaceArena(cm, alloc_sequence, _lock, used_words_counter, "gtest-MetaspaceArenaTestBed-sm");
+  }
+
+  ~MetaspaceArenaTestBed() {
+
+    verify_arena_statistics();
+
+    allocation_t* a = _allocations;
+    while (a != NULL) {
+      allocation_t* b = a->next;
+      a->verify();
+      FREE_C_HEAP_OBJ(a);
+      a = b;
+    }
+
+    DEBUG_ONLY(_arena->verify(true);)
+
+    // Delete MetaspaceArena. That should clean up all metaspace.
+    delete _arena;
+    delete _lock;
+
+  }
+
+  size_t words_allocated() const        { return _alloc_count.total_size(); }
+  int num_allocations() const           { return _alloc_count.count(); }
+
+  size_t size_of_last_failed_allocation() const { return _size_of_last_failed_allocation; }
+
+  // Allocate a random amount. Return false if the allocation failed.
+  bool checked_random_allocate() {
+    size_t word_size = 1 + _allocation_range.random_value();
+    MetaWord* p = _arena->allocate(word_size);
+    if (p != NULL) {
+      EXPECT_TRUE(is_aligned(p, sizeof(MetaWord)));
+      allocation_t* a = NEW_C_HEAP_OBJ(allocation_t, mtInternal);
+      a->word_size = word_size;
+      a->p = p;
+      a->mark();
+      a->next = _allocations;
+      _allocations = a;
+      _alloc_count.add(word_size);
+      if ((_alloc_count.count() % 20) == 0) {
+        verify_arena_statistics();
+        DEBUG_ONLY(_arena->verify(true);)
+      }
+      return true;
+    } else {
+      _size_of_last_failed_allocation = word_size;
+    }
+    return false;
+  }
+
+  // Deallocate a random allocation
+  void checked_random_deallocate() {
+    allocation_t* a = _allocations;
+    while (a && a->p != NULL && os::random() % 10 != 0) {
+      a = a->next;
+    }
+    if (a != NULL && a->p != NULL) {
+      a->verify();
+      _arena->deallocate(a->p, a->word_size);
+      _dealloc_count.add(a->word_size);
+      a->p = NULL; a->word_size = 0;
+      if ((_dealloc_count.count() % 20) == 0) {
+        verify_arena_statistics();
+        DEBUG_ONLY(_arena->verify(true);)
+      }
+    }
+  }
+
+}; // End: MetaspaceArenaTestBed
+
+
+class MetaspaceArenaTest {
+
+  MetaspaceTestContext _helper;
+
+  SizeAtomicCounter _used_words_counter;
+
+  SparseArray<MetaspaceArenaTestBed*> _testbeds;
+  IntCounter _num_beds;
+
+  //////// Bed creation, destruction ///////
+
+  void create_new_test_bed_at(int slotindex, const ArenaGrowthPolicy* growth_policy, SizeRange allocation_range) {
+    DEBUG_ONLY(_testbeds.check_slot_is_null(slotindex));
+    MetaspaceArenaTestBed* bed = new MetaspaceArenaTestBed(&_helper.cm(), growth_policy,
+                                                       &_used_words_counter, allocation_range);
+    _testbeds.set_at(slotindex, bed);
+    _num_beds.increment();
+  }
+
+  void create_random_test_bed_at(int slotindex) {
+    SizeRange allocation_range(1, 100); // randomize too?
+    const ArenaGrowthPolicy* growth_policy = ArenaGrowthPolicy::policy_for_space_type(
+        (fifty_fifty() ? Metaspace::StandardMetaspaceType : Metaspace::ReflectionMetaspaceType),
+         fifty_fifty());
+    create_new_test_bed_at(slotindex, growth_policy, allocation_range);
+   }
+
+  // Randomly create a random test bed at a random slot, and return its slot index
+  // (returns false if we reached max number of test beds)
+  bool create_random_test_bed() {
+    const int slot = _testbeds.random_null_slot_index();
+    if (slot != -1) {
+      create_random_test_bed_at(slot);
+    }
+    return slot;
+  }
+
+  // Create test beds for all slots
+  void create_all_test_beds() {
+    for (int slot = 0; slot < _testbeds.size(); slot ++) {
+      if (_testbeds.slot_is_null(slot)) {
+        create_random_test_bed_at(slot);
+      }
+    }
+  }
+
+  void delete_test_bed_at(int slotindex) {
+    DEBUG_ONLY(_testbeds.check_slot_is_not_null(slotindex));
+    MetaspaceArenaTestBed* bed = _testbeds.at(slotindex);
+    delete bed; // This will return all its memory to the chunk manager
+    _testbeds.set_at(slotindex, NULL);
+    _num_beds.decrement();
+  }
+
+  // Randomly delete a random test bed at a random slot
+  // Return false if there are no test beds to delete.
+  bool delete_random_test_bed() {
+    const int slotindex = _testbeds.random_non_null_slot_index();
+    if (slotindex != -1) {
+      delete_test_bed_at(slotindex);
+      return true;
+    }
+    return false;
+  }
+
+  // Delete all test beds.
+  void delete_all_test_beds() {
+    for (int slot = _testbeds.first_non_null_slot(); slot != -1; slot = _testbeds.next_non_null_slot(slot)) {
+      delete_test_bed_at(slot);
+    }
+  }
+
+  //////// Allocating metaspace from test beds ///////
+
+  bool random_allocate_from_testbed(int slotindex) {
+    DEBUG_ONLY(_testbeds.check_slot_is_not_null(slotindex);)
+    MetaspaceArenaTestBed* bed = _testbeds.at(slotindex);
+    bool success = bed->checked_random_allocate();
+    if (success == false) {
+      // We must have hit a limit.
+      EXPECT_LT(_helper.commit_limiter().possible_expansion_words(),
+                metaspace::get_raw_word_size_for_requested_word_size(bed->size_of_last_failed_allocation()));
+    }
+    return success;
+  }
+
+  // Allocate multiple times random sizes from a single MetaspaceArena.
+  bool random_allocate_multiple_times_from_testbed(int slotindex, int num_allocations) {
+    bool success = true;
+    int n = 0;
+    while (success && n < num_allocations) {
+      success = random_allocate_from_testbed(slotindex);
+      n ++;
+    }
+    return success;
+  }
+
+  // Allocate multiple times random sizes from a single random MetaspaceArena.
+  bool random_allocate_random_times_from_random_testbed() {
+    int slot = _testbeds.random_non_null_slot_index();
+    bool success = false;
+    if (slot != -1) {
+      const int n = IntRange(5, 20).random_value();
+      success = random_allocate_multiple_times_from_testbed(slot, n);
+    }
+    return success;
+  }
+
+  /////// Deallocating from testbed ///////////////////
+
+  void deallocate_from_testbed(int slotindex) {
+    DEBUG_ONLY(_testbeds.check_slot_is_not_null(slotindex);)
+    MetaspaceArenaTestBed* bed = _testbeds.at(slotindex);
+    bed->checked_random_deallocate();
+  }
+
+  void deallocate_from_random_testbed() {
+    int slot = _testbeds.random_non_null_slot_index();
+    if (slot != -1) {
+      deallocate_from_testbed(slot);
+    }
+  }
+
+  /////// Stats ///////////////////////////////////////
+
+  int get_total_number_of_allocations() const {
+    int sum = 0;
+    for (int i = _testbeds.first_non_null_slot(); i != -1; i = _testbeds.next_non_null_slot(i)) {
+      sum += _testbeds.at(i)->num_allocations();
+    }
+    return sum;
+  }
+
+  size_t get_total_words_allocated() const {
+    size_t sum = 0;
+    for (int i = _testbeds.first_non_null_slot(); i != -1; i = _testbeds.next_non_null_slot(i)) {
+      sum += _testbeds.at(i)->words_allocated();
+    }
+    return sum;
+  }
+
+public:
+
+  MetaspaceArenaTest(size_t commit_limit, int num_testbeds)
+    : _helper(commit_limit),
+      _testbeds(num_testbeds),
+      _num_beds()
+  {}
+
+  ~MetaspaceArenaTest () {
+
+    delete_all_test_beds();
+
+  }
+
+
+  //////////////// Tests ////////////////////////
+
+  void test() {
+
+    // In a big loop, randomly chose one of these actions
+    // - creating a test bed (simulates a new loader creation)
+    // - allocating from a test bed (simulates allocating metaspace for a loader)
+    // - (rarely) deallocate (simulates metaspace deallocation, e.g. class redefinitions)
+    // - delete a test bed (simulates collection of a loader and subsequent return of metaspace to freelists)
+
+    const int iterations = 10000;
+
+    // Lets have a ceiling on number of words allocated (this is independent from the commit limit)
+    const size_t max_allocation_size = 8 * M;
+
+    bool force_bed_deletion = false;
+
+    for (int niter = 0; niter < iterations; niter ++) {
+
+      const int r = IntRange(100).random_value();
+
+      if (force_bed_deletion || r < 10) {
+
+        force_bed_deletion = false;
+        delete_random_test_bed();
+
+      } else if (r < 20 || _num_beds.get() < (unsigned)_testbeds.size() / 2) {
+
+        create_random_test_bed();
+
+      } else if (r < 95) {
+
+        // If allocation fails, we hit the commit limit and should delete some beds first
+        force_bed_deletion = ! random_allocate_random_times_from_random_testbed();
+
+      } else {
+
+        // Note: does not affect the used words counter.
+        deallocate_from_random_testbed();
+
+      }
+
+      // If we are close to our quota, start bed deletion
+      if (_used_words_counter.get() >= max_allocation_size) {
+
+        force_bed_deletion = true;
+
+      }
+
+    }
+
+  }
+
+
+};
+
+
+// 32 parallel MetaspaceArena objects, random allocating without commit limit
+TEST_VM(metaspace, MetaspaceArena_random_allocs_32_beds_no_commit_limit) {
+  MetaspaceArenaTest test(max_uintx, 32);
+  test.test();
+}
+
+// 32 parallel Metaspace arena objects, random allocating with commit limit
+TEST_VM(metaspace, MetaspaceArena_random_allocs_32_beds_with_commit_limit) {
+  MetaspaceArenaTest test(2 * M, 32);
+  test.test();
+}
+
+// A single MetaspaceArena, random allocating without commit limit. This should exercise
+//  chunk enlargement since allocation is undisturbed.
+TEST_VM(metaspace, MetaspaceArena_random_allocs_1_bed_no_commit_limit) {
+  MetaspaceArenaTest test(max_uintx, 1);
+  test.test();
+}
+
+
+
+
+
diff --git a/test/hotspot/gtest/metaspace/test_report.cpp b/test/hotspot/gtest/metaspace/test_report.cpp
new file mode 100644
--- /dev/null
+++ b/test/hotspot/gtest/metaspace/test_report.cpp
@@ -0,0 +1,55 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+
+//#define LOG_PLEASE
+
+#include "metaspaceTestsCommon.hpp"
+#include "utilities/globalDefinitions.hpp"
+#include "utilities/ostream.hpp"
+
+TEST_VM(metaspace, report_basic) {
+
+  stringStream ss;
+  //outputStream* st = tty;
+  outputStream* st = &ss;
+
+  MetaspaceUtils::print_basic_report(st, 0);
+
+  ASSERT_GT(ss.size(), (size_t)0);
+
+}
+
+// Note: full report needs CLDG lock or a safepoint. We test this as part of the
+// metaspace jtreg jcmd tests, lets not test it here.
+//TEST_VM(metaspace, report_full) {
+//
+//  outputStream* st = tty;
+//
+//  metaspace::MetaspaceReporter::print_report(st, 0, 0);
+//
+//}
+
diff --git a/test/hotspot/gtest/metaspace/test_virtualspacenode.cpp b/test/hotspot/gtest/metaspace/test_virtualspacenode.cpp
new file mode 100644
--- /dev/null
+++ b/test/hotspot/gtest/metaspace/test_virtualspacenode.cpp
@@ -0,0 +1,583 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+
+ #define LOG_PLEASE
+
+#include "metaspace/metaspaceTestsCommon.hpp"
+#include "metaspace/metaspace_rangehelpers.hpp"
+
+static int test_node_id = 100000; // start high to make it stick out in logs.
+
+
+
+class VirtualSpaceNodeTest {
+
+  // These counters are updated by the Node.
+  SizeCounter _counter_reserved_words;
+  SizeCounter _counter_committed_words;
+  CommitLimiter _commit_limiter;
+  VirtualSpaceNode* _node;
+
+  // These are my checks and counters.
+  const size_t _vs_word_size;
+  const size_t _commit_limit;
+
+  MetachunkList _root_chunks;
+
+  void verify() const {
+
+    ASSERT_EQ(_root_chunks.count() * metaspace::chunklevel::MAX_CHUNK_WORD_SIZE,
+              _node->used_words());
+
+    ASSERT_GE(_commit_limit,                      _counter_committed_words.get());
+    ASSERT_EQ(_commit_limiter.committed_words(),  _counter_committed_words.get());
+
+    // Since we know _counter_committed_words serves our single node alone, the counter has to
+    // match the number of bits in the node internal commit mask.
+    ASSERT_EQ(_counter_committed_words.get(), _node->committed_words());
+
+    ASSERT_EQ(_counter_reserved_words.get(), _vs_word_size);
+    ASSERT_EQ(_counter_reserved_words.get(), _node->word_size());
+
+  }
+
+  void lock_and_verify_node() {
+#ifdef ASSERT
+    MutexLocker fcl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
+    _node->verify_locked(true);
+#endif
+  }
+
+  Metachunk* alloc_root_chunk() {
+
+    verify();
+
+    const bool node_is_full = _node->used_words() == _node->word_size();
+    Metachunk* c = NULL;
+    {
+      MutexLocker fcl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
+      c = _node->allocate_root_chunk();
+    }
+
+    lock_and_verify_node();
+
+    if (node_is_full) {
+
+      EXPECT_NULL(c);
+
+    } else {
+
+      DEBUG_ONLY(c->verify(true);)
+      EXPECT_NOT_NULL(c);
+      EXPECT_TRUE(c->is_root_chunk());
+      EXPECT_TRUE(c->is_free());
+      EXPECT_EQ(c->word_size(), metaspace::chunklevel::MAX_CHUNK_WORD_SIZE);
+
+      EXPECT_TRUE(c->is_fully_uncommitted());
+
+      EXPECT_TRUE(_node->contains(c->base()));
+
+      _root_chunks.add(c);
+
+    }
+
+    verify();
+
+    return c;
+
+  }
+
+  bool commit_root_chunk(Metachunk* c, size_t request_commit_words) {
+
+    verify();
+
+    const size_t committed_words_before = _counter_committed_words.get();
+
+    bool rc = c->ensure_committed(request_commit_words);
+
+    verify();
+    DEBUG_ONLY(c->verify(true);)
+
+    lock_and_verify_node();
+
+    if (rc == false) {
+
+      // We must have hit the commit limit.
+      EXPECT_GE(committed_words_before + request_commit_words, _commit_limit);
+
+    } else {
+
+      // We should not have hit the commit limit.
+      EXPECT_LE(_counter_committed_words.get(), _commit_limit);
+
+      // We do not know how much we really committed - maybe nothing if the
+      // chunk had been committed before - but we know the numbers should have
+      // risen or at least stayed equal.
+      EXPECT_GE(_counter_committed_words.get(), committed_words_before);
+
+      // The chunk should be as far committed as was requested
+      EXPECT_GE(c->committed_words(), request_commit_words);
+
+      // Zap committed portion.
+      DEBUG_ONLY(zap_range(c->base(), c->committed_words());)
+
+    }
+
+    verify();
+
+    return rc;
+
+  } // commit_root_chunk
+
+  void uncommit_chunk(Metachunk* c) {
+
+    verify();
+
+    const size_t committed_words_before = _counter_committed_words.get();
+    const size_t available_words_before = _commit_limiter.possible_expansion_words();
+
+    c->uncommit();
+
+    DEBUG_ONLY(c->verify(true);)
+
+    lock_and_verify_node();
+
+    EXPECT_EQ(c->committed_words(), (size_t)0);
+
+    // Commit counter should have gone down (by exactly the size of the chunk) if chunk
+    // is larger than a commit granule.
+    // For smaller chunks, we do not know, but at least we know the commit size should not
+    // have gone up.
+    if (c->word_size() >= Settings::commit_granule_words()) {
+
+      EXPECT_EQ(_counter_committed_words.get(), committed_words_before - c->word_size());
+
+      // also, commit number in commit limiter should have gone down, so we have more space
+      EXPECT_EQ(_commit_limiter.possible_expansion_words(),
+                available_words_before + c->word_size());
+
+    } else {
+
+      EXPECT_LE(_counter_committed_words.get(), committed_words_before);
+
+    }
+
+    verify();
+
+  } // uncommit_chunk
+
+  Metachunk* split_chunk_with_checks(Metachunk* c, chunklevel_t target_level, FreeChunkListVector* freelist) {
+
+    DEBUG_ONLY(c->verify(true);)
+
+    const chunklevel_t orig_level = c->level();
+    assert(orig_level < target_level, "Sanity");
+    DEBUG_ONLY(metaspace::chunklevel::check_valid_level(target_level);)
+
+    const int total_num_chunks_in_freelist_before = freelist->num_chunks();
+    const size_t total_word_size_in_freelist_before = freelist->word_size();
+
+   // freelist->print_on(tty);
+
+    // Split...
+    {
+      MutexLocker fcl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
+      _node->split(target_level, c, freelist);
+    }
+
+    // freelist->print_on(tty);
+
+    EXPECT_NOT_NULL(c);
+    EXPECT_EQ(c->level(), target_level);
+    EXPECT_TRUE(c->is_free());
+
+    // ... check that we get the proper amount of splinters. For every chunk split we expect one
+    // buddy chunk to appear of level + 1 (aka, half size).
+    size_t expected_wordsize_increase = 0;
+    int expected_num_chunks_increase = 0;
+    for (chunklevel_t l = orig_level + 1; l <= target_level; l ++) {
+      expected_wordsize_increase += metaspace::chunklevel::word_size_for_level(l);
+      expected_num_chunks_increase ++;
+    }
+
+    const int total_num_chunks_in_freelist_after = freelist->num_chunks();
+    const size_t total_word_size_in_freelist_after = freelist->word_size();
+
+    EXPECT_EQ(total_num_chunks_in_freelist_after, total_num_chunks_in_freelist_before + expected_num_chunks_increase);
+    EXPECT_EQ(total_word_size_in_freelist_after, total_word_size_in_freelist_before + expected_wordsize_increase);
+
+    return c;
+
+  } // end: split_chunk_with_checks
+
+
+  Metachunk* merge_chunk_with_checks(Metachunk* c, chunklevel_t expected_target_level, FreeChunkListVector* freelist) {
+
+    const chunklevel_t orig_level = c->level();
+    assert(expected_target_level < orig_level, "Sanity");
+
+    const int total_num_chunks_in_freelist_before = freelist->num_chunks();
+    const size_t total_word_size_in_freelist_before = freelist->word_size();
+
+    //freelist->print_on(tty);
+
+    Metachunk* result = NULL;
+    {
+      MutexLocker fcl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
+      result = _node->merge(c, freelist);
+    }
+    EXPECT_NOT_NULL(result);
+    EXPECT_TRUE(result->level() == expected_target_level);
+
+    //freelist->print_on(tty);
+
+    // ... check that we merged in the proper amount of chunks. For every decreased level
+    // of the original chunk (each size doubling) we should see one buddy chunk swallowed up.
+    size_t expected_wordsize_decrease = 0;
+    int expected_num_chunks_decrease = 0;
+    for (chunklevel_t l = orig_level; l > expected_target_level; l --) {
+      expected_wordsize_decrease += metaspace::chunklevel::word_size_for_level(l);
+      expected_num_chunks_decrease ++;
+    }
+
+    const int total_num_chunks_in_freelist_after = freelist->num_chunks();
+    const size_t total_word_size_in_freelist_after = freelist->word_size();
+
+    EXPECT_EQ(total_num_chunks_in_freelist_after, total_num_chunks_in_freelist_before - expected_num_chunks_decrease);
+    EXPECT_EQ(total_word_size_in_freelist_after, total_word_size_in_freelist_before - expected_wordsize_decrease);
+
+    return result;
+
+  } // end: merge_chunk_with_checks
+
+public:
+
+  VirtualSpaceNodeTest(size_t vs_word_size, size_t commit_limit)
+    : _counter_reserved_words(), _counter_committed_words(), _commit_limiter(commit_limit),
+      _node(NULL), _vs_word_size(vs_word_size), _commit_limit(commit_limit)
+  {
+    {
+      MutexLocker fcl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
+      _node = VirtualSpaceNode::create_node(vs_word_size, &_commit_limiter,
+                                            &_counter_reserved_words, &_counter_committed_words);
+      EXPECT_EQ(_node->word_size(), vs_word_size);
+    }
+    EXPECT_TRUE(_commit_limiter.possible_expansion_words() == _commit_limit);
+    verify();
+  }
+
+  ~VirtualSpaceNodeTest() {
+    {
+      MutexLocker fcl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
+      delete _node;
+    }
+    // After the node is deleted, counters should be back to zero
+    // (we cannot use ASSERT/EXPECT here in the destructor)
+    assert(_counter_reserved_words.get() == 0, "Sanity");
+    assert(_counter_committed_words.get() == 0, "Sanity");
+    assert(_commit_limiter.committed_words() == 0, "Sanity");
+  }
+
+  void test_simple() {
+    Metachunk* c = alloc_root_chunk();
+    commit_root_chunk(c, Settings::commit_granule_words());
+    commit_root_chunk(c, c->word_size());
+    uncommit_chunk(c);
+  }
+
+  void test_exhaust_node() {
+    Metachunk* c = NULL;
+    bool rc = true;
+    do {
+      c = alloc_root_chunk();
+      if (c != NULL) {
+        rc = commit_root_chunk(c, c->word_size());
+      }
+    } while (c != NULL && rc);
+  }
+
+  void test_arbitrary_commits() {
+
+    assert(_commit_limit >= _vs_word_size, "For this test no commit limit.");
+
+    // Get a root chunk to have a committable region
+    Metachunk* c = alloc_root_chunk();
+    ASSERT_NOT_NULL(c);
+
+    if (c->committed_words() > 0) {
+      c->uncommit();
+    }
+
+    ASSERT_EQ(_node->committed_words(), (size_t)0);
+    ASSERT_EQ(_counter_committed_words.get(), (size_t)0);
+
+    TestMap testmap(c->word_size());
+    assert(testmap.get_num_set() == 0, "Sanity");
+
+    for (int run = 0; run < 1000; run ++) {
+
+      const size_t committed_words_before = testmap.get_num_set();
+      ASSERT_EQ(_commit_limiter.committed_words(), committed_words_before);
+      ASSERT_EQ(_counter_committed_words.get(), committed_words_before);
+
+      // A random range
+      SizeRange r = SizeRange(c->word_size()).random_aligned_subrange(Settings::commit_granule_words());
+
+      const size_t committed_words_in_range_before =
+                   testmap.get_num_set(r.start(), r.end());
+
+      const bool do_commit = IntRange(100).random_value() >= 50;
+      if (do_commit) {
+
+        //LOG("c " SIZE_FORMAT "," SIZE_FORMAT, r.start(), r.end());
+
+        bool rc = false;
+        {
+          MutexLocker fcl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
+          rc = _node->ensure_range_is_committed(c->base() + r.start(), r.size());
+        }
+
+        // Test-zap
+        zap_range(c->base() + r.start(), r.size());
+
+        // We should never reach commit limit since it is as large as the whole area.
+        ASSERT_TRUE(rc);
+
+        testmap.set_range(r.start(), r.end());
+
+      } else {
+
+        //LOG("u " SIZE_FORMAT "," SIZE_FORMAT, r.start(), r.end());
+
+        {
+          MutexLocker fcl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
+          _node->uncommit_range(c->base() + r.start(), r.size());
+        }
+
+        testmap.clear_range(r.start(), r.end());
+
+      }
+
+      const size_t committed_words_after = testmap.get_num_set();
+
+      ASSERT_EQ(_commit_limiter.committed_words(), committed_words_after);
+      ASSERT_EQ(_counter_committed_words.get(), committed_words_after);
+
+      verify();
+    }
+  }
+
+  // Helper function for test_splitting_chunks_1
+  static void check_chunk_is_committed_at_least_up_to(const Metachunk* c, size_t& word_size) {
+    if (word_size >= c->word_size()) {
+      EXPECT_TRUE(c->is_fully_committed());
+      word_size -= c->word_size();
+    } else {
+      EXPECT_EQ(c->committed_words(), word_size);
+      word_size = 0; // clear remaining size if there is.
+    }
+  }
+
+  void test_split_and_merge_chunks() {
+
+    assert(_commit_limit >= _vs_word_size, "No commit limit here pls");
+
+    // Allocate a root chunk and commit a random part of it. Then repeatedly split
+    // it and merge it back together; observe the committed regions of the split chunks.
+
+    Metachunk* c = alloc_root_chunk();
+
+    if (c->committed_words() > 0) {
+      c->uncommit();
+    }
+
+    // To capture split-off chunks. Note: it is okay to use this here as a temp object.
+    FreeChunkListVector freelist;
+
+    const int granules_per_root_chunk = (int)(c->word_size() / Settings::commit_granule_words());
+
+    for (int granules_to_commit = 0; granules_to_commit < granules_per_root_chunk; granules_to_commit ++) {
+
+      const size_t words_to_commit = Settings::commit_granule_words() * granules_to_commit;
+
+      c->ensure_committed(words_to_commit);
+
+      ASSERT_EQ(c->committed_words(), words_to_commit);
+      ASSERT_EQ(_counter_committed_words.get(), words_to_commit);
+      ASSERT_EQ(_commit_limiter.committed_words(), words_to_commit);
+
+      const size_t committed_words_before = c->committed_words();
+
+      verify();
+
+      for (chunklevel_t target_level = LOWEST_CHUNK_LEVEL + 1;
+           target_level <= HIGHEST_CHUNK_LEVEL; target_level ++) {
+
+        // Split:
+        Metachunk* c2 = split_chunk_with_checks(c, target_level, &freelist);
+        c2->set_in_use();
+
+        // Split smallest leftover chunk.
+        if (c2->level() < HIGHEST_CHUNK_LEVEL) {
+
+          Metachunk* c3 = freelist.remove_first(c2->level());
+          ASSERT_NOT_NULL(c3); // Must exist since c2 must have a splinter buddy now.
+
+          Metachunk* c4 = split_chunk_with_checks(c3, HIGHEST_CHUNK_LEVEL, &freelist);
+          c4->set_in_use();
+
+          // Merge it back. We expect this to merge up to c2's level, since c2 is in use.
+          c4->set_free();
+          Metachunk* c5 = merge_chunk_with_checks(c4, c2->level(), &freelist);
+          ASSERT_NOT_NULL(c5);
+          freelist.add(c5);
+
+        }
+
+        // Merge c2 back.
+        c2->set_free();
+        merge_chunk_with_checks(c2, LOWEST_CHUNK_LEVEL, &freelist);
+
+        // After all this splitting and combining committed size should not have changed.
+        ASSERT_EQ(c2->committed_words(), committed_words_before);
+
+      }
+
+    }
+
+  } // end: test_splitting_chunks
+
+
+
+
+};
+
+
+
+TEST_VM(metaspace, virtual_space_node_test_basics) {
+
+  MutexLocker fcl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
+
+  const size_t word_size = metaspace::chunklevel::MAX_CHUNK_WORD_SIZE * 10;
+
+  SizeCounter scomm;
+  SizeCounter sres;
+  CommitLimiter cl (word_size * 2); // basically, no commit limiter.
+
+  VirtualSpaceNode* node = VirtualSpaceNode::create_node(word_size, &cl, &sres, &scomm);
+  ASSERT_NOT_NULL(node);
+  ASSERT_EQ(node->committed_words(), (size_t)0);
+  ASSERT_EQ(node->committed_words(), scomm.get());
+  DEBUG_ONLY(node->verify_locked(true);)
+
+  bool b = node->ensure_range_is_committed(node->base(), node->word_size());
+  ASSERT_TRUE(b);
+  ASSERT_EQ(node->committed_words(), word_size);
+  ASSERT_EQ(node->committed_words(), scomm.get());
+  DEBUG_ONLY(node->verify_locked(true);)
+  zap_range(node->base(), node->word_size());
+
+  node->uncommit_range(node->base(), node->word_size());
+  ASSERT_EQ(node->committed_words(), (size_t)0);
+  ASSERT_EQ(node->committed_words(), scomm.get());
+  DEBUG_ONLY(node->verify_locked(true);)
+
+  const int num_granules = (int)(word_size / Settings::commit_granule_words());
+  for (int i = 1; i < num_granules; i += 4) {
+    b = node->ensure_range_is_committed(node->base(), i * Settings::commit_granule_words());
+    ASSERT_TRUE(b);
+    ASSERT_EQ(node->committed_words(), i * Settings::commit_granule_words());
+    ASSERT_EQ(node->committed_words(), scomm.get());
+    DEBUG_ONLY(node->verify_locked(true);)
+    zap_range(node->base(), i * Settings::commit_granule_words());
+  }
+
+  node->uncommit_range(node->base(), node->word_size());
+  ASSERT_EQ(node->committed_words(), (size_t)0);
+  ASSERT_EQ(node->committed_words(), scomm.get());
+  DEBUG_ONLY(node->verify_locked(true);)
+
+}
+
+
+// Note: we unfortunately need TEST_VM even though the system tested
+// should be pretty independent since we need things like os::vm_page_size()
+// which in turn need OS layer initialization.
+TEST_VM(metaspace, virtual_space_node_test_1) {
+  VirtualSpaceNodeTest test(metaspace::chunklevel::MAX_CHUNK_WORD_SIZE,
+      metaspace::chunklevel::MAX_CHUNK_WORD_SIZE);
+  test.test_simple();
+}
+
+TEST_VM(metaspace, virtual_space_node_test_2) {
+  // Should not hit commit limit
+  VirtualSpaceNodeTest test(3 * metaspace::chunklevel::MAX_CHUNK_WORD_SIZE,
+      3 * metaspace::chunklevel::MAX_CHUNK_WORD_SIZE);
+  test.test_simple();
+  test.test_exhaust_node();
+}
+
+TEST_VM(metaspace, virtual_space_node_test_3) {
+  double d = os::elapsedTime();
+  // Test committing uncommitting arbitrary ranges
+  for (int run = 0; run < 100; run ++) {
+    VirtualSpaceNodeTest test(metaspace::chunklevel::MAX_CHUNK_WORD_SIZE,
+        metaspace::chunklevel::MAX_CHUNK_WORD_SIZE);
+    test.test_split_and_merge_chunks();
+  }
+  double d2 = os::elapsedTime();
+  LOG("%f", (d2-d));
+}
+
+TEST_VM(metaspace, virtual_space_node_test_4) {
+  // Should hit commit limit
+  VirtualSpaceNodeTest test(10 * metaspace::chunklevel::MAX_CHUNK_WORD_SIZE,
+      3 * metaspace::chunklevel::MAX_CHUNK_WORD_SIZE);
+  test.test_exhaust_node();
+}
+
+TEST_VM(metaspace, virtual_space_node_test_5) {
+  // Test committing uncommitting arbitrary ranges
+  VirtualSpaceNodeTest test(metaspace::chunklevel::MAX_CHUNK_WORD_SIZE,
+      metaspace::chunklevel::MAX_CHUNK_WORD_SIZE);
+  test.test_arbitrary_commits();
+}
+
+TEST_VM(metaspace, virtual_space_node_test_7) {
+  // Test large allocation and freeing.
+  {
+    VirtualSpaceNodeTest test(metaspace::chunklevel::MAX_CHUNK_WORD_SIZE * 100,
+        metaspace::chunklevel::MAX_CHUNK_WORD_SIZE * 100);
+    test.test_exhaust_node();
+  }
+  {
+    VirtualSpaceNodeTest test(metaspace::chunklevel::MAX_CHUNK_WORD_SIZE * 100,
+        metaspace::chunklevel::MAX_CHUNK_WORD_SIZE * 100);
+    test.test_exhaust_node();
+  }
+
+}
diff --git a/test/hotspot/jtreg/TEST.groups b/test/hotspot/jtreg/TEST.groups
--- a/test/hotspot/jtreg/TEST.groups
+++ b/test/hotspot/jtreg/TEST.groups
@@ -77,7 +77,8 @@
 
 tier1_common = \
   sanity/BasicVMTest.java \
-  gtest/GTestWrapper.java
+  gtest/GTestWrapper.java \
+  gtest/MetaspaceGtests.java
 
 tier1_compiler = \
   :tier1_compiler_1 \
@@ -351,6 +352,15 @@
   serviceability/sa \
  -runtime/cds/DeterministicDump.java
 
+# needs -nativepath:<output>/images/test/hotspot/jtreg/native/
+hotspot_metaspace = \
+  gtest/MetaspaceGtests.java \
+  gc/metaspace \
+  gc/class_unloading \
+  runtime/Metaspace \
+  vmTestbase/metaspace \
+  runtime/SelectionResolution
+
 # A subset of AppCDS tests to be run in tier1
 tier1_runtime_appcds = \
   runtime/cds/appcds/HelloTest.java \
diff --git a/test/hotspot/jtreg/gc/TestSystemGC.java b/test/hotspot/jtreg/gc/TestSystemGC.java
--- a/test/hotspot/jtreg/gc/TestSystemGC.java
+++ b/test/hotspot/jtreg/gc/TestSystemGC.java
@@ -44,8 +44,7 @@
  * @run main/othervm -XX:+UseG1GC gc.TestSystemGC
  * @run main/othervm -XX:+UseG1GC -XX:+ExplicitGCInvokesConcurrent gc.TestSystemGC
  * @run main/othervm -XX:+UseLargePages gc.TestSystemGC
- * @run main/othervm -XX:+UseLargePages -XX:+UseLargePagesInMetaspace gc.TestSystemGC
- */
+  */
 
 /*
  * @test TestSystemGCShenandoah
diff --git a/test/hotspot/jtreg/gc/class_unloading/TestG1ClassUnloadingHWM.java b/test/hotspot/jtreg/gc/class_unloading/TestG1ClassUnloadingHWM.java
--- a/test/hotspot/jtreg/gc/class_unloading/TestG1ClassUnloadingHWM.java
+++ b/test/hotspot/jtreg/gc/class_unloading/TestG1ClassUnloadingHWM.java
@@ -102,12 +102,18 @@
       // Allocate past the MetaspaceSize limit
       long metaspaceSize = Long.parseLong(args[0]);
       long allocationBeyondMetaspaceSize  = metaspaceSize * 2;
-      long metaspace = wb.allocateMetaspace(null, allocationBeyondMetaspaceSize);
+
+      // There is a cap on how large a single metaspace allocation can get. So we may have to allocate in blocks.
+      final long max = wb.maxMetaspaceAllocationSize();
+      while (allocationBeyondMetaspaceSize > 0) {
+        long s = max < allocationBeyondMetaspaceSize ? max : allocationBeyondMetaspaceSize;
+        wb.allocateMetaspace(null, s);
+        allocationBeyondMetaspaceSize -= s;
+      }
 
       long youngGenSize = Long.parseLong(args[1]);
       triggerYoungGCs(youngGenSize);
 
-      wb.freeMetaspace(null, metaspace, metaspace);
     }
 
     public static void triggerYoungGCs(long youngGenSize) {
diff --git a/test/hotspot/jtreg/gc/metaspace/CompressedClassSpaceSizeInJmapHeap.java b/test/hotspot/jtreg/gc/metaspace/CompressedClassSpaceSizeInJmapHeap.java
--- a/test/hotspot/jtreg/gc/metaspace/CompressedClassSpaceSizeInJmapHeap.java
+++ b/test/hotspot/jtreg/gc/metaspace/CompressedClassSpaceSizeInJmapHeap.java
@@ -32,7 +32,7 @@
  * @library /test/lib
  * @modules java.base/jdk.internal.misc
  *          java.management
- * @run main/othervm -XX:+IgnoreUnrecognizedVMOptions -XX:CompressedClassSpaceSize=50m gc.metaspace.CompressedClassSpaceSizeInJmapHeap
+ * @run main/othervm -XX:+IgnoreUnrecognizedVMOptions -XX:CompressedClassSpaceSize=48m gc.metaspace.CompressedClassSpaceSizeInJmapHeap
  */
 
 import jdk.test.lib.JDKToolLauncher;
@@ -67,7 +67,7 @@
         run(pb);
 
         OutputAnalyzer output = new OutputAnalyzer(read(out));
-        output.shouldContain("CompressedClassSpaceSize = 52428800 (50.0MB)");
+        output.shouldContain("CompressedClassSpaceSize = 50331648 (48.0MB)");
         out.delete();
     }
 
diff --git a/test/hotspot/jtreg/gtest/GTestWrapper.java b/test/hotspot/jtreg/gtest/GTestWrapper.java
--- a/test/hotspot/jtreg/gtest/GTestWrapper.java
+++ b/test/hotspot/jtreg/gtest/GTestWrapper.java
@@ -37,6 +37,7 @@
 import java.nio.file.Files;
 import java.nio.file.Path;
 import java.nio.file.Paths;
+import java.util.ArrayList;
 import java.util.Collections;
 import java.util.List;
 import java.util.Map;
@@ -75,9 +76,16 @@
         }
 
         Path resultFile = Paths.get("test_result.xml");
-        pb.command(execPath.toAbsolutePath().toString(),
-                "-jdk", Utils.TEST_JDK,
-                "--gtest_output=xml:" + resultFile);
+
+        ArrayList<String> command = new ArrayList<>();
+        command.add(execPath.toAbsolutePath().toString());
+        command.add("-jdk");
+        command.add(Utils.TEST_JDK);
+        command.add("--gtest_output=xml:" + resultFile);
+        for (String a : args) {
+            command.add(a);
+        }
+        pb.command(command);
         int exitCode = ProcessTools.executeCommand(pb).getExitValue();
         if (exitCode != 0) {
             List<String> failedTests = failedTests(resultFile);
diff --git a/test/hotspot/jtreg/gtest/MetaspaceGtests.java b/test/hotspot/jtreg/gtest/MetaspaceGtests.java
new file mode 100644
--- /dev/null
+++ b/test/hotspot/jtreg/gtest/MetaspaceGtests.java
@@ -0,0 +1,90 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+/*
+ * Note: This runs the metaspace-related parts of gtest in configurations which
+ *  are not tested explicitely in the standard gtests.
+ *
+ */
+
+/* @test id=reclaim-none-debug
+ * @summary Run metaspace-related gtests for reclaim policy none (with verifications)
+ * @requires vm.debug
+ * @library /test/lib
+ * @modules java.base/jdk.internal.misc
+ *          java.xml
+ * @run main/native GTestWrapper --gtest_filter=metaspace* -XX:MetaspaceReclaimPolicy=none -XX:+UnlockDiagnosticVMOptions -XX:VerifyMetaspaceInterval=3
+ */
+
+/* @test id=reclaim-none-ndebug
+ * @summary Run metaspace-related gtests for reclaim policy none
+ * @library /test/lib
+ * @modules java.base/jdk.internal.misc
+ *          java.xml
+ * @run main/native GTestWrapper --gtest_filter=metaspace* -XX:MetaspaceReclaimPolicy=none
+ */
+
+
+
+
+/* @test id=reclaim-aggressive-debug
+ * @summary Run metaspace-related gtests for reclaim policy aggressive (with verifications)
+ * @requires vm.debug
+ * @library /test/lib
+ * @modules java.base/jdk.internal.misc
+ *          java.xml
+ * @run main/native GTestWrapper --gtest_filter=metaspace* -XX:MetaspaceReclaimPolicy=aggressive -XX:+UnlockDiagnosticVMOptions -XX:VerifyMetaspaceInterval=3
+ */
+
+/* @test id=reclaim-aggressive-ndebug
+ * @summary Run metaspace-related gtests for reclaim policy aggressive
+ * @library /test/lib
+ * @modules java.base/jdk.internal.misc
+ *          java.xml
+ * @run main/native GTestWrapper --gtest_filter=metaspace* -XX:MetaspaceReclaimPolicy=aggressive
+ */
+
+
+
+
+/* @test id=balanced-with-guards
+ * @summary Run metaspace-related gtests with allocation guards enabled
+ * @requires vm.debug
+ * @library /test/lib
+ * @modules java.base/jdk.internal.misc
+ *          java.xml
+ * @run main/native GTestWrapper --gtest_filter=metaspace* -XX:+UnlockDiagnosticVMOptions -XX:VerifyMetaspaceInterval=3 -XX:+MetaspaceGuardAllocations
+ */
+
+
+
+
+/* @test id=balanced-no-ccs
+ * @summary Run metaspace-related gtests with compressed class pointers off
+ * @library /test/lib
+ * @modules java.base/jdk.internal.misc
+ *          java.xml
+ * @run main/native GTestWrapper --gtest_filter=metaspace* -XX:MetaspaceReclaimPolicy=balanced -XX:-UseCompressedClassPointers
+ */
diff --git a/test/hotspot/jtreg/runtime/CommandLine/OptionsValidation/TestOptionsWithRanges.java b/test/hotspot/jtreg/runtime/CommandLine/OptionsValidation/TestOptionsWithRanges.java
--- a/test/hotspot/jtreg/runtime/CommandLine/OptionsValidation/TestOptionsWithRanges.java
+++ b/test/hotspot/jtreg/runtime/CommandLine/OptionsValidation/TestOptionsWithRanges.java
@@ -233,7 +233,6 @@
         excludeTestMaxRange("G1RSetRegionEntries");
         excludeTestMaxRange("G1RSetSparseRegionEntries");
         excludeTestMaxRange("G1UpdateBufferSize");
-        excludeTestMaxRange("InitialBootClassLoaderMetaspaceSize");
         excludeTestMaxRange("InitialHeapSize");
         excludeTestMaxRange("MaxHeapSize");
         excludeTestMaxRange("MaxRAM");
diff --git a/test/hotspot/jtreg/runtime/CompressedOops/CompressedClassSpaceSize.java b/test/hotspot/jtreg/runtime/CompressedOops/CompressedClassSpaceSize.java
--- a/test/hotspot/jtreg/runtime/CompressedOops/CompressedClassSpaceSize.java
+++ b/test/hotspot/jtreg/runtime/CompressedOops/CompressedClassSpaceSize.java
@@ -64,12 +64,14 @@
 
 
         // Make sure the minimum size is set correctly and printed
+        // (Note: ccs size shall be rounded up to the minimum size of 4m since metaspace reservations
+        //  are done in a 4m granularity. Note that this is **reserved** size and does not affect rss.
         pb = ProcessTools.createJavaProcessBuilder("-XX:+UnlockDiagnosticVMOptions",
                                                    "-XX:CompressedClassSpaceSize=1m",
                                                    "-Xlog:gc+metaspace=trace",
                                                    "-version");
         output = new OutputAnalyzer(pb.start());
-        output.shouldMatch("Compressed class space.*1048576")
+        output.shouldMatch("Compressed class space.*4194304")
               .shouldHaveExitValue(0);
 
 
diff --git a/test/hotspot/jtreg/runtime/Metaspace/MaxMetaspaceSizeTest.java b/test/hotspot/jtreg/runtime/Metaspace/MaxMetaspaceSizeTest.java
--- a/test/hotspot/jtreg/runtime/Metaspace/MaxMetaspaceSizeTest.java
+++ b/test/hotspot/jtreg/runtime/Metaspace/MaxMetaspaceSizeTest.java
@@ -36,13 +36,16 @@
     public static void main(String... args) throws Exception {
         ProcessBuilder pb = ProcessTools.createJavaProcessBuilder(
             "-Xmx1g",
-            "-XX:InitialBootClassLoaderMetaspaceSize=4195328",
-            "-XX:MaxMetaspaceSize=4195328",
+            "-XX:MaxMetaspaceSize=4K",
             "-XX:+UseCompressedClassPointers",
             "-XX:CompressedClassSpaceSize=1g",
             "--version");
         OutputAnalyzer output = new OutputAnalyzer(pb.start());
-        output.shouldContain("MaxMetaspaceSize is too small.");
+        // We do not explicitly limit MaxMetaspaceSize to a lower minimum. User can get as low as he wants.
+        // However, you most certainly will hit either one of
+        // "OutOfMemoryError: Metaspace" or
+        // "OutOfMemoryError: Compressed class space"
+        output.shouldMatch("OutOfMemoryError.*(Compressed class space|Metaspace)");
         output.shouldNotHaveExitValue(0);
     }
 }
diff --git a/test/hotspot/jtreg/runtime/Metaspace/PrintMetaspaceDcmd.java b/test/hotspot/jtreg/runtime/Metaspace/PrintMetaspaceDcmd.java
--- a/test/hotspot/jtreg/runtime/Metaspace/PrintMetaspaceDcmd.java
+++ b/test/hotspot/jtreg/runtime/Metaspace/PrintMetaspaceDcmd.java
@@ -87,10 +87,19 @@
         pb.command(new String[] { JDKToolFinder.getJDKTool("jcmd"), pid, "VM.metaspace", "by-chunktype"});
         output = new OutputAnalyzer(pb.start());
         output.shouldHaveExitValue(0);
-        output.shouldContain("specialized:");
-        output.shouldContain("small:");
-        output.shouldContain("medium:");
-        output.shouldContain("humongous:");
+        output.shouldContain("1k:");
+        output.shouldContain("2k:");
+        output.shouldContain("4k:");
+        output.shouldContain("8k:");
+        output.shouldContain("16k:");
+        output.shouldContain("32k:");
+        output.shouldContain("64k:");
+        output.shouldContain("128k:");
+        output.shouldContain("256k:");
+        output.shouldContain("512k:");
+        output.shouldContain("1m:");
+        output.shouldContain("2m:");
+        output.shouldContain("4m:");
 
         pb.command(new String[] { JDKToolFinder.getJDKTool("jcmd"), pid, "VM.metaspace", "vslist"});
         output = new OutputAnalyzer(pb.start());
@@ -98,12 +107,6 @@
         output.shouldContain("Virtual space list");
         output.shouldMatch("node.*reserved.*committed.*used.*");
 
-        pb.command(new String[] { JDKToolFinder.getJDKTool("jcmd"), pid, "VM.metaspace", "vsmap"});
-        output = new OutputAnalyzer(pb.start());
-        output.shouldHaveExitValue(0);
-        output.shouldContain("Virtual space map:");
-        output.shouldContain("HHHHHHHHHHH");
-
         // Test with different scales
         pb.command(new String[] { JDKToolFinder.getJDKTool("jcmd"), pid, "VM.metaspace", "scale=G"});
         output = new OutputAnalyzer(pb.start());
diff --git a/test/hotspot/jtreg/runtime/Metaspace/elastic/Allocation.java b/test/hotspot/jtreg/runtime/Metaspace/elastic/Allocation.java
new file mode 100644
--- /dev/null
+++ b/test/hotspot/jtreg/runtime/Metaspace/elastic/Allocation.java
@@ -0,0 +1,47 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+public class Allocation {
+
+    public long p;
+    public long word_size;
+
+    public Allocation(long p, long word_size) {
+        this.p = p;
+        this.word_size = word_size;
+    }
+
+    public boolean isNull() {
+        return p == 0;
+    }
+
+    @Override
+    public String toString() {
+        return "Allocation{" +
+                "p=" + p +
+                ", word_size=" + word_size +
+                '}';
+    }
+}
diff --git a/test/hotspot/jtreg/runtime/Metaspace/elastic/AllocationProfile.java b/test/hotspot/jtreg/runtime/Metaspace/elastic/AllocationProfile.java
new file mode 100644
--- /dev/null
+++ b/test/hotspot/jtreg/runtime/Metaspace/elastic/AllocationProfile.java
@@ -0,0 +1,75 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+import java.util.*;
+
+public class AllocationProfile {
+
+    final String name;
+
+    // Allocation word size spread
+    public final long minimumSingleAllocationSize;
+    public final long maximumSingleAllocationSize;
+
+    // dealloc probability [0.0 .. 1.0]
+    public final double randomDeallocProbability;
+
+    public AllocationProfile(String name, long minimumSingleAllocationSize, long maximumSingleAllocationSize, double randomDeallocProbability) {
+        this.minimumSingleAllocationSize = minimumSingleAllocationSize;
+        this.maximumSingleAllocationSize = maximumSingleAllocationSize;
+        this.randomDeallocProbability = randomDeallocProbability;
+        this.name = name;
+    }
+
+    public long randomAllocationSize() {
+        Random r = new Random();
+        return r.nextInt((int)(maximumSingleAllocationSize - minimumSingleAllocationSize + 1)) + minimumSingleAllocationSize;
+    }
+
+
+    // Some standard profiles
+    static final List<AllocationProfile> standardProfiles = new ArrayList<>();
+
+    static {
+        standardProfiles.add(new AllocationProfile("medium-range",1, 2048, 0.15));
+        standardProfiles.add(new AllocationProfile("small-blocks",1, 512, 0.15));
+        standardProfiles.add(new AllocationProfile("micro-blocks",1, 32, 0.15));
+    }
+
+    static AllocationProfile randomProfile() {
+        return standardProfiles.get(RandomHelper.random().nextInt(standardProfiles.size()));
+    }
+
+    @Override
+    public String toString() {
+        return "MetaspaceTestAllocationProfile{" +
+                "name='" + name + '\'' +
+                ", minimumSingleAllocationSize=" + minimumSingleAllocationSize +
+                ", maximumSingleAllocationSize=" + maximumSingleAllocationSize +
+                ", randomDeallocProbability=" + randomDeallocProbability +
+                '}';
+    }
+
+}
diff --git a/test/hotspot/jtreg/runtime/Metaspace/elastic/MetaspaceTestArena.java b/test/hotspot/jtreg/runtime/Metaspace/elastic/MetaspaceTestArena.java
new file mode 100644
--- /dev/null
+++ b/test/hotspot/jtreg/runtime/Metaspace/elastic/MetaspaceTestArena.java
@@ -0,0 +1,118 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+import sun.hotspot.WhiteBox;
+
+import java.util.concurrent.atomic.AtomicLong;
+
+public class MetaspaceTestArena {
+
+    long arena;
+
+    final long allocationCeiling;
+
+    // Number and word size of allocations
+    long allocatedWords = 0;
+    long numAllocated = 0;
+    long deallocatedWords = 0;
+    long numDeallocated = 0;
+    long numAllocationFailures = 0;
+
+    private synchronized boolean reachedCeiling() {
+        return (allocatedWords - deallocatedWords) > allocationCeiling;
+    }
+
+    private synchronized void accountAllocation(long words) {
+        numAllocated ++;
+        allocatedWords += words;
+    }
+
+    private synchronized void accountDeallocation(long words) {
+        numDeallocated ++;
+        deallocatedWords += words;
+    }
+
+    MetaspaceTestArena(long arena0, long allocationCeiling) {
+        this.allocationCeiling = allocationCeiling;
+        this.arena = arena0;
+    }
+
+    public Allocation allocate(long words) {
+        if (reachedCeiling()) {
+            numAllocationFailures ++;
+            return null;
+        }
+        WhiteBox wb = WhiteBox.getWhiteBox();
+        long p = wb.allocateFromMetaspaceTestArena(arena, words);
+        if (p == 0) {
+            numAllocationFailures ++;
+            return null;
+        } else {
+            accountAllocation(words);
+        }
+        return new Allocation(p, words);
+    }
+
+    public void deallocate(Allocation a) {
+        WhiteBox wb = WhiteBox.getWhiteBox();
+        wb.deallocateToMetaspaceTestArena(arena, a.p, a.word_size);
+        accountDeallocation(a.word_size);
+    }
+
+    //// Convenience functions ////
+
+    public Allocation allocate_expect_success(long words) {
+        Allocation a = allocate(words);
+        if (a.isNull()) {
+            throw new RuntimeException("Allocation failed (" + words + ")");
+        }
+        return a;
+    }
+
+    public void allocate_expect_failure(long words) {
+        Allocation a = allocate(words);
+        if (!a.isNull()) {
+            throw new RuntimeException("Allocation failed (" + words + ")");
+        }
+    }
+
+    boolean isLive() {
+        return arena != 0;
+    }
+
+
+    @Override
+    public String toString() {
+        return "arena=" + arena +
+                ", ceiling=" + allocationCeiling +
+                ", allocatedWords=" + allocatedWords +
+                ", numAllocated=" + numAllocated +
+                ", deallocatedWords=" + deallocatedWords +
+                ", numDeallocated=" + numDeallocated +
+                ", numAllocationFailures=" + numAllocationFailures +
+                '}';
+    }
+
+}
diff --git a/test/hotspot/jtreg/runtime/Metaspace/elastic/MetaspaceTestContext.java b/test/hotspot/jtreg/runtime/Metaspace/elastic/MetaspaceTestContext.java
new file mode 100644
--- /dev/null
+++ b/test/hotspot/jtreg/runtime/Metaspace/elastic/MetaspaceTestContext.java
@@ -0,0 +1,246 @@
+
+import sun.hotspot.WhiteBox;
+
+import java.util.ArrayList;
+import java.util.HashSet;
+import java.util.List;
+
+public class MetaspaceTestContext {
+
+    long context;
+
+    final long commitLimit;
+    final long reserveLimit;
+
+    int numArenasCreated;
+    int numArenasDestroyed;
+
+    HashSet<MetaspaceTestArena> arenaList = new HashSet<>();
+
+    long allocatedWords;
+    long numAllocated;
+    long deallocatedWords;
+    long numDeallocated;
+    long allocationFailures;
+
+
+    public MetaspaceTestContext(long commitLimit, long reserveLimit) {
+        this.commitLimit = commitLimit;
+        this.reserveLimit = reserveLimit;
+        WhiteBox wb = WhiteBox.getWhiteBox();
+        context = wb.createMetaspaceTestContext(commitLimit, reserveLimit);
+        if (context == 0) {
+            throw new RuntimeException("Failed to create context");
+        }
+    }
+
+    // no limits
+    public MetaspaceTestContext() {
+        this(0, 0);
+    }
+
+    public void destroy() {
+        if (context != 0) {
+            WhiteBox wb = WhiteBox.getWhiteBox();
+            wb.destroyMetaspaceTestContext(context);
+            context = 0;
+        }
+    }
+
+    public void purge() {
+        if (context != 0) {
+            WhiteBox wb = WhiteBox.getWhiteBox();
+            wb.purgeMetaspaceTestContext(context);
+        }
+    }
+
+    public MetaspaceTestArena createArena(boolean is_micro, long ceiling) {
+        MetaspaceTestArena arena = null;
+        if (context != 0) {
+            WhiteBox wb = WhiteBox.getWhiteBox();
+            long arena0 = wb.createArenaInTestContext(context, is_micro);
+            if (arena0 == 0) {
+                throw new RuntimeException("Failed to create arena");
+            }
+            numArenasCreated++;
+            arena = new MetaspaceTestArena(arena0, ceiling);
+            arenaList.add(arena);
+        }
+        return arena;
+    }
+
+    public void destroyArena(MetaspaceTestArena a) {
+        if (context != 0) {
+            if (a.isLive()) {
+                WhiteBox wb = WhiteBox.getWhiteBox();
+                wb.destroyMetaspaceTestArena(a.arena);
+                numArenasDestroyed++;
+            }
+            arenaList.remove(a);
+        }
+    }
+
+    public long committedWords() {
+        long l = 0;
+        if (context != 0) {
+            WhiteBox wb = WhiteBox.getWhiteBox();
+            l = wb.getTotalCommittedWordsInMetaspaceTestContext(context);
+        }
+        return l;
+    }
+
+    public long usedWords() {
+        long l = 0;
+        if (context != 0) {
+            WhiteBox wb = WhiteBox.getWhiteBox();
+            l = wb.getTotalUsedWordsInMetaspaceTestContext(context);
+        }
+        return l;
+    }
+
+    public int numLiveArenas() {
+        return arenaList.size();
+    }
+
+    public void updateTotals() {
+        allocatedWords = deallocatedWords = numAllocated = numDeallocated = 0;
+        for (MetaspaceTestArena a : arenaList) {
+            allocatedWords += a.allocatedWords;
+            deallocatedWords += a.deallocatedWords;
+            numAllocated += a.numAllocated;
+            numDeallocated += a.numDeallocated;
+            allocationFailures += a.numAllocationFailures;
+        }
+    }
+
+    public void printToTTY() {
+        if (context != 0) {
+            WhiteBox wb = WhiteBox.getWhiteBox();
+            wb.printMetaspaceTestContext(context);
+        }
+    }
+
+    /**
+     * Given usage and some context information for current live arenas, do a heuristic about whether the
+     * Usage seems right for this case.
+     */
+    public void checkStatistics() {
+
+
+        // Note:
+        // Estimating Used and Committed is fuzzy, and we only have limited information here
+        // (we know the current state, but not the history, which determines fragmentation and
+        //  freelist occupancy).
+        //
+        // We do not want test which constantly generate false positives, so these checks are
+        // somewhat loose and only meant to check for clear outliers, e.g. leaks.
+
+        ///// used /////
+
+        updateTotals();
+
+        long usageMeasured = usedWords();
+        long committedMeasured = committedWords();
+
+        if (usageMeasured > committedMeasured) {
+            throw new RuntimeException("Weirdness.");
+        }
+
+        if (deallocatedWords > allocatedWords) {
+            throw new RuntimeException("Weirdness.");
+        }
+
+        // If no arenas are alive, usage should be zero and committed too (in reclaiming mode)
+        if (numLiveArenas() == 0) {
+            if (usageMeasured > 0) {
+                throw new RuntimeException("Usage > 0, expected 0");
+            }
+            if (Settings.settings().doesReclaim()) {
+                if (committedMeasured > 0) {
+                    throw new RuntimeException("Committed > 0, expected 0");
+                }
+            }
+        }
+
+        long expectedMinUsage = allocatedWords - deallocatedWords;
+
+        if (usageMeasured < expectedMinUsage) {
+            throw new RuntimeException("Usage too low: " + usageMeasured + " expected at least " + expectedMinUsage);
+        }
+
+        long expectedMaxUsage = allocatedWords;
+
+        // This is necessary a bit fuzzy, since Metaspace usage consists of:
+        // - whatever we allocated
+        // - deallocated blocks in fbl
+        // - remains of retired chunks in fbl
+        // - overhead per allocation (padding for alignment, possibly allocation guards)
+
+        // Overhead per allocation (see metaspaceArena.cpp, get_raw_allocation_word_size() )
+        // Any allocation is 3 words least
+        expectedMaxUsage += (numAllocated * 3);
+        if (Settings.settings().usesAllocationGuards) {
+            // Guards need space.
+            expectedMaxUsage += (numAllocated * 2);
+            // Also, they disable the fbl, so deallocated still counts as used.
+            expectedMaxUsage += deallocatedWords;
+        }
+
+        // Lets add a overhead per arena. Each arena carries a free block list containing
+        // deallocated/retired blocks. We do not know how much. In general, the free block list should not
+        // accumulate a lot of memory but be drained in the course of allocating memory from the arena.
+        long overheadPerArena = 1024 * 1024 * numLiveArenas();
+        expectedMaxUsage += overheadPerArena;
+
+        if (expectedMaxUsage < usageMeasured) {
+            throw new RuntimeException("Usage seems high: " + usageMeasured + " expected at most " + expectedMaxUsage);
+        }
+
+        ///// Committed //////
+
+        if (committedMeasured < expectedMinUsage) {
+            throw new RuntimeException("Usage too low: " + usageMeasured + " expected at least " + expectedMinUsage);
+        }
+
+        // Max committed:
+        // This is difficult to estimate, so just a rough guess.
+        //
+        // Committed space depends on:
+        // 1) Usage (how much we allocated + overhead per allocation + free block list content)
+        // 2) free space in used chunks
+        // 3) committed chunks in freelist.
+        //
+        // Having only live usage numbers without history, (2) and (3) can only be roughly estimated. Since these
+        // are stress tests,
+        //
+        long expectedMaxCommitted = usageMeasured;
+        expectedMaxCommitted += Settings.rootChunkWordSize;
+        if (Settings.settings().doesReclaim()) {
+            expectedMaxCommitted *= 10.0;
+        } else {
+            expectedMaxCommitted *= 100.0;
+        }
+
+        if (committedMeasured > expectedMaxCommitted) {
+            throw new RuntimeException("Committed seems high: " + committedMeasured + " expected at most " + expectedMaxCommitted);
+        }
+
+    }
+
+    @java.lang.Override
+    public java.lang.String toString() {
+        return "MetaspaceTestContext{" +
+                "context=" + context +
+                ", commitLimit=" + commitLimit +
+                ", reserveLimit=" + reserveLimit +
+                ", numArenasCreated=" + numArenasCreated +
+                ", numArenasDestroyed=" + numArenasDestroyed +
+                ", numLiveArenas=" + numLiveArenas() +
+                ", allocatedWords=" + allocatedWords +
+                ", numAllocated=" + numAllocated +
+                ", deallocatedWords=" + deallocatedWords +
+                ", numDeallocated=" + numDeallocated +
+                ", allocationFailures=" + allocationFailures +
+                '}';
+    }
+}
diff --git a/test/hotspot/jtreg/runtime/Metaspace/elastic/MetaspaceTestManyArenasManyThreads.java b/test/hotspot/jtreg/runtime/Metaspace/elastic/MetaspaceTestManyArenasManyThreads.java
new file mode 100644
--- /dev/null
+++ b/test/hotspot/jtreg/runtime/Metaspace/elastic/MetaspaceTestManyArenasManyThreads.java
@@ -0,0 +1,103 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+import java.util.concurrent.CyclicBarrier;
+
+import static java.lang.System.currentTimeMillis;
+
+public class MetaspaceTestManyArenasManyThreads extends MetaspaceTestWithThreads {
+
+    // Several threads allocate from a single arena.
+    // This mimicks several threads loading classes via the same class loader.
+
+    public MetaspaceTestManyArenasManyThreads(MetaspaceTestContext context, long testAllocationCeiling, int numThreads, int seconds) {
+        super(context, testAllocationCeiling, numThreads, seconds);
+    }
+
+    public void runTest() throws Exception {
+
+        long t_start = currentTimeMillis();
+        long t_stop = t_start + (seconds * 1000);
+
+        CyclicBarrier gate = new CyclicBarrier(numThreads + 1);
+
+        final long ceilingPerThread = testAllocationCeiling / numThreads;
+
+        for (int i = 0; i < numThreads; i ++) {
+            // Create n test threads, each one with its own allocator/arena pair
+            MetaspaceTestArena arena = context.createArena(RandomHelper.fiftyfifty(), ceilingPerThread);
+            RandomAllocator allocator = new RandomAllocator(arena);
+            RandomAllocatorThread thread = new RandomAllocatorThread(gate, allocator, i);
+            threads[i] = thread;
+            thread.start();
+        }
+
+        gate.await();
+
+        // while test is running, skim the arenas and kill any arena which is saturated (has started getting an
+        // untoward number of allocation failures)
+        while (System.currentTimeMillis() < t_stop) {
+
+            // Wait a bit
+            Thread.sleep(200);
+
+            for (RandomAllocatorThread t: threads) {
+                if (t.allocator.arena.numAllocationFailures > 0) {
+                    t.interrupt();
+                    t.join();
+                    context.destroyArena(t.allocator.arena);
+
+                    // Create a new arena, allocator, then a new thread (note: do not pass in a start gate this time
+                    // since we do not need to wait) and fire it up.
+                    MetaspaceTestArena arena = context.createArena(RandomHelper.fiftyfifty(), ceilingPerThread);
+                    RandomAllocator allocator = new RandomAllocator(arena);
+                    RandomAllocatorThread t2 = new RandomAllocatorThread(null, allocator, t.id);
+                    threads[t.id] = t2;
+                    t2.start();
+                }
+            }
+
+        }
+
+        // Stop all threads.
+        stopAllThreads();
+
+        context.updateTotals();
+        System.out.println("  ## Finished: " + context);
+
+        context.checkStatistics();
+
+        // Destroy all arenas; then purge the space.
+        destroyArenasAndPurgeSpace();
+
+        context.destroy();
+
+        context.updateTotals();
+
+        System.out.println("This took " + (System.currentTimeMillis() - t_start) + "ms");
+
+    }
+
+}
+
diff --git a/test/hotspot/jtreg/runtime/Metaspace/elastic/MetaspaceTestOneArenaManyThreads.java b/test/hotspot/jtreg/runtime/Metaspace/elastic/MetaspaceTestOneArenaManyThreads.java
new file mode 100644
--- /dev/null
+++ b/test/hotspot/jtreg/runtime/Metaspace/elastic/MetaspaceTestOneArenaManyThreads.java
@@ -0,0 +1,81 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+import java.util.concurrent.CyclicBarrier;
+
+import static java.lang.System.currentTimeMillis;
+
+public class MetaspaceTestOneArenaManyThreads extends MetaspaceTestWithThreads {
+
+    // Several threads allocate from a single arena.
+    // This mimicks several threads loading classes via the same class loader.
+
+
+    public MetaspaceTestOneArenaManyThreads(MetaspaceTestContext context, long testAllocationCeiling, int numThreads, int seconds) {
+        super(context, testAllocationCeiling, numThreads, seconds);
+    }
+
+    public void runTest() throws Exception {
+
+        long t_start = currentTimeMillis();
+        long t_stop = t_start + (seconds * 1000);
+
+        // We create a single arena, and n threads which will allocate from that single arena.
+
+        MetaspaceTestArena arena = context.createArena(RandomHelper.fiftyfifty(), testAllocationCeiling);
+        CyclicBarrier gate = new CyclicBarrier(numThreads + 1);
+
+        for (int i = 0; i < numThreads; i ++) {
+            RandomAllocator allocator = new RandomAllocator(arena);
+            RandomAllocatorThread thread = new RandomAllocatorThread(gate, allocator, i);
+            threads[i] = thread;
+            thread.start();
+        }
+
+        gate.await();
+
+        while (System.currentTimeMillis() < t_stop) {
+            Thread.sleep(200);
+        }
+
+        stopAllThreads();
+
+        context.updateTotals();
+        System.out.println("  ## Finished: " + context);
+
+        context.checkStatistics();
+
+        context.destroyArena(arena);
+
+        context.purge();
+
+        context.destroy();
+
+        System.out.println("This took " + (System.currentTimeMillis() - t_start) + "ms");
+
+    }
+
+}
+
diff --git a/test/hotspot/jtreg/runtime/Metaspace/elastic/MetaspaceTestWithThreads.java b/test/hotspot/jtreg/runtime/Metaspace/elastic/MetaspaceTestWithThreads.java
new file mode 100644
--- /dev/null
+++ b/test/hotspot/jtreg/runtime/Metaspace/elastic/MetaspaceTestWithThreads.java
@@ -0,0 +1,108 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+import java.util.Set;
+
+public class MetaspaceTestWithThreads {
+
+    // The context to use.
+    final MetaspaceTestContext context;
+
+    // Total *word* size we allow for the test to allocation. The test may overshoot this a bit, but should not by much.
+    final long testAllocationCeiling;
+
+    // Number of parallel allocators
+    final int numThreads;
+
+    // Number of seconds for each test
+    final int seconds;
+
+    RandomAllocatorThread threads[];
+
+    public MetaspaceTestWithThreads(MetaspaceTestContext context, long testAllocationCeiling, int numThreads, int seconds) {
+        this.context = context;
+        this.testAllocationCeiling = testAllocationCeiling;
+        this.numThreads = numThreads;
+        this.seconds = seconds;
+        this.threads = new RandomAllocatorThread[numThreads];
+    }
+
+    protected void stopAllThreads() throws InterruptedException {
+        // Stop all threads.
+        for (Thread t: threads) {
+            t.interrupt();
+            t.join();
+        }
+    }
+
+    void destroyArenasAndPurgeSpace() {
+
+        for (RandomAllocatorThread t: threads) {
+            if (t.allocator.arena.isLive()) {
+                context.destroyArena(t.allocator.arena);
+            }
+        }
+
+        context.checkStatistics();
+
+        // After deleting all arenas, we should have no committed space left: all arena chunks have been returned to
+        // the freelist amd should have been maximally merged to a bunch of root chunks, which should be uncommitted
+        // in one go.
+        // Exception: if reclamation policy is none.
+        if (Settings.settings().doesReclaim()) {
+            if (context.committedWords() > 0) {
+                throw new RuntimeException("Expected no committed words after purging empty metaspace context (was: " + context.committedWords() + ")");
+            }
+        }
+
+        context.purge();
+
+        context.checkStatistics();
+
+        // After purging - if all arenas had been deleted before - we should have no committed space left even in
+        //   recmalation=none mode:
+        // purging deletes all nodes with only free chunks, and in this case no node should still house in-use chunks,
+        //  so all nodes would have been unmapped.
+        // This is independent on reclamation policy. Only one exception: if the area was created with a reserve limit
+        // (mimicking compressed class space), the underlying virtual space list cannot be purged.
+        if (context.reserveLimit == 0) {
+            if (context.committedWords() > 0) {
+                throw new RuntimeException("Expected no committed words after purging empty metaspace context (was: " + context.committedWords() + ")");
+            }
+        }
+
+    }
+
+    @Override
+    public String toString() {
+        return "commitLimit=" + context.commitLimit +
+                ", reserveLimit=" + context.reserveLimit +
+                ", testAllocationCeiling=" + testAllocationCeiling +
+                ", num_allocators=" + numThreads +
+                ", seconds=" + seconds;
+    }
+
+
+}
diff --git a/test/hotspot/jtreg/runtime/Metaspace/elastic/RandomAllocator.java b/test/hotspot/jtreg/runtime/Metaspace/elastic/RandomAllocator.java
new file mode 100644
--- /dev/null
+++ b/test/hotspot/jtreg/runtime/Metaspace/elastic/RandomAllocator.java
@@ -0,0 +1,111 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+import java.util.ArrayList;
+import java.util.Random;
+
+/**
+ * RandomAllocator sits atop an arena and allocates from it.
+ *
+ * It will, according to an allocation profile, allocate random blocks in a certain size range and, from time to time,
+ * deallocate old blocks.
+ *
+ * At some point it will reach a limit: either the commit/reserve limit of the underlying MetaspaceTestContext,
+ * or the allocation ceiling imposed by the test. From that point on allocations will start failing. We can (and do)
+ * deallocate a bit more, but since that will only exercise the Arena's internal free block list and nothing much else,
+ * this is unexciting in terms of stressing Metaspace. So, the caller may decide to kill the arena and create a new one.
+ *
+ */
+public class RandomAllocator {
+
+    final MetaspaceTestArena arena;
+    final AllocationProfile profile;
+
+    ArrayList<Allocation> to_dealloc = new ArrayList<>();
+
+    long ticks = 0;
+    boolean allocationError = false;
+
+    Random localRandom;
+
+    // Roll dice and return true if probability was hit
+    private boolean rollDice(double probability) {
+        return ((double)localRandom.nextInt(100) > (100.0 * (1.0 - probability))) ? true : false;
+    }
+
+    // Allocate a random amount from the arena. If dice hits right, add this to the deallocation list.
+    void allocateRandomly() {
+        allocationError = false;
+        long word_size = profile.randomAllocationSize();
+        Allocation a = arena.allocate(word_size);
+        if (a != null) {
+            if (to_dealloc.size() < 10000) {
+                to_dealloc.add(a);
+            }
+        } else {
+            allocationError = true;
+        }
+    }
+
+    // Randomly choose one of the allocated in the deallocation list and deallocate it
+    void deallocateRandomly() {
+        if (to_dealloc.size() == 0) {
+            return;
+        }
+        int n = localRandom.nextInt(to_dealloc.size());
+        Allocation a = to_dealloc.remove(n);
+        arena.deallocate(a);
+    }
+
+    public void tick() {
+
+        if (!allocationError) {
+            allocateRandomly();
+            if(rollDice(profile.randomDeallocProbability)) {
+               deallocateRandomly();
+            }
+        } else {
+            deallocateRandomly();
+            allocationError = false;
+        }
+
+        ticks ++;
+
+    }
+
+    public RandomAllocator(MetaspaceTestArena arena) {
+        this.arena = arena;
+        this.profile = AllocationProfile.randomProfile();
+        // reproducable randoms (we assume each allocator is only used from within one thread, and gets created from the main thread).
+        this.localRandom = new Random(RandomHelper.random().nextInt());
+    }
+
+
+    @Override
+    public String toString() {
+        return  arena.toString() + ", ticks=" + ticks;
+    }
+
+}
diff --git a/test/hotspot/jtreg/runtime/Metaspace/elastic/RandomAllocatorThread.java b/test/hotspot/jtreg/runtime/Metaspace/elastic/RandomAllocatorThread.java
new file mode 100644
--- /dev/null
+++ b/test/hotspot/jtreg/runtime/Metaspace/elastic/RandomAllocatorThread.java
@@ -0,0 +1,69 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+import java.util.Random;
+import java.util.concurrent.BrokenBarrierException;
+import java.util.concurrent.CyclicBarrier;
+
+public class RandomAllocatorThread extends Thread {
+
+    public final CyclicBarrier gate;
+    public final RandomAllocator allocator;
+    public final int id;
+
+    public RandomAllocatorThread(CyclicBarrier gate, RandomAllocator allocator, int id) {
+        this.gate = gate;
+        this.allocator = allocator;
+        this.id = id;
+    }
+
+    @Override
+    public void run() {
+
+       // System.out.println("* [" + id + "] " + allocator);
+
+        try {
+            if (gate != null) {
+                gate.await();
+            }
+        } catch (InterruptedException | BrokenBarrierException e) {
+            // At this point, interrupt would be an error.
+            e.printStackTrace();
+            throw new RuntimeException(e);
+        }
+
+        while (!Thread.interrupted()) {
+            for (int i = 0; i < 1000; i++) {
+                allocator.tick();
+            }
+        }
+
+        // System.out.println("+ [" + id + "] " + allocator);
+
+    }
+
+
+
+}
diff --git a/test/hotspot/jtreg/runtime/Metaspace/elastic/RandomHelper.java b/test/hotspot/jtreg/runtime/Metaspace/elastic/RandomHelper.java
new file mode 100644
--- /dev/null
+++ b/test/hotspot/jtreg/runtime/Metaspace/elastic/RandomHelper.java
@@ -0,0 +1,47 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+import java.util.Random;
+
+public class RandomHelper {
+
+    static Random rand;
+
+    static {
+        long seed = Long.parseLong(System.getProperty("metaspace.random.seed", "0"));
+        if (seed == 0) {
+            seed = System.currentTimeMillis();
+            System.out.println("Random seed: " + seed);
+        } else {
+            System.out.println("Random seed: " + seed + " (passed in)");
+        }
+        rand = new Random(seed);
+    }
+
+    static Random random() { return rand; }
+
+    static boolean fiftyfifty() { return random().nextInt(10) >= 5; }
+
+}
diff --git a/test/hotspot/jtreg/runtime/Metaspace/elastic/Settings.java b/test/hotspot/jtreg/runtime/Metaspace/elastic/Settings.java
new file mode 100644
--- /dev/null
+++ b/test/hotspot/jtreg/runtime/Metaspace/elastic/Settings.java
@@ -0,0 +1,48 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+import sun.hotspot.WhiteBox;
+
+public final class Settings {
+
+    public String reclaimPolicy = WhiteBox.getWhiteBox().getStringVMFlag("MetaspaceReclaimPolicy");
+    public boolean usesAllocationGuards = WhiteBox.getWhiteBox().getBooleanVMFlag("MetaspaceGuardAllocations");
+
+    final public boolean doesReclaim() {
+        return reclaimPolicy.equals("balanced") || reclaimPolicy.equals("aggessive");
+    }
+
+    final static long rootChunkWordSize = 512 * 1024;
+
+    static Settings theSettings;
+
+    static Settings settings()  {
+       if (theSettings == null) {
+            theSettings = new Settings();
+       }
+       return theSettings;
+    }
+
+}
diff --git a/test/hotspot/jtreg/runtime/Metaspace/elastic/TestMetaspaceAllocation.java b/test/hotspot/jtreg/runtime/Metaspace/elastic/TestMetaspaceAllocation.java
new file mode 100644
--- /dev/null
+++ b/test/hotspot/jtreg/runtime/Metaspace/elastic/TestMetaspaceAllocation.java
@@ -0,0 +1,84 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+/*
+ * @test id=debug
+ * @library /test/lib
+ * @modules java.base/jdk.internal.misc
+ *          java.management
+ * @build sun.hotspot.WhiteBox
+ * @requires (vm.debug == true)
+ *
+ * @run driver ClassFileInstaller sun.hotspot.WhiteBox
+ *
+ * @run main/othervm -Xbootclasspath/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI  -XX:VerifyMetaspaceInterval=10                                        TestMetaspaceAllocation
+ * @run main/othervm -Xbootclasspath/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI  -XX:VerifyMetaspaceInterval=10  -XX:MetaspaceReclaimPolicy=none       TestMetaspaceAllocation
+ * @run main/othervm -Xbootclasspath/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI  -XX:VerifyMetaspaceInterval=10  -XX:MetaspaceReclaimPolicy=aggressive TestMetaspaceAllocation
+ * @run main/othervm -Xbootclasspath/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI  -XX:VerifyMetaspaceInterval=10  -XX:+MetaspaceGuardAllocations        TestMetaspaceAllocation
+ *
+ */
+
+/*
+ * @test id=ndebug
+ * @library /test/lib
+ * @modules java.base/jdk.internal.misc
+ *          java.management
+ * @build sun.hotspot.WhiteBox
+ * @requires (vm.debug == false)
+ *
+ * @run driver ClassFileInstaller sun.hotspot.WhiteBox
+ *
+ * @run main/othervm -Xbootclasspath/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI                                        TestMetaspaceAllocation
+ * @run main/othervm -Xbootclasspath/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI  -XX:MetaspaceReclaimPolicy=none       TestMetaspaceAllocation
+ * @run main/othervm -Xbootclasspath/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI  -XX:MetaspaceReclaimPolicy=aggressive TestMetaspaceAllocation
+ */
+
+public class TestMetaspaceAllocation {
+
+    public static void main(String[] args) {
+
+        MetaspaceTestContext context = new MetaspaceTestContext();
+        MetaspaceTestArena arena1 = context.createArena(false, 1024 * 1024 * 4);
+        MetaspaceTestArena arena2 = context.createArena(true,1024 * 1024 * 4);
+
+        Allocation a1 = arena1.allocate(100);
+        Allocation a2 = arena2.allocate(100);
+
+        long used = context.usedWords();
+        long committed = context.committedWords();
+
+        System.out.println("used " + used + " committed " + committed);
+
+        arena1.deallocate(a1);
+
+        context.destroyArena(arena2);
+        context.destroyArena(arena1);
+
+        context.purge();
+
+        context.destroy();
+
+    }
+}
diff --git a/test/hotspot/jtreg/runtime/Metaspace/elastic/TestMetaspaceAllocationMT1.java b/test/hotspot/jtreg/runtime/Metaspace/elastic/TestMetaspaceAllocationMT1.java
new file mode 100644
--- /dev/null
+++ b/test/hotspot/jtreg/runtime/Metaspace/elastic/TestMetaspaceAllocationMT1.java
@@ -0,0 +1,123 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+/*
+ * This is a stress test for allocating from a single MetaspaceArena from
+ *  multiple threads, optionally with reserve limit (mimicking the non-expandable CompressedClassSpace)
+ * or commit limit (mimimcking MaxMetaspaceSize).
+ *
+ * The test threads will start to allocate from the Arena, and occasionally deallocate.
+ * The threads run with a safety allocation max; if reached (or, if the underlying arena
+ * hits either commit or reserve limit, if given) they will switch to deallocation and then
+ * kind of float at the allocation ceiling, alternating between allocation and deallocation.
+ *
+ * We test with various flags, to exercise all 3 reclaim policies (none, balanced (default)
+ * and aggessive) as well as one run with allocation guards enabled.
+ *
+ * We also set MetaspaceVerifyInterval very low to trigger many verifications in debug vm.
+ *
+ */
+
+
+/*
+ * @test id=debug
+ * @library /test/lib
+ * @modules java.base/jdk.internal.misc
+ *          java.management
+ * @build sun.hotspot.WhiteBox
+ * @key randomness
+ * @requires (vm.debug == true)
+ *
+ * @run driver ClassFileInstaller sun.hotspot.WhiteBox
+ *
+ * @run main/othervm/timeout=400 -Xbootclasspath/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI  -XX:VerifyMetaspaceInterval=10                                        TestMetaspaceAllocationMT1
+ * @run main/othervm/timeout=400 -Xbootclasspath/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI  -XX:VerifyMetaspaceInterval=10  -XX:MetaspaceReclaimPolicy=none       TestMetaspaceAllocationMT1
+ * @run main/othervm/timeout=400 -Xbootclasspath/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI  -XX:VerifyMetaspaceInterval=10  -XX:MetaspaceReclaimPolicy=aggressive TestMetaspaceAllocationMT1
+ * @run main/othervm/timeout=400 -Xbootclasspath/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI  -XX:VerifyMetaspaceInterval=10  -XX:+MetaspaceGuardAllocations        TestMetaspaceAllocationMT1
+ *
+ */
+
+/*
+ * @test id=ndebug
+ * @library /test/lib
+ * @modules java.base/jdk.internal.misc
+ *          java.management
+ * @build sun.hotspot.WhiteBox
+ * @key randomness
+ * @requires (vm.debug == false)
+ *
+ * @run driver ClassFileInstaller sun.hotspot.WhiteBox
+ *
+ * @run main/othervm/timeout=400 -Xbootclasspath/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI                                        TestMetaspaceAllocationMT1
+ * @run main/othervm/timeout=400 -Xbootclasspath/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI  -XX:MetaspaceReclaimPolicy=none       TestMetaspaceAllocationMT1
+ * @run main/othervm/timeout=400 -Xbootclasspath/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI  -XX:MetaspaceReclaimPolicy=aggressive TestMetaspaceAllocationMT1
+ */
+
+public class TestMetaspaceAllocationMT1 {
+
+    public static void main(String[] args) throws Exception {
+
+        final long testAllocationCeiling = 1024 * 1024 * 8; // 8m words = 64M on 64bit
+        final int numThreads = 4;
+        final int seconds = 10;
+
+        for (int i = 0; i < 3; i ++) {
+
+            long commitLimit = (i == 1) ? 1024 * 256 : 0;
+
+            // Note: reserve limit must be a multiple of Metaspace::reserve_alignment_words()
+            //  (512 K)
+            long reserveLimit = (i == 2) ? 1024 * 512 : 0;
+
+            System.out.println("#### Test: ");
+            System.out.println("#### testAllocationCeiling: " + testAllocationCeiling);
+            System.out.println("#### numThreads: " + numThreads);
+            System.out.println("#### seconds: " + seconds);
+            System.out.println("#### commitLimit: " + commitLimit);
+            System.out.println("#### reserveLimit: " + reserveLimit);
+            System.out.println("#### ReclaimPolicy: " + Settings.settings().reclaimPolicy);
+            System.out.println("#### guards: " + Settings.settings().usesAllocationGuards);
+
+            MetaspaceTestContext context = new MetaspaceTestContext(commitLimit, reserveLimit);
+            MetaspaceTestOneArenaManyThreads test = new MetaspaceTestOneArenaManyThreads(context, testAllocationCeiling, numThreads, seconds);
+
+            try {
+                test.runTest();
+            } catch (RuntimeException e) {
+                System.out.println(e);
+                context.printToTTY();
+                throw e;
+            }
+
+            context.destroy();
+
+            System.out.println("#### Done. ####");
+            System.out.println("###############");
+
+        }
+
+    }
+
+}
diff --git a/test/hotspot/jtreg/runtime/Metaspace/elastic/TestMetaspaceAllocationMT2.java b/test/hotspot/jtreg/runtime/Metaspace/elastic/TestMetaspaceAllocationMT2.java
new file mode 100644
--- /dev/null
+++ b/test/hotspot/jtreg/runtime/Metaspace/elastic/TestMetaspaceAllocationMT2.java
@@ -0,0 +1,124 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+/*
+ * This is a stress test for allocating from a single MetaspaceArena from
+ *  multiple threads, optionally with reserve limit (mimicking the non-expandable CompressedClassSpace)
+ * or commit limit (mimimcking MaxMetaspaceSize).
+ *
+ * The test threads will start to allocate from the Arena, and occasionally deallocate.
+ * The threads run with a safety allocation max; if reached (or, if the underlying arena
+ * hits either commit or reserve limit, if given) they will switch to deallocation and then
+ * kind of float at the allocation ceiling, alternating between allocation and deallocation.
+ *
+ * We test with various flags, to exercise all 3 reclaim policies (none, balanced (default)
+ * and aggessive) as well as one run with allocation guards enabled.
+ *
+ * We also set MetaspaceVerifyInterval very low to trigger many verifications in debug vm.
+ *
+ */
+
+/*
+ * @test id=debug
+ * @library /test/lib
+ * @modules java.base/jdk.internal.misc
+ *          java.management
+ * @build sun.hotspot.WhiteBox
+ * @key randomness
+ * @requires (vm.debug == true)
+ *
+ * @run driver ClassFileInstaller sun.hotspot.WhiteBox
+ *
+ * @run main/othervm/timeout=400 -Xbootclasspath/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI  -XX:VerifyMetaspaceInterval=10                                        TestMetaspaceAllocationMT2
+ * @run main/othervm/timeout=400 -Xbootclasspath/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI  -XX:VerifyMetaspaceInterval=10  -XX:MetaspaceReclaimPolicy=none       TestMetaspaceAllocationMT2
+ * @run main/othervm/timeout=400 -Xbootclasspath/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI  -XX:VerifyMetaspaceInterval=10  -XX:MetaspaceReclaimPolicy=aggressive TestMetaspaceAllocationMT2
+ * @run main/othervm/timeout=400 -Xbootclasspath/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI  -XX:VerifyMetaspaceInterval=10  -XX:+MetaspaceGuardAllocations        TestMetaspaceAllocationMT2
+ *
+ */
+
+/*
+ * @test id=ndebug
+ * @library /test/lib
+ * @modules java.base/jdk.internal.misc
+ *          java.management
+ * @build sun.hotspot.WhiteBox
+ * @key randomness
+ * @requires (vm.debug == false)
+ *
+ * @run driver ClassFileInstaller sun.hotspot.WhiteBox
+ *
+ * @run main/othervm/timeout=400 -Xbootclasspath/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI                                        TestMetaspaceAllocationMT2
+ * @run main/othervm/timeout=400 -Xbootclasspath/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI  -XX:MetaspaceReclaimPolicy=none       TestMetaspaceAllocationMT2
+ * @run main/othervm/timeout=400 -Xbootclasspath/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI  -XX:MetaspaceReclaimPolicy=aggressive TestMetaspaceAllocationMT2
+ */
+
+
+public class TestMetaspaceAllocationMT2 {
+
+    public static void main(String[] args) throws Exception {
+
+        final long testAllocationCeiling = 1024 * 1024 * 6; // 8m words = 64M on 64bit
+        final int numThreads = 4;
+        final int seconds = 10;
+
+        for (int i = 0; i < 3; i ++) {
+
+            long commitLimit = (i == 1) ? 1024 * 256 : 0;
+
+            // Note: reserve limit must be a multiple of Metaspace::reserve_alignment_words()
+            //  (512 K)
+            long reserveLimit = (i == 2) ? 1024 * 512 : 0;
+
+            System.out.println("#### Test: ");
+            System.out.println("#### testAllocationCeiling: " + testAllocationCeiling);
+            System.out.println("#### numThreads: " + numThreads);
+            System.out.println("#### seconds: " + seconds);
+            System.out.println("#### commitLimit: " + commitLimit);
+            System.out.println("#### reserveLimit: " + reserveLimit);
+            System.out.println("#### ReclaimPolicy: " + Settings.settings().reclaimPolicy);
+            System.out.println("#### guards: " + Settings.settings().usesAllocationGuards);
+
+            MetaspaceTestContext context = new MetaspaceTestContext(commitLimit, reserveLimit);
+            MetaspaceTestManyArenasManyThreads test = new MetaspaceTestManyArenasManyThreads(context, testAllocationCeiling, numThreads, seconds);
+
+            try {
+                test.runTest();
+            } catch (RuntimeException e) {
+                System.out.println(e);
+                context.printToTTY();
+                throw e;
+            }
+
+            context.destroy();
+
+            System.out.println("#### Done. ####");
+            System.out.println("###############");
+
+        }
+
+    }
+
+}
+
diff --git a/test/hotspot/jtreg/runtime/cds/MaxMetaspaceSize.java b/test/hotspot/jtreg/runtime/cds/MaxMetaspaceSize.java
--- a/test/hotspot/jtreg/runtime/cds/MaxMetaspaceSize.java
+++ b/test/hotspot/jtreg/runtime/cds/MaxMetaspaceSize.java
@@ -44,9 +44,8 @@
     processArgs.add("-Xshare:dump");
 
     if (Platform.is64bit()) {
-      processArgs.add("-XX:MaxMetaspaceSize=3m");
+      processArgs.add("-XX:MaxMetaspaceSize=8m");
       processArgs.add("-XX:CompressedClassSpaceSize=1m");
-      processArgs.add("-XX:InitialBootClassLoaderMetaspaceSize=1m");
     } else {
       processArgs.add("-XX:MaxMetaspaceSize=1m");
     }
diff --git a/test/hotspot/jtreg/runtime/cds/appcds/sharedStrings/LargePages.java b/test/hotspot/jtreg/runtime/cds/appcds/sharedStrings/LargePages.java
--- a/test/hotspot/jtreg/runtime/cds/appcds/sharedStrings/LargePages.java
+++ b/test/hotspot/jtreg/runtime/cds/appcds/sharedStrings/LargePages.java
@@ -46,8 +46,8 @@
 
         SharedStringsUtils.dump(TestCommon.list("HelloString"),
             "SharedStringsBasic.txt", CDS_LOGGING,
-            "-XX:+UseLargePages", "-XX:+UseLargePagesInMetaspace");
+            "-XX:+UseLargePages");
         SharedStringsUtils.runWithArchive("HelloString",
-            "-XX:+UseLargePages", "-XX:+UseLargePagesInMetaspace");
+            "-XX:+UseLargePages");
     }
 }
diff --git a/test/hotspot/jtreg/vmTestbase/metaspace/gc/MetaspaceBaseGC.java b/test/hotspot/jtreg/vmTestbase/metaspace/gc/MetaspaceBaseGC.java
--- a/test/hotspot/jtreg/vmTestbase/metaspace/gc/MetaspaceBaseGC.java
+++ b/test/hotspot/jtreg/vmTestbase/metaspace/gc/MetaspaceBaseGC.java
@@ -101,7 +101,6 @@
 
     protected void configure(String args[]) {
         vmArgs.addAll(ManagementFactory.getRuntimeMXBean().getInputArguments());
-        useLargepages = PAGE_SIZE > 1_000_000 && !vmArgs.contains("-XX:-UseLargePagesInMetaspace");
 
         System.out.println(vmArgs);
 
diff --git a/test/jdk/java/lang/management/MemoryMXBean/LowMemoryTest2.sh b/test/jdk/java/lang/management/MemoryMXBean/LowMemoryTest2.sh
--- a/test/jdk/java/lang/management/MemoryMXBean/LowMemoryTest2.sh
+++ b/test/jdk/java/lang/management/MemoryMXBean/LowMemoryTest2.sh
@@ -62,6 +62,15 @@
 
 # Test class metaspace - might hit MaxMetaspaceSize instead if
 # UseCompressedClassPointers is off or if 32 bit.
+#
+# (note: This is very shaky and that shakiness exposes a problem with MemoryMXBean:
+#
+#  MemoryMXBean defines "used" "committed" and "max" (see java/lang/management/MemoryUsage.java)
+#  This abstraction misses a definition for "address space exhausted" which with the new Metaspace (jep387)
+#  can happen before committed/used hits any trigger. We now commit only on demand and therefore class loaders
+#  can sit atop of uncommitted address space, denying new loaders address space. In the old Metaspace,
+#  we would have committed the space right away and therefore the MemoryMXBean "committed" trigger
+#  would have fired. In the new Metaspace, we don't commit, so the MemoryMXBean does not fire.
 go -noclassgc -XX:MaxMetaspaceSize=16m -XX:CompressedClassSpaceSize=4m LowMemoryTest2
 
 echo ''
diff --git a/test/lib/sun/hotspot/WhiteBox.java b/test/lib/sun/hotspot/WhiteBox.java
--- a/test/lib/sun/hotspot/WhiteBox.java
+++ b/test/lib/sun/hotspot/WhiteBox.java
@@ -396,11 +396,24 @@
   // Memory
   public native void readReservedMemory();
   public native long allocateMetaspace(ClassLoader classLoader, long size);
-  public native void freeMetaspace(ClassLoader classLoader, long addr, long size);
   public native long incMetaspaceCapacityUntilGC(long increment);
   public native long metaspaceCapacityUntilGC();
   public native long metaspaceReserveAlignment();
 
+  // Metaspace Arena Tests
+  public native long createMetaspaceTestContext(long commit_limit, long reserve_limit);
+  public native void destroyMetaspaceTestContext(long context);
+  public native void purgeMetaspaceTestContext(long context);
+  public native void printMetaspaceTestContext(long context);
+  public native long getTotalCommittedWordsInMetaspaceTestContext(long context);
+  public native long getTotalUsedWordsInMetaspaceTestContext(long context);
+  public native long createArenaInTestContext(long context, boolean is_micro);
+  public native void destroyMetaspaceTestArena(long arena);
+  public native long allocateFromMetaspaceTestArena(long arena, long word_size);
+  public native void deallocateToMetaspaceTestArena(long arena, long p, long word_size);
+
+  public native long maxMetaspaceAllocationSize();
+
   // Don't use these methods directly
   // Use sun.hotspot.gc.GC class instead.
   public native boolean isGCSupported(int name);
