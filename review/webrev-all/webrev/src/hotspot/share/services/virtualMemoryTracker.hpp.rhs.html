<?xml version="1.0"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head><meta charset="utf-8">
<meta http-equiv="cache-control" content="no-cache" />
<meta http-equiv="Pragma" content="no-cache" />
<meta http-equiv="Expires" content="-1" />
<!--
   Note to customizers: the body of the webrev is IDed as SUNWwebrev
   to allow easy overriding by users of webrev via the userContent.css
   mechanism available in some browsers.

   For example, to have all "removed" information be red instead of
   brown, set a rule in your userContent.css file like:

       body#SUNWwebrev span.removed { color: red ! important; }
-->
<style type="text/css" media="screen">
body {
    background-color: #eeeeee;
}
hr {
    border: none 0;
    border-top: 1px solid #aaa;
    height: 1px;
}
div.summary {
    font-size: .8em;
    border-bottom: 1px solid #aaa;
    padding-left: 1em;
    padding-right: 1em;
}
div.summary h2 {
    margin-bottom: 0.3em;
}
div.summary table th {
    text-align: right;
    vertical-align: top;
    white-space: nowrap;
}
span.lineschanged {
    font-size: 0.7em;
}
span.oldmarker {
    color: red;
    font-size: large;
    font-weight: bold;
}
span.newmarker {
    color: green;
    font-size: large;
    font-weight: bold;
}
span.removed {
    color: brown;
}
span.changed {
    color: blue;
}
span.new {
    color: blue;
    font-weight: bold;
}
a.print { font-size: x-small; }

</style>

<style type="text/css" media="print">
pre { font-size: 0.8em; font-family: courier, monospace; }
span.removed { color: #444; font-style: italic }
span.changed { font-weight: bold; }
span.new { font-weight: bold; }
span.newmarker { font-size: 1.2em; font-weight: bold; }
span.oldmarker { font-size: 1.2em; font-weight: bold; }
a.print {display: none}
hr { border: none 0; border-top: 1px solid #aaa; height: 1px; }
</style>

    <script type="text/javascript" src="../../../../ancnav.js"></script>
    </head>
    <body id="SUNWwebrev" onkeypress="keypress(event);">
    <a name="0"></a>
    <pre>rev <a href="https://bugs.openjdk.java.net/browse/JDK-60818">60818</a> : imported patch jep387-all.patch</pre><hr></hr>
<pre>
   1 /*
   2  * Copyright (c) 2013, 2020, Oracle and/or its affiliates. All rights reserved.
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #ifndef SHARE_SERVICES_VIRTUALMEMORYTRACKER_HPP
  26 #define SHARE_SERVICES_VIRTUALMEMORYTRACKER_HPP
  27 
  28 #if INCLUDE_NMT
  29 
  30 #include "memory/allocation.hpp"
  31 #include "memory/metaspace.hpp"
  32 #include "services/allocationSite.hpp"
  33 #include "services/nmtCommon.hpp"
  34 #include "utilities/linkedlist.hpp"
  35 #include "utilities/nativeCallStack.hpp"
  36 #include "utilities/ostream.hpp"
  37 
  38 
  39 /*
  40  * Virtual memory counter
  41  */
  42 class VirtualMemory {
  43  private:
  44   size_t     _reserved;
  45   size_t     _committed;
  46 
  47  public:
  48   VirtualMemory() : _reserved(0), _committed(0) { }
  49 
  50   inline void reserve_memory(size_t sz) { _reserved += sz; }
  51   inline void commit_memory (size_t sz) {
  52     _committed += sz;
  53     assert(_committed &lt;= _reserved, "Sanity check");
  54   }
  55 
  56   inline void release_memory (size_t sz) {
  57     assert(_reserved &gt;= sz, "Negative amount");
  58     _reserved -= sz;
  59   }
  60 
  61   inline void uncommit_memory(size_t sz) {
  62     assert(_committed &gt;= sz, "Negative amount");
  63     _committed -= sz;
  64   }
  65 
  66   inline size_t reserved()  const { return _reserved;  }
  67   inline size_t committed() const { return _committed; }
  68 };
  69 
  70 // Virtual memory allocation site, keeps track where the virtual memory is reserved.
  71 class VirtualMemoryAllocationSite : public AllocationSite&lt;VirtualMemory&gt; {
  72  public:
  73   VirtualMemoryAllocationSite(const NativeCallStack&amp; stack, MEMFLAGS flag) :
  74     AllocationSite&lt;VirtualMemory&gt;(stack, flag) { }
  75 
  76   inline void reserve_memory(size_t sz)  { data()-&gt;reserve_memory(sz);  }
  77   inline void commit_memory (size_t sz)  { data()-&gt;commit_memory(sz);   }
  78   inline void uncommit_memory(size_t sz) { data()-&gt;uncommit_memory(sz); }
  79   inline void release_memory(size_t sz)  { data()-&gt;release_memory(sz);  }
  80   inline size_t reserved() const  { return peek()-&gt;reserved(); }
  81   inline size_t committed() const { return peek()-&gt;committed(); }
  82 };
  83 
  84 class VirtualMemorySummary;
  85 
  86 // This class represents a snapshot of virtual memory at a given time.
  87 // The latest snapshot is saved in a static area.
  88 class VirtualMemorySnapshot : public ResourceObj {
  89   friend class VirtualMemorySummary;
  90 
  91  private:
  92   VirtualMemory  _virtual_memory[mt_number_of_types];
  93 
  94  public:
  95   inline VirtualMemory* by_type(MEMFLAGS flag) {
  96     int index = NMTUtil::flag_to_index(flag);
  97     return &amp;_virtual_memory[index];
  98   }
  99 
 100   inline VirtualMemory* by_index(int index) {
 101     assert(index &gt;= 0, "Index out of bound");
 102     assert(index &lt; mt_number_of_types, "Index out of bound");
 103     return &amp;_virtual_memory[index];
 104   }
 105 
 106   inline size_t total_reserved() const {
 107     size_t amount = 0;
 108     for (int index = 0; index &lt; mt_number_of_types; index ++) {
 109       amount += _virtual_memory[index].reserved();
 110     }
 111     return amount;
 112   }
 113 
 114   inline size_t total_committed() const {
 115     size_t amount = 0;
 116     for (int index = 0; index &lt; mt_number_of_types; index ++) {
 117       amount += _virtual_memory[index].committed();
 118     }
 119     return amount;
 120   }
 121 
 122   void copy_to(VirtualMemorySnapshot* s) {
 123     for (int index = 0; index &lt; mt_number_of_types; index ++) {
 124       s-&gt;_virtual_memory[index] = _virtual_memory[index];
 125     }
 126   }
 127 };
 128 
 129 class VirtualMemorySummary : AllStatic {
 130  public:
 131   static void initialize();
 132 
 133   static inline void record_reserved_memory(size_t size, MEMFLAGS flag) {
 134     as_snapshot()-&gt;by_type(flag)-&gt;reserve_memory(size);
 135   }
 136 
 137   static inline void record_committed_memory(size_t size, MEMFLAGS flag) {
 138     as_snapshot()-&gt;by_type(flag)-&gt;commit_memory(size);
 139   }
 140 
 141   static inline void record_uncommitted_memory(size_t size, MEMFLAGS flag) {
 142     as_snapshot()-&gt;by_type(flag)-&gt;uncommit_memory(size);
 143   }
 144 
 145   static inline void record_released_memory(size_t size, MEMFLAGS flag) {
 146     as_snapshot()-&gt;by_type(flag)-&gt;release_memory(size);
 147   }
 148 
 149   // Move virtual memory from one memory type to another.
 150   // Virtual memory can be reserved before it is associated with a memory type, and tagged
 151   // as 'unknown'. Once the memory is tagged, the virtual memory will be moved from 'unknown'
 152   // type to specified memory type.
 153   static inline void move_reserved_memory(MEMFLAGS from, MEMFLAGS to, size_t size) {
 154     as_snapshot()-&gt;by_type(from)-&gt;release_memory(size);
 155     as_snapshot()-&gt;by_type(to)-&gt;reserve_memory(size);
 156   }
 157 
 158   static inline void move_committed_memory(MEMFLAGS from, MEMFLAGS to, size_t size) {
 159     as_snapshot()-&gt;by_type(from)-&gt;uncommit_memory(size);
 160     as_snapshot()-&gt;by_type(to)-&gt;commit_memory(size);
 161   }
 162 
 163   static void snapshot(VirtualMemorySnapshot* s);
 164 
 165   static VirtualMemorySnapshot* as_snapshot() {
 166     return (VirtualMemorySnapshot*)_snapshot;
 167   }
 168 
 169  private:
 170   static size_t _snapshot[CALC_OBJ_SIZE_IN_TYPE(VirtualMemorySnapshot, size_t)];
 171 };
 172 
 173 
 174 
 175 /*
 176  * A virtual memory region
 177  */
 178 class VirtualMemoryRegion {
 179  private:
 180   address      _base_address;
 181   size_t       _size;
 182 
 183  public:
 184   VirtualMemoryRegion(address addr, size_t size) :
 185     _base_address(addr), _size(size) {
 186      assert(addr != NULL, "Invalid address");
 187      assert(size &gt; 0, "Invalid size");
 188    }
 189 
 190   inline address base() const { return _base_address;   }
 191   inline address end()  const { return base() + size(); }
 192   inline size_t  size() const { return _size;           }
 193 
 194   inline bool is_empty() const { return size() == 0; }
 195 
 196   inline bool contain_address(address addr) const {
 197     return (addr &gt;= base() &amp;&amp; addr &lt; end());
 198   }
 199 
 200 
 201   inline bool contain_region(address addr, size_t size) const {
 202     return contain_address(addr) &amp;&amp; contain_address(addr + size - 1);
 203   }
 204 
 205   inline bool same_region(address addr, size_t sz) const {
 206     return (addr == base() &amp;&amp; sz == size());
 207   }
 208 
 209 
 210   inline bool overlap_region(address addr, size_t sz) const {
 211     assert(sz &gt; 0, "Invalid size");
 212     assert(size() &gt; 0, "Invalid size");
 213     return contain_address(addr) ||
 214            contain_address(addr + sz - 1);
 215   }
 216 
 217   inline bool adjacent_to(address addr, size_t sz) const {
 218     return (addr == end() || (addr + sz) == base());
 219   }
 220 
 221   void exclude_region(address addr, size_t sz) {
 222     assert(contain_region(addr, sz), "Not containment");
 223     assert(addr == base() || addr + sz == end(), "Can not exclude from middle");
 224     size_t new_size = size() - sz;
 225 
 226     if (addr == base()) {
 227       set_base(addr + sz);
 228     }
 229     set_size(new_size);
 230   }
 231 
 232   void expand_region(address addr, size_t sz) {
 233     assert(adjacent_to(addr, sz), "Not adjacent regions");
 234     if (base() == addr + sz) {
 235       set_base(addr);
 236     }
 237     set_size(size() + sz);
 238   }
 239 
 240   // Returns 0 if regions overlap; 1 if this region follows rgn;
 241   //  -1 if this region precedes rgn.
 242   inline int compare(const VirtualMemoryRegion&amp; rgn) const {
 243     if (overlap_region(rgn.base(), rgn.size())) {
 244       return 0;
 245     } else if (base() &gt;= rgn.end()) {
 246       return 1;
 247     } else {
 248       assert(rgn.base() &gt;= end(), "Sanity");
 249       return -1;
 250     }
 251   }
 252 
 253   // Returns true if regions overlap, false otherwise.
 254   inline bool equals(const VirtualMemoryRegion&amp; rgn) const {
 255     return compare(rgn) == 0;
 256   }
 257 
 258  protected:
 259   void set_base(address base) {
 260     assert(base != NULL, "Sanity check");
 261     _base_address = base;
 262   }
 263 
 264   void set_size(size_t  size) {
 265     assert(size &gt; 0, "Sanity check");
 266     _size = size;
 267   }
 268 };
 269 
 270 
 271 class CommittedMemoryRegion : public VirtualMemoryRegion {
 272  private:
 273   NativeCallStack  _stack;
 274 
 275  public:
 276   CommittedMemoryRegion(address addr, size_t size, const NativeCallStack&amp; stack) :
 277     VirtualMemoryRegion(addr, size), _stack(stack) { }
 278 
 279   inline void set_call_stack(const NativeCallStack&amp; stack) { _stack = stack; }
 280   inline const NativeCallStack* call_stack() const         { return &amp;_stack; }
 281 };
 282 
 283 
 284 typedef LinkedListIterator&lt;CommittedMemoryRegion&gt; CommittedRegionIterator;
 285 
 286 int compare_committed_region(const CommittedMemoryRegion&amp;, const CommittedMemoryRegion&amp;);
 287 class ReservedMemoryRegion : public VirtualMemoryRegion {
 288  private:
 289   SortedLinkedList&lt;CommittedMemoryRegion, compare_committed_region&gt;
 290     _committed_regions;
 291 
 292   NativeCallStack  _stack;
 293   MEMFLAGS         _flag;
 294 
 295  public:
 296   ReservedMemoryRegion(address base, size_t size, const NativeCallStack&amp; stack,
 297     MEMFLAGS flag = mtNone) :
 298     VirtualMemoryRegion(base, size), _stack(stack), _flag(flag) { }
 299 
 300 
 301   ReservedMemoryRegion(address base, size_t size) :
 302     VirtualMemoryRegion(base, size), _stack(NativeCallStack::empty_stack()), _flag(mtNone) { }
 303 
 304   // Copy constructor
 305   ReservedMemoryRegion(const ReservedMemoryRegion&amp; rr) :
 306     VirtualMemoryRegion(rr.base(), rr.size()) {
 307     *this = rr;
 308   }
 309 
 310   inline void  set_call_stack(const NativeCallStack&amp; stack) { _stack = stack; }
 311   inline const NativeCallStack* call_stack() const          { return &amp;_stack;  }
 312 
 313   void  set_flag(MEMFLAGS flag);
 314   inline MEMFLAGS flag() const            { return _flag;  }
 315 
 316   // uncommitted thread stack bottom, above guard pages if there is any.
 317   address thread_stack_uncommitted_bottom() const;
 318 
 319   bool    add_committed_region(address addr, size_t size, const NativeCallStack&amp; stack);
 320   bool    remove_uncommitted_region(address addr, size_t size);
 321 
 322   size_t  committed_size() const;
 323 
 324   // move committed regions that higher than specified address to
 325   // the new region
 326   void    move_committed_regions(address addr, ReservedMemoryRegion&amp; rgn);
 327 
 328   CommittedRegionIterator iterate_committed_regions() const {
 329     return CommittedRegionIterator(_committed_regions.head());
 330   }
 331 
 332   ReservedMemoryRegion&amp; operator= (const ReservedMemoryRegion&amp; other) {
 333     set_base(other.base());
 334     set_size(other.size());
 335 
 336     _stack =         *other.call_stack();
 337     _flag  =         other.flag();
 338 
 339     CommittedRegionIterator itr = other.iterate_committed_regions();
 340     const CommittedMemoryRegion* rgn = itr.next();
 341     while (rgn != NULL) {
 342       _committed_regions.add(*rgn);
 343       rgn = itr.next();
 344     }
 345 
 346     return *this;
 347   }
 348 
 349  private:
 350   // The committed region contains the uncommitted region, subtract the uncommitted
 351   // region from this committed region
 352   bool remove_uncommitted_region(LinkedListNode&lt;CommittedMemoryRegion&gt;* node,
 353     address addr, size_t sz);
 354 
 355   bool add_committed_region(const CommittedMemoryRegion&amp; rgn) {
 356     assert(rgn.base() != NULL, "Invalid base address");
 357     assert(size() &gt; 0, "Invalid size");
 358     return _committed_regions.add(rgn) != NULL;
 359   }
 360 };
 361 
 362 int compare_reserved_region_base(const ReservedMemoryRegion&amp; r1, const ReservedMemoryRegion&amp; r2);
 363 
 364 class VirtualMemoryWalker : public StackObj {
 365  public:
 366    virtual bool do_allocation_site(const ReservedMemoryRegion* rgn) { return false; }
 367 };
 368 
 369 // Main class called from MemTracker to track virtual memory allocations, commits and releases.
 370 class VirtualMemoryTracker : AllStatic {
 371   friend class VirtualMemoryTrackerTest;
 372   friend class CommittedVirtualMemoryTest;
 373 
 374  public:
 375   static bool initialize(NMT_TrackingLevel level);
 376 
 377   // Late phase initialization
 378   static bool late_initialize(NMT_TrackingLevel level);
 379 
 380   static bool add_reserved_region (address base_addr, size_t size, const NativeCallStack&amp; stack, MEMFLAGS flag = mtNone);
 381 
 382   static bool add_committed_region      (address base_addr, size_t size, const NativeCallStack&amp; stack);
 383   static bool remove_uncommitted_region (address base_addr, size_t size);
 384   static bool remove_released_region    (address base_addr, size_t size);
 385   static bool remove_released_region    (ReservedMemoryRegion* rgn);
 386   static void set_reserved_region_type  (address addr, MEMFLAGS flag);
 387 
 388   // Given an existing memory mapping registered with NMT, split the mapping in
 389   //  two. The newly created two mappings will be registered under the call
 390   //  stack and the memory flags of the original section.
 391   static bool split_reserved_region(address addr, size_t size, size_t split);
 392 
 393   // Walk virtual memory data structure for creating baseline, etc.
 394   static bool walk_virtual_memory(VirtualMemoryWalker* walker);
 395 
 396   static bool transition(NMT_TrackingLevel from, NMT_TrackingLevel to);
 397 
 398   // Snapshot current thread stacks
 399   static void snapshot_thread_stacks();
 400 
 401  private:
 402   static SortedLinkedList&lt;ReservedMemoryRegion, compare_reserved_region_base&gt;* _reserved_regions;
 403 };
 404 
<a name="1" id="anc1"></a><span class="changed"> 405 // Todo: clean up after jep387, see JDK-8251392</span>
 406 class MetaspaceSnapshot : public ResourceObj {
 407 private:
 408   size_t  _reserved_in_bytes[Metaspace::MetadataTypeCount];
 409   size_t  _committed_in_bytes[Metaspace::MetadataTypeCount];
 410   size_t  _used_in_bytes[Metaspace::MetadataTypeCount];
 411   size_t  _free_in_bytes[Metaspace::MetadataTypeCount];
 412 
 413 public:
 414   MetaspaceSnapshot();
 415   size_t reserved_in_bytes(Metaspace::MetadataType type)   const { assert_valid_metadata_type(type); return _reserved_in_bytes[type]; }
 416   size_t committed_in_bytes(Metaspace::MetadataType type)  const { assert_valid_metadata_type(type); return _committed_in_bytes[type]; }
 417   size_t used_in_bytes(Metaspace::MetadataType type)       const { assert_valid_metadata_type(type); return _used_in_bytes[type]; }
 418   size_t free_in_bytes(Metaspace::MetadataType type)       const { assert_valid_metadata_type(type); return _free_in_bytes[type]; }
 419 
 420   static void snapshot(MetaspaceSnapshot&amp; s);
 421 
 422 private:
 423   static void snapshot(Metaspace::MetadataType type, MetaspaceSnapshot&amp; s);
 424 
 425   static void assert_valid_metadata_type(Metaspace::MetadataType type) {
 426     assert(type == Metaspace::ClassType || type == Metaspace::NonClassType,
 427       "Invalid metadata type");
 428   }
 429 };
 430 
 431 #endif // INCLUDE_NMT
 432 
 433 #endif // SHARE_SERVICES_VIRTUALMEMORYTRACKER_HPP
<a name="2" id="anc2"></a><b style="font-size: large; color: red">--- EOF ---</b>















































































</pre><form name="eof"><input name="value" value="2" type="hidden" /></form></body></html>
