<?xml version="1.0"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head><meta charset="utf-8">
<meta http-equiv="cache-control" content="no-cache" />
<meta http-equiv="Pragma" content="no-cache" />
<meta http-equiv="Expires" content="-1" />
<!--
   Note to customizers: the body of the webrev is IDed as SUNWwebrev
   to allow easy overriding by users of webrev via the userContent.css
   mechanism available in some browsers.

   For example, to have all "removed" information be red instead of
   brown, set a rule in your userContent.css file like:

       body#SUNWwebrev span.removed { color: red ! important; }
-->
<style type="text/css" media="screen">
body {
    background-color: #eeeeee;
}
hr {
    border: none 0;
    border-top: 1px solid #aaa;
    height: 1px;
}
div.summary {
    font-size: .8em;
    border-bottom: 1px solid #aaa;
    padding-left: 1em;
    padding-right: 1em;
}
div.summary h2 {
    margin-bottom: 0.3em;
}
div.summary table th {
    text-align: right;
    vertical-align: top;
    white-space: nowrap;
}
span.lineschanged {
    font-size: 0.7em;
}
span.oldmarker {
    color: red;
    font-size: large;
    font-weight: bold;
}
span.newmarker {
    color: green;
    font-size: large;
    font-weight: bold;
}
span.removed {
    color: brown;
}
span.changed {
    color: blue;
}
span.new {
    color: blue;
    font-weight: bold;
}
a.print { font-size: x-small; }

</style>

<style type="text/css" media="print">
pre { font-size: 0.8em; font-family: courier, monospace; }
span.removed { color: #444; font-style: italic }
span.changed { font-weight: bold; }
span.new { font-weight: bold; }
span.newmarker { font-size: 1.2em; font-weight: bold; }
span.oldmarker { font-size: 1.2em; font-weight: bold; }
a.print {display: none}
hr { border: none 0; border-top: 1px solid #aaa; height: 1px; }
</style>

    <script type="text/javascript" src="../../../../ancnav.js"></script>
    </head>
    <body id="SUNWwebrev" onkeypress="keypress(event);">
    <a name="0"></a>
    <pre>rev <a href="https://bugs.openjdk.java.net/browse/JDK-60811">60811</a> : imported patch jep387-all.patch</pre><hr></hr>
<pre>
   1 /*
   2  * Copyright (c) 2011, 2020, Oracle and/or its affiliates. All rights reserved.
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include "precompiled.hpp"
<a name="1" id="anc1"></a><span class="new">  26 </span>
  27 #include "aot/aotLoader.hpp"
<a name="2" id="anc2"></a>
  28 #include "gc/shared/collectedHeap.hpp"
  29 #include "logging/log.hpp"
  30 #include "logging/logStream.hpp"
  31 #include "memory/filemap.hpp"
<a name="3" id="anc3"></a><span class="new">  32 #include "memory/metaspace/metaspaceSizesSnapshot.hpp"</span>
<span class="new">  33 #include "memory/metaspace/msChunkHeaderPool.hpp"</span>
<span class="new">  34 #include "memory/metaspace/msChunkManager.hpp"</span>
<span class="new">  35 #include "memory/metaspace/msCommitLimiter.hpp"</span>
<span class="new">  36 #include "memory/metaspace/msCommon.hpp"</span>
<span class="new">  37 #include "memory/metaspace/msContext.hpp"</span>
<span class="new">  38 #include "memory/metaspace/msReport.hpp"</span>
<span class="new">  39 #include "memory/metaspace/msRunningCounters.hpp"</span>
<span class="new">  40 #include "memory/metaspace/msSettings.hpp"</span>
<span class="new">  41 #include "memory/metaspace/msVirtualSpaceList.hpp"</span>
  42 #include "memory/metaspace.hpp"
<a name="4" id="anc4"></a>





  43 #include "memory/metaspaceShared.hpp"
  44 #include "memory/metaspaceTracer.hpp"
  45 #include "memory/universe.hpp"
  46 #include "oops/compressedOops.hpp"
  47 #include "runtime/arguments.hpp"
  48 #include "runtime/atomic.hpp"
  49 #include "runtime/init.hpp"
<a name="5" id="anc5"></a><span class="new">  50 #include "runtime/java.hpp"</span>
  51 #include "services/memTracker.hpp"
  52 #include "utilities/copy.hpp"
  53 #include "utilities/debug.hpp"
  54 #include "utilities/formatBuffer.hpp"
  55 #include "utilities/globalDefinitions.hpp"
<a name="6" id="anc6"></a>
  56 
  57 
<a name="7" id="anc7"></a><span class="changed">  58 using metaspace::ChunkManager;</span>
<span class="changed">  59 using metaspace::CommitLimiter;</span>
<span class="changed">  60 using metaspace::MetaspaceContext;</span>
<span class="changed">  61 using metaspace::MetaspaceReporter;</span>
<span class="changed">  62 using metaspace::RunningCounters;</span>
<span class="changed">  63 using metaspace::VirtualSpaceList;</span>
  64 
<a name="8" id="anc8"></a>
  65 
<a name="9" id="anc9"></a><span class="changed">  66 size_t MetaspaceUtils::used_words() {</span>
<span class="changed">  67   return RunningCounters::used_words();</span>
<span class="changed">  68 }</span>
  69 
<a name="10" id="anc10"></a><span class="changed">  70 size_t MetaspaceUtils::used_words(Metaspace::MetadataType mdtype) {</span>
<span class="changed">  71   return Metaspace::is_class_space_allocation(mdtype) ? RunningCounters::used_words_class() : RunningCounters::used_words_nonclass();</span>
<span class="changed">  72 }</span>
<span class="changed">  73 </span>
<span class="changed">  74 size_t MetaspaceUtils::reserved_words() {</span>
<span class="changed">  75   return RunningCounters::reserved_words();</span>
<span class="changed">  76 }</span>
<span class="changed">  77 </span>
<span class="changed">  78 size_t MetaspaceUtils::reserved_words(Metaspace::MetadataType mdtype) {</span>
<span class="changed">  79   return Metaspace::is_class_space_allocation(mdtype) ? RunningCounters::reserved_words_class() : RunningCounters::reserved_words_nonclass();</span>
<span class="changed">  80 }</span>
<span class="changed">  81 </span>
<span class="changed">  82 size_t MetaspaceUtils::committed_words() {</span>
<span class="changed">  83   return RunningCounters::committed_words();</span>
<span class="changed">  84 }</span>
<span class="changed">  85 </span>
<span class="changed">  86 size_t MetaspaceUtils::committed_words(Metaspace::MetadataType mdtype) {</span>
<span class="changed">  87   return Metaspace::is_class_space_allocation(mdtype) ? RunningCounters::committed_words_class() : RunningCounters::committed_words_nonclass();</span>
<span class="changed">  88 }</span>
  89 
<a name="11" id="anc11"></a><span class="changed">  90 </span>
<span class="changed">  91 </span>
<span class="changed">  92 void MetaspaceUtils::print_metaspace_change(const metaspace::MetaspaceSizesSnapshot&amp; pre_meta_values) {</span>
<span class="changed">  93   const metaspace::MetaspaceSizesSnapshot meta_values;</span>
<span class="changed">  94 </span>
<span class="changed">  95   // We print used and committed since these are the most useful at-a-glance vitals for Metaspace:</span>
<span class="changed">  96   // - used tells you how much memory is actually used for metadata</span>
<span class="changed">  97   // - committed tells you how much memory is committed for the purpose of metadata</span>
<span class="changed">  98   // The difference between those two would be waste, which can have various forms (freelists,</span>
<span class="changed">  99   //   unused parts of committed chunks etc)</span>
<span class="changed"> 100   //</span>
<span class="changed"> 101   // Left out is reserved, since this is not as exciting as the first two values: for class space,</span>
<span class="changed"> 102   // it is a constant (to uninformed users, often confusingly large). For non-class space, it would</span>
<span class="changed"> 103   // be interesting since free chunks can be uncommitted, but for now it is left out.</span>
<span class="changed"> 104 </span>
<span class="changed"> 105   if (Metaspace::using_class_space()) {</span>
<span class="changed"> 106     log_info(gc, metaspace)(HEAP_CHANGE_FORMAT" "</span>
<span class="changed"> 107                             HEAP_CHANGE_FORMAT" "</span>
<span class="changed"> 108                             HEAP_CHANGE_FORMAT,</span>
<span class="changed"> 109                             HEAP_CHANGE_FORMAT_ARGS("Metaspace",</span>
<span class="changed"> 110                                                     pre_meta_values.used(),</span>
<span class="changed"> 111                                                     pre_meta_values.committed(),</span>
<span class="changed"> 112                                                     meta_values.used(),</span>
<span class="changed"> 113                                                     meta_values.committed()),</span>
<span class="changed"> 114                             HEAP_CHANGE_FORMAT_ARGS("NonClass",</span>
<span class="changed"> 115                                                     pre_meta_values.non_class_used(),</span>
<span class="changed"> 116                                                     pre_meta_values.non_class_committed(),</span>
<span class="changed"> 117                                                     meta_values.non_class_used(),</span>
<span class="changed"> 118                                                     meta_values.non_class_committed()),</span>
<span class="changed"> 119                             HEAP_CHANGE_FORMAT_ARGS("Class",</span>
<span class="changed"> 120                                                     pre_meta_values.class_used(),</span>
<span class="changed"> 121                                                     pre_meta_values.class_committed(),</span>
<span class="changed"> 122                                                     meta_values.class_used(),</span>
<span class="changed"> 123                                                     meta_values.class_committed()));</span>
<span class="changed"> 124   } else {</span>
<span class="changed"> 125     log_info(gc, metaspace)(HEAP_CHANGE_FORMAT,</span>
<span class="changed"> 126                             HEAP_CHANGE_FORMAT_ARGS("Metaspace",</span>
<span class="changed"> 127                                                     pre_meta_values.used(),</span>
<span class="changed"> 128                                                     pre_meta_values.committed(),</span>
<span class="changed"> 129                                                     meta_values.used(),</span>
<span class="changed"> 130                                                     meta_values.committed()));</span>
 131   }
<a name="12" id="anc12"></a>
 132 }
 133 
<a name="13" id="anc13"></a><span class="changed"> 134 // This will print out a basic metaspace usage report but</span>
<span class="changed"> 135 // unlike print_report() is guaranteed not to lock or to walk the CLDG.</span>
<span class="changed"> 136 void MetaspaceUtils::print_basic_report(outputStream* out, size_t scale) {</span>
<span class="changed"> 137   MetaspaceReporter::print_basic_report(out, scale);</span>
<span class="changed"> 138 }</span>
 139 
<a name="14" id="anc14"></a><span class="changed"> 140 // Prints a report about the current metaspace state.</span>
<span class="changed"> 141 // Optional parts can be enabled via flags.</span>
<span class="changed"> 142 // Function will walk the CLDG and will lock the expand lock; if that is not</span>
<span class="changed"> 143 // convenient, use print_basic_report() instead.</span>
<span class="changed"> 144 void MetaspaceUtils::print_report(outputStream* out, size_t scale) {</span>
<span class="changed"> 145   const int flags =</span>
<span class="changed"> 146       (int)MetaspaceReporter::Option::ShowLoaders |</span>
<span class="changed"> 147       (int)MetaspaceReporter::Option::BreakDownByChunkType |</span>
<span class="changed"> 148       (int)MetaspaceReporter::Option::ShowClasses;</span>
<span class="changed"> 149   MetaspaceReporter::print_report(out, scale, flags);</span>
<span class="changed"> 150 }</span>
<span class="changed"> 151 </span>
<span class="changed"> 152 void MetaspaceUtils::print_on(outputStream* out) {</span>
<span class="changed"> 153 </span>
<span class="changed"> 154   // Used from all GCs. It first prints out totals, then, separately, the class space portion.</span>
<span class="changed"> 155 </span>
<span class="changed"> 156   out-&gt;print_cr(" Metaspace       "</span>
<span class="changed"> 157                 "used "      SIZE_FORMAT "K, "</span>
<span class="changed"> 158                 "committed " SIZE_FORMAT "K, "</span>
<span class="changed"> 159                 "reserved "  SIZE_FORMAT "K",</span>
<span class="changed"> 160                 used_bytes()/K,</span>
<span class="changed"> 161                 committed_bytes()/K,</span>
<span class="changed"> 162                 reserved_bytes()/K);</span>
<span class="changed"> 163 </span>
<span class="changed"> 164   if (Metaspace::using_class_space()) {</span>
<span class="changed"> 165     const Metaspace::MetadataType ct = Metaspace::ClassType;</span>
<span class="changed"> 166     out-&gt;print_cr("  class space    "</span>
<span class="changed"> 167                   "used "      SIZE_FORMAT "K, "</span>
<span class="changed"> 168                   "committed " SIZE_FORMAT "K, "</span>
<span class="changed"> 169                   "reserved "  SIZE_FORMAT "K",</span>
<span class="changed"> 170                   used_bytes(ct)/K,</span>
<span class="changed"> 171                   committed_bytes(ct)/K,</span>
<span class="changed"> 172                   reserved_bytes(ct)/K);</span>
<span class="changed"> 173   }</span>
<span class="changed"> 174 }</span>
<span class="changed"> 175 </span>
<span class="changed"> 176 #ifdef ASSERT</span>
<span class="changed"> 177 void MetaspaceUtils::verify() {</span>
<span class="changed"> 178   if (Metaspace::initialized()) {</span>
<span class="changed"> 179 </span>
<span class="changed"> 180     // Verify non-class chunkmanager...</span>
<span class="changed"> 181     ChunkManager* cm = ChunkManager::chunkmanager_nonclass();</span>
<span class="changed"> 182     cm-&gt;verify();</span>
 183 
<a name="15" id="anc15"></a><span class="changed"> 184     // ... and space list.</span>
<span class="changed"> 185     VirtualSpaceList* vsl = VirtualSpaceList::vslist_nonclass();</span>
<span class="changed"> 186     vsl-&gt;verify();</span>
 187 
<a name="16" id="anc16"></a><span class="new"> 188     if (Metaspace::using_class_space()) {</span>
<span class="new"> 189       // If we use compressed class pointers, verify class chunkmanager...</span>
<span class="new"> 190       cm = ChunkManager::chunkmanager_class();</span>
<span class="new"> 191       cm-&gt;verify();</span>
<span class="new"> 192 </span>
<span class="new"> 193       // ... and class spacelist.</span>
<span class="new"> 194       vsl = VirtualSpaceList::vslist_class();</span>
<span class="new"> 195       vsl-&gt;verify();</span>
<span class="new"> 196     }</span>
<span class="new"> 197 </span>
<span class="new"> 198   }</span>
<span class="new"> 199 }</span>
<span class="new"> 200 #endif</span>
<span class="new"> 201 </span>
<span class="new"> 202 ////////////////////////////////7</span>
 203 // MetaspaceGC methods
 204 
<a name="17" id="anc17"></a><span class="new"> 205 volatile size_t MetaspaceGC::_capacity_until_GC = 0;</span>
<span class="new"> 206 uint MetaspaceGC::_shrink_factor = 0;</span>
<span class="new"> 207 </span>
 208 // VM_CollectForMetadataAllocation is the vm operation used to GC.
 209 // Within the VM operation after the GC the attempt to allocate the metadata
 210 // should succeed.  If the GC did not free enough space for the metaspace
 211 // allocation, the HWM is increased so that another virtualspace will be
 212 // allocated for the metadata.  With perm gen the increase in the perm
 213 // gen had bounds, MinMetaspaceExpansion and MaxMetaspaceExpansion.  The
 214 // metaspace policy uses those as the small and large steps for the HWM.
 215 //
 216 // After the GC the compute_new_size() for MetaspaceGC is called to
 217 // resize the capacity of the metaspaces.  The current implementation
 218 // is based on the flags MinMetaspaceFreeRatio and MaxMetaspaceFreeRatio used
 219 // to resize the Java heap by some GC's.  New flags can be implemented
 220 // if really needed.  MinMetaspaceFreeRatio is used to calculate how much
 221 // free space is desirable in the metaspace capacity to decide how much
 222 // to increase the HWM.  MaxMetaspaceFreeRatio is used to decide how much
 223 // free space is desirable in the metaspace capacity before decreasing
 224 // the HWM.
 225 
 226 // Calculate the amount to increase the high water mark (HWM).
 227 // Increase by a minimum amount (MinMetaspaceExpansion) so that
 228 // another expansion is not requested too soon.  If that is not
 229 // enough to satisfy the allocation, increase by MaxMetaspaceExpansion.
 230 // If that is still not enough, expand by the size of the allocation
 231 // plus some.
 232 size_t MetaspaceGC::delta_capacity_until_GC(size_t bytes) {
 233   size_t min_delta = MinMetaspaceExpansion;
 234   size_t max_delta = MaxMetaspaceExpansion;
 235   size_t delta = align_up(bytes, Metaspace::commit_alignment());
 236 
 237   if (delta &lt;= min_delta) {
 238     delta = min_delta;
 239   } else if (delta &lt;= max_delta) {
 240     // Don't want to hit the high water mark on the next
 241     // allocation so make the delta greater than just enough
 242     // for this allocation.
 243     delta = max_delta;
 244   } else {
 245     // This allocation is large but the next ones are probably not
 246     // so increase by the minimum.
 247     delta = delta + min_delta;
 248   }
 249 
 250   assert_is_aligned(delta, Metaspace::commit_alignment());
 251 
 252   return delta;
 253 }
 254 
 255 size_t MetaspaceGC::capacity_until_GC() {
 256   size_t value = Atomic::load_acquire(&amp;_capacity_until_GC);
 257   assert(value &gt;= MetaspaceSize, "Not initialized properly?");
 258   return value;
 259 }
 260 
 261 // Try to increase the _capacity_until_GC limit counter by v bytes.
 262 // Returns true if it succeeded. It may fail if either another thread
 263 // concurrently increased the limit or the new limit would be larger
 264 // than MaxMetaspaceSize.
 265 // On success, optionally returns new and old metaspace capacity in
 266 // new_cap_until_GC and old_cap_until_GC respectively.
 267 // On error, optionally sets can_retry to indicate whether if there is
 268 // actually enough space remaining to satisfy the request.
 269 bool MetaspaceGC::inc_capacity_until_GC(size_t v, size_t* new_cap_until_GC, size_t* old_cap_until_GC, bool* can_retry) {
 270   assert_is_aligned(v, Metaspace::commit_alignment());
 271 
 272   size_t old_capacity_until_GC = _capacity_until_GC;
 273   size_t new_value = old_capacity_until_GC + v;
 274 
 275   if (new_value &lt; old_capacity_until_GC) {
 276     // The addition wrapped around, set new_value to aligned max value.
 277     new_value = align_down(max_uintx, Metaspace::commit_alignment());
 278   }
 279 
 280   if (new_value &gt; MaxMetaspaceSize) {
 281     if (can_retry != NULL) {
 282       *can_retry = false;
 283     }
 284     return false;
 285   }
 286 
 287   if (can_retry != NULL) {
 288     *can_retry = true;
 289   }
 290   size_t prev_value = Atomic::cmpxchg(&amp;_capacity_until_GC, old_capacity_until_GC, new_value);
 291 
 292   if (old_capacity_until_GC != prev_value) {
 293     return false;
 294   }
 295 
 296   if (new_cap_until_GC != NULL) {
 297     *new_cap_until_GC = new_value;
 298   }
 299   if (old_cap_until_GC != NULL) {
 300     *old_cap_until_GC = old_capacity_until_GC;
 301   }
 302   return true;
 303 }
 304 
 305 size_t MetaspaceGC::dec_capacity_until_GC(size_t v) {
 306   assert_is_aligned(v, Metaspace::commit_alignment());
 307 
 308   return Atomic::sub(&amp;_capacity_until_GC, v);
 309 }
 310 
 311 void MetaspaceGC::initialize() {
 312   // Set the high-water mark to MaxMetapaceSize during VM initializaton since
 313   // we can't do a GC during initialization.
 314   _capacity_until_GC = MaxMetaspaceSize;
 315 }
 316 
 317 void MetaspaceGC::post_initialize() {
 318   // Reset the high-water mark once the VM initialization is done.
 319   _capacity_until_GC = MAX2(MetaspaceUtils::committed_bytes(), MetaspaceSize);
 320 }
 321 
 322 bool MetaspaceGC::can_expand(size_t word_size, bool is_class) {
 323   // Check if the compressed class space is full.
 324   if (is_class &amp;&amp; Metaspace::using_class_space()) {
 325     size_t class_committed = MetaspaceUtils::committed_bytes(Metaspace::ClassType);
 326     if (class_committed + word_size * BytesPerWord &gt; CompressedClassSpaceSize) {
 327       log_trace(gc, metaspace, freelist)("Cannot expand %s metaspace by " SIZE_FORMAT " words (CompressedClassSpaceSize = " SIZE_FORMAT " words)",
 328                 (is_class ? "class" : "non-class"), word_size, CompressedClassSpaceSize / sizeof(MetaWord));
 329       return false;
 330     }
 331   }
 332 
 333   // Check if the user has imposed a limit on the metaspace memory.
 334   size_t committed_bytes = MetaspaceUtils::committed_bytes();
 335   if (committed_bytes + word_size * BytesPerWord &gt; MaxMetaspaceSize) {
 336     log_trace(gc, metaspace, freelist)("Cannot expand %s metaspace by " SIZE_FORMAT " words (MaxMetaspaceSize = " SIZE_FORMAT " words)",
 337               (is_class ? "class" : "non-class"), word_size, MaxMetaspaceSize / sizeof(MetaWord));
 338     return false;
 339   }
 340 
 341   return true;
 342 }
 343 
 344 size_t MetaspaceGC::allowed_expansion() {
 345   size_t committed_bytes = MetaspaceUtils::committed_bytes();
 346   size_t capacity_until_gc = capacity_until_GC();
 347 
 348   assert(capacity_until_gc &gt;= committed_bytes,
 349          "capacity_until_gc: " SIZE_FORMAT " &lt; committed_bytes: " SIZE_FORMAT,
 350          capacity_until_gc, committed_bytes);
 351 
 352   size_t left_until_max  = MaxMetaspaceSize - committed_bytes;
 353   size_t left_until_GC = capacity_until_gc - committed_bytes;
 354   size_t left_to_commit = MIN2(left_until_GC, left_until_max);
 355   log_trace(gc, metaspace, freelist)("allowed expansion words: " SIZE_FORMAT
 356             " (left_until_max: " SIZE_FORMAT ", left_until_GC: " SIZE_FORMAT ".",
 357             left_to_commit / BytesPerWord, left_until_max / BytesPerWord, left_until_GC / BytesPerWord);
 358 
 359   return left_to_commit / BytesPerWord;
 360 }
 361 
 362 void MetaspaceGC::compute_new_size() {
 363   assert(_shrink_factor &lt;= 100, "invalid shrink factor");
 364   uint current_shrink_factor = _shrink_factor;
 365   _shrink_factor = 0;
 366 
 367   // Using committed_bytes() for used_after_gc is an overestimation, since the
 368   // chunk free lists are included in committed_bytes() and the memory in an
 369   // un-fragmented chunk free list is available for future allocations.
 370   // However, if the chunk free lists becomes fragmented, then the memory may
 371   // not be available for future allocations and the memory is therefore "in use".
 372   // Including the chunk free lists in the definition of "in use" is therefore
 373   // necessary. Not including the chunk free lists can cause capacity_until_GC to
 374   // shrink below committed_bytes() and this has caused serious bugs in the past.
 375   const size_t used_after_gc = MetaspaceUtils::committed_bytes();
 376   const size_t capacity_until_GC = MetaspaceGC::capacity_until_GC();
 377 
 378   const double minimum_free_percentage = MinMetaspaceFreeRatio / 100.0;
 379   const double maximum_used_percentage = 1.0 - minimum_free_percentage;
 380 
 381   const double min_tmp = used_after_gc / maximum_used_percentage;
 382   size_t minimum_desired_capacity =
 383     (size_t)MIN2(min_tmp, double(MaxMetaspaceSize));
 384   // Don't shrink less than the initial generation size
 385   minimum_desired_capacity = MAX2(minimum_desired_capacity,
 386                                   MetaspaceSize);
 387 
 388   log_trace(gc, metaspace)("MetaspaceGC::compute_new_size: ");
 389   log_trace(gc, metaspace)("    minimum_free_percentage: %6.2f  maximum_used_percentage: %6.2f",
 390                            minimum_free_percentage, maximum_used_percentage);
 391   log_trace(gc, metaspace)("     used_after_gc       : %6.1fKB", used_after_gc / (double) K);
 392 
 393 
 394   size_t shrink_bytes = 0;
 395   if (capacity_until_GC &lt; minimum_desired_capacity) {
 396     // If we have less capacity below the metaspace HWM, then
 397     // increment the HWM.
 398     size_t expand_bytes = minimum_desired_capacity - capacity_until_GC;
 399     expand_bytes = align_up(expand_bytes, Metaspace::commit_alignment());
 400     // Don't expand unless it's significant
 401     if (expand_bytes &gt;= MinMetaspaceExpansion) {
 402       size_t new_capacity_until_GC = 0;
 403       bool succeeded = MetaspaceGC::inc_capacity_until_GC(expand_bytes, &amp;new_capacity_until_GC);
 404       assert(succeeded, "Should always succesfully increment HWM when at safepoint");
 405 
 406       Metaspace::tracer()-&gt;report_gc_threshold(capacity_until_GC,
 407                                                new_capacity_until_GC,
 408                                                MetaspaceGCThresholdUpdater::ComputeNewSize);
 409       log_trace(gc, metaspace)("    expanding:  minimum_desired_capacity: %6.1fKB  expand_bytes: %6.1fKB  MinMetaspaceExpansion: %6.1fKB  new metaspace HWM:  %6.1fKB",
 410                                minimum_desired_capacity / (double) K,
 411                                expand_bytes / (double) K,
 412                                MinMetaspaceExpansion / (double) K,
 413                                new_capacity_until_GC / (double) K);
 414     }
 415     return;
 416   }
 417 
 418   // No expansion, now see if we want to shrink
 419   // We would never want to shrink more than this
 420   assert(capacity_until_GC &gt;= minimum_desired_capacity,
 421          SIZE_FORMAT " &gt;= " SIZE_FORMAT,
 422          capacity_until_GC, minimum_desired_capacity);
 423   size_t max_shrink_bytes = capacity_until_GC - minimum_desired_capacity;
 424 
 425   // Should shrinking be considered?
 426   if (MaxMetaspaceFreeRatio &lt; 100) {
 427     const double maximum_free_percentage = MaxMetaspaceFreeRatio / 100.0;
 428     const double minimum_used_percentage = 1.0 - maximum_free_percentage;
 429     const double max_tmp = used_after_gc / minimum_used_percentage;
 430     size_t maximum_desired_capacity = (size_t)MIN2(max_tmp, double(MaxMetaspaceSize));
 431     maximum_desired_capacity = MAX2(maximum_desired_capacity,
 432                                     MetaspaceSize);
 433     log_trace(gc, metaspace)("    maximum_free_percentage: %6.2f  minimum_used_percentage: %6.2f",
 434                              maximum_free_percentage, minimum_used_percentage);
 435     log_trace(gc, metaspace)("    minimum_desired_capacity: %6.1fKB  maximum_desired_capacity: %6.1fKB",
 436                              minimum_desired_capacity / (double) K, maximum_desired_capacity / (double) K);
 437 
 438     assert(minimum_desired_capacity &lt;= maximum_desired_capacity,
 439            "sanity check");
 440 
 441     if (capacity_until_GC &gt; maximum_desired_capacity) {
 442       // Capacity too large, compute shrinking size
 443       shrink_bytes = capacity_until_GC - maximum_desired_capacity;
 444       // We don't want shrink all the way back to initSize if people call
 445       // System.gc(), because some programs do that between "phases" and then
 446       // we'd just have to grow the heap up again for the next phase.  So we
 447       // damp the shrinking: 0% on the first call, 10% on the second call, 40%
 448       // on the third call, and 100% by the fourth call.  But if we recompute
 449       // size without shrinking, it goes back to 0%.
 450       shrink_bytes = shrink_bytes / 100 * current_shrink_factor;
 451 
 452       shrink_bytes = align_down(shrink_bytes, Metaspace::commit_alignment());
 453 
 454       assert(shrink_bytes &lt;= max_shrink_bytes,
 455              "invalid shrink size " SIZE_FORMAT " not &lt;= " SIZE_FORMAT,
 456              shrink_bytes, max_shrink_bytes);
 457       if (current_shrink_factor == 0) {
 458         _shrink_factor = 10;
 459       } else {
 460         _shrink_factor = MIN2(current_shrink_factor * 4, (uint) 100);
 461       }
 462       log_trace(gc, metaspace)("    shrinking:  initThreshold: %.1fK  maximum_desired_capacity: %.1fK",
 463                                MetaspaceSize / (double) K, maximum_desired_capacity / (double) K);
 464       log_trace(gc, metaspace)("    shrink_bytes: %.1fK  current_shrink_factor: %d  new shrink factor: %d  MinMetaspaceExpansion: %.1fK",
 465                                shrink_bytes / (double) K, current_shrink_factor, _shrink_factor, MinMetaspaceExpansion / (double) K);
 466     }
 467   }
 468 
 469   // Don't shrink unless it's significant
 470   if (shrink_bytes &gt;= MinMetaspaceExpansion &amp;&amp;
 471       ((capacity_until_GC - shrink_bytes) &gt;= MetaspaceSize)) {
 472     size_t new_capacity_until_GC = MetaspaceGC::dec_capacity_until_GC(shrink_bytes);
 473     Metaspace::tracer()-&gt;report_gc_threshold(capacity_until_GC,
 474                                              new_capacity_until_GC,
 475                                              MetaspaceGCThresholdUpdater::ComputeNewSize);
 476   }
 477 }
 478 
<a name="18" id="anc18"></a>



 479 
<a name="19" id="anc19"></a>



































 480 
<a name="20" id="anc20"></a><span class="changed"> 481 //////  Metaspace methods /////</span>

































































































































































































 482 
<a name="21" id="anc21"></a><span class="changed"> 483 const MetaspaceTracer* Metaspace::_tracer = NULL;</span>




































































































































































































































































































































 484 
<a name="22" id="anc22"></a><span class="changed"> 485 DEBUG_ONLY(bool Metaspace::_frozen = false;)</span>







 486 
<a name="23" id="anc23"></a><span class="changed"> 487 bool Metaspace::initialized() {</span>
<span class="changed"> 488   return metaspace::MetaspaceContext::context_nonclass() != NULL &amp;&amp;</span>
<span class="changed"> 489       (using_class_space() ? metaspace::MetaspaceContext::context_class() != NULL : true);</span>


























 490 }
 491 
<a name="24" id="anc24"></a>

















 492 #ifdef _LP64
 493 
 494 void Metaspace::print_compressed_class_space(outputStream* st) {
<a name="25" id="anc25"></a><span class="changed"> 495   if (VirtualSpaceList::vslist_class() != NULL) {</span>
<span class="changed"> 496     MetaWord* base = VirtualSpaceList::vslist_class()-&gt;base_of_first_node();</span>
<span class="changed"> 497     size_t size = VirtualSpaceList::vslist_class()-&gt;word_size_of_first_node();</span>
<span class="changed"> 498     MetaWord* top = base + size;</span>
<span class="changed"> 499     st-&gt;print("Compressed class space mapped at: " PTR_FORMAT "-" PTR_FORMAT ", reserved size: " SIZE_FORMAT,</span>
<span class="changed"> 500                p2i(base), p2i(top), (top - base) * BytesPerWord);</span>
 501     st-&gt;cr();
 502   }
 503 }
 504 
 505 // Given a prereserved space, use that to set up the compressed class space list.
 506 void Metaspace::initialize_class_space(ReservedSpace rs) {
<a name="26" id="anc26"></a><span class="new"> 507   assert(rs.size() &gt;= CompressedClassSpaceSize,</span>
<span class="new"> 508          SIZE_FORMAT " != " SIZE_FORMAT, rs.size(), CompressedClassSpaceSize);</span>
 509   assert(using_class_space(), "Must be using class space");
<a name="27" id="anc27"></a>
 510 
 511   assert(rs.size() == CompressedClassSpaceSize, SIZE_FORMAT " != " SIZE_FORMAT,
 512          rs.size(), CompressedClassSpaceSize);
 513   assert(is_aligned(rs.base(), Metaspace::reserve_alignment()) &amp;&amp;
 514          is_aligned(rs.size(), Metaspace::reserve_alignment()),
 515          "wrong alignment");
 516 
<a name="28" id="anc28"></a><span class="changed"> 517   MetaspaceContext::initialize_class_space_context(rs);</span>

 518 
 519   // This does currently not work because rs may be the result of a split
 520   // operation and NMT seems not to be able to handle splits.
 521   // Will be fixed with JDK-8243535.
 522   // MemTracker::record_virtual_memory_type((address)rs.base(), mtClass);
 523 
<a name="29" id="anc29"></a><span class="changed"> 524 }</span>


 525 
<a name="30" id="anc30"></a><span class="new"> 526 // Returns true if class space has been setup (initialize_class_space).</span>
<span class="new"> 527 bool Metaspace::class_space_is_initialized() {</span>
<span class="new"> 528   return MetaspaceContext::context_class() != NULL;</span>
 529 }
 530 
 531 // Reserve a range of memory at an address suitable for en/decoding narrow
 532 // Klass pointers (see: CompressedClassPointers::is_valid_base()).
 533 // The returned address shall both be suitable as a compressed class pointers
 534 //  base, and aligned to Metaspace::reserve_alignment (which is equal to or a
 535 //  multiple of allocation granularity).
 536 // On error, returns an unreserved space.
 537 ReservedSpace Metaspace::reserve_address_space_for_compressed_classes(size_t size) {
 538 
 539 #ifdef AARCH64
 540   const size_t alignment = Metaspace::reserve_alignment();
 541 
 542   // AArch64: Try to align metaspace so that we can decode a compressed
 543   // klass with a single MOVK instruction. We can do this iff the
 544   // compressed class base is a multiple of 4G.
 545   // Additionally, above 32G, ensure the lower LogKlassAlignmentInBytes bits
 546   // of the upper 32-bits of the address are zero so we can handle a shift
 547   // when decoding.
 548 
 549   static const struct {
 550     address from;
 551     address to;
 552     size_t increment;
 553   } search_ranges[] = {
 554     {  (address)(4*G),   (address)(32*G),   4*G, },
 555     {  (address)(32*G),  (address)(1024*G), (4 &lt;&lt; LogKlassAlignmentInBytes) * G },
 556     {  NULL, NULL, 0 }
 557   };
 558 
 559   for (int i = 0; search_ranges[i].from != NULL; i ++) {
 560     address a = search_ranges[i].from;
 561     assert(CompressedKlassPointers::is_valid_base(a), "Sanity");
 562     while (a &lt; search_ranges[i].to) {
 563       ReservedSpace rs(size, Metaspace::reserve_alignment(),
 564                        false /*large_pages*/, (char*)a);
 565       if (rs.is_reserved()) {
 566         assert(a == (address)rs.base(), "Sanity");
 567         return rs;
 568       }
 569       a +=  search_ranges[i].increment;
 570     }
 571   }
 572 
 573   // Note: on AARCH64, if the code above does not find any good placement, we
 574   // have no recourse. We return an empty space and the VM will exit.
 575   return ReservedSpace();
 576 #else
 577   // Default implementation: Just reserve anywhere.
 578   return ReservedSpace(size, Metaspace::reserve_alignment(), false, (char*)NULL);
 579 #endif // AARCH64
 580 }
 581 
 582 #endif // _LP64
 583 
 584 
<a name="31" id="anc31"></a><span class="changed"> 585 size_t Metaspace::reserve_alignment_words() {</span>
<span class="changed"> 586   return metaspace::Settings::virtual_space_node_reserve_alignment_words();</span>
<span class="changed"> 587 }</span>


 588 
<a name="32" id="anc32"></a><span class="changed"> 589 size_t Metaspace::commit_alignment_words() {</span>
<span class="changed"> 590   return metaspace::Settings::commit_granule_words();</span>
<span class="changed"> 591 }</span>

 592 
<a name="33" id="anc33"></a><span class="changed"> 593 void Metaspace::ergo_initialize() {</span>

 594 
<a name="34" id="anc34"></a><span class="changed"> 595   // Must happen before using any setting from Settings::---</span>
<span class="changed"> 596   metaspace::Settings::ergo_initialize();</span>




 597 
<a name="35" id="anc35"></a><span class="changed"> 598   // MaxMetaspaceSize and CompressedClassSpaceSize:</span>
<span class="changed"> 599   //</span>
<span class="changed"> 600   // MaxMetaspaceSize is the maximum size, in bytes, of memory we are allowed</span>
<span class="changed"> 601   //  to commit for the Metaspace.</span>
<span class="changed"> 602   //  It is just a number; a limit we compare against before committing. It</span>
<span class="changed"> 603   //  does not have to be aligned to anything.</span>
<span class="changed"> 604   //  It gets used as compare value in class CommitLimiter.</span>
<span class="changed"> 605   //  It is set to max_uintx in globals.hpp by default, so by default it does</span>
<span class="changed"> 606   //  not limit anything.</span>
<span class="changed"> 607   //</span>
<span class="changed"> 608   // CompressedClassSpaceSize is the size, in bytes, of the address range we</span>
<span class="changed"> 609   //  pre-reserve for the compressed class space (if we use class space).</span>
<span class="changed"> 610   //  This size has to be aligned to the metaspace reserve alignment (to the</span>
<span class="changed"> 611   //  size of a root chunk). It gets aligned up from whatever value the caller</span>
<span class="changed"> 612   //  gave us to the next multiple of root chunk size.</span>
<span class="changed"> 613   //</span>
<span class="changed"> 614   // Note: Strictly speaking MaxMetaspaceSize and CompressedClassSpaceSize have</span>
<span class="changed"> 615   //  very little to do with each other. The notion often encountered:</span>
<span class="changed"> 616   //  MaxMetaspaceSize = CompressedClassSpaceSize + &lt;non-class metadata size&gt;</span>
<span class="changed"> 617   //  is subtly wrong: MaxMetaspaceSize can besmaller than CompressedClassSpaceSize,</span>
<span class="changed"> 618   //  in which case we just would not be able to fully commit the class space range.</span>
 619   //
<a name="36" id="anc36"></a><span class="changed"> 620   // We still adjust CompressedClassSpaceSize to reasonable limits, mainly to</span>
<span class="changed"> 621   //  save on reserved space, and to make ergnonomics less confusing.</span>


 622 
<a name="37" id="anc37"></a><span class="new"> 623   // (aligned just for cleanliness:)</span>
<span class="new"> 624   MaxMetaspaceSize = MAX2(align_down(MaxMetaspaceSize, commit_alignment()), commit_alignment());</span>
<span class="new"> 625 </span>
<span class="new"> 626   if (UseCompressedClassPointers) {</span>
<span class="new"> 627     // Let CCS size not be larger than 80% of MaxMetaspaceSize. Note that is</span>
<span class="new"> 628     // grossly over-dimensioned for most usage scenarios; typical ratio of</span>
<span class="new"> 629     // class space : non class space usage is about 1:6. With many small classes,</span>
<span class="new"> 630     // it can get as low as 1:2. It is not a big deal though since ccs is only</span>
<span class="new"> 631     // reserved and will be committed on demand only.</span>
<span class="new"> 632     size_t max_ccs_size = MaxMetaspaceSize * 0.8;</span>
<span class="new"> 633     size_t adjusted_ccs_size = MIN2(CompressedClassSpaceSize, max_ccs_size);</span>
<span class="new"> 634 </span>
<span class="new"> 635     // CCS must be aligned to root chunk size, and be at least the size of one</span>
<span class="new"> 636     //  root chunk.</span>
<span class="new"> 637     adjusted_ccs_size = align_up(adjusted_ccs_size, reserve_alignment());</span>
<span class="new"> 638     adjusted_ccs_size = MAX2(adjusted_ccs_size, reserve_alignment());</span>
<span class="new"> 639 </span>
<span class="new"> 640     // Note: re-adjusting may have us left with a CompressedClassSpaceSize</span>
<span class="new"> 641     //  larger than MaxMetaspaceSize for very small values of MaxMetaspaceSize.</span>
<span class="new"> 642     //  Lets just live with that, its not a big deal.</span>
<span class="new"> 643 </span>
<span class="new"> 644     if (adjusted_ccs_size != CompressedClassSpaceSize) {</span>
<span class="new"> 645       FLAG_SET_ERGO(CompressedClassSpaceSize, adjusted_ccs_size);</span>
<span class="new"> 646       log_info(metaspace)("Setting CompressedClassSpaceSize to " SIZE_FORMAT ".",</span>
<span class="new"> 647                           CompressedClassSpaceSize);</span>
<span class="new"> 648     }</span>
<span class="new"> 649   }</span>
<span class="new"> 650 </span>
<span class="new"> 651   // Set MetaspaceSize, MinMetaspaceExpansion and MaxMetaspaceExpansion</span>
 652   if (MetaspaceSize &gt; MaxMetaspaceSize) {
 653     MetaspaceSize = MaxMetaspaceSize;
 654   }
 655 
<a name="38" id="anc38"></a><span class="changed"> 656   MetaspaceSize = align_down_bounded(MetaspaceSize, commit_alignment());</span>
 657 
 658   assert(MetaspaceSize &lt;= MaxMetaspaceSize, "MetaspaceSize should be limited by MaxMetaspaceSize");
 659 
<a name="39" id="anc39"></a><span class="changed"> 660   MinMetaspaceExpansion = align_down_bounded(MinMetaspaceExpansion, commit_alignment());</span>
<span class="changed"> 661   MaxMetaspaceExpansion = align_down_bounded(MaxMetaspaceExpansion, commit_alignment());</span>


 662 
<a name="40" id="anc40"></a>

















 663 }
 664 
 665 void Metaspace::global_initialize() {
<a name="41" id="anc41"></a><span class="changed"> 666   MetaspaceGC::initialize(); // &lt;- since we do not prealloc init chunks anymore is this still needed?</span>
<span class="changed"> 667 </span>
<span class="changed"> 668   metaspace::ChunkHeaderPool::initialize();</span>
 669 
 670   // If UseCompressedClassPointers=1, we have two cases:
 671   // a) if CDS is active (either dump time or runtime), it will create the ccs
 672   //    for us, initialize it and set up CompressedKlassPointers encoding.
 673   //    Class space will be reserved above the mapped archives.
 674   // b) if CDS is not active, we will create the ccs on our own. It will be
 675   //    placed above the java heap, since we assume it has been placed in low
 676   //    address regions. We may rethink this (see JDK-8244943). Failing that,
 677   //    it will be placed anywhere.
 678 
 679 #if INCLUDE_CDS
 680   // case (a)
 681   if (DumpSharedSpaces) {
 682     MetaspaceShared::initialize_dumptime_shared_and_meta_spaces();
 683   } else if (UseSharedSpaces) {
 684     // If any of the archived space fails to map, UseSharedSpaces
 685     // is reset to false.
 686     MetaspaceShared::initialize_runtime_shared_and_meta_spaces();
 687   }
 688 
 689   if (DynamicDumpSharedSpaces &amp;&amp; !UseSharedSpaces) {
 690     vm_exit_during_initialization("DynamicDumpSharedSpaces is unsupported when base CDS archive is not loaded", NULL);
 691   }
 692 #endif // INCLUDE_CDS
 693 
 694 #ifdef _LP64
 695 
 696   if (using_class_space() &amp;&amp; !class_space_is_initialized()) {
 697     assert(!UseSharedSpaces &amp;&amp; !DumpSharedSpaces, "CDS should be off at this point");
 698 
 699     // case (b)
 700     ReservedSpace rs;
 701 
 702     // If UseCompressedOops=1, java heap may have been placed in coops-friendly
 703     //  territory already (lower address regions), so we attempt to place ccs
 704     //  right above the java heap.
 705     // If UseCompressedOops=0, the heap has been placed anywhere - probably in
 706     //  high memory regions. In that case, try to place ccs at the lowest allowed
 707     //  mapping address.
 708     address base = UseCompressedOops ? CompressedOops::end() : (address)HeapBaseMinAddress;
 709     base = align_up(base, Metaspace::reserve_alignment());
 710 
 711     const size_t size = align_up(CompressedClassSpaceSize, Metaspace::reserve_alignment());
 712     if (base != NULL) {
 713       if (CompressedKlassPointers::is_valid_base(base)) {
 714         rs = ReservedSpace(size, Metaspace::reserve_alignment(),
 715                            false /* large */, (char*)base);
 716       }
 717     }
 718 
 719     // ...failing that, reserve anywhere, but let platform do optimized placement:
 720     if (!rs.is_reserved()) {
 721       rs = Metaspace::reserve_address_space_for_compressed_classes(size);
 722     }
 723 
 724     // ...failing that, give up.
 725     if (!rs.is_reserved()) {
 726       vm_exit_during_initialization(
 727           err_msg("Could not allocate compressed class space: " SIZE_FORMAT " bytes",
<a name="42" id="anc42"></a><span class="changed"> 728                    CompressedClassSpaceSize));</span>
 729     }
 730 
 731     // Initialize space
 732     Metaspace::initialize_class_space(rs);
 733 
 734     // Set up compressed class pointer encoding.
 735     CompressedKlassPointers::initialize((address)rs.base(), rs.size());
 736   }
 737 
 738 #endif
 739 
<a name="43" id="anc43"></a><span class="changed"> 740   // Initialize non-class virtual space list, and its chunk manager:</span>
<span class="changed"> 741   MetaspaceContext::initialize_nonclass_space_context();</span>



















 742 
 743   _tracer = new MetaspaceTracer();
 744 
<a name="44" id="anc44"></a><span class="changed"> 745   // We must prevent the very first address of the ccs from being used to store</span>
<span class="changed"> 746   // metadata, since that address would translate to a narrow pointer of 0, and the</span>
<span class="changed"> 747   // VM does not distinguish between "narrow 0 as in NULL" and "narrow 0 as in start</span>
<span class="changed"> 748   //  of ccs".</span>
<span class="changed"> 749   // Before Elastic Metaspace that did not happen due to the fact that every Metachunk</span>
<span class="changed"> 750   // had a header and therefore could not allocate anything at offset 0.</span>
<span class="changed"> 751 #ifdef _LP64</span>
<span class="changed"> 752   if (using_class_space()) {</span>
<span class="changed"> 753     // The simplest way to fix this is to allocate a tiny dummy chunk right at the</span>
<span class="changed"> 754     // start of ccs and do not use it for anything.</span>
<span class="changed"> 755     MetaspaceContext::context_class()-&gt;cm()-&gt;get_chunk(metaspace::chunklevel::HIGHEST_CHUNK_LEVEL);</span>
<span class="changed"> 756   }</span>
<span class="changed"> 757 #endif</span>
 758 
 759 #ifdef _LP64
 760   if (UseCompressedClassPointers) {
 761     // Note: "cds" would be a better fit but keep this for backward compatibility.
 762     LogTarget(Info, gc, metaspace) lt;
 763     if (lt.is_enabled()) {
 764       ResourceMark rm;
 765       LogStream ls(lt);
 766       CDS_ONLY(MetaspaceShared::print_on(&amp;ls);)
 767       Metaspace::print_compressed_class_space(&amp;ls);
 768       CompressedKlassPointers::print_mode(&amp;ls);
 769     }
 770   }
 771 #endif
 772 
 773 }
 774 
 775 void Metaspace::post_initialize() {
 776   MetaspaceGC::post_initialize();
 777 }
 778 
<a name="45" id="anc45"></a><span class="changed"> 779 size_t Metaspace::max_allocation_word_size() {</span>
<span class="changed"> 780   const size_t max_overhead_words = metaspace::get_raw_word_size_for_requested_word_size(1);</span>
<span class="changed"> 781   return metaspace::chunklevel::MAX_CHUNK_WORD_SIZE - max_overhead_words;</span>










 782 }
 783 
 784 MetaWord* Metaspace::allocate(ClassLoaderData* loader_data, size_t word_size,
 785                               MetaspaceObj::Type type, TRAPS) {
<a name="46" id="anc46"></a><span class="new"> 786   assert(word_size &lt;= Metaspace::max_allocation_word_size(),</span>
<span class="new"> 787          "allocation size too large (" SIZE_FORMAT ")", word_size);</span>
 788   assert(!_frozen, "sanity");
 789   assert(!(DumpSharedSpaces &amp;&amp; THREAD-&gt;is_VM_thread()), "sanity");
 790 
 791   if (HAS_PENDING_EXCEPTION) {
 792     assert(false, "Should not allocate with exception pending");
 793     return NULL;  // caller does a CHECK_NULL too
 794   }
 795 
 796   assert(loader_data != NULL, "Should never pass around a NULL loader_data. "
 797         "ClassLoaderData::the_null_class_loader_data() should have been used.");
 798 
 799   MetadataType mdtype = (type == MetaspaceObj::ClassType) ? ClassType : NonClassType;
 800 
 801   // Try to allocate metadata.
 802   MetaWord* result = loader_data-&gt;metaspace_non_null()-&gt;allocate(word_size, mdtype);
 803 
 804   if (result == NULL) {
 805     tracer()-&gt;report_metaspace_allocation_failure(loader_data, word_size, type, mdtype);
 806 
 807     // Allocation failed.
 808     if (is_init_completed()) {
 809       // Only start a GC if the bootstrapping has completed.
 810       // Try to clean out some heap memory and retry. This can prevent premature
 811       // expansion of the metaspace.
 812       result = Universe::heap()-&gt;satisfy_failed_metadata_allocation(loader_data, word_size, mdtype);
 813     }
 814   }
 815 
 816   if (result == NULL) {
 817     if (DumpSharedSpaces) {
 818       // CDS dumping keeps loading classes, so if we hit an OOM we probably will keep hitting OOM.
 819       // We should abort to avoid generating a potentially bad archive.
 820       vm_exit_during_cds_dumping(err_msg("Failed allocating metaspace object type %s of size " SIZE_FORMAT ". CDS dump aborted.",
 821           MetaspaceObj::type_name(type), word_size * BytesPerWord),
 822         err_msg("Please increase MaxMetaspaceSize (currently " SIZE_FORMAT " bytes).", MaxMetaspaceSize));
 823     }
 824     report_metadata_oome(loader_data, word_size, type, mdtype, THREAD);
 825     assert(HAS_PENDING_EXCEPTION, "sanity");
 826     return NULL;
 827   }
 828 
 829   // Zero initialize.
 830   Copy::fill_to_words((HeapWord*)result, word_size, 0);
 831 
<a name="47" id="anc47"></a><span class="new"> 832   log_trace(metaspace)("Metaspace::allocate: type %d return " PTR_FORMAT ".", (int)type, p2i(result));</span>
<span class="new"> 833 </span>
 834   return result;
 835 }
 836 
 837 void Metaspace::report_metadata_oome(ClassLoaderData* loader_data, size_t word_size, MetaspaceObj::Type type, MetadataType mdtype, TRAPS) {
 838   tracer()-&gt;report_metadata_oom(loader_data, word_size, type, mdtype);
 839 
 840   // If result is still null, we are out of memory.
 841   Log(gc, metaspace, freelist, oom) log;
 842   if (log.is_info()) {
 843     log.info("Metaspace (%s) allocation failed for size " SIZE_FORMAT,
 844              is_class_space_allocation(mdtype) ? "class" : "data", word_size);
 845     ResourceMark rm;
 846     if (log.is_debug()) {
 847       if (loader_data-&gt;metaspace_or_null() != NULL) {
 848         LogStream ls(log.debug());
 849         loader_data-&gt;print_value_on(&amp;ls);
 850       }
 851     }
 852     LogStream ls(log.info());
 853     // In case of an OOM, log out a short but still useful report.
 854     MetaspaceUtils::print_basic_report(&amp;ls, 0);
 855   }
 856 
<a name="48" id="anc48"></a><span class="new"> 857   // TODO: this exception text may be wrong and misleading. This needs more thinking. See JDK-8252189.</span>
 858   bool out_of_compressed_class_space = false;
 859   if (is_class_space_allocation(mdtype)) {
 860     ClassLoaderMetaspace* metaspace = loader_data-&gt;metaspace_non_null();
 861     out_of_compressed_class_space =
 862       MetaspaceUtils::committed_bytes(Metaspace::ClassType) +
<a name="49" id="anc49"></a><span class="changed"> 863       align_up(word_size * BytesPerWord, 4 * M) &gt;</span>
 864       CompressedClassSpaceSize;
 865   }
 866 
 867   // -XX:+HeapDumpOnOutOfMemoryError and -XX:OnOutOfMemoryError support
 868   const char* space_string = out_of_compressed_class_space ?
 869     "Compressed class space" : "Metaspace";
 870 
 871   report_java_out_of_memory(space_string);
 872 
 873   if (JvmtiExport::should_post_resource_exhausted()) {
 874     JvmtiExport::post_resource_exhausted(
 875         JVMTI_RESOURCE_EXHAUSTED_OOM_ERROR,
 876         space_string);
 877   }
 878 
 879   if (!is_init_completed()) {
 880     vm_exit_during_initialization("OutOfMemoryError", space_string);
 881   }
 882 
 883   if (out_of_compressed_class_space) {
 884     THROW_OOP(Universe::out_of_memory_error_class_metaspace());
 885   } else {
 886     THROW_OOP(Universe::out_of_memory_error_metaspace());
 887   }
 888 }
 889 
 890 const char* Metaspace::metadata_type_name(Metaspace::MetadataType mdtype) {
 891   switch (mdtype) {
 892     case Metaspace::ClassType: return "Class";
 893     case Metaspace::NonClassType: return "Metadata";
 894     default:
 895       assert(false, "Got bad mdtype: %d", (int) mdtype);
 896       return NULL;
 897   }
 898 }
 899 
<a name="50" id="anc50"></a>



 900 void Metaspace::purge() {
<a name="51" id="anc51"></a><span class="changed"> 901   ChunkManager* cm = ChunkManager::chunkmanager_nonclass();</span>
<span class="changed"> 902   if (cm != NULL) {</span>
<span class="changed"> 903     cm-&gt;purge();</span>
<span class="changed"> 904   }</span>
 905   if (using_class_space()) {
<a name="52" id="anc52"></a><span class="changed"> 906     cm = ChunkManager::chunkmanager_class();</span>
<span class="changed"> 907     if (cm != NULL) {</span>
<span class="changed"> 908       cm-&gt;purge();</span>
<span class="changed"> 909     }</span>
 910   }
 911 }
 912 
 913 bool Metaspace::contains(const void* ptr) {
 914   if (MetaspaceShared::is_in_shared_metaspace(ptr)) {
 915     return true;
 916   }
 917   return contains_non_shared(ptr);
 918 }
 919 
 920 bool Metaspace::contains_non_shared(const void* ptr) {
<a name="53" id="anc53"></a><span class="changed"> 921   if (using_class_space() &amp;&amp; VirtualSpaceList::vslist_class()-&gt;contains((MetaWord*)ptr)) {</span>
 922      return true;
 923   }
 924 
<a name="54" id="anc54"></a><span class="changed"> 925   return VirtualSpaceList::vslist_nonclass()-&gt;contains((MetaWord*)ptr);</span>













































































































































































































 926 }
<a name="55" id="anc55"></a><b style="font-size: large; color: red">--- EOF ---</b>















































































</pre><form name="eof"><input name="value" value="55" type="hidden" /></form></body></html>
