<?xml version="1.0"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head><meta charset="utf-8">
<meta http-equiv="cache-control" content="no-cache" />
<meta http-equiv="Pragma" content="no-cache" />
<meta http-equiv="Expires" content="-1" />
<!--
   Note to customizers: the body of the webrev is IDed as SUNWwebrev
   to allow easy overriding by users of webrev via the userContent.css
   mechanism available in some browsers.

   For example, to have all "removed" information be red instead of
   brown, set a rule in your userContent.css file like:

       body#SUNWwebrev span.removed { color: red ! important; }
-->
<style type="text/css" media="screen">
body {
    background-color: #eeeeee;
}
hr {
    border: none 0;
    border-top: 1px solid #aaa;
    height: 1px;
}
div.summary {
    font-size: .8em;
    border-bottom: 1px solid #aaa;
    padding-left: 1em;
    padding-right: 1em;
}
div.summary h2 {
    margin-bottom: 0.3em;
}
div.summary table th {
    text-align: right;
    vertical-align: top;
    white-space: nowrap;
}
span.lineschanged {
    font-size: 0.7em;
}
span.oldmarker {
    color: red;
    font-size: large;
    font-weight: bold;
}
span.newmarker {
    color: green;
    font-size: large;
    font-weight: bold;
}
span.removed {
    color: brown;
}
span.changed {
    color: blue;
}
span.new {
    color: blue;
    font-weight: bold;
}
a.print { font-size: x-small; }

</style>

<style type="text/css" media="print">
pre { font-size: 0.8em; font-family: courier, monospace; }
span.removed { color: #444; font-style: italic }
span.changed { font-weight: bold; }
span.new { font-weight: bold; }
span.newmarker { font-size: 1.2em; font-weight: bold; }
span.oldmarker { font-size: 1.2em; font-weight: bold; }
a.print {display: none}
hr { border: none 0; border-top: 1px solid #aaa; height: 1px; }
</style>

<title>source Sdiff src/hotspot/share/memory/metaspace </title>
</head><body id="SUNWwebrev">
<center><a href='../../../../../src/hotspot/share/memory/metaspace/virtualSpaceList.hpp.sdiff.html' target='_top'>&lt prev</a> <a href='../../../../../index.html' target='_top'>index</a> <a href='../../../../../src/hotspot/share/memory/metaspace/virtualSpaceNode.hpp.sdiff.html' target='_top'>next &gt</a></center>
<h2>src/hotspot/share/memory/metaspace/virtualSpaceNode.cpp</h2>
<a class="print" href="javascript:print()">Print this page</a>
<pre>rev <a href="https://bugs.openjdk.java.net/browse/JDK-60529">60529</a> : imported patch jep387-all.patch</pre>

<table><tr valign="top">
<td><pre>
   1 /*
<span class="changed">   2  * Copyright (c) 2018, Oracle and/or its affiliates. All rights reserved.</span>

   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include "precompiled.hpp"
  26 
  27 #include "logging/log.hpp"
<span class="changed">  28 #include "logging/logStream.hpp"</span>






  29 #include "memory/metaspace/metachunk.hpp"
<span class="removed">  30 #include "memory/metaspace.hpp"</span>
<span class="removed">  31 #include "memory/metaspace/chunkManager.hpp"</span>
<span class="removed">  32 #include "memory/metaspace/metaDebug.hpp"</span>
  33 #include "memory/metaspace/metaspaceCommon.hpp"
<span class="changed">  34 #include "memory/metaspace/occupancyMap.hpp"</span>


  35 #include "memory/metaspace/virtualSpaceNode.hpp"
<span class="changed">  36 #include "memory/virtualspace.hpp"</span>
<span class="changed">  37 #include "runtime/atomic.hpp"</span>


  38 #include "runtime/os.hpp"
<span class="changed">  39 #include "services/memTracker.hpp"</span>
<span class="changed">  40 #include "utilities/copy.hpp"</span>
  41 #include "utilities/debug.hpp"
  42 #include "utilities/globalDefinitions.hpp"

  43 
  44 namespace metaspace {
  45 
<span class="changed">  46 // Decide if large pages should be committed when the memory is reserved.</span>
<span class="changed">  47 static bool should_commit_large_pages_when_reserving(size_t bytes) {</span>
<span class="changed">  48   if (UseLargePages &amp;&amp; UseLargePagesInMetaspace &amp;&amp; !os::can_commit_large_page_memory()) {</span>
<span class="changed">  49     size_t words = bytes / BytesPerWord;</span>
<span class="changed">  50     bool is_class = false; // We never reserve large pages for the class space.</span>
<span class="changed">  51     if (MetaspaceGC::can_expand(words, is_class) &amp;&amp;</span>
<span class="changed">  52         MetaspaceGC::allowed_expansion() &gt;= words) {</span>
<span class="changed">  53       return true;</span>
<span class="changed">  54     }</span>
<span class="changed">  55   }</span>
  56 
<span class="changed">  57   return false;</span>








  58 }

  59 
<span class="changed">  60 // byte_size is the size of the associated virtualspace.</span>
<span class="changed">  61 VirtualSpaceNode::VirtualSpaceNode(bool is_class, size_t bytes) :</span>
<span class="changed">  62     _next(NULL), _is_class(is_class), _rs(), _top(NULL), _container_count(0), _occupancy_map(NULL) {</span>
<span class="changed">  63   assert_is_aligned(bytes, Metaspace::reserve_alignment());</span>
<span class="changed">  64   bool large_pages = should_commit_large_pages_when_reserving(bytes);</span>
<span class="changed">  65   _rs = ReservedSpace(bytes, Metaspace::reserve_alignment(), large_pages);</span>
<span class="changed">  66 </span>
<span class="changed">  67   if (_rs.is_reserved()) {</span>
<span class="changed">  68     assert(_rs.base() != NULL, "Catch if we get a NULL address");</span>
<span class="changed">  69     assert(_rs.size() != 0, "Catch if we get a 0 size");</span>
<span class="changed">  70     assert_is_aligned(_rs.base(), Metaspace::reserve_alignment());</span>
<span class="changed">  71     assert_is_aligned(_rs.size(), Metaspace::reserve_alignment());</span>
<span class="changed">  72 </span>
<span class="changed">  73     MemTracker::record_virtual_memory_type((address)_rs.base(), mtClass);</span>
<span class="changed">  74   }</span>
<span class="changed">  75 }</span>
<span class="changed">  76 </span>
<span class="changed">  77 void VirtualSpaceNode::purge(ChunkManager* chunk_manager) {</span>
<span class="changed">  78   // When a node is purged, lets give it a thorough examination.</span>
<span class="changed">  79   DEBUG_ONLY(verify(true);)</span>
<span class="changed">  80   Metachunk* chunk = first_chunk();</span>
<span class="changed">  81   Metachunk* invalid_chunk = (Metachunk*) top();</span>
<span class="changed">  82   while (chunk &lt; invalid_chunk ) {</span>
<span class="changed">  83     assert(chunk-&gt;is_tagged_free(), "Should be tagged free");</span>
<span class="changed">  84     MetaWord* next = ((MetaWord*)chunk) + chunk-&gt;word_size();</span>
<span class="changed">  85     chunk_manager-&gt;remove_chunk(chunk);</span>
<span class="changed">  86     chunk-&gt;remove_sentinel();</span>
<span class="changed">  87     assert(chunk-&gt;next() == NULL &amp;&amp;</span>
<span class="changed">  88         chunk-&gt;prev() == NULL,</span>
<span class="changed">  89         "Was not removed from its list");</span>
<span class="changed">  90     chunk = (Metachunk*) next;</span>
<span class="changed">  91   }</span>
<span class="changed">  92 }</span>
<span class="changed">  93 </span>
<span class="changed">  94 void VirtualSpaceNode::print_map(outputStream* st, bool is_class) const {</span>
<span class="changed">  95 </span>
<span class="changed">  96   if (bottom() == top()) {</span>
<span class="changed">  97     return;</span>
<span class="changed">  98   }</span>
<span class="changed">  99 </span>
<span class="changed"> 100   const size_t spec_chunk_size = is_class ? ClassSpecializedChunk : SpecializedChunk;</span>
<span class="changed"> 101   const size_t small_chunk_size = is_class ? ClassSmallChunk : SmallChunk;</span>
<span class="changed"> 102   const size_t med_chunk_size = is_class ? ClassMediumChunk : MediumChunk;</span>
<span class="changed"> 103 </span>
<span class="changed"> 104   int line_len = 100;</span>
<span class="changed"> 105   const size_t section_len = align_up(spec_chunk_size * line_len, med_chunk_size);</span>
<span class="changed"> 106   line_len = (int)(section_len / spec_chunk_size);</span>
<span class="changed"> 107 </span>
<span class="changed"> 108   static const int NUM_LINES = 4;</span>
<span class="changed"> 109 </span>
<span class="changed"> 110   char* lines[NUM_LINES];</span>
<span class="changed"> 111   for (int i = 0; i &lt; NUM_LINES; i ++) {</span>
<span class="changed"> 112     lines[i] = (char*)os::malloc(line_len, mtInternal);</span>
<span class="changed"> 113   }</span>
<span class="changed"> 114   int pos = 0;</span>
<span class="changed"> 115   const MetaWord* p = bottom();</span>
<span class="changed"> 116   const Metachunk* chunk = (const Metachunk*)p;</span>
<span class="changed"> 117   const MetaWord* chunk_end = p + chunk-&gt;word_size();</span>
<span class="changed"> 118   while (p &lt; top()) {</span>
<span class="changed"> 119     if (pos == line_len) {</span>
<span class="changed"> 120       pos = 0;</span>
<span class="changed"> 121       for (int i = 0; i &lt; NUM_LINES; i ++) {</span>
<span class="changed"> 122         st-&gt;fill_to(22);</span>
<span class="changed"> 123         st-&gt;print_raw(lines[i], line_len);</span>
<span class="changed"> 124         st-&gt;cr();</span>
<span class="changed"> 125       }</span>
<span class="changed"> 126     }</span>
<span class="changed"> 127     if (pos == 0) {</span>
<span class="changed"> 128       st-&gt;print(PTR_FORMAT ":", p2i(p));</span>
 129     }
<span class="changed"> 130     if (p == chunk_end) {</span>
<span class="changed"> 131       chunk = (Metachunk*)p;</span>
<span class="changed"> 132       chunk_end = p + chunk-&gt;word_size();</span>
<span class="changed"> 133     }</span>
<span class="changed"> 134     // line 1: chunk starting points (a dot if that area is a chunk start).</span>
<span class="changed"> 135     lines[0][pos] = p == (const MetaWord*)chunk ? '.' : ' ';</span>
<span class="changed"> 136 </span>
<span class="changed"> 137     // Line 2: chunk type (x=spec, s=small, m=medium, h=humongous), uppercase if</span>
<span class="changed"> 138     // chunk is in use.</span>
<span class="changed"> 139     const bool chunk_is_free = ((Metachunk*)chunk)-&gt;is_tagged_free();</span>
<span class="changed"> 140     if (chunk-&gt;word_size() == spec_chunk_size) {</span>
<span class="changed"> 141       lines[1][pos] = chunk_is_free ? 'x' : 'X';</span>
<span class="changed"> 142     } else if (chunk-&gt;word_size() == small_chunk_size) {</span>
<span class="changed"> 143       lines[1][pos] = chunk_is_free ? 's' : 'S';</span>
<span class="changed"> 144     } else if (chunk-&gt;word_size() == med_chunk_size) {</span>
<span class="changed"> 145       lines[1][pos] = chunk_is_free ? 'm' : 'M';</span>
<span class="changed"> 146     } else if (chunk-&gt;word_size() &gt; med_chunk_size) {</span>
<span class="changed"> 147       lines[1][pos] = chunk_is_free ? 'h' : 'H';</span>
<span class="changed"> 148     } else {</span>
<span class="changed"> 149       ShouldNotReachHere();</span>
<span class="changed"> 150     }</span>
<span class="changed"> 151 </span>
<span class="changed"> 152     // Line 3: chunk origin</span>
<span class="changed"> 153     const ChunkOrigin origin = chunk-&gt;get_origin();</span>
<span class="changed"> 154     lines[2][pos] = origin == origin_normal ? ' ' : '0' + (int) origin;</span>
<span class="changed"> 155 </span>
<span class="changed"> 156     // Line 4: Virgin chunk? Virgin chunks are chunks created as a byproduct of padding or splitting,</span>
<span class="changed"> 157     //         but were never used.</span>
<span class="changed"> 158     lines[3][pos] = chunk-&gt;get_use_count() &gt; 0 ? ' ' : 'v';</span>
<span class="changed"> 159 </span>
<span class="changed"> 160     p += spec_chunk_size;</span>
<span class="changed"> 161     pos ++;</span>
<span class="changed"> 162   }</span>
<span class="changed"> 163   if (pos &gt; 0) {</span>
<span class="changed"> 164     for (int i = 0; i &lt; NUM_LINES; i ++) {</span>
<span class="changed"> 165       st-&gt;fill_to(22);</span>
<span class="changed"> 166       st-&gt;print_raw(lines[i], line_len);</span>
<span class="changed"> 167       st-&gt;cr();</span>
 168     }




 169   }
<span class="changed"> 170   for (int i = 0; i &lt; NUM_LINES; i ++) {</span>
<span class="changed"> 171     os::free(lines[i]);</span>

 172   }
<span class="removed"> 173 }</span>
 174 

 175 
<span class="changed"> 176 #ifdef ASSERT</span>

 177 
<span class="changed"> 178 // Verify counters, all chunks in this list node and the occupancy map.</span>
<span class="changed"> 179 void VirtualSpaceNode::verify(bool slow) {</span>
<span class="changed"> 180   log_trace(gc, metaspace, freelist)("verifying %s virtual space node (%s).",</span>
<span class="changed"> 181     (is_class() ? "class space" : "metaspace"), (slow ? "slow" : "quick"));</span>
<span class="changed"> 182   // Fast mode: just verify chunk counters and basic geometry</span>
<span class="changed"> 183   // Slow mode: verify chunks and occupancy map</span>
<span class="changed"> 184   uintx num_in_use_chunks = 0;</span>
<span class="changed"> 185   Metachunk* chunk = first_chunk();</span>
<span class="changed"> 186   Metachunk* invalid_chunk = (Metachunk*) top();</span>
<span class="changed"> 187 </span>
<span class="changed"> 188   // Iterate the chunks in this node and verify each chunk.</span>
<span class="changed"> 189   while (chunk &lt; invalid_chunk ) {</span>
<span class="changed"> 190     if (slow) {</span>
<span class="changed"> 191       do_verify_chunk(chunk);</span>
<span class="changed"> 192     }</span>
<span class="changed"> 193     if (!chunk-&gt;is_tagged_free()) {</span>
<span class="changed"> 194       num_in_use_chunks ++;</span>
<span class="changed"> 195     }</span>
<span class="changed"> 196     const size_t s = chunk-&gt;word_size();</span>
<span class="changed"> 197     // Prevent endless loop on invalid chunk size.</span>
<span class="changed"> 198     assert(is_valid_chunksize(is_class(), s), "Invalid chunk size: " SIZE_FORMAT ".", s);</span>
<span class="changed"> 199     MetaWord* next = ((MetaWord*)chunk) + s;</span>
<span class="changed"> 200     chunk = (Metachunk*) next;</span>
<span class="changed"> 201   }</span>
<span class="changed"> 202   assert(_container_count == num_in_use_chunks, "Container count mismatch (real: " UINTX_FORMAT</span>
<span class="changed"> 203       ", counter: " UINTX_FORMAT ".", num_in_use_chunks, _container_count);</span>
<span class="changed"> 204   // Also verify the occupancy map.</span>
<span class="changed"> 205   if (slow) {</span>
<span class="changed"> 206     occupancy_map()-&gt;verify(bottom(), top());</span>
<span class="changed"> 207   }</span>
<span class="changed"> 208 }</span>
<span class="changed"> 209 </span>
<span class="changed"> 210 // Verify that all free chunks in this node are ideally merged</span>
<span class="changed"> 211 // (there not should be multiple small chunks where a large chunk could exist.)</span>
<span class="changed"> 212 void VirtualSpaceNode::verify_free_chunks_are_ideally_merged() {</span>
<span class="changed"> 213   Metachunk* chunk = first_chunk();</span>
<span class="changed"> 214   Metachunk* invalid_chunk = (Metachunk*) top();</span>
<span class="changed"> 215   // Shorthands.</span>
<span class="changed"> 216   const size_t size_med = (is_class() ? ClassMediumChunk : MediumChunk) * BytesPerWord;</span>
<span class="changed"> 217   const size_t size_small = (is_class() ? ClassSmallChunk : SmallChunk) * BytesPerWord;</span>
<span class="changed"> 218   int num_free_chunks_since_last_med_boundary = -1;</span>
<span class="changed"> 219   int num_free_chunks_since_last_small_boundary = -1;</span>
<span class="changed"> 220   bool error = false;</span>
<span class="changed"> 221   char err[256];</span>
<span class="changed"> 222   while (!error &amp;&amp; chunk &lt; invalid_chunk ) {</span>
<span class="changed"> 223     // Test for missed chunk merge opportunities: count number of free chunks since last chunk boundary.</span>
<span class="changed"> 224     // Reset the counter when encountering a non-free chunk.</span>
<span class="changed"> 225     if (chunk-&gt;get_chunk_type() != HumongousIndex) {</span>
<span class="changed"> 226       if (chunk-&gt;is_tagged_free()) {</span>
<span class="changed"> 227         // Count successive free, non-humongous chunks.</span>
<span class="changed"> 228         if (is_aligned(chunk, size_small)) {</span>
<span class="changed"> 229           if (num_free_chunks_since_last_small_boundary &gt; 0) {</span>
<span class="changed"> 230             error = true;</span>
<span class="changed"> 231             jio_snprintf(err, sizeof(err), "Missed chunk merge opportunity to merge a small chunk preceding " PTR_FORMAT ".", p2i(chunk));</span>
<span class="changed"> 232           } else {</span>
<span class="changed"> 233             num_free_chunks_since_last_small_boundary = 0;</span>
<span class="changed"> 234           }</span>
<span class="changed"> 235         } else if (num_free_chunks_since_last_small_boundary != -1) {</span>
<span class="changed"> 236           num_free_chunks_since_last_small_boundary ++;</span>
<span class="changed"> 237         }</span>
<span class="changed"> 238         if (is_aligned(chunk, size_med)) {</span>
<span class="changed"> 239           if (num_free_chunks_since_last_med_boundary &gt; 0) {</span>
<span class="changed"> 240             error = true;</span>
<span class="changed"> 241             jio_snprintf(err, sizeof(err), "Missed chunk merge opportunity to merge a medium chunk preceding " PTR_FORMAT ".", p2i(chunk));</span>
<span class="changed"> 242           } else {</span>
<span class="changed"> 243             num_free_chunks_since_last_med_boundary = 0;</span>
<span class="changed"> 244           }</span>
<span class="changed"> 245         } else if (num_free_chunks_since_last_med_boundary != -1) {</span>
<span class="changed"> 246           num_free_chunks_since_last_med_boundary ++;</span>
<span class="changed"> 247         }</span>
<span class="changed"> 248       } else {</span>
<span class="changed"> 249         // Encountering a non-free chunk, reset counters.</span>
<span class="changed"> 250         num_free_chunks_since_last_med_boundary = -1;</span>
<span class="changed"> 251         num_free_chunks_since_last_small_boundary = -1;</span>
<span class="changed"> 252       }</span>
<span class="changed"> 253     } else {</span>
<span class="changed"> 254       // One cannot merge areas with a humongous chunk in the middle. Reset counters.</span>
<span class="changed"> 255       num_free_chunks_since_last_med_boundary = -1;</span>
<span class="changed"> 256       num_free_chunks_since_last_small_boundary = -1;</span>
<span class="changed"> 257     }</span>
<span class="changed"> 258 </span>
<span class="changed"> 259     if (error) {</span>
<span class="changed"> 260       print_map(tty, is_class());</span>
<span class="changed"> 261       fatal("%s", err);</span>
<span class="changed"> 262     }</span>
 263 
<span class="changed"> 264     MetaWord* next = ((MetaWord*)chunk) + chunk-&gt;word_size();</span>
<span class="changed"> 265     chunk = (Metachunk*) next;</span>






 266   }






 267 }
<span class="removed"> 268 #endif // ASSERT</span>
 269 
<span class="changed"> 270 void VirtualSpaceNode::inc_container_count() {</span>




















 271   assert_lock_strong(MetaspaceExpand_lock);
<span class="changed"> 272   _container_count++;</span>







 273 }
 274 
<span class="changed"> 275 void VirtualSpaceNode::dec_container_count() {</span>






 276   assert_lock_strong(MetaspaceExpand_lock);
<span class="removed"> 277   _container_count--;</span>
<span class="removed"> 278 }</span>
 279 
<span class="changed"> 280 VirtualSpaceNode::~VirtualSpaceNode() {</span>
<span class="changed"> 281   _rs.release();</span>
<span class="changed"> 282   if (_occupancy_map != NULL) {</span>
<span class="changed"> 283     delete _occupancy_map;</span>






 284   }


















 285 #ifdef ASSERT
<span class="changed"> 286   size_t word_size = sizeof(*this) / BytesPerWord;</span>
<span class="changed"> 287   Copy::fill_to_words((HeapWord*) this, word_size, 0xf1f1f1f1);</span>



 288 #endif



 289 }
 290 
<span class="changed"> 291 size_t VirtualSpaceNode::used_words_in_vs() const {</span>
<span class="changed"> 292   return pointer_delta(top(), bottom(), sizeof(MetaWord));</span>






















 293 }
 294 
<span class="removed"> 295 // Space committed in the VirtualSpace</span>
<span class="removed"> 296 size_t VirtualSpaceNode::capacity_words_in_vs() const {</span>
<span class="removed"> 297   return pointer_delta(end(), bottom(), sizeof(MetaWord));</span>
<span class="removed"> 298 }</span>
<span class="removed"> 299 </span>
<span class="removed"> 300 size_t VirtualSpaceNode::free_words_in_vs() const {</span>
<span class="removed"> 301   return pointer_delta(end(), top(), sizeof(MetaWord));</span>
<span class="removed"> 302 }</span>
<span class="removed"> 303 </span>
<span class="removed"> 304 // Given an address larger than top(), allocate padding chunks until top is at the given address.</span>
<span class="removed"> 305 void VirtualSpaceNode::allocate_padding_chunks_until_top_is_at(MetaWord* target_top) {</span>
<span class="removed"> 306 </span>
<span class="removed"> 307   assert(target_top &gt; top(), "Sanity");</span>
<span class="removed"> 308 </span>
<span class="removed"> 309   // Padding chunks are added to the freelist.</span>
<span class="removed"> 310   ChunkManager* const chunk_manager = Metaspace::get_chunk_manager(is_class());</span>
<span class="removed"> 311 </span>
<span class="removed"> 312   // shorthands</span>
<span class="removed"> 313   const size_t spec_word_size = chunk_manager-&gt;specialized_chunk_word_size();</span>
<span class="removed"> 314   const size_t small_word_size = chunk_manager-&gt;small_chunk_word_size();</span>
<span class="removed"> 315   const size_t med_word_size = chunk_manager-&gt;medium_chunk_word_size();</span>
<span class="removed"> 316 </span>
<span class="removed"> 317   while (top() &lt; target_top) {</span>
<span class="removed"> 318 </span>
<span class="removed"> 319     // We could make this coding more generic, but right now we only deal with two possible chunk sizes</span>
<span class="removed"> 320     // for padding chunks, so it is not worth it.</span>
<span class="removed"> 321     size_t padding_chunk_word_size = small_word_size;</span>
<span class="removed"> 322     if (is_aligned(top(), small_word_size * sizeof(MetaWord)) == false) {</span>
<span class="removed"> 323       assert_is_aligned(top(), spec_word_size * sizeof(MetaWord)); // Should always hold true.</span>
<span class="removed"> 324       padding_chunk_word_size = spec_word_size;</span>
<span class="removed"> 325     }</span>
<span class="removed"> 326     MetaWord* here = top();</span>
<span class="removed"> 327     assert_is_aligned(here, padding_chunk_word_size * sizeof(MetaWord));</span>
<span class="removed"> 328     inc_top(padding_chunk_word_size);</span>
<span class="removed"> 329 </span>
<span class="removed"> 330     // Create new padding chunk.</span>
<span class="removed"> 331     ChunkIndex padding_chunk_type = get_chunk_type_by_size(padding_chunk_word_size, is_class());</span>
<span class="removed"> 332     assert(padding_chunk_type == SpecializedIndex || padding_chunk_type == SmallIndex, "sanity");</span>
<span class="removed"> 333 </span>
<span class="removed"> 334     Metachunk* const padding_chunk =</span>
<span class="removed"> 335         ::new (here) Metachunk(padding_chunk_type, is_class(), padding_chunk_word_size, this);</span>
<span class="removed"> 336     assert(padding_chunk == (Metachunk*)here, "Sanity");</span>
<span class="removed"> 337     DEBUG_ONLY(padding_chunk-&gt;set_origin(origin_pad);)</span>
<span class="removed"> 338     log_trace(gc, metaspace, freelist)("Created padding chunk in %s at "</span>
<span class="removed"> 339         PTR_FORMAT ", size " SIZE_FORMAT_HEX ".",</span>
<span class="removed"> 340         (is_class() ? "class space " : "metaspace"),</span>
<span class="removed"> 341         p2i(padding_chunk), padding_chunk-&gt;word_size() * sizeof(MetaWord));</span>
<span class="removed"> 342 </span>
<span class="removed"> 343     // Mark chunk start in occupancy map.</span>
<span class="removed"> 344     occupancy_map()-&gt;set_chunk_starts_at_address((MetaWord*)padding_chunk, true);</span>
<span class="removed"> 345 </span>
<span class="removed"> 346     // Chunks are born as in-use (see MetaChunk ctor). So, before returning</span>
<span class="removed"> 347     // the padding chunk to its chunk manager, mark it as in use (ChunkManager</span>
<span class="removed"> 348     // will assert that).</span>
<span class="removed"> 349     do_update_in_use_info_for_chunk(padding_chunk, true);</span>
<span class="removed"> 350 </span>
<span class="removed"> 351     // Return Chunk to freelist.</span>
<span class="removed"> 352     inc_container_count();</span>
<span class="removed"> 353     chunk_manager-&gt;return_single_chunk(padding_chunk);</span>
<span class="removed"> 354     // Please note: at this point, ChunkManager::return_single_chunk()</span>
<span class="removed"> 355     // may already have merged the padding chunk with neighboring chunks, so</span>
<span class="removed"> 356     // it may have vanished at this point. Do not reference the padding</span>
<span class="removed"> 357     // chunk beyond this point.</span>
<span class="removed"> 358   }</span>
<span class="removed"> 359 </span>
<span class="removed"> 360   assert(top() == target_top, "Sanity");</span>
<span class="removed"> 361 </span>
<span class="removed"> 362 } // allocate_padding_chunks_until_top_is_at()</span>
<span class="removed"> 363 </span>
<span class="removed"> 364 // Allocates the chunk from the virtual space only.</span>
<span class="removed"> 365 // This interface is also used internally for debugging.  Not all</span>
<span class="removed"> 366 // chunks removed here are necessarily used for allocation.</span>
<span class="removed"> 367 Metachunk* VirtualSpaceNode::take_from_committed(size_t chunk_word_size) {</span>
<span class="removed"> 368   // Non-humongous chunks are to be allocated aligned to their chunk</span>
<span class="removed"> 369   // size. So, start addresses of medium chunks are aligned to medium</span>
<span class="removed"> 370   // chunk size, those of small chunks to small chunk size and so</span>
<span class="removed"> 371   // forth. This facilitates merging of free chunks and reduces</span>
<span class="removed"> 372   // fragmentation. Chunk sizes are spec &lt; small &lt; medium, with each</span>
<span class="removed"> 373   // larger chunk size being a multiple of the next smaller chunk</span>
<span class="removed"> 374   // size.</span>
<span class="removed"> 375   // Because of this alignment, me may need to create a number of padding</span>
<span class="removed"> 376   // chunks. These chunks are created and added to the freelist.</span>
<span class="removed"> 377 </span>
<span class="removed"> 378   // The chunk manager to which we will give our padding chunks.</span>
<span class="removed"> 379   ChunkManager* const chunk_manager = Metaspace::get_chunk_manager(is_class());</span>
<span class="removed"> 380 </span>
<span class="removed"> 381   // shorthands</span>
<span class="removed"> 382   const size_t spec_word_size = chunk_manager-&gt;specialized_chunk_word_size();</span>
<span class="removed"> 383   const size_t small_word_size = chunk_manager-&gt;small_chunk_word_size();</span>
<span class="removed"> 384   const size_t med_word_size = chunk_manager-&gt;medium_chunk_word_size();</span>
<span class="removed"> 385 </span>
<span class="removed"> 386   assert(chunk_word_size == spec_word_size || chunk_word_size == small_word_size ||</span>
<span class="removed"> 387       chunk_word_size &gt;= med_word_size, "Invalid chunk size requested.");</span>
<span class="removed"> 388 </span>
<span class="removed"> 389   // Chunk alignment (in bytes) == chunk size unless humongous.</span>
<span class="removed"> 390   // Humongous chunks are aligned to the smallest chunk size (spec).</span>
<span class="removed"> 391   const size_t required_chunk_alignment = (chunk_word_size &gt; med_word_size ?</span>
<span class="removed"> 392       spec_word_size : chunk_word_size) * sizeof(MetaWord);</span>
<span class="removed"> 393 </span>
<span class="removed"> 394   // Do we have enough space to create the requested chunk plus</span>
<span class="removed"> 395   // any padding chunks needed?</span>
<span class="removed"> 396   MetaWord* const next_aligned =</span>
<span class="removed"> 397       static_cast&lt;MetaWord*&gt;(align_up(top(), required_chunk_alignment));</span>
<span class="removed"> 398   if (!is_available((next_aligned - top()) + chunk_word_size)) {</span>
<span class="removed"> 399     return NULL;</span>
<span class="removed"> 400   }</span>
<span class="removed"> 401 </span>
<span class="removed"> 402   // Before allocating the requested chunk, allocate padding chunks if necessary.</span>
<span class="removed"> 403   // We only need to do this for small or medium chunks: specialized chunks are the</span>
<span class="removed"> 404   // smallest size, hence always aligned. Homungous chunks are allocated unaligned</span>
<span class="removed"> 405   // (implicitly, also aligned to smallest chunk size).</span>
<span class="removed"> 406   if ((chunk_word_size == med_word_size || chunk_word_size == small_word_size) &amp;&amp; next_aligned &gt; top())  {</span>
<span class="removed"> 407     log_trace(gc, metaspace, freelist)("Creating padding chunks in %s between %p and %p...",</span>
<span class="removed"> 408         (is_class() ? "class space " : "metaspace"),</span>
<span class="removed"> 409         top(), next_aligned);</span>
<span class="removed"> 410     allocate_padding_chunks_until_top_is_at(next_aligned);</span>
<span class="removed"> 411     // Now, top should be aligned correctly.</span>
<span class="removed"> 412     assert_is_aligned(top(), required_chunk_alignment);</span>
<span class="removed"> 413   }</span>
<span class="removed"> 414 </span>
<span class="removed"> 415   // Now, top should be aligned correctly.</span>
<span class="removed"> 416   assert_is_aligned(top(), required_chunk_alignment);</span>
<span class="removed"> 417 </span>
<span class="removed"> 418   // Bottom of the new chunk</span>
<span class="removed"> 419   MetaWord* chunk_limit = top();</span>
<span class="removed"> 420   assert(chunk_limit != NULL, "Not safe to call this method");</span>
<span class="removed"> 421 </span>
<span class="removed"> 422   // The virtual spaces are always expanded by the</span>
<span class="removed"> 423   // commit granularity to enforce the following condition.</span>
<span class="removed"> 424   // Without this the is_available check will not work correctly.</span>
<span class="removed"> 425   assert(_virtual_space.committed_size() == _virtual_space.actual_committed_size(),</span>
<span class="removed"> 426       "The committed memory doesn't match the expanded memory.");</span>
<span class="removed"> 427 </span>
<span class="removed"> 428   if (!is_available(chunk_word_size)) {</span>
<span class="removed"> 429     LogTarget(Trace, gc, metaspace, freelist) lt;</span>
<span class="removed"> 430     if (lt.is_enabled()) {</span>
<span class="removed"> 431       LogStream ls(lt);</span>
<span class="removed"> 432       ls.print("VirtualSpaceNode::take_from_committed() not available " SIZE_FORMAT " words ", chunk_word_size);</span>
<span class="removed"> 433       // Dump some information about the virtual space that is nearly full</span>
<span class="removed"> 434       print_on(&amp;ls);</span>
<span class="removed"> 435     }</span>
<span class="removed"> 436     return NULL;</span>
<span class="removed"> 437   }</span>
<span class="removed"> 438 </span>
<span class="removed"> 439   // Take the space  (bump top on the current virtual space).</span>
<span class="removed"> 440   inc_top(chunk_word_size);</span>
<span class="removed"> 441 </span>
<span class="removed"> 442   // Initialize the chunk</span>
<span class="removed"> 443   ChunkIndex chunk_type = get_chunk_type_by_size(chunk_word_size, is_class());</span>
<span class="removed"> 444   Metachunk* result = ::new (chunk_limit) Metachunk(chunk_type, is_class(), chunk_word_size, this);</span>
<span class="removed"> 445   assert(result == (Metachunk*)chunk_limit, "Sanity");</span>
<span class="removed"> 446   occupancy_map()-&gt;set_chunk_starts_at_address((MetaWord*)result, true);</span>
<span class="removed"> 447   do_update_in_use_info_for_chunk(result, true);</span>
 448 
<span class="changed"> 449   inc_container_count();</span>




 450 
<span class="changed"> 451 #ifdef ASSERT</span>
<span class="changed"> 452   EVERY_NTH(VerifyMetaspaceInterval)</span>
<span class="changed"> 453     chunk_manager-&gt;locked_verify(true);</span>
<span class="changed"> 454     verify(true);</span>
<span class="changed"> 455   END_EVERY_NTH</span>
<span class="changed"> 456   do_verify_chunk(result);</span>
<span class="changed"> 457 #endif</span>
 458 
<span class="changed"> 459   result-&gt;inc_use_count();</span>












 460 
<span class="removed"> 461   return result;</span>
 462 }
 463 









 464 
<span class="changed"> 465 // Expand the virtual space (commit more of the reserved space)</span>
<span class="changed"> 466 bool VirtualSpaceNode::expand_by(size_t min_words, size_t preferred_words) {</span>
<span class="changed"> 467   size_t min_bytes = min_words * BytesPerWord;</span>
<span class="changed"> 468   size_t preferred_bytes = preferred_words * BytesPerWord;</span>
 469 
<span class="changed"> 470   size_t uncommitted = virtual_space()-&gt;reserved_size() - virtual_space()-&gt;actual_committed_size();</span>
 471 
<span class="changed"> 472   if (uncommitted &lt; min_bytes) {</span>
<span class="changed"> 473     return false;</span>
 474   }
 475 
<span class="changed"> 476   size_t commit = MIN2(preferred_bytes, uncommitted);</span>
<span class="changed"> 477   bool result = virtual_space()-&gt;expand_by(commit, false);</span>










































 478 
<span class="removed"> 479   if (result) {</span>
<span class="removed"> 480     log_trace(gc, metaspace, freelist)("Expanded %s virtual space list node by " SIZE_FORMAT " words.",</span>
<span class="removed"> 481         (is_class() ? "class" : "non-class"), commit);</span>
<span class="removed"> 482     DEBUG_ONLY(Atomic::inc(&amp;g_internal_statistics.num_committed_space_expanded));</span>
<span class="removed"> 483   } else {</span>
<span class="removed"> 484     log_trace(gc, metaspace, freelist)("Failed to expand %s virtual space list node by " SIZE_FORMAT " words.",</span>
<span class="removed"> 485         (is_class() ? "class" : "non-class"), commit);</span>
 486   }
 487 
<span class="changed"> 488   assert(result, "Failed to commit memory");</span>
 489 
<span class="removed"> 490   return result;</span>
 491 }
 492 
<span class="changed"> 493 Metachunk* VirtualSpaceNode::get_chunk_vs(size_t chunk_word_size) {</span>





 494   assert_lock_strong(MetaspaceExpand_lock);
<span class="changed"> 495   Metachunk* result = take_from_committed(chunk_word_size);</span>
<span class="changed"> 496   return result;</span>






 497 }
 498 
<span class="changed"> 499 bool VirtualSpaceNode::initialize() {</span>









 500 
<span class="changed"> 501   if (!_rs.is_reserved()) {</span>
<span class="changed"> 502     return false;</span>



































 503   }
 504 
<span class="changed"> 505   // These are necessary restriction to make sure that the virtual space always</span>
<span class="changed"> 506   // grows in steps of Metaspace::commit_alignment(). If both base and size are</span>
<span class="changed"> 507   // aligned only the middle alignment of the VirtualSpace is used.</span>
<span class="changed"> 508   assert_is_aligned(_rs.base(), Metaspace::commit_alignment());</span>
<span class="changed"> 509   assert_is_aligned(_rs.size(), Metaspace::commit_alignment());</span>
 510 
<span class="changed"> 511   // ReservedSpaces marked as special will have the entire memory</span>
<span class="changed"> 512   // pre-committed. Setting a committed size will make sure that</span>
<span class="changed"> 513   // committed_size and actual_committed_size agrees.</span>
<span class="changed"> 514   size_t pre_committed_size = _rs.special() ? _rs.size() : 0;</span>
 515 
<span class="changed"> 516   bool result = virtual_space()-&gt;initialize_with_granularity(_rs, pre_committed_size,</span>
<span class="changed"> 517       Metaspace::commit_alignment());</span>
<span class="changed"> 518   if (result) {</span>
<span class="changed"> 519     assert(virtual_space()-&gt;committed_size() == virtual_space()-&gt;actual_committed_size(),</span>
<span class="changed"> 520         "Checking that the pre-committed memory was registered by the VirtualSpace");</span>



 521 
<span class="changed"> 522     set_top((MetaWord*)virtual_space()-&gt;low());</span>





 523   }
 524 
<span class="changed"> 525   // Initialize Occupancy Map.</span>
<span class="changed"> 526   const size_t smallest_chunk_size = is_class() ? ClassSpecializedChunk : SpecializedChunk;</span>
<span class="changed"> 527   _occupancy_map = new OccupancyMap(bottom(), reserved_words(), smallest_chunk_size);</span>





















 528 
<span class="removed"> 529   return result;</span>
 530 }
 531 
<span class="removed"> 532 void VirtualSpaceNode::print_on(outputStream* st, size_t scale) const {</span>
<span class="removed"> 533   size_t used_words = used_words_in_vs();</span>
<span class="removed"> 534   size_t commit_words = committed_words();</span>
<span class="removed"> 535   size_t res_words = reserved_words();</span>
<span class="removed"> 536   VirtualSpace* vs = virtual_space();</span>
 537 
<span class="changed"> 538   st-&gt;print("node @" PTR_FORMAT ": ", p2i(this));</span>




 539   st-&gt;print("reserved=");
<span class="changed"> 540   print_scaled_words(st, res_words, scale);</span>
 541   st-&gt;print(", committed=");
<span class="changed"> 542   print_scaled_words_and_percentage(st, commit_words, res_words, scale);</span>
 543   st-&gt;print(", used=");
<span class="changed"> 544   print_scaled_words_and_percentage(st, used_words, res_words, scale);</span>

 545   st-&gt;cr();
<span class="changed"> 546   st-&gt;print("   [" PTR_FORMAT ", " PTR_FORMAT ", "</span>
<span class="changed"> 547       PTR_FORMAT ", " PTR_FORMAT ")",</span>
<span class="changed"> 548       p2i(bottom()), p2i(top()), p2i(end()),</span>
<span class="changed"> 549       p2i(vs-&gt;high_boundary()));</span>
 550 }
 551 
<span class="changed"> 552 #ifdef ASSERT</span>
<span class="changed"> 553 void VirtualSpaceNode::mangle() {</span>
<span class="changed"> 554   size_t word_size = capacity_words_in_vs();</span>
<span class="changed"> 555   Copy::fill_to_words((HeapWord*) low(), word_size, 0xf1f1f1f1);</span>
 556 }
<span class="removed"> 557 #endif // ASSERT</span>
 558 
<span class="removed"> 559 void VirtualSpaceNode::retire(ChunkManager* chunk_manager) {</span>
<span class="removed"> 560   assert(is_class() == chunk_manager-&gt;is_class(), "Wrong ChunkManager?");</span>
 561 #ifdef ASSERT
<span class="changed"> 562   verify(false);</span>
<span class="changed"> 563   EVERY_NTH(VerifyMetaspaceInterval)</span>
<span class="changed"> 564     verify(true);</span>
<span class="changed"> 565   END_EVERY_NTH</span>
<span class="changed"> 566 #endif</span>
<span class="changed"> 567   for (int i = (int)MediumIndex; i &gt;= (int)ZeroIndex; --i) {</span>
<span class="changed"> 568     ChunkIndex index = (ChunkIndex)i;</span>
<span class="changed"> 569     size_t chunk_size = chunk_manager-&gt;size_by_index(index);</span>
<span class="changed"> 570 </span>
<span class="changed"> 571     while (free_words_in_vs() &gt;= chunk_size) {</span>
<span class="changed"> 572       Metachunk* chunk = get_chunk_vs(chunk_size);</span>
<span class="changed"> 573       // Chunk will be allocated aligned, so allocation may require</span>
<span class="changed"> 574       // additional padding chunks. That may cause above allocation to</span>
<span class="changed"> 575       // fail. Just ignore the failed allocation and continue with the</span>
<span class="changed"> 576       // next smaller chunk size. As the VirtualSpaceNode comitted</span>
<span class="changed"> 577       // size should be a multiple of the smallest chunk size, we</span>
<span class="changed"> 578       // should always be able to fill the VirtualSpace completely.</span>
<span class="changed"> 579       if (chunk == NULL) {</span>
<span class="changed"> 580         break;</span>
<span class="changed"> 581       }</span>
<span class="changed"> 582       chunk_manager-&gt;return_single_chunk(chunk);</span>
<span class="changed"> 583     }</span>
<span class="changed"> 584   }</span>
<span class="changed"> 585   assert(free_words_in_vs() == 0, "should be empty now");</span>
 586 }


























 587 
 588 } // namespace metaspace
</pre></td><td><pre>
   1 /*
<span class="changed">   2  * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.</span>
<span class="changed">   3  * Copyright (c) 2018, 2020 SAP SE. All rights reserved.</span>
   4  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   5  *
   6  * This code is free software; you can redistribute it and/or modify it
   7  * under the terms of the GNU General Public License version 2 only, as
   8  * published by the Free Software Foundation.
   9  *
  10  * This code is distributed in the hope that it will be useful, but WITHOUT
  11  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  12  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  13  * version 2 for more details (a copy is included in the LICENSE file that
  14  * accompanied this code).
  15  *
  16  * You should have received a copy of the GNU General Public License version
  17  * 2 along with this work; if not, write to the Free Software Foundation,
  18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  19  *
  20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  21  * or visit www.oracle.com if you need additional information or have any
  22  * questions.
  23  *
  24  */
  25 
  26 #include "precompiled.hpp"
  27 
  28 #include "logging/log.hpp"
<span class="changed">  29 </span>
<span class="changed">  30 #include "memory/metaspace/chunkLevel.hpp"</span>
<span class="changed">  31 #include "memory/metaspace/chunkHeaderPool.hpp"</span>
<span class="changed">  32 #include "memory/metaspace/commitLimiter.hpp"</span>
<span class="changed">  33 #include "memory/metaspace/counter.hpp"</span>
<span class="changed">  34 #include "memory/metaspace/freeChunkList.hpp"</span>
<span class="changed">  35 #include "memory/metaspace/internStat.hpp"</span>
  36 #include "memory/metaspace/metachunk.hpp"



  37 #include "memory/metaspace/metaspaceCommon.hpp"
<span class="changed">  38 #include "memory/metaspace/rootChunkArea.hpp"</span>
<span class="changed">  39 #include "memory/metaspace/runningCounters.hpp"</span>
<span class="changed">  40 #include "memory/metaspace/settings.hpp"</span>
  41 #include "memory/metaspace/virtualSpaceNode.hpp"
<span class="changed">  42 #include "memory/metaspace.hpp"</span>
<span class="changed">  43 </span>
<span class="changed">  44 #include "runtime/globals.hpp"</span>
<span class="changed">  45 #include "runtime/mutexLocker.hpp"</span>
  46 #include "runtime/os.hpp"
<span class="changed">  47 </span>
<span class="changed">  48 #include "utilities/align.hpp"</span>
  49 #include "utilities/debug.hpp"
  50 #include "utilities/globalDefinitions.hpp"
<span class="new">  51 #include "utilities/ostream.hpp"</span>
  52 
  53 namespace metaspace {
  54 
<span class="changed">  55 #define LOGFMT         "VsListNode @" PTR_FORMAT " base " PTR_FORMAT " "</span>
<span class="changed">  56 #define LOGFMT_ARGS    p2i(this), p2i(_base)</span>








  57 
<span class="changed">  58 #ifdef ASSERT</span>
<span class="changed">  59 void check_pointer_is_aligned_to_commit_granule(const MetaWord* p) {</span>
<span class="changed">  60   assert(is_aligned(p, Settings::commit_granule_bytes()),</span>
<span class="changed">  61          "Pointer not aligned to commit granule size: " PTR_FORMAT ".",</span>
<span class="changed">  62          p2i(p));</span>
<span class="changed">  63 }</span>
<span class="changed">  64 void check_word_size_is_aligned_to_commit_granule(size_t word_size) {</span>
<span class="changed">  65   assert(is_aligned(word_size, Settings::commit_granule_words()),</span>
<span class="changed">  66          "Not aligned to commit granule size: " SIZE_FORMAT ".", word_size);</span>
  67 }
<span class="new">  68 #endif</span>
  69 
<span class="changed">  70 </span>
<span class="changed">  71 // Given an address range, ensure it is committed.</span>
<span class="changed">  72 //</span>
<span class="changed">  73 // The range has to be aligned to granule size.</span>
<span class="changed">  74 //</span>
<span class="changed">  75 // Function will:</span>
<span class="changed">  76 // - check how many granules in that region are uncommitted; If all are committed, it</span>
<span class="changed">  77 //    returns true immediately.</span>
<span class="changed">  78 // - check if committing those uncommitted granules would bring us over the commit limit</span>
<span class="changed">  79 //    (GC threshold, MaxMetaspaceSize). If true, it returns false.</span>
<span class="changed">  80 // - commit the memory.</span>
<span class="changed">  81 // - mark the range as committed in the commit mask</span>
<span class="changed">  82 //</span>
<span class="changed">  83 // Returns true if success, false if it did hit a commit limit.</span>
<span class="changed">  84 bool VirtualSpaceNode::commit_range(MetaWord* p, size_t word_size) {</span>
<span class="changed">  85 </span>
<span class="changed">  86   DEBUG_ONLY(check_pointer_is_aligned_to_commit_granule(p);)</span>
<span class="changed">  87   DEBUG_ONLY(check_word_size_is_aligned_to_commit_granule(word_size);)</span>
<span class="changed">  88   assert_lock_strong(MetaspaceExpand_lock);</span>
<span class="changed">  89 </span>
<span class="changed">  90   // First calculate how large the committed regions in this range are</span>
<span class="changed">  91   const size_t committed_words_in_range = _commit_mask.get_committed_size_in_range(p, word_size);</span>
<span class="changed">  92   DEBUG_ONLY(check_word_size_is_aligned_to_commit_granule(committed_words_in_range);)</span>
<span class="changed">  93 </span>
<span class="changed">  94   // By how much words we would increase commit charge</span>
<span class="changed">  95   //  were we to commit the given address range completely.</span>
<span class="changed">  96   const size_t commit_increase_words = word_size - committed_words_in_range;</span>
<span class="changed">  97 </span>
<span class="changed">  98   UL2(debug, "committing range " PTR_FORMAT ".." PTR_FORMAT "(" SIZE_FORMAT " words)",</span>
<span class="changed">  99       p2i(p), p2i(p + word_size), word_size);</span>
<span class="changed"> 100 </span>
<span class="changed"> 101   if (commit_increase_words == 0) {</span>
<span class="changed"> 102     UL(debug, "... already fully committed.");</span>
<span class="changed"> 103     return true; // Already fully committed, nothing to do.</span>



































 104   }
<span class="changed"> 105 </span>
<span class="changed"> 106   // Before committing any more memory, check limits.</span>
<span class="changed"> 107   if (_commit_limiter-&gt;possible_expansion_words() &lt; commit_increase_words) {</span>
<span class="changed"> 108     UL(debug, "... cannot commit (limit).");</span>
<span class="changed"> 109     return false;</span>

































 110   }
<span class="new"> 111 </span>
<span class="new"> 112   // Commit...</span>
<span class="new"> 113   if (os::commit_memory((char*)p, word_size * BytesPerWord, false) == false) {</span>
<span class="new"> 114     vm_exit_out_of_memory(word_size * BytesPerWord, OOM_MMAP_ERROR, "Failed to commit metaspace.");</span>
 115   }
<span class="changed"> 116 </span>
<span class="changed"> 117   if (AlwaysPreTouch) {</span>
<span class="changed"> 118     os::pretouch_memory(p, p + word_size);</span>
 119   }

 120 
<span class="new"> 121   UL2(debug, "... committed " SIZE_FORMAT " additional words.", commit_increase_words);</span>
 122 
<span class="changed"> 123   // ... tell commit limiter...</span>
<span class="changed"> 124   _commit_limiter-&gt;increase_committed(commit_increase_words);</span>
 125 
<span class="changed"> 126   // ... update counters in containing vslist ...</span>
<span class="changed"> 127   _total_committed_words_counter-&gt;increment_by(commit_increase_words);</span>



















































































 128 
<span class="changed"> 129   // ... and update the commit mask.</span>
<span class="changed"> 130   _commit_mask.mark_range_as_committed(p, word_size);</span>
<span class="changed"> 131 </span>
<span class="changed"> 132 #ifdef ASSERT</span>
<span class="changed"> 133   // The commit boundary maintained in the CommitLimiter should be equal the sum of committed words</span>
<span class="changed"> 134   // in both class and non-class vslist (outside gtests).</span>
<span class="changed"> 135   if (_commit_limiter == CommitLimiter::globalLimiter()) {</span>
<span class="changed"> 136     assert(_commit_limiter-&gt;committed_words() == RunningCounters::committed_words(), "counter mismatch");</span>
 137   }
<span class="new"> 138 #endif</span>
<span class="new"> 139 </span>
<span class="new"> 140   InternalStats::inc_num_space_committed();</span>
<span class="new"> 141 </span>
<span class="new"> 142   return true;</span>
<span class="new"> 143 </span>
 144 }

 145 
<span class="changed"> 146 // Given an address range, ensure it is committed.</span>
<span class="changed"> 147 //</span>
<span class="changed"> 148 // The range does not have to be aligned to granule size. However, the function will always commit</span>
<span class="changed"> 149 // whole granules.</span>
<span class="changed"> 150 //</span>
<span class="changed"> 151 // Function will:</span>
<span class="changed"> 152 // - check how many granules in that region are uncommitted; If all are committed, it</span>
<span class="changed"> 153 //    returns true immediately.</span>
<span class="changed"> 154 // - check if committing those uncommitted granules would bring us over the commit limit</span>
<span class="changed"> 155 //    (GC threshold, MaxMetaspaceSize). If true, it returns false.</span>
<span class="changed"> 156 // - commit the memory.</span>
<span class="changed"> 157 // - mark the range as committed in the commit mask</span>
<span class="changed"> 158 //</span>
<span class="changed"> 159 // !! Careful:</span>
<span class="changed"> 160 //    calling ensure_range_is_committed on a range which contains both committed and uncommitted</span>
<span class="changed"> 161 //    areas will commit the whole area, thus erase the content in the existing committed parts.</span>
<span class="changed"> 162 //    Make sure you never call this on an address range containing live data. !!</span>
<span class="changed"> 163 //</span>
<span class="changed"> 164 // Returns true if success, false if it did hit a commit limit.</span>
<span class="changed"> 165 bool VirtualSpaceNode::ensure_range_is_committed(MetaWord* p, size_t word_size) {</span>
<span class="changed"> 166 </span>
 167   assert_lock_strong(MetaspaceExpand_lock);
<span class="changed"> 168   assert(p != NULL &amp;&amp; word_size &gt; 0, "Sanity");</span>
<span class="changed"> 169 </span>
<span class="changed"> 170   MetaWord* p_start = align_down(p, Settings::commit_granule_bytes());</span>
<span class="changed"> 171   MetaWord* p_end = align_up(p + word_size, Settings::commit_granule_bytes());</span>
<span class="changed"> 172 </span>
<span class="changed"> 173   // Todo: simple for now. Make it more intelligent late</span>
<span class="changed"> 174   return commit_range(p_start, p_end - p_start);</span>
<span class="changed"> 175 </span>
 176 }
 177 
<span class="changed"> 178 // Given an address range (which has to be aligned to commit granule size):</span>
<span class="changed"> 179 //  - uncommit it</span>
<span class="changed"> 180 //  - mark it as uncommitted in the commit mask</span>
<span class="changed"> 181 void VirtualSpaceNode::uncommit_range(MetaWord* p, size_t word_size) {</span>
<span class="changed"> 182 </span>
<span class="changed"> 183   DEBUG_ONLY(check_pointer_is_aligned_to_commit_granule(p);)</span>
<span class="changed"> 184   DEBUG_ONLY(check_word_size_is_aligned_to_commit_granule(word_size);)</span>
 185   assert_lock_strong(MetaspaceExpand_lock);


 186 
<span class="changed"> 187   // First calculate how large the committed regions in this range are</span>
<span class="changed"> 188   const size_t committed_words_in_range = _commit_mask.get_committed_size_in_range(p, word_size);</span>
<span class="changed"> 189   DEBUG_ONLY(check_word_size_is_aligned_to_commit_granule(committed_words_in_range);)</span>
<span class="changed"> 190 </span>
<span class="changed"> 191   UL2(debug, "uncommitting range " PTR_FORMAT ".." PTR_FORMAT "(" SIZE_FORMAT " words)",</span>
<span class="changed"> 192       p2i(p), p2i(p + word_size), word_size);</span>
<span class="changed"> 193 </span>
<span class="changed"> 194   if (committed_words_in_range == 0) {</span>
<span class="changed"> 195     UL(debug, "... already fully uncommitted.");</span>
<span class="changed"> 196     return; // Already fully uncommitted, nothing to do.</span>
 197   }
<span class="new"> 198 </span>
<span class="new"> 199   // Uncommit...</span>
<span class="new"> 200   if (os::uncommit_memory((char*)p, word_size * BytesPerWord) == false) {</span>
<span class="new"> 201     // Note: this can actually happen, since uncommit may increase the number of mappings.</span>
<span class="new"> 202     fatal("Failed to uncommit metaspace.");</span>
<span class="new"> 203   }</span>
<span class="new"> 204 </span>
<span class="new"> 205   UL2(debug, "... uncommitted " SIZE_FORMAT " words.", committed_words_in_range);</span>
<span class="new"> 206 </span>
<span class="new"> 207   // ... tell commit limiter...</span>
<span class="new"> 208   _commit_limiter-&gt;decrease_committed(committed_words_in_range);</span>
<span class="new"> 209 </span>
<span class="new"> 210   // ... and global counters...</span>
<span class="new"> 211   _total_committed_words_counter-&gt;decrement_by(committed_words_in_range);</span>
<span class="new"> 212 </span>
<span class="new"> 213    // ... and update the commit mask.</span>
<span class="new"> 214   _commit_mask.mark_range_as_uncommitted(p, word_size);</span>
<span class="new"> 215 </span>
 216 #ifdef ASSERT
<span class="changed"> 217   // The commit boundary maintained in the CommitLimiter should be equal the sum of committed words</span>
<span class="changed"> 218   // in both class and non-class vslist (outside gtests).</span>
<span class="changed"> 219   if (_commit_limiter == CommitLimiter::globalLimiter()) { // We are outside a test scenario</span>
<span class="changed"> 220     assert(_commit_limiter-&gt;committed_words() == RunningCounters::committed_words(), "counter mismatch");</span>
<span class="changed"> 221   }</span>
 222 #endif
<span class="new"> 223 </span>
<span class="new"> 224   InternalStats::inc_num_space_uncommitted();</span>
<span class="new"> 225 </span>
 226 }
 227 
<span class="changed"> 228 //// creation, destruction ////</span>
<span class="changed"> 229 </span>
<span class="changed"> 230 VirtualSpaceNode::VirtualSpaceNode(ReservedSpace rs, bool owns_rs, CommitLimiter* limiter,</span>
<span class="changed"> 231                                    SizeCounter* reserve_counter, SizeCounter* commit_counter)</span>
<span class="changed"> 232   : _next(NULL),</span>
<span class="changed"> 233     _rs(rs),</span>
<span class="changed"> 234     _owns_rs(owns_rs),</span>
<span class="changed"> 235     _base((MetaWord*)rs.base()),</span>
<span class="changed"> 236     _word_size(rs.size() / BytesPerWord),</span>
<span class="changed"> 237     _used_words(0),</span>
<span class="changed"> 238     _commit_mask((MetaWord*)rs.base(), rs.size() / BytesPerWord),</span>
<span class="changed"> 239     _root_chunk_area_lut((MetaWord*)rs.base(), rs.size() / BytesPerWord),</span>
<span class="changed"> 240     _commit_limiter(limiter),</span>
<span class="changed"> 241     _total_reserved_words_counter(reserve_counter),</span>
<span class="changed"> 242     _total_committed_words_counter(commit_counter)</span>
<span class="changed"> 243 {</span>
<span class="changed"> 244   UL2(debug, "born (word_size " SIZE_FORMAT ").", _word_size);</span>
<span class="changed"> 245 </span>
<span class="changed"> 246   // Update reserved counter in vslist</span>
<span class="changed"> 247   _total_reserved_words_counter-&gt;increment_by(_word_size);</span>
<span class="changed"> 248 </span>
<span class="changed"> 249   assert_is_aligned(_base, chunklevel::MAX_CHUNK_BYTE_SIZE);</span>
<span class="changed"> 250   assert_is_aligned(_word_size, chunklevel::MAX_CHUNK_WORD_SIZE);</span>
<span class="changed"> 251 </span>
 252 }
 253 

























































































































































 254 
<span class="changed"> 255 // Create a node of a given size (it will create its own space).</span>
<span class="changed"> 256 VirtualSpaceNode* VirtualSpaceNode::create_node(size_t word_size,</span>
<span class="changed"> 257                                                 CommitLimiter* limiter, SizeCounter* reserve_words_counter,</span>
<span class="changed"> 258                                                 SizeCounter* commit_words_counter)</span>
<span class="changed"> 259 {</span>
 260 
<span class="changed"> 261   DEBUG_ONLY(assert_is_aligned(word_size, chunklevel::MAX_CHUNK_WORD_SIZE);)</span>






 262 
<span class="changed"> 263   ReservedSpace rs(word_size * BytesPerWord,</span>
<span class="changed"> 264                    Settings::virtual_space_node_reserve_alignment_words() * BytesPerWord,</span>
<span class="changed"> 265                    false // large</span>
<span class="changed"> 266                    );</span>
<span class="changed"> 267 </span>
<span class="changed"> 268   if (!rs.is_reserved()) {</span>
<span class="changed"> 269     vm_exit_out_of_memory(word_size * BytesPerWord, OOM_MMAP_ERROR, "Failed to reserve memory for metaspace");</span>
<span class="changed"> 270   }</span>
<span class="changed"> 271 </span>
<span class="changed"> 272   assert_is_aligned(rs.base(), chunklevel::MAX_CHUNK_BYTE_SIZE);</span>
<span class="changed"> 273 </span>
<span class="changed"> 274   InternalStats::inc_num_vsnodes_births();</span>
<span class="changed"> 275   return new VirtualSpaceNode(rs, true, limiter, reserve_words_counter, commit_words_counter);</span>
 276 

 277 }
 278 
<span class="new"> 279 // Create a node over an existing space</span>
<span class="new"> 280 VirtualSpaceNode* VirtualSpaceNode::create_node(ReservedSpace rs, CommitLimiter* limiter,</span>
<span class="new"> 281                                                 SizeCounter* reserve_words_counter, SizeCounter* commit_words_counter)</span>
<span class="new"> 282 {</span>
<span class="new"> 283   InternalStats::inc_num_vsnodes_births();</span>
<span class="new"> 284   return new VirtualSpaceNode(rs, false, limiter, reserve_words_counter, commit_words_counter);</span>
<span class="new"> 285 }</span>
<span class="new"> 286 </span>
<span class="new"> 287 VirtualSpaceNode::~VirtualSpaceNode() {</span>
 288 
<span class="changed"> 289   DEBUG_ONLY(verify_locked(true);)</span>



 290 
<span class="changed"> 291   UL(debug, ": dies.");</span>
 292 
<span class="changed"> 293   if (_owns_rs) {</span>
<span class="changed"> 294     _rs.release();</span>
 295   }
 296 
<span class="changed"> 297   // Update counters in vslist</span>
<span class="changed"> 298   size_t committed = committed_words();</span>
<span class="changed"> 299   _total_committed_words_counter-&gt;decrement_by(committed);</span>
<span class="changed"> 300   _total_reserved_words_counter-&gt;decrement_by(_word_size);</span>
<span class="changed"> 301 </span>
<span class="changed"> 302   // ... and tell commit limiter</span>
<span class="changed"> 303   _commit_limiter-&gt;decrease_committed(committed);</span>
<span class="changed"> 304 </span>
<span class="changed"> 305   InternalStats::inc_num_vsnodes_deaths();</span>
<span class="changed"> 306 </span>
<span class="changed"> 307 }</span>
<span class="changed"> 308 </span>
<span class="changed"> 309 //// Chunk allocation, splitting, merging /////</span>
<span class="changed"> 310 </span>
<span class="changed"> 311 // Allocate a root chunk from this node. Will fail and return NULL if the node is full</span>
<span class="changed"> 312 //  - if we used up the whole address space of this node's memory region.</span>
<span class="changed"> 313 //    (in case this node backs compressed class space, this is how we hit</span>
<span class="changed"> 314 //     CompressedClassSpaceSize).</span>
<span class="changed"> 315 // Note that this just returns reserved memory; caller must take care of committing this</span>
<span class="changed"> 316 //  chunk before using it.</span>
<span class="changed"> 317 Metachunk* VirtualSpaceNode::allocate_root_chunk() {</span>
<span class="changed"> 318 </span>
<span class="changed"> 319   assert_lock_strong(MetaspaceExpand_lock);</span>
<span class="changed"> 320 </span>
<span class="changed"> 321   assert_is_aligned(free_words(), chunklevel::MAX_CHUNK_WORD_SIZE);</span>
<span class="changed"> 322 </span>
<span class="changed"> 323   if (free_words() &gt;= chunklevel::MAX_CHUNK_WORD_SIZE) {</span>
<span class="changed"> 324 </span>
<span class="changed"> 325     MetaWord* loc = _base + _used_words;</span>
<span class="changed"> 326     _used_words += chunklevel::MAX_CHUNK_WORD_SIZE;</span>
<span class="changed"> 327 </span>
<span class="changed"> 328     RootChunkArea* rca = _root_chunk_area_lut.get_area_by_address(loc);</span>
<span class="changed"> 329 </span>
<span class="changed"> 330     // Create a root chunk header and initialize it;</span>
<span class="changed"> 331     Metachunk* c = rca-&gt;alloc_root_chunk_header(this);</span>
<span class="changed"> 332 </span>
<span class="changed"> 333     assert(c-&gt;base() == loc &amp;&amp; c-&gt;vsnode() == this &amp;&amp;</span>
<span class="changed"> 334            c-&gt;is_free(), "Sanity");</span>
<span class="changed"> 335 </span>
<span class="changed"> 336     DEBUG_ONLY(c-&gt;verify(true);)</span>
<span class="changed"> 337 </span>
<span class="changed"> 338     UL2(debug, "new root chunk " METACHUNK_FORMAT ".", METACHUNK_FORMAT_ARGS(c));</span>
<span class="changed"> 339 </span>
<span class="changed"> 340     return c;</span>
 341 







 342   }
 343 
<span class="changed"> 344   return NULL; // Node is full.</span>
 345 

 346 }
 347 
<span class="changed"> 348 // Given a chunk c, split it recursively until you get a chunk of the given target_level.</span>
<span class="changed"> 349 //</span>
<span class="changed"> 350 // The resulting target chunk resides at the same address as the original chunk.</span>
<span class="changed"> 351 // The resulting splinters are added to freelists.</span>
<span class="changed"> 352 void VirtualSpaceNode::split(chunklevel_t target_level, Metachunk* c, FreeChunkListVector* freelists) {</span>
<span class="changed"> 353 </span>
 354   assert_lock_strong(MetaspaceExpand_lock);
<span class="changed"> 355 </span>
<span class="changed"> 356   // Get the area associated with this chunk and let it handle the splitting</span>
<span class="changed"> 357   RootChunkArea* rca = _root_chunk_area_lut.get_area_by_address(c-&gt;base());</span>
<span class="changed"> 358 </span>
<span class="changed"> 359   DEBUG_ONLY(rca-&gt;verify_area_is_ideally_merged();)</span>
<span class="changed"> 360 </span>
<span class="changed"> 361   rca-&gt;split(target_level, c, freelists);</span>
<span class="changed"> 362 </span>
 363 }
 364 
<span class="changed"> 365 // Given a chunk, attempt to merge it recursively with its neighboring chunks.</span>
<span class="changed"> 366 //</span>
<span class="changed"> 367 // If successful (merged at least once), returns address of</span>
<span class="changed"> 368 // the merged chunk; NULL otherwise.</span>
<span class="changed"> 369 //</span>
<span class="changed"> 370 // The merged chunks are removed from the freelists.</span>
<span class="changed"> 371 //</span>
<span class="changed"> 372 // !!! Please note that if this method returns a non-NULL value, the</span>
<span class="changed"> 373 // original chunk will be invalid and should not be accessed anymore! !!!</span>
<span class="changed"> 374 Metachunk* VirtualSpaceNode::merge(Metachunk* c, FreeChunkListVector* freelists) {</span>
 375 
<span class="changed"> 376   assert(c != NULL &amp;&amp; c-&gt;is_free(), "Sanity");</span>
<span class="changed"> 377   assert_lock_strong(MetaspaceExpand_lock);</span>
<span class="changed"> 378 </span>
<span class="changed"> 379   // Get the rca associated with this chunk and let it handle the merging</span>
<span class="changed"> 380   RootChunkArea* rca = _root_chunk_area_lut.get_area_by_address(c-&gt;base());</span>
<span class="changed"> 381 </span>
<span class="changed"> 382   Metachunk* c2 = rca-&gt;merge(c, freelists);</span>
<span class="changed"> 383 </span>
<span class="changed"> 384   DEBUG_ONLY(rca-&gt;verify_area_is_ideally_merged();)</span>
<span class="changed"> 385 </span>
<span class="changed"> 386   return c2;</span>
<span class="changed"> 387 </span>
<span class="changed"> 388 }</span>
<span class="changed"> 389 </span>
<span class="changed"> 390 // Given a chunk c, which must be "in use" and must not be a root chunk, attempt to</span>
<span class="changed"> 391 // enlarge it in place by claiming its trailing buddy.</span>
<span class="changed"> 392 //</span>
<span class="changed"> 393 // This will only work if c is the leader of the buddy pair and the trailing buddy is free.</span>
<span class="changed"> 394 //</span>
<span class="changed"> 395 // If successful, the follower chunk will be removed from the freelists, the leader chunk c will</span>
<span class="changed"> 396 // double in size (level decreased by one).</span>
<span class="changed"> 397 //</span>
<span class="changed"> 398 // On success, true is returned, false otherwise.</span>
<span class="changed"> 399 bool VirtualSpaceNode::attempt_enlarge_chunk(Metachunk* c, FreeChunkListVector* freelists) {</span>
<span class="changed"> 400 </span>
<span class="changed"> 401   assert(c != NULL &amp;&amp; c-&gt;is_in_use() &amp;&amp; !c-&gt;is_root_chunk(), "Sanity");</span>
<span class="changed"> 402   assert_lock_strong(MetaspaceExpand_lock);</span>
<span class="changed"> 403 </span>
<span class="changed"> 404   // Get the rca associated with this chunk and let it handle the merging</span>
<span class="changed"> 405   RootChunkArea* rca = _root_chunk_area_lut.get_area_by_address(c-&gt;base());</span>
<span class="changed"> 406 </span>
<span class="changed"> 407   bool rc = rca-&gt;attempt_enlarge_chunk(c, freelists);</span>
<span class="changed"> 408 </span>
<span class="changed"> 409   DEBUG_ONLY(rca-&gt;verify_area_is_ideally_merged();)</span>
<span class="changed"> 410 </span>
<span class="changed"> 411   if (rc) {</span>
<span class="changed"> 412     InternalStats::inc_num_chunks_enlarged();</span>
 413   }
 414 
<span class="changed"> 415   return rc;</span>




 416 
<span class="changed"> 417 }</span>



 418 
<span class="changed"> 419 // Attempts to purge the node:</span>
<span class="changed"> 420 //</span>
<span class="changed"> 421 // If all chunks living in this node are free, they will all be removed from</span>
<span class="changed"> 422 //  the freelist they currently reside in. Then, the node will be deleted.</span>
<span class="changed"> 423 //</span>
<span class="changed"> 424 // Returns true if the node has been deleted, false if not.</span>
<span class="changed"> 425 // !! If this returns true, do not access the node from this point on. !!</span>
<span class="changed"> 426 bool VirtualSpaceNode::attempt_purge(FreeChunkListVector* freelists) {</span>
 427 
<span class="changed"> 428   assert_lock_strong(MetaspaceExpand_lock);</span>
<span class="changed"> 429 </span>
<span class="changed"> 430   if (!_owns_rs) {</span>
<span class="changed"> 431     // We do not allow purging of nodes if we do not own the</span>
<span class="changed"> 432     // underlying ReservedSpace (CompressClassSpace case).</span>
<span class="changed"> 433     return false;</span>
 434   }
 435 
<span class="changed"> 436   // First find out if all areas are empty. Since empty chunks collapse to root chunk</span>
<span class="changed"> 437   // size, if all chunks in this node are free root chunks we are good to go.</span>
<span class="changed"> 438   if (!_root_chunk_area_lut.is_free()) {</span>
<span class="changed"> 439     return false;</span>
<span class="changed"> 440   }</span>
<span class="changed"> 441 </span>
<span class="changed"> 442   UL(debug, ": purging.");</span>
<span class="changed"> 443 </span>
<span class="changed"> 444   // Okay, we can purge. Before we can do this, we need to remove all chunks from the freelist.</span>
<span class="changed"> 445   for (int narea = 0; narea &lt; _root_chunk_area_lut.number_of_areas(); narea ++) {</span>
<span class="changed"> 446     RootChunkArea* ra = _root_chunk_area_lut.get_area_by_index(narea);</span>
<span class="changed"> 447     Metachunk* c = ra-&gt;first_chunk();</span>
<span class="changed"> 448     if (c != NULL) {</span>
<span class="changed"> 449       UL2(trace, "removing chunk from to-be-purged node: "</span>
<span class="changed"> 450           METACHUNK_FULL_FORMAT ".", METACHUNK_FULL_FORMAT_ARGS(c));</span>
<span class="changed"> 451       assert(c-&gt;is_free() &amp;&amp; c-&gt;is_root_chunk(), "Sanity");</span>
<span class="changed"> 452       freelists-&gt;remove(c);</span>
<span class="changed"> 453     }</span>
<span class="changed"> 454   }</span>
<span class="changed"> 455 </span>
<span class="changed"> 456   // Now, delete the node, then right away return since this object is invalid.</span>
<span class="changed"> 457   delete this;</span>
<span class="changed"> 458 </span>
<span class="changed"> 459   return true;</span>
 460 

 461 }
 462 





 463 
<span class="changed"> 464 void VirtualSpaceNode::print_on(outputStream* st) const {</span>
<span class="changed"> 465 </span>
<span class="changed"> 466   size_t scale = K;</span>
<span class="changed"> 467 </span>
<span class="changed"> 468   st-&gt;print("base " PTR_FORMAT ": ", p2i(base()));</span>
 469   st-&gt;print("reserved=");
<span class="changed"> 470   print_scaled_words(st, word_size(), scale);</span>
 471   st-&gt;print(", committed=");
<span class="changed"> 472   print_scaled_words_and_percentage(st, committed_words(), word_size(), scale);</span>
 473   st-&gt;print(", used=");
<span class="changed"> 474   print_scaled_words_and_percentage(st, used_words(), word_size(), scale);</span>
<span class="changed"> 475 </span>
 476   st-&gt;cr();
<span class="changed"> 477   _root_chunk_area_lut.print_on(st);</span>
<span class="changed"> 478   _commit_mask.print_on(st);</span>
<span class="changed"> 479 </span>

 480 }
 481 
<span class="changed"> 482 // Returns size, in words, of committed space in this node alone.</span>
<span class="changed"> 483 // Note: iterates over commit mask and hence may be a tad expensive on large nodes.</span>
<span class="changed"> 484 size_t VirtualSpaceNode::committed_words() const {</span>
<span class="changed"> 485   return _commit_mask.get_committed_size();</span>
 486 }

 487 


 488 #ifdef ASSERT
<span class="changed"> 489 void VirtualSpaceNode::verify(bool slow) const {</span>
<span class="changed"> 490   MutexLocker fcl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);</span>
<span class="changed"> 491   verify_locked(slow);</span>





















 492 }
<span class="new"> 493 </span>
<span class="new"> 494 // Verify counters and basic structure. Slow mode: verify all chunks in depth</span>
<span class="new"> 495 void VirtualSpaceNode::verify_locked(bool slow) const {</span>
<span class="new"> 496 </span>
<span class="new"> 497   assert_lock_strong(MetaspaceExpand_lock);</span>
<span class="new"> 498 </span>
<span class="new"> 499   assert(base() != NULL, "Invalid base");</span>
<span class="new"> 500   assert(base() == (MetaWord*)_rs.base() &amp;&amp;</span>
<span class="new"> 501          word_size() == _rs.size() / BytesPerWord,</span>
<span class="new"> 502          "Sanity");</span>
<span class="new"> 503   assert_is_aligned(base(), chunklevel::MAX_CHUNK_BYTE_SIZE);</span>
<span class="new"> 504   assert(used_words() &lt;= word_size(), "Sanity");</span>
<span class="new"> 505 </span>
<span class="new"> 506   // Since we only ever hand out root chunks from a vsnode, top should always be aligned</span>
<span class="new"> 507   // to root chunk size.</span>
<span class="new"> 508   assert_is_aligned(used_words(), chunklevel::MAX_CHUNK_WORD_SIZE);</span>
<span class="new"> 509 </span>
<span class="new"> 510   _commit_mask.verify(slow);</span>
<span class="new"> 511   assert(committed_words() &lt;= word_size(), "Sanity");</span>
<span class="new"> 512   assert_is_aligned(committed_words(), Settings::commit_granule_words());</span>
<span class="new"> 513   _root_chunk_area_lut.verify(slow);</span>
<span class="new"> 514 </span>
<span class="new"> 515 }</span>
<span class="new"> 516 </span>
<span class="new"> 517 #endif</span>
<span class="new"> 518 </span>
 519 
 520 } // namespace metaspace
</pre></td>
</tr></table>
<center><a href='../../../../../src/hotspot/share/memory/metaspace/virtualSpaceList.hpp.sdiff.html' target='_top'>&lt prev</a> <a href='../../../../../index.html' target='_top'>index</a> <a href='../../../../../src/hotspot/share/memory/metaspace/virtualSpaceNode.hpp.sdiff.html' target='_top'>next &gt</a></center>
</body></html>
