<?xml version="1.0"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head><meta charset="utf-8">
<meta http-equiv="cache-control" content="no-cache" />
<meta http-equiv="Pragma" content="no-cache" />
<meta http-equiv="Expires" content="-1" />
<!--
   Note to customizers: the body of the webrev is IDed as SUNWwebrev
   to allow easy overriding by users of webrev via the userContent.css
   mechanism available in some browsers.

   For example, to have all "removed" information be red instead of
   brown, set a rule in your userContent.css file like:

       body#SUNWwebrev span.removed { color: red ! important; }
-->
<style type="text/css" media="screen">
body {
    background-color: #eeeeee;
}
hr {
    border: none 0;
    border-top: 1px solid #aaa;
    height: 1px;
}
div.summary {
    font-size: .8em;
    border-bottom: 1px solid #aaa;
    padding-left: 1em;
    padding-right: 1em;
}
div.summary h2 {
    margin-bottom: 0.3em;
}
div.summary table th {
    text-align: right;
    vertical-align: top;
    white-space: nowrap;
}
span.lineschanged {
    font-size: 0.7em;
}
span.oldmarker {
    color: red;
    font-size: large;
    font-weight: bold;
}
span.newmarker {
    color: green;
    font-size: large;
    font-weight: bold;
}
span.removed {
    color: brown;
}
span.changed {
    color: blue;
}
span.new {
    color: blue;
    font-weight: bold;
}
a.print { font-size: x-small; }

</style>

<style type="text/css" media="print">
pre { font-size: 0.8em; font-family: courier, monospace; }
span.removed { color: #444; font-style: italic }
span.changed { font-weight: bold; }
span.new { font-weight: bold; }
span.newmarker { font-size: 1.2em; font-weight: bold; }
span.oldmarker { font-size: 1.2em; font-weight: bold; }
a.print {display: none}
hr { border: none 0; border-top: 1px solid #aaa; height: 1px; }
</style>

<title>New src/hotspot/share/memory/metaspace/virtualSpaceNode.cpp</title>
<body id="SUNWwebrev">
<pre>
   1 /*
   2  * Copyright (c) 2018, 2019, Oracle and/or its affiliates. All rights reserved.
   3  * Copyright (c) 2018, 2019 SAP SE. All rights reserved.
   4  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   5  *
   6  * This code is free software; you can redistribute it and/or modify it
   7  * under the terms of the GNU General Public License version 2 only, as
   8  * published by the Free Software Foundation.
   9  *
  10  * This code is distributed in the hope that it will be useful, but WITHOUT
  11  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  12  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  13  * version 2 for more details (a copy is included in the LICENSE file that
  14  * accompanied this code).
  15  *
  16  * You should have received a copy of the GNU General Public License version
  17  * 2 along with this work; if not, write to the Free Software Foundation,
  18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  19  *
  20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  21  * or visit www.oracle.com if you need additional information or have any
  22  * questions.
  23  *
  24  */
  25 
  26 
  27 
  28 #include "precompiled.hpp"
  29 
  30 #include "logging/log.hpp"
  31 
  32 #include "memory/metaspace/chunkLevel.hpp"
  33 #include "memory/metaspace/chunkHeaderPool.hpp"
  34 #include "memory/metaspace/commitLimiter.hpp"
  35 #include "memory/metaspace/counter.hpp"
  36 #include "memory/metaspace/freeChunkList.hpp"
  37 #include "memory/metaspace/internStat.hpp"
  38 #include "memory/metaspace/metachunk.hpp"
  39 #include "memory/metaspace/metaspaceCommon.hpp"
  40 #include "memory/metaspace/rootChunkArea.hpp"
  41 #include "memory/metaspace/runningCounters.hpp"
  42 #include "memory/metaspace/settings.hpp"
  43 #include "memory/metaspace/virtualSpaceNode.hpp"
  44 #include "memory/metaspace.hpp"
  45 
  46 #include "runtime/globals.hpp"
  47 #include "runtime/mutexLocker.hpp"
  48 #include "runtime/os.hpp"
  49 
  50 #include "utilities/align.hpp"
  51 #include "utilities/debug.hpp"
  52 #include "utilities/globalDefinitions.hpp"
  53 #include "utilities/ostream.hpp"
  54 
  55 namespace metaspace {
  56 
  57 #define LOGFMT         "VsListNode @" PTR_FORMAT " base " PTR_FORMAT " "
  58 #define LOGFMT_ARGS    p2i(this), p2i(_base)
  59 
  60 #ifdef ASSERT
  61 void check_pointer_is_aligned_to_commit_granule(const MetaWord* p) {
  62   assert(is_aligned(p, Settings::commit_granule_bytes()),
  63          "Pointer not aligned to commit granule size: " PTR_FORMAT ".",
  64          p2i(p));
  65 }
  66 void check_word_size_is_aligned_to_commit_granule(size_t word_size) {
  67   assert(is_aligned(word_size, Settings::commit_granule_words()),
  68          "Not aligned to commit granule size: " SIZE_FORMAT ".", word_size);
  69 }
  70 #endif
  71 
  72 
  73 // Given an address range, ensure it is committed.
  74 //
  75 // The range has to be aligned to granule size.
  76 //
  77 // Function will:
  78 // - check how many granules in that region are uncommitted; If all are committed, it
  79 //    returns true immediately.
  80 // - check if committing those uncommitted granules would bring us over the commit limit
  81 //    (GC threshold, MaxMetaspaceSize). If true, it returns false.
  82 // - commit the memory.
  83 // - mark the range as committed in the commit mask
  84 //
  85 // Returns true if success, false if it did hit a commit limit.
  86 bool VirtualSpaceNode::commit_range(MetaWord* p, size_t word_size) {
  87 
  88   DEBUG_ONLY(check_pointer_is_aligned_to_commit_granule(p);)
  89   DEBUG_ONLY(check_word_size_is_aligned_to_commit_granule(word_size);)
  90   assert_lock_strong(MetaspaceExpand_lock);
  91 
  92   // First calculate how large the committed regions in this range are
  93   const size_t committed_words_in_range = _commit_mask.get_committed_size_in_range(p, word_size);
  94   DEBUG_ONLY(check_word_size_is_aligned_to_commit_granule(committed_words_in_range);)
  95 
  96   // By how much words we would increase commit charge
  97   //  were we to commit the given address range completely.
  98   const size_t commit_increase_words = word_size - committed_words_in_range;
  99 
 100   UL2(debug, "committing range " PTR_FORMAT ".." PTR_FORMAT "(" SIZE_FORMAT " words)",
 101       p2i(p), p2i(p + word_size), word_size);
 102 
 103   if (commit_increase_words == 0) {
 104     UL(debug, "... already fully committed.");
 105     return true; // Already fully committed, nothing to do.
 106   }
 107 
 108   // Before committing any more memory, check limits.
 109   if (_commit_limiter-&gt;possible_expansion_words() &lt; commit_increase_words) {
 110     UL(debug, "... cannot commit (limit).");
 111     return false;
 112   }
 113 
 114   // Commit...
 115   if (os::commit_memory((char*)p, word_size * BytesPerWord, false) == false) {
 116     vm_exit_out_of_memory(word_size * BytesPerWord, OOM_MMAP_ERROR, "Failed to commit metaspace.");
 117   }
 118 
 119   if (AlwaysPreTouch) {
 120     os::pretouch_memory(p, p + word_size);
 121   }
 122 
 123   UL2(debug, "... committed " SIZE_FORMAT " additional words.", commit_increase_words);
 124 
 125   // ... tell commit limiter...
 126   _commit_limiter-&gt;increase_committed(commit_increase_words);
 127 
 128   // ... update counters in containing vslist ...
 129   _total_committed_words_counter-&gt;increment_by(commit_increase_words);
 130 
 131   // ... and update the commit mask.
 132   _commit_mask.mark_range_as_committed(p, word_size);
 133 
 134 #ifdef ASSERT
 135   // The commit boundary maintained in the CommitLimiter should be equal the sum of committed words
 136   // in both class and non-class vslist (outside gtests).
 137   if (_commit_limiter == CommitLimiter::globalLimiter()) {
 138     assert(_commit_limiter-&gt;committed_words() == RunningCounters::committed_words(), "counter mismatch");
 139   }
 140 #endif
 141 
 142   DEBUG_ONLY(InternalStats::inc_num_space_committed();)
 143 
 144   return true;
 145 
 146 }
 147 
 148 // Given an address range, ensure it is committed.
 149 //
 150 // The range does not have to be aligned to granule size. However, the function will always commit
 151 // whole granules.
 152 //
 153 // Function will:
 154 // - check how many granules in that region are uncommitted; If all are committed, it
 155 //    returns true immediately.
 156 // - check if committing those uncommitted granules would bring us over the commit limit
 157 //    (GC threshold, MaxMetaspaceSize). If true, it returns false.
 158 // - commit the memory.
 159 // - mark the range as committed in the commit mask
 160 //
 161 // !! Careful:
 162 //    calling ensure_range_is_committed on a range which contains both committed and uncommitted
 163 //    areas will commit the whole area, thus erase the content in the existing committed parts.
 164 //    Make sure you never call this on an address range containing live data. !!
 165 //
 166 // Returns true if success, false if it did hit a commit limit.
 167 bool VirtualSpaceNode::ensure_range_is_committed(MetaWord* p, size_t word_size) {
 168 
 169   assert_lock_strong(MetaspaceExpand_lock);
 170   assert(p != NULL &amp;&amp; word_size &gt; 0, "Sanity");
 171 
 172   MetaWord* p_start = align_down(p, Settings::commit_granule_bytes());
 173   MetaWord* p_end = align_up(p + word_size, Settings::commit_granule_bytes());
 174 
 175   // Todo: simple for now. Make it more intelligent late
 176   return commit_range(p_start, p_end - p_start);
 177 
 178 }
 179 
 180 // Given an address range (which has to be aligned to commit granule size):
 181 //  - uncommit it
 182 //  - mark it as uncommitted in the commit mask
 183 void VirtualSpaceNode::uncommit_range(MetaWord* p, size_t word_size) {
 184 
 185   DEBUG_ONLY(check_pointer_is_aligned_to_commit_granule(p);)
 186   DEBUG_ONLY(check_word_size_is_aligned_to_commit_granule(word_size);)
 187   assert_lock_strong(MetaspaceExpand_lock);
 188 
 189   // First calculate how large the committed regions in this range are
 190   const size_t committed_words_in_range = _commit_mask.get_committed_size_in_range(p, word_size);
 191   DEBUG_ONLY(check_word_size_is_aligned_to_commit_granule(committed_words_in_range);)
 192 
 193   UL2(debug, "uncommitting range " PTR_FORMAT ".." PTR_FORMAT "(" SIZE_FORMAT " words)",
 194       p2i(p), p2i(p + word_size), word_size);
 195 
 196   if (committed_words_in_range == 0) {
 197     UL(debug, "... already fully uncommitted.");
 198     return; // Already fully uncommitted, nothing to do.
 199   }
 200 
 201   // Uncommit...
 202   if (os::uncommit_memory((char*)p, word_size * BytesPerWord) == false) {
 203     // Note: this can actually happen, since uncommit may increase the number of mappings.
 204     fatal("Failed to uncommit metaspace.");
 205   }
 206 
 207   UL2(debug, "... uncommitted " SIZE_FORMAT " words.", committed_words_in_range);
 208 
 209   // ... tell commit limiter...
 210   _commit_limiter-&gt;decrease_committed(committed_words_in_range);
 211 
 212   // ... and global counters...
 213   _total_committed_words_counter-&gt;decrement_by(committed_words_in_range);
 214 
 215    // ... and update the commit mask.
 216   _commit_mask.mark_range_as_uncommitted(p, word_size);
 217 
 218 #ifdef ASSERT
 219   // The commit boundary maintained in the CommitLimiter should be equal the sum of committed words
 220   // in both class and non-class vslist (outside gtests).
 221   if (_commit_limiter == CommitLimiter::globalLimiter()) { // We are outside a test scenario
 222     assert(_commit_limiter-&gt;committed_words() == RunningCounters::committed_words(), "counter mismatch");
 223   }
 224 #endif
 225 
 226   DEBUG_ONLY(InternalStats::inc_num_space_uncommitted();)
 227 
 228 }
 229 
 230 //// creation, destruction ////
 231 
 232 VirtualSpaceNode::VirtualSpaceNode(int node_id,
 233                                    ReservedSpace rs,
 234                                    CommitLimiter* limiter,
 235                                    SizeCounter* reserve_words_counter,
 236                                    SizeCounter* commit_words_counter)
 237   : _next(NULL),
 238     _rs(rs),
 239     _base((MetaWord*)rs.base()),
 240     _word_size(rs.size() / BytesPerWord),
 241     _used_words(0),
 242     _commit_mask((MetaWord*)rs.base(), rs.size() / BytesPerWord),
 243     _root_chunk_area_lut((MetaWord*)rs.base(), rs.size() / BytesPerWord),
 244     _commit_limiter(limiter),
 245     _total_reserved_words_counter(reserve_words_counter),
 246     _total_committed_words_counter(commit_words_counter),
 247     _node_id(node_id)
 248 {
 249   UL2(debug, "born (word_size " SIZE_FORMAT ").", _word_size);
 250 
 251   // Update reserved counter in vslist
 252   _total_reserved_words_counter-&gt;increment_by(_word_size);
 253 
 254   assert_is_aligned(_base, chunklevel::MAX_CHUNK_BYTE_SIZE);
 255   assert_is_aligned(_word_size, chunklevel::MAX_CHUNK_WORD_SIZE);
 256 
 257 }
 258 
 259 // Create a node of a given size
 260 VirtualSpaceNode* VirtualSpaceNode::create_node(int node_id,
 261                                                 size_t word_size,
 262                                                 CommitLimiter* limiter,
 263                                                 SizeCounter* reserve_words_counter,
 264                                                 SizeCounter* commit_words_counter)
 265 {
 266 
 267   DEBUG_ONLY(assert_is_aligned(word_size, chunklevel::MAX_CHUNK_WORD_SIZE);)
 268 
 269 #ifdef ASSERT
 270   size_t alignment = chunklevel::MAX_CHUNK_BYTE_SIZE;
 271 #endif
 272 
 273   ReservedSpace rs(word_size * BytesPerWord,
 274                    Metaspace::reserve_alignment(),
 275                    false // large
 276                    );
 277 
 278   if (!rs.is_reserved()) {
 279     vm_exit_out_of_memory(word_size * BytesPerWord, OOM_MMAP_ERROR, "Failed to reserve memory for metaspace");
 280   }
 281 
 282   assert_is_aligned(rs.base(), chunklevel::MAX_CHUNK_BYTE_SIZE);
 283 
 284   return create_node(node_id, rs, limiter, reserve_words_counter, commit_words_counter);
 285 
 286 }
 287 
 288 // Create a node over an existing space
 289 VirtualSpaceNode* VirtualSpaceNode::create_node(int node_id,
 290                                                 ReservedSpace rs,
 291                                                 CommitLimiter* limiter,
 292                                                 SizeCounter* reserve_words_counter,
 293                                                 SizeCounter* commit_words_counter)
 294 {
 295   DEBUG_ONLY(InternalStats::inc_num_vsnodes_created();)
 296   return new VirtualSpaceNode(node_id, rs, limiter, reserve_words_counter, commit_words_counter);
 297 }
 298 
 299 VirtualSpaceNode::~VirtualSpaceNode() {
 300   _rs.release();
 301 
 302   UL(debug, ": dies.");
 303 
 304   // Update counters in vslist
 305   _total_committed_words_counter-&gt;decrement_by(committed_words());
 306   _total_reserved_words_counter-&gt;decrement_by(_word_size);
 307 
 308   DEBUG_ONLY(InternalStats::inc_num_vsnodes_destroyed();)
 309 
 310 }
 311 
 312 
 313 
 314 //// Chunk allocation, splitting, merging /////
 315 
 316 // Allocate a root chunk from this node. Will fail and return NULL
 317 // if the node is full.
 318 // Note: this just returns a chunk whose memory is reserved; no memory is committed yet.
 319 // Hence, before using this chunk, it must be committed.
 320 // Also, no limits are checked, since no committing takes place.
 321 Metachunk* VirtualSpaceNode::allocate_root_chunk() {
 322 
 323   assert_lock_strong(MetaspaceExpand_lock);
 324 
 325   assert_is_aligned(free_words(), chunklevel::MAX_CHUNK_WORD_SIZE);
 326 
 327   if (free_words() &gt;= chunklevel::MAX_CHUNK_WORD_SIZE) {
 328 
 329     MetaWord* loc = _base + _used_words;
 330     _used_words += chunklevel::MAX_CHUNK_WORD_SIZE;
 331 
 332     RootChunkArea* rca = _root_chunk_area_lut.get_area_by_address(loc);
 333 
 334     // Create a root chunk header and initialize it;
 335     Metachunk* c = rca-&gt;alloc_root_chunk_header(this);
 336 
 337     assert(c-&gt;base() == loc &amp;&amp; c-&gt;vsnode() == this &amp;&amp;
 338            c-&gt;is_free(), "Sanity");
 339 
 340     DEBUG_ONLY(c-&gt;verify(true);)
 341 
 342     UL2(debug, "new root chunk " METACHUNK_FORMAT ".", METACHUNK_FORMAT_ARGS(c));
 343 
 344     if (Settings::newborn_root_chunks_are_fully_committed()) {
 345       // Note: use Metachunk::ensure_commit, do not commit directly. This makes sure the chunk knows
 346       // its commit range and does not ask needlessly.
 347       c-&gt;ensure_fully_committed_locked();
 348     }
 349 
 350     return c;
 351 
 352   }
 353 
 354   return NULL; // Node is full.
 355 
 356 }
 357 
 358 // Given a chunk c, split it recursively until you get a chunk of the given target_level.
 359 //
 360 // The resulting target chunk resides at the same address as the original chunk.
 361 // The resulting splinters are added to freelists.
 362 void VirtualSpaceNode::split(chunklevel_t target_level, Metachunk* c, FreeChunkListVector* freelists) {
 363 
 364   assert_lock_strong(MetaspaceExpand_lock);
 365 
 366   // Get the area associated with this chunk and let it handle the splitting
 367   RootChunkArea* rca = _root_chunk_area_lut.get_area_by_address(c-&gt;base());
 368 
 369   DEBUG_ONLY(rca-&gt;verify_area_is_ideally_merged();)
 370 
 371   rca-&gt;split(target_level, c, freelists);
 372 
 373 }
 374 
 375 // Given a chunk, attempt to merge it recursively with its neighboring chunks.
 376 //
 377 // If successful (merged at least once), returns address of
 378 // the merged chunk; NULL otherwise.
 379 //
 380 // The merged chunks are removed from the freelists.
 381 //
 382 // !!! Please note that if this method returns a non-NULL value, the
 383 // original chunk will be invalid and should not be accessed anymore! !!!
 384 Metachunk* VirtualSpaceNode::merge(Metachunk* c, FreeChunkListVector* freelists) {
 385 
 386   assert(c != NULL &amp;&amp; c-&gt;is_free(), "Sanity");
 387   assert_lock_strong(MetaspaceExpand_lock);
 388 
 389   // Get the rca associated with this chunk and let it handle the merging
 390   RootChunkArea* rca = _root_chunk_area_lut.get_area_by_address(c-&gt;base());
 391 
 392   Metachunk* c2 = rca-&gt;merge(c, freelists);
 393 
 394   DEBUG_ONLY(rca-&gt;verify_area_is_ideally_merged();)
 395 
 396   return c2;
 397 
 398 }
 399 
 400 // Given a chunk c, which must be "in use" and must not be a root chunk, attempt to
 401 // enlarge it in place by claiming its trailing buddy.
 402 //
 403 // This will only work if c is the leader of the buddy pair and the trailing buddy is free.
 404 //
 405 // If successful, the follower chunk will be removed from the freelists, the leader chunk c will
 406 // double in size (level decreased by one).
 407 //
 408 // On success, true is returned, false otherwise.
 409 bool VirtualSpaceNode::attempt_enlarge_chunk(Metachunk* c, FreeChunkListVector* freelists) {
 410 
 411   assert(c != NULL &amp;&amp; c-&gt;is_in_use() &amp;&amp; !c-&gt;is_root_chunk(), "Sanity");
 412   assert_lock_strong(MetaspaceExpand_lock);
 413 
 414   // Get the rca associated with this chunk and let it handle the merging
 415   RootChunkArea* rca = _root_chunk_area_lut.get_area_by_address(c-&gt;base());
 416 
 417   bool rc = rca-&gt;attempt_enlarge_chunk(c, freelists);
 418 
 419   DEBUG_ONLY(rca-&gt;verify_area_is_ideally_merged();)
 420 
 421   return rc;
 422 
 423 }
 424 
 425 // Attempts to purge the node:
 426 //
 427 // If all chunks living in this node are free, they will all be removed from their freelists
 428 //   and deletes the node.
 429 //
 430 // Returns true if the node has been deleted, false if not.
 431 // !! If this returns true, do not access the node from this point on. !!
 432 bool VirtualSpaceNode::attempt_purge(FreeChunkListVector* freelists) {
 433 
 434   assert_lock_strong(MetaspaceExpand_lock);
 435 
 436   // First find out if all areas are empty. Since empty chunks collapse to root chunk
 437   // size, if all chunks in this node are free root chunks we are good to go.
 438   for (int narea = 0; narea &lt; _root_chunk_area_lut.number_of_areas(); narea ++) {
 439     const RootChunkArea* ra = _root_chunk_area_lut.get_area_by_index(narea);
 440     const Metachunk* c = ra-&gt;first_chunk();
 441     if (c != NULL) {
 442       if (!(c-&gt;is_root_chunk() &amp;&amp; c-&gt;is_free())) {
 443         return false;
 444       }
 445     }
 446   }
 447 
 448   UL(debug, ": purging.");
 449 
 450   // Okay, we can purge. Before we can do this, we need to remove all chunks from the freelist.
 451   for (int narea = 0; narea &lt; _root_chunk_area_lut.number_of_areas(); narea ++) {
 452     RootChunkArea* ra = _root_chunk_area_lut.get_area_by_index(narea);
 453     Metachunk* c = ra-&gt;first_chunk();
 454     if (c != NULL) {
 455       UL2(trace, "removing chunk from purged node: " METACHUNK_FULL_FORMAT ".", METACHUNK_FULL_FORMAT_ARGS(c));
 456       assert(c-&gt;is_free() &amp;&amp; c-&gt;is_root_chunk(), "Sanity");
 457       freelists-&gt;remove(c);
 458     }
 459   }
 460 
 461   // Now, delete the node, then right away return since this object is invalid.
 462   delete this;
 463 
 464   return true;
 465 
 466 }
 467 
 468 
 469 void VirtualSpaceNode::print_on(outputStream* st) const {
 470 
 471   size_t scale = K;
 472 
 473   st-&gt;print("id: %d, base " PTR_FORMAT ": ", _node_id, p2i(base()));
 474   st-&gt;print("reserved=");
 475   print_scaled_words(st, word_size(), scale);
 476   st-&gt;print(", committed=");
 477   print_scaled_words_and_percentage(st, committed_words(), word_size(), scale);
 478   st-&gt;print(", used=");
 479   print_scaled_words_and_percentage(st, used_words(), word_size(), scale);
 480 
 481   st-&gt;cr();
 482 
 483   _root_chunk_area_lut.print_on(st);
 484   _commit_mask.print_on(st);
 485 
 486 }
 487 
 488 // Returns size, in words, of committed space in this node alone.
 489 // Note: iterates over commit mask and hence may be a tad expensive on large nodes.
 490 size_t VirtualSpaceNode::committed_words() const {
 491   return _commit_mask.get_committed_size();
 492 }
 493 
 494 #ifdef ASSERT
 495 // Verify counters and basic structure. Slow mode: verify all chunks in depth
 496 void VirtualSpaceNode::verify(bool slow) const {
 497 
 498   assert_lock_strong(MetaspaceExpand_lock);
 499 
 500   assert(base() != NULL, "Invalid base");
 501   assert(base() == (MetaWord*)_rs.base() &amp;&amp;
 502          word_size() == _rs.size() / BytesPerWord,
 503          "Sanity");
 504   assert_is_aligned(base(), chunklevel::MAX_CHUNK_BYTE_SIZE);
 505   assert(used_words() &lt;= word_size(), "Sanity");
 506 
 507   // Since we only ever hand out root chunks from a vsnode, top should always be aligned
 508   // to root chunk size.
 509   assert_is_aligned(used_words(), chunklevel::MAX_CHUNK_WORD_SIZE);
 510 
 511   _commit_mask.verify(slow);
 512   assert(committed_words() &lt;= word_size(), "Sanity");
 513   assert_is_aligned(committed_words(), Settings::commit_granule_words());
 514   _root_chunk_area_lut.verify(slow);
 515 
 516 }
 517 
 518 #endif
 519 
 520 
 521 } // namespace metaspace
</pre></body></html>
