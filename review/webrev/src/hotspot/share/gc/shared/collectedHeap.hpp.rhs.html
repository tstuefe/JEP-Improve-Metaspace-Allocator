<?xml version="1.0"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head><meta charset="utf-8">
<meta http-equiv="cache-control" content="no-cache" />
<meta http-equiv="Pragma" content="no-cache" />
<meta http-equiv="Expires" content="-1" />
<!--
   Note to customizers: the body of the webrev is IDed as SUNWwebrev
   to allow easy overriding by users of webrev via the userContent.css
   mechanism available in some browsers.

   For example, to have all "removed" information be red instead of
   brown, set a rule in your userContent.css file like:

       body#SUNWwebrev span.removed { color: red ! important; }
-->
<style type="text/css" media="screen">
body {
    background-color: #eeeeee;
}
hr {
    border: none 0;
    border-top: 1px solid #aaa;
    height: 1px;
}
div.summary {
    font-size: .8em;
    border-bottom: 1px solid #aaa;
    padding-left: 1em;
    padding-right: 1em;
}
div.summary h2 {
    margin-bottom: 0.3em;
}
div.summary table th {
    text-align: right;
    vertical-align: top;
    white-space: nowrap;
}
span.lineschanged {
    font-size: 0.7em;
}
span.oldmarker {
    color: red;
    font-size: large;
    font-weight: bold;
}
span.newmarker {
    color: green;
    font-size: large;
    font-weight: bold;
}
span.removed {
    color: brown;
}
span.changed {
    color: blue;
}
span.new {
    color: blue;
    font-weight: bold;
}
a.print { font-size: x-small; }

</style>

<style type="text/css" media="print">
pre { font-size: 0.8em; font-family: courier, monospace; }
span.removed { color: #444; font-style: italic }
span.changed { font-weight: bold; }
span.new { font-weight: bold; }
span.newmarker { font-size: 1.2em; font-weight: bold; }
span.oldmarker { font-size: 1.2em; font-weight: bold; }
a.print {display: none}
hr { border: none 0; border-top: 1px solid #aaa; height: 1px; }
</style>

    <script type="text/javascript" src="../../../../../ancnav.js"></script>
    </head>
    <body id="SUNWwebrev" onkeypress="keypress(event);">
    <a name="0"></a>
    <pre>rev <a href="https://bugs.openjdk.java.net/browse/JDK-60448">60448</a> : imported patch jep387-all.patch</pre><hr></hr>
<pre>
   1 /*
   2  * Copyright (c) 2001, 2020, Oracle and/or its affiliates. All rights reserved.
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #ifndef SHARE_GC_SHARED_COLLECTEDHEAP_HPP
  26 #define SHARE_GC_SHARED_COLLECTEDHEAP_HPP
  27 
  28 #include "gc/shared/gcCause.hpp"
  29 #include "gc/shared/gcWhen.hpp"
  30 #include "gc/shared/verifyOption.hpp"
  31 #include "memory/allocation.hpp"
<a name="1" id="anc1"></a><span class="new">  32 #include "memory/metaspace.hpp"</span>
  33 #include "memory/universe.hpp"
  34 #include "runtime/handles.hpp"
  35 #include "runtime/perfData.hpp"
  36 #include "runtime/safepoint.hpp"
  37 #include "services/memoryUsage.hpp"
  38 #include "utilities/debug.hpp"
  39 #include "utilities/events.hpp"
  40 #include "utilities/formatBuffer.hpp"
  41 #include "utilities/growableArray.hpp"
  42 
  43 // A "CollectedHeap" is an implementation of a java heap for HotSpot.  This
  44 // is an abstract class: there may be many different kinds of heaps.  This
  45 // class defines the functions that a heap must implement, and contains
  46 // infrastructure common to all heaps.
  47 
  48 class AdaptiveSizePolicy;
  49 class BarrierSet;
  50 class GCHeapSummary;
  51 class GCTimer;
  52 class GCTracer;
  53 class GCMemoryManager;
  54 class MemoryPool;
  55 class MetaspaceSummary;
  56 class ReservedHeapSpace;
  57 class SoftRefPolicy;
  58 class Thread;
  59 class ThreadClosure;
  60 class VirtualSpaceSummary;
  61 class WorkGang;
  62 class nmethod;
  63 
  64 class GCMessage : public FormatBuffer&lt;1024&gt; {
  65  public:
  66   bool is_before;
  67 
  68  public:
  69   GCMessage() {}
  70 };
  71 
  72 class CollectedHeap;
  73 
  74 class GCHeapLog : public EventLogBase&lt;GCMessage&gt; {
  75  private:
  76   void log_heap(CollectedHeap* heap, bool before);
  77 
  78  public:
  79   GCHeapLog() : EventLogBase&lt;GCMessage&gt;("GC Heap History", "gc") {}
  80 
  81   void log_heap_before(CollectedHeap* heap) {
  82     log_heap(heap, true);
  83   }
  84   void log_heap_after(CollectedHeap* heap) {
  85     log_heap(heap, false);
  86   }
  87 };
  88 
  89 //
  90 // CollectedHeap
  91 //   GenCollectedHeap
  92 //     SerialHeap
  93 //   G1CollectedHeap
  94 //   ParallelScavengeHeap
  95 //   ShenandoahHeap
  96 //   ZCollectedHeap
  97 //
  98 class CollectedHeap : public CHeapObj&lt;mtInternal&gt; {
  99   friend class VMStructs;
 100   friend class JVMCIVMStructs;
 101   friend class IsGCActiveMark; // Block structured external access to _is_gc_active
 102   friend class MemAllocator;
 103 
 104  private:
 105   GCHeapLog* _gc_heap_log;
 106 
 107  protected:
 108   // Not used by all GCs
 109   MemRegion _reserved;
 110 
 111   bool _is_gc_active;
 112 
 113   // Used for filler objects (static, but initialized in ctor).
 114   static size_t _filler_array_max_size;
 115 
 116   unsigned int _total_collections;          // ... started
 117   unsigned int _total_full_collections;     // ... started
 118   NOT_PRODUCT(volatile size_t _promotion_failure_alot_count;)
 119   NOT_PRODUCT(volatile size_t _promotion_failure_alot_gc_number;)
 120 
 121   // Reason for current garbage collection.  Should be set to
 122   // a value reflecting no collection between collections.
 123   GCCause::Cause _gc_cause;
 124   GCCause::Cause _gc_lastcause;
 125   PerfStringVariable* _perf_gc_cause;
 126   PerfStringVariable* _perf_gc_lastcause;
 127 
 128   // Constructor
 129   CollectedHeap();
 130 
 131   // Create a new tlab. All TLAB allocations must go through this.
 132   // To allow more flexible TLAB allocations min_size specifies
 133   // the minimum size needed, while requested_size is the requested
 134   // size based on ergonomics. The actually allocated size will be
 135   // returned in actual_size.
 136   virtual HeapWord* allocate_new_tlab(size_t min_size,
 137                                       size_t requested_size,
 138                                       size_t* actual_size);
 139 
 140   // Reinitialize tlabs before resuming mutators.
 141   virtual void resize_all_tlabs();
 142 
 143   // Raw memory allocation facilities
 144   // The obj and array allocate methods are covers for these methods.
 145   // mem_allocate() should never be
 146   // called to allocate TLABs, only individual objects.
 147   virtual HeapWord* mem_allocate(size_t size,
 148                                  bool* gc_overhead_limit_was_exceeded) = 0;
 149 
 150   // Filler object utilities.
 151   static inline size_t filler_array_hdr_size();
 152   static inline size_t filler_array_min_size();
 153 
 154   DEBUG_ONLY(static void fill_args_check(HeapWord* start, size_t words);)
 155   DEBUG_ONLY(static void zap_filler_array(HeapWord* start, size_t words, bool zap = true);)
 156 
 157   // Fill with a single array; caller must ensure filler_array_min_size() &lt;=
 158   // words &lt;= filler_array_max_size().
 159   static inline void fill_with_array(HeapWord* start, size_t words, bool zap = true);
 160 
 161   // Fill with a single object (either an int array or a java.lang.Object).
 162   static inline void fill_with_object_impl(HeapWord* start, size_t words, bool zap = true);
 163 
 164   virtual void trace_heap(GCWhen::Type when, const GCTracer* tracer);
 165 
 166   // Verification functions
 167   virtual void check_for_non_bad_heap_word_value(HeapWord* addr, size_t size)
 168     PRODUCT_RETURN;
 169   debug_only(static void check_for_valid_allocation_state();)
 170 
 171  public:
 172   enum Name {
 173     None,
 174     Serial,
 175     Parallel,
 176     G1,
 177     Epsilon,
 178     Z,
 179     Shenandoah
 180   };
 181 
 182  protected:
 183   // Get a pointer to the derived heap object.  Used to implement
 184   // derived class heap() functions rather than being called directly.
 185   template&lt;typename T&gt;
 186   static T* named_heap(Name kind) {
 187     CollectedHeap* heap = Universe::heap();
 188     assert(heap != NULL, "Uninitialized heap");
 189     assert(kind == heap-&gt;kind(), "Heap kind %u should be %u",
 190            static_cast&lt;uint&gt;(heap-&gt;kind()), static_cast&lt;uint&gt;(kind));
 191     return static_cast&lt;T*&gt;(heap);
 192   }
 193 
 194  public:
 195 
 196   static inline size_t filler_array_max_size() {
 197     return _filler_array_max_size;
 198   }
 199 
 200   virtual Name kind() const = 0;
 201 
 202   virtual const char* name() const = 0;
 203 
 204   /**
 205    * Returns JNI error code JNI_ENOMEM if memory could not be allocated,
 206    * and JNI_OK on success.
 207    */
 208   virtual jint initialize() = 0;
 209 
 210   // In many heaps, there will be a need to perform some initialization activities
 211   // after the Universe is fully formed, but before general heap allocation is allowed.
 212   // This is the correct place to place such initialization methods.
 213   virtual void post_initialize();
 214 
 215   // Stop any onging concurrent work and prepare for exit.
 216   virtual void stop() {}
 217 
 218   // Stop and resume concurrent GC threads interfering with safepoint operations
 219   virtual void safepoint_synchronize_begin() {}
 220   virtual void safepoint_synchronize_end() {}
 221 
 222   void initialize_reserved_region(const ReservedHeapSpace&amp; rs);
 223 
 224   virtual size_t capacity() const = 0;
 225   virtual size_t used() const = 0;
 226 
 227   // Returns unused capacity.
 228   virtual size_t unused() const;
 229 
 230   // Return "true" if the part of the heap that allocates Java
 231   // objects has reached the maximal committed limit that it can
 232   // reach, without a garbage collection.
 233   virtual bool is_maximal_no_gc() const = 0;
 234 
 235   // Support for java.lang.Runtime.maxMemory():  return the maximum amount of
 236   // memory that the vm could make available for storing 'normal' java objects.
 237   // This is based on the reserved address space, but should not include space
 238   // that the vm uses internally for bookkeeping or temporary storage
 239   // (e.g., in the case of the young gen, one of the survivor
 240   // spaces).
 241   virtual size_t max_capacity() const = 0;
 242 
 243   // Returns "TRUE" iff "p" points into the committed areas of the heap.
 244   // This method can be expensive so avoid using it in performance critical
 245   // code.
 246   virtual bool is_in(const void* p) const = 0;
 247 
 248   DEBUG_ONLY(bool is_in_or_null(const void* p) const { return p == NULL || is_in(p); })
 249 
 250   virtual uint32_t hash_oop(oop obj) const;
 251 
 252   void set_gc_cause(GCCause::Cause v) {
 253      if (UsePerfData) {
 254        _gc_lastcause = _gc_cause;
 255        _perf_gc_lastcause-&gt;set_value(GCCause::to_string(_gc_lastcause));
 256        _perf_gc_cause-&gt;set_value(GCCause::to_string(v));
 257      }
 258     _gc_cause = v;
 259   }
 260   GCCause::Cause gc_cause() { return _gc_cause; }
 261 
 262   oop obj_allocate(Klass* klass, int size, TRAPS);
 263   virtual oop array_allocate(Klass* klass, int size, int length, bool do_zero, TRAPS);
 264   oop class_allocate(Klass* klass, int size, TRAPS);
 265 
 266   // Utilities for turning raw memory into filler objects.
 267   //
 268   // min_fill_size() is the smallest region that can be filled.
 269   // fill_with_objects() can fill arbitrary-sized regions of the heap using
 270   // multiple objects.  fill_with_object() is for regions known to be smaller
 271   // than the largest array of integers; it uses a single object to fill the
 272   // region and has slightly less overhead.
 273   static size_t min_fill_size() {
 274     return size_t(align_object_size(oopDesc::header_size()));
 275   }
 276 
 277   static void fill_with_objects(HeapWord* start, size_t words, bool zap = true);
 278 
 279   static void fill_with_object(HeapWord* start, size_t words, bool zap = true);
 280   static void fill_with_object(MemRegion region, bool zap = true) {
 281     fill_with_object(region.start(), region.word_size(), zap);
 282   }
 283   static void fill_with_object(HeapWord* start, HeapWord* end, bool zap = true) {
 284     fill_with_object(start, pointer_delta(end, start), zap);
 285   }
 286 
 287   virtual void fill_with_dummy_object(HeapWord* start, HeapWord* end, bool zap);
 288   virtual size_t min_dummy_object_size() const;
 289   size_t tlab_alloc_reserve() const;
 290 
 291   // Return the address "addr" aligned by "alignment_in_bytes" if such
 292   // an address is below "end".  Return NULL otherwise.
 293   inline static HeapWord* align_allocation_or_fail(HeapWord* addr,
 294                                                    HeapWord* end,
 295                                                    unsigned short alignment_in_bytes);
 296 
 297   // Some heaps may offer a contiguous region for shared non-blocking
 298   // allocation, via inlined code (by exporting the address of the top and
 299   // end fields defining the extent of the contiguous allocation region.)
 300 
 301   // This function returns "true" iff the heap supports this kind of
 302   // allocation.  (Default is "no".)
 303   virtual bool supports_inline_contig_alloc() const {
 304     return false;
 305   }
 306   // These functions return the addresses of the fields that define the
 307   // boundaries of the contiguous allocation area.  (These fields should be
 308   // physically near to one another.)
 309   virtual HeapWord* volatile* top_addr() const {
 310     guarantee(false, "inline contiguous allocation not supported");
 311     return NULL;
 312   }
 313   virtual HeapWord** end_addr() const {
 314     guarantee(false, "inline contiguous allocation not supported");
 315     return NULL;
 316   }
 317 
 318   // Some heaps may be in an unparseable state at certain times between
 319   // collections. This may be necessary for efficient implementation of
 320   // certain allocation-related activities. Calling this function before
 321   // attempting to parse a heap ensures that the heap is in a parsable
 322   // state (provided other concurrent activity does not introduce
 323   // unparsability). It is normally expected, therefore, that this
 324   // method is invoked with the world stopped.
 325   // NOTE: if you override this method, make sure you call
 326   // super::ensure_parsability so that the non-generational
 327   // part of the work gets done. See implementation of
 328   // CollectedHeap::ensure_parsability and, for instance,
 329   // that of GenCollectedHeap::ensure_parsability().
 330   // The argument "retire_tlabs" controls whether existing TLABs
 331   // are merely filled or also retired, thus preventing further
 332   // allocation from them and necessitating allocation of new TLABs.
 333   virtual void ensure_parsability(bool retire_tlabs);
 334 
 335   // Section on thread-local allocation buffers (TLABs)
 336   // If the heap supports thread-local allocation buffers, it should override
 337   // the following methods:
 338   // Returns "true" iff the heap supports thread-local allocation buffers.
 339   // The default is "no".
 340   virtual bool supports_tlab_allocation() const = 0;
 341 
 342   // The amount of space available for thread-local allocation buffers.
 343   virtual size_t tlab_capacity(Thread *thr) const = 0;
 344 
 345   // The amount of used space for thread-local allocation buffers for the given thread.
 346   virtual size_t tlab_used(Thread *thr) const = 0;
 347 
 348   virtual size_t max_tlab_size() const;
 349 
 350   // An estimate of the maximum allocation that could be performed
 351   // for thread-local allocation buffers without triggering any
 352   // collection or expansion activity.
 353   virtual size_t unsafe_max_tlab_alloc(Thread *thr) const {
 354     guarantee(false, "thread-local allocation buffers not supported");
 355     return 0;
 356   }
 357 
 358   // Perform a collection of the heap; intended for use in implementing
 359   // "System.gc".  This probably implies as full a collection as the
 360   // "CollectedHeap" supports.
 361   virtual void collect(GCCause::Cause cause) = 0;
 362 
 363   // Perform a full collection
 364   virtual void do_full_collection(bool clear_all_soft_refs) = 0;
 365 
 366   // This interface assumes that it's being called by the
 367   // vm thread. It collects the heap assuming that the
 368   // heap lock is already held and that we are executing in
 369   // the context of the vm thread.
 370   virtual void collect_as_vm_thread(GCCause::Cause cause);
 371 
 372   virtual MetaWord* satisfy_failed_metadata_allocation(ClassLoaderData* loader_data,
 373                                                        size_t size,
 374                                                        Metaspace::MetadataType mdtype);
 375 
 376   // Returns "true" iff there is a stop-world GC in progress.  (I assume
 377   // that it should answer "false" for the concurrent part of a concurrent
 378   // collector -- dld).
 379   bool is_gc_active() const { return _is_gc_active; }
 380 
 381   // Total number of GC collections (started)
 382   unsigned int total_collections() const { return _total_collections; }
 383   unsigned int total_full_collections() const { return _total_full_collections;}
 384 
 385   // Increment total number of GC collections (started)
 386   void increment_total_collections(bool full = false) {
 387     _total_collections++;
 388     if (full) {
 389       increment_total_full_collections();
 390     }
 391   }
 392 
 393   void increment_total_full_collections() { _total_full_collections++; }
 394 
 395   // Return the SoftRefPolicy for the heap;
 396   virtual SoftRefPolicy* soft_ref_policy() = 0;
 397 
 398   virtual MemoryUsage memory_usage();
 399   virtual GrowableArray&lt;GCMemoryManager*&gt; memory_managers() = 0;
 400   virtual GrowableArray&lt;MemoryPool*&gt; memory_pools() = 0;
 401 
 402   // Iterate over all objects, calling "cl.do_object" on each.
 403   virtual void object_iterate(ObjectClosure* cl) = 0;
 404 
 405   // Keep alive an object that was loaded with AS_NO_KEEPALIVE.
 406   virtual void keep_alive(oop obj) {}
 407 
 408   // Returns the longest time (in ms) that has elapsed since the last
 409   // time that any part of the heap was examined by a garbage collection.
 410   virtual jlong millis_since_last_gc() = 0;
 411 
 412   // Perform any cleanup actions necessary before allowing a verification.
 413   virtual void prepare_for_verify() = 0;
 414 
 415   // Generate any dumps preceding or following a full gc
 416  private:
 417   void full_gc_dump(GCTimer* timer, bool before);
 418 
 419   virtual void initialize_serviceability() = 0;
 420 
 421  public:
 422   void pre_full_gc_dump(GCTimer* timer);
 423   void post_full_gc_dump(GCTimer* timer);
 424 
 425   virtual VirtualSpaceSummary create_heap_space_summary();
 426   GCHeapSummary create_heap_summary();
 427 
 428   MetaspaceSummary create_metaspace_summary();
 429 
 430   // Print heap information on the given outputStream.
 431   virtual void print_on(outputStream* st) const = 0;
 432   // The default behavior is to call print_on() on tty.
 433   virtual void print() const;
 434 
 435   // Print more detailed heap information on the given
 436   // outputStream. The default behavior is to call print_on(). It is
 437   // up to each subclass to override it and add any additional output
 438   // it needs.
 439   virtual void print_extended_on(outputStream* st) const {
 440     print_on(st);
 441   }
 442 
 443   virtual void print_on_error(outputStream* st) const;
 444 
 445   // Used to print information about locations in the hs_err file.
 446   virtual bool print_location(outputStream* st, void* addr) const = 0;
 447 
 448   // Iterator for all GC threads (other than VM thread)
 449   virtual void gc_threads_do(ThreadClosure* tc) const = 0;
 450 
 451   // Print any relevant tracing info that flags imply.
 452   // Default implementation does nothing.
 453   virtual void print_tracing_info() const = 0;
 454 
 455   void print_heap_before_gc();
 456   void print_heap_after_gc();
 457 
 458   // Registering and unregistering an nmethod (compiled code) with the heap.
 459   virtual void register_nmethod(nmethod* nm) = 0;
 460   virtual void unregister_nmethod(nmethod* nm) = 0;
 461   // Callback for when nmethod is about to be deleted.
 462   virtual void flush_nmethod(nmethod* nm) = 0;
 463   virtual void verify_nmethod(nmethod* nm) = 0;
 464 
 465   void trace_heap_before_gc(const GCTracer* gc_tracer);
 466   void trace_heap_after_gc(const GCTracer* gc_tracer);
 467 
 468   // Heap verification
 469   virtual void verify(VerifyOption option) = 0;
 470 
 471   // Return true if concurrent gc control via WhiteBox is supported by
 472   // this collector.  The default implementation returns false.
 473   virtual bool supports_concurrent_gc_breakpoints() const;
 474 
 475   // Provides a thread pool to SafepointSynchronize to use
 476   // for parallel safepoint cleanup.
 477   // GCs that use a GC worker thread pool may want to share
 478   // it for use during safepoint cleanup. This is only possible
 479   // if the GC can pause and resume concurrent work (e.g. G1
 480   // concurrent marking) for an intermittent non-GC safepoint.
 481   // If this method returns NULL, SafepointSynchronize will
 482   // perform cleanup tasks serially in the VMThread.
 483   virtual WorkGang* get_safepoint_workers() { return NULL; }
 484 
 485   // Support for object pinning. This is used by JNI Get*Critical()
 486   // and Release*Critical() family of functions. If supported, the GC
 487   // must guarantee that pinned objects never move.
 488   virtual bool supports_object_pinning() const;
 489   virtual oop pin_object(JavaThread* thread, oop obj);
 490   virtual void unpin_object(JavaThread* thread, oop obj);
 491 
 492   // Deduplicate the string, iff the GC supports string deduplication.
 493   virtual void deduplicate_string(oop str);
 494 
 495   virtual bool is_oop(oop object) const;
 496 
 497   // Non product verification and debugging.
 498 #ifndef PRODUCT
 499   // Support for PromotionFailureALot.  Return true if it's time to cause a
 500   // promotion failure.  The no-argument version uses
 501   // this-&gt;_promotion_failure_alot_count as the counter.
 502   bool promotion_should_fail(volatile size_t* count);
 503   bool promotion_should_fail();
 504 
 505   // Reset the PromotionFailureALot counters.  Should be called at the end of a
 506   // GC in which promotion failure occurred.
 507   void reset_promotion_should_fail(volatile size_t* count);
 508   void reset_promotion_should_fail();
 509 #endif  // #ifndef PRODUCT
 510 };
 511 
 512 // Class to set and reset the GC cause for a CollectedHeap.
 513 
 514 class GCCauseSetter : StackObj {
 515   CollectedHeap* _heap;
 516   GCCause::Cause _previous_cause;
 517  public:
 518   GCCauseSetter(CollectedHeap* heap, GCCause::Cause cause) {
 519     _heap = heap;
 520     _previous_cause = _heap-&gt;gc_cause();
 521     _heap-&gt;set_gc_cause(cause);
 522   }
 523 
 524   ~GCCauseSetter() {
 525     _heap-&gt;set_gc_cause(_previous_cause);
 526   }
 527 };
 528 
 529 #endif // SHARE_GC_SHARED_COLLECTEDHEAP_HPP
<a name="2" id="anc2"></a><b style="font-size: large; color: red">--- EOF ---</b>















































































</pre><form name="eof"><input name="value" value="2" type="hidden" /></form></body></html>
