<?xml version="1.0"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head><meta charset="utf-8">
<meta http-equiv="cache-control" content="no-cache" />
<meta http-equiv="Pragma" content="no-cache" />
<meta http-equiv="Expires" content="-1" />
<!--
   Note to customizers: the body of the webrev is IDed as SUNWwebrev
   to allow easy overriding by users of webrev via the userContent.css
   mechanism available in some browsers.

   For example, to have all "removed" information be red instead of
   brown, set a rule in your userContent.css file like:

       body#SUNWwebrev span.removed { color: red ! important; }
-->
<style type="text/css" media="screen">
body {
    background-color: #eeeeee;
}
hr {
    border: none 0;
    border-top: 1px solid #aaa;
    height: 1px;
}
div.summary {
    font-size: .8em;
    border-bottom: 1px solid #aaa;
    padding-left: 1em;
    padding-right: 1em;
}
div.summary h2 {
    margin-bottom: 0.3em;
}
div.summary table th {
    text-align: right;
    vertical-align: top;
    white-space: nowrap;
}
span.lineschanged {
    font-size: 0.7em;
}
span.oldmarker {
    color: red;
    font-size: large;
    font-weight: bold;
}
span.newmarker {
    color: green;
    font-size: large;
    font-weight: bold;
}
span.removed {
    color: brown;
}
span.changed {
    color: blue;
}
span.new {
    color: blue;
    font-weight: bold;
}
a.print { font-size: x-small; }

</style>

<style type="text/css" media="print">
pre { font-size: 0.8em; font-family: courier, monospace; }
span.removed { color: #444; font-style: italic }
span.changed { font-weight: bold; }
span.new { font-weight: bold; }
span.newmarker { font-size: 1.2em; font-weight: bold; }
span.oldmarker { font-size: 1.2em; font-weight: bold; }
a.print {display: none}
hr { border: none 0; border-top: 1px solid #aaa; height: 1px; }
</style>

    <script type="text/javascript" src="../../../../ancnav.js"></script>
    </head>
    <body id="SUNWwebrev" onkeypress="keypress(event);">
    <a name="0"></a>
    <pre>rev <a href="https://bugs.openjdk.java.net/browse/JDK-60448">60448</a> : imported patch jep387-all.patch</pre><hr></hr>
<pre>
   1 /*
   2  * Copyright (c) 2011, 2020, Oracle and/or its affiliates. All rights reserved.
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include "precompiled.hpp"
<a name="1" id="anc1"></a><span class="new">  26 </span>
  27 #include "aot/aotLoader.hpp"
<a name="2" id="anc2"></a>
  28 #include "gc/shared/collectedHeap.hpp"
  29 #include "logging/log.hpp"
  30 #include "logging/logStream.hpp"
  31 #include "memory/filemap.hpp"
  32 #include "memory/metaspace.hpp"
<a name="3" id="anc3"></a><span class="new">  33 #include "memory/metaspaceShared.hpp"</span>
<span class="new">  34 #include "memory/metaspaceTracer.hpp"</span>
  35 #include "memory/metaspace/chunkManager.hpp"
<a name="4" id="anc4"></a><span class="changed">  36 #include "memory/metaspace/classLoaderMetaspace.hpp"</span>
<span class="changed">  37 #include "memory/metaspace/commitLimiter.hpp"</span>
  38 #include "memory/metaspace/metaspaceCommon.hpp"
<a name="5" id="anc5"></a><span class="changed">  39 #include "memory/metaspace/metaspaceContext.hpp"</span>
<span class="changed">  40 #include "memory/metaspace/metaspaceEnums.hpp"</span>
<span class="changed">  41 #include "memory/metaspace/metaspaceReport.hpp"</span>
<span class="changed">  42 #include "memory/metaspace/metaspaceSizesSnapshot.hpp"</span>
<span class="changed">  43 #include "memory/metaspace/runningCounters.hpp"</span>
<span class="changed">  44 #include "memory/metaspace/settings.hpp"</span>
  45 #include "memory/metaspace/virtualSpaceList.hpp"
<a name="6" id="anc6"></a>

  46 #include "memory/universe.hpp"
  47 #include "oops/compressedOops.hpp"
  48 #include "runtime/atomic.hpp"
  49 #include "runtime/init.hpp"
<a name="7" id="anc7"></a><span class="new">  50 #include "runtime/java.hpp"</span>
  51 #include "services/memTracker.hpp"
  52 #include "utilities/copy.hpp"
  53 #include "utilities/debug.hpp"
  54 #include "utilities/formatBuffer.hpp"
  55 #include "utilities/globalDefinitions.hpp"
<a name="8" id="anc8"></a>
  56 
  57 
<a name="9" id="anc9"></a><span class="changed">  58 using metaspace::ChunkManager;</span>
<span class="changed">  59 using metaspace::ClassLoaderMetaspace;</span>
<span class="changed">  60 using metaspace::CommitLimiter;</span>
<span class="changed">  61 using metaspace::MetaspaceContext;</span>
<span class="changed">  62 using metaspace::MetaspaceReporter;</span>
<span class="changed">  63 using metaspace::MetaspaceType;</span>
<span class="changed">  64 using metaspace::RunningCounters;</span>
<span class="changed">  65 using metaspace::VirtualSpaceList;</span>
  66 
<a name="10" id="anc10"></a>
  67 
<a name="11" id="anc11"></a><span class="changed">  68 // Used by MetaspaceCounters</span>
<span class="changed">  69 size_t MetaspaceUtils::free_chunks_total_words(Metaspace::MetadataType mdtype) {</span>
<span class="changed">  70   return metaspace::is_class(mdtype) ? RunningCounters::free_chunks_words_class() : RunningCounters::free_chunks_words_nonclass();</span>
<span class="changed">  71 }</span>
  72 
<a name="12" id="anc12"></a><span class="changed">  73 size_t MetaspaceUtils::used_words() {</span>
<span class="changed">  74   return RunningCounters::used_words();</span>
<span class="changed">  75 }</span>
<span class="changed">  76 </span>
<span class="changed">  77 size_t MetaspaceUtils::used_words(Metaspace::MetadataType mdtype) {</span>
<span class="changed">  78   return metaspace::is_class(mdtype) ? RunningCounters::used_words_class() : RunningCounters::used_words_nonclass();</span>
<span class="changed">  79 }</span>
<span class="changed">  80 </span>
<span class="changed">  81 size_t MetaspaceUtils::reserved_words() {</span>
<span class="changed">  82   return RunningCounters::reserved_words();</span>
<span class="changed">  83 }</span>
<span class="changed">  84 </span>
<span class="changed">  85 size_t MetaspaceUtils::reserved_words(Metaspace::MetadataType mdtype) {</span>
<span class="changed">  86   return metaspace::is_class(mdtype) ? RunningCounters::reserved_words_class() : RunningCounters::reserved_words_nonclass();</span>
<span class="changed">  87 }</span>
<span class="changed">  88 </span>
<span class="changed">  89 size_t MetaspaceUtils::committed_words() {</span>
<span class="changed">  90   return RunningCounters::committed_words();</span>
<span class="changed">  91 }</span>
<span class="changed">  92 </span>
<span class="changed">  93 size_t MetaspaceUtils::committed_words(Metaspace::MetadataType mdtype) {</span>
<span class="changed">  94   return metaspace::is_class(mdtype) ? RunningCounters::committed_words_class() : RunningCounters::committed_words_nonclass();</span>
<span class="changed">  95 }</span>
<span class="changed">  96 </span>
<span class="changed">  97 </span>
<span class="changed">  98 </span>
<span class="changed">  99 void MetaspaceUtils::print_metaspace_change(const metaspace::MetaspaceSizesSnapshot&amp; pre_meta_values) {</span>
<span class="changed"> 100   const metaspace::MetaspaceSizesSnapshot meta_values;</span>
<span class="changed"> 101 </span>
<span class="changed"> 102   // We print used and committed since these are the most useful at-a-glance vitals for Metaspace:</span>
<span class="changed"> 103   // - used tells you how much memory is actually used for metadata</span>
<span class="changed"> 104   // - committed tells you how much memory is committed for the purpose of metadata</span>
<span class="changed"> 105   // The difference between those two would be waste, which can have various forms (freelists,</span>
<span class="changed"> 106   //   unused parts of committed chunks etc)</span>
<span class="changed"> 107   //</span>
<span class="changed"> 108   // Left out is reserved, since this is not as exciting as the first two values: for class space,</span>
<span class="changed"> 109   // it is a constant (to uninformed users, often confusingly large). For non-class space, it would</span>
<span class="changed"> 110   // be interesting since free chunks can be uncommitted, but for now it is left out.</span>
<span class="changed"> 111 </span>
<span class="changed"> 112   if (Metaspace::using_class_space()) {</span>
<span class="changed"> 113     log_info(gc, metaspace)(HEAP_CHANGE_FORMAT" "</span>
<span class="changed"> 114                             HEAP_CHANGE_FORMAT" "</span>
<span class="changed"> 115                             HEAP_CHANGE_FORMAT,</span>
<span class="changed"> 116                             HEAP_CHANGE_FORMAT_ARGS("Metaspace",</span>
<span class="changed"> 117                                                     pre_meta_values.used(),</span>
<span class="changed"> 118                                                     pre_meta_values.committed(),</span>
<span class="changed"> 119                                                     meta_values.used(),</span>
<span class="changed"> 120                                                     meta_values.committed()),</span>
<span class="changed"> 121                             HEAP_CHANGE_FORMAT_ARGS("NonClass",</span>
<span class="changed"> 122                                                     pre_meta_values.non_class_used(),</span>
<span class="changed"> 123                                                     pre_meta_values.non_class_committed(),</span>
<span class="changed"> 124                                                     meta_values.non_class_used(),</span>
<span class="changed"> 125                                                     meta_values.non_class_committed()),</span>
<span class="changed"> 126                             HEAP_CHANGE_FORMAT_ARGS("Class",</span>
<span class="changed"> 127                                                     pre_meta_values.class_used(),</span>
<span class="changed"> 128                                                     pre_meta_values.class_committed(),</span>
<span class="changed"> 129                                                     meta_values.class_used(),</span>
<span class="changed"> 130                                                     meta_values.class_committed()));</span>
<span class="changed"> 131   } else {</span>
<span class="changed"> 132     log_info(gc, metaspace)(HEAP_CHANGE_FORMAT,</span>
<span class="changed"> 133                             HEAP_CHANGE_FORMAT_ARGS("Metaspace",</span>
<span class="changed"> 134                                                     pre_meta_values.used(),</span>
<span class="changed"> 135                                                     pre_meta_values.committed(),</span>
<span class="changed"> 136                                                     meta_values.used(),</span>
<span class="changed"> 137                                                     meta_values.committed()));</span>
<span class="changed"> 138   }</span>
<span class="changed"> 139 }</span>
<span class="changed"> 140 </span>
<span class="changed"> 141 // This will print out a basic metaspace usage report but</span>
<span class="changed"> 142 // unlike print_report() is guaranteed not to lock or to walk the CLDG.</span>
<span class="changed"> 143 void MetaspaceUtils::print_basic_report(outputStream* out, size_t scale) {</span>
<span class="changed"> 144   MetaspaceReporter::print_basic_report(out, scale);</span>
<span class="changed"> 145 }</span>
<span class="changed"> 146 </span>
<span class="changed"> 147 // Prints a report about the current metaspace state.</span>
<span class="changed"> 148 // Optional parts can be enabled via flags.</span>
<span class="changed"> 149 // Function will walk the CLDG and will lock the expand lock; if that is not</span>
<span class="changed"> 150 // convenient, use print_basic_report() instead.</span>
<span class="changed"> 151 void MetaspaceUtils::print_full_report(outputStream* out, size_t scale) {</span>
<span class="changed"> 152   const int flags =</span>
<span class="changed"> 153       MetaspaceReporter::rf_show_loaders |</span>
<span class="changed"> 154       MetaspaceReporter::rf_break_down_by_chunktype |</span>
<span class="changed"> 155       MetaspaceReporter::rf_show_classes;</span>
<span class="changed"> 156   MetaspaceReporter::print_report(out, scale, flags);</span>
<span class="changed"> 157 }</span>
<span class="changed"> 158 </span>
<span class="changed"> 159 void MetaspaceUtils::print_on(outputStream* out) {</span>
 160 
<a name="13" id="anc13"></a><span class="changed"> 161   // Used from all GCs. It first prints out totals, then, separately, the class space portion.</span>
<span class="changed"> 162 </span>
<span class="changed"> 163   out-&gt;print_cr(" Metaspace       "</span>
<span class="changed"> 164                 "used "      SIZE_FORMAT "K, "</span>
<span class="changed"> 165                 "committed " SIZE_FORMAT "K, "</span>
<span class="changed"> 166                 "reserved "  SIZE_FORMAT "K",</span>
<span class="changed"> 167                 used_bytes()/K,</span>
<span class="changed"> 168                 committed_bytes()/K,</span>
<span class="changed"> 169                 reserved_bytes()/K);</span>
<span class="changed"> 170 </span>
<span class="changed"> 171   if (Metaspace::using_class_space()) {</span>
<span class="changed"> 172     const Metaspace::MetadataType ct = Metaspace::ClassType;</span>
<span class="changed"> 173     out-&gt;print_cr("  class space    "</span>
<span class="changed"> 174                   "used "      SIZE_FORMAT "K, "</span>
<span class="changed"> 175                   "committed " SIZE_FORMAT "K, "</span>
<span class="changed"> 176                   "reserved "  SIZE_FORMAT "K",</span>
<span class="changed"> 177                   used_bytes(ct)/K,</span>
<span class="changed"> 178                   committed_bytes(ct)/K,</span>
<span class="changed"> 179                   reserved_bytes(ct)/K);</span>
 180   }
<a name="14" id="anc14"></a>
 181 }
 182 
<a name="15" id="anc15"></a><span class="changed"> 183 #ifdef ASSERT</span>
<span class="changed"> 184 void MetaspaceUtils::verify(bool slow) {</span>
<span class="changed"> 185   if (Metaspace::initialized()) {</span>
 186 
<a name="16" id="anc16"></a><span class="changed"> 187     // Verify non-class chunkmanager...</span>
<span class="changed"> 188     ChunkManager* cm = ChunkManager::chunkmanager_nonclass();</span>
<span class="changed"> 189     cm-&gt;verify(slow);</span>
<span class="changed"> 190 </span>
<span class="changed"> 191     // ... and space list.</span>
<span class="changed"> 192     VirtualSpaceList* vsl = VirtualSpaceList::vslist_nonclass();</span>
<span class="changed"> 193     vsl-&gt;verify(slow);</span>
<span class="changed"> 194 </span>
<span class="changed"> 195     if (Metaspace::using_class_space()) {</span>
<span class="changed"> 196       // If we use compressed class pointers, verify class chunkmanager...</span>
<span class="changed"> 197       cm = ChunkManager::chunkmanager_class();</span>
<span class="changed"> 198       assert(cm != NULL, "Sanity");</span>
<span class="changed"> 199       cm-&gt;verify(slow);</span>
<span class="changed"> 200 </span>
<span class="changed"> 201       // ... and class spacelist.</span>
<span class="changed"> 202       VirtualSpaceList* vsl = VirtualSpaceList::vslist_nonclass();</span>
<span class="changed"> 203       assert(vsl != NULL, "Sanity");</span>
<span class="changed"> 204       vsl-&gt;verify(slow);</span>
<span class="changed"> 205     }</span>
 206 
<a name="17" id="anc17"></a><span class="changed"> 207   }</span>
<span class="changed"> 208 }</span>
<span class="changed"> 209 #endif</span>
 210 
<a name="18" id="anc18"></a><span class="new"> 211 ////////////////////////////////7</span>
 212 // MetaspaceGC methods
 213 
<a name="19" id="anc19"></a><span class="new"> 214 volatile size_t MetaspaceGC::_capacity_until_GC = 0;</span>
<span class="new"> 215 uint MetaspaceGC::_shrink_factor = 0;</span>
<span class="new"> 216 </span>
 217 // VM_CollectForMetadataAllocation is the vm operation used to GC.
 218 // Within the VM operation after the GC the attempt to allocate the metadata
 219 // should succeed.  If the GC did not free enough space for the metaspace
 220 // allocation, the HWM is increased so that another virtualspace will be
 221 // allocated for the metadata.  With perm gen the increase in the perm
 222 // gen had bounds, MinMetaspaceExpansion and MaxMetaspaceExpansion.  The
 223 // metaspace policy uses those as the small and large steps for the HWM.
 224 //
 225 // After the GC the compute_new_size() for MetaspaceGC is called to
 226 // resize the capacity of the metaspaces.  The current implementation
 227 // is based on the flags MinMetaspaceFreeRatio and MaxMetaspaceFreeRatio used
 228 // to resize the Java heap by some GC's.  New flags can be implemented
 229 // if really needed.  MinMetaspaceFreeRatio is used to calculate how much
 230 // free space is desirable in the metaspace capacity to decide how much
 231 // to increase the HWM.  MaxMetaspaceFreeRatio is used to decide how much
 232 // free space is desirable in the metaspace capacity before decreasing
 233 // the HWM.
 234 
 235 // Calculate the amount to increase the high water mark (HWM).
 236 // Increase by a minimum amount (MinMetaspaceExpansion) so that
 237 // another expansion is not requested too soon.  If that is not
 238 // enough to satisfy the allocation, increase by MaxMetaspaceExpansion.
 239 // If that is still not enough, expand by the size of the allocation
 240 // plus some.
 241 size_t MetaspaceGC::delta_capacity_until_GC(size_t bytes) {
 242   size_t min_delta = MinMetaspaceExpansion;
 243   size_t max_delta = MaxMetaspaceExpansion;
 244   size_t delta = align_up(bytes, Metaspace::commit_alignment());
 245 
 246   if (delta &lt;= min_delta) {
 247     delta = min_delta;
 248   } else if (delta &lt;= max_delta) {
 249     // Don't want to hit the high water mark on the next
 250     // allocation so make the delta greater than just enough
 251     // for this allocation.
 252     delta = max_delta;
 253   } else {
 254     // This allocation is large but the next ones are probably not
 255     // so increase by the minimum.
 256     delta = delta + min_delta;
 257   }
 258 
 259   assert_is_aligned(delta, Metaspace::commit_alignment());
 260 
 261   return delta;
 262 }
 263 
 264 size_t MetaspaceGC::capacity_until_GC() {
 265   size_t value = Atomic::load_acquire(&amp;_capacity_until_GC);
 266   assert(value &gt;= MetaspaceSize, "Not initialized properly?");
 267   return value;
 268 }
 269 
 270 // Try to increase the _capacity_until_GC limit counter by v bytes.
 271 // Returns true if it succeeded. It may fail if either another thread
 272 // concurrently increased the limit or the new limit would be larger
 273 // than MaxMetaspaceSize.
 274 // On success, optionally returns new and old metaspace capacity in
 275 // new_cap_until_GC and old_cap_until_GC respectively.
 276 // On error, optionally sets can_retry to indicate whether if there is
 277 // actually enough space remaining to satisfy the request.
 278 bool MetaspaceGC::inc_capacity_until_GC(size_t v, size_t* new_cap_until_GC, size_t* old_cap_until_GC, bool* can_retry) {
 279   assert_is_aligned(v, Metaspace::commit_alignment());
 280 
 281   size_t old_capacity_until_GC = _capacity_until_GC;
 282   size_t new_value = old_capacity_until_GC + v;
 283 
 284   if (new_value &lt; old_capacity_until_GC) {
 285     // The addition wrapped around, set new_value to aligned max value.
 286     new_value = align_down(max_uintx, Metaspace::commit_alignment());
 287   }
 288 
 289   if (new_value &gt; MaxMetaspaceSize) {
 290     if (can_retry != NULL) {
 291       *can_retry = false;
 292     }
 293     return false;
 294   }
 295 
 296   if (can_retry != NULL) {
 297     *can_retry = true;
 298   }
 299   size_t prev_value = Atomic::cmpxchg(&amp;_capacity_until_GC, old_capacity_until_GC, new_value);
 300 
 301   if (old_capacity_until_GC != prev_value) {
 302     return false;
 303   }
 304 
 305   if (new_cap_until_GC != NULL) {
 306     *new_cap_until_GC = new_value;
 307   }
 308   if (old_cap_until_GC != NULL) {
 309     *old_cap_until_GC = old_capacity_until_GC;
 310   }
 311   return true;
 312 }
 313 
 314 size_t MetaspaceGC::dec_capacity_until_GC(size_t v) {
 315   assert_is_aligned(v, Metaspace::commit_alignment());
 316 
 317   return Atomic::sub(&amp;_capacity_until_GC, v);
 318 }
 319 
 320 void MetaspaceGC::initialize() {
 321   // Set the high-water mark to MaxMetapaceSize during VM initializaton since
 322   // we can't do a GC during initialization.
 323   _capacity_until_GC = MaxMetaspaceSize;
 324 }
 325 
 326 void MetaspaceGC::post_initialize() {
 327   // Reset the high-water mark once the VM initialization is done.
 328   _capacity_until_GC = MAX2(MetaspaceUtils::committed_bytes(), MetaspaceSize);
 329 }
 330 
 331 bool MetaspaceGC::can_expand(size_t word_size, bool is_class) {
 332   // Check if the compressed class space is full.
 333   if (is_class &amp;&amp; Metaspace::using_class_space()) {
 334     size_t class_committed = MetaspaceUtils::committed_bytes(Metaspace::ClassType);
 335     if (class_committed + word_size * BytesPerWord &gt; CompressedClassSpaceSize) {
 336       log_trace(gc, metaspace, freelist)("Cannot expand %s metaspace by " SIZE_FORMAT " words (CompressedClassSpaceSize = " SIZE_FORMAT " words)",
 337                 (is_class ? "class" : "non-class"), word_size, CompressedClassSpaceSize / sizeof(MetaWord));
 338       return false;
 339     }
 340   }
 341 
 342   // Check if the user has imposed a limit on the metaspace memory.
 343   size_t committed_bytes = MetaspaceUtils::committed_bytes();
 344   if (committed_bytes + word_size * BytesPerWord &gt; MaxMetaspaceSize) {
 345     log_trace(gc, metaspace, freelist)("Cannot expand %s metaspace by " SIZE_FORMAT " words (MaxMetaspaceSize = " SIZE_FORMAT " words)",
 346               (is_class ? "class" : "non-class"), word_size, MaxMetaspaceSize / sizeof(MetaWord));
 347     return false;
 348   }
 349 
 350   return true;
 351 }
 352 
 353 size_t MetaspaceGC::allowed_expansion() {
 354   size_t committed_bytes = MetaspaceUtils::committed_bytes();
 355   size_t capacity_until_gc = capacity_until_GC();
 356 
 357   assert(capacity_until_gc &gt;= committed_bytes,
 358          "capacity_until_gc: " SIZE_FORMAT " &lt; committed_bytes: " SIZE_FORMAT,
 359          capacity_until_gc, committed_bytes);
 360 
 361   size_t left_until_max  = MaxMetaspaceSize - committed_bytes;
 362   size_t left_until_GC = capacity_until_gc - committed_bytes;
 363   size_t left_to_commit = MIN2(left_until_GC, left_until_max);
 364   log_trace(gc, metaspace, freelist)("allowed expansion words: " SIZE_FORMAT
 365             " (left_until_max: " SIZE_FORMAT ", left_until_GC: " SIZE_FORMAT ".",
 366             left_to_commit / BytesPerWord, left_until_max / BytesPerWord, left_until_GC / BytesPerWord);
 367 
 368   return left_to_commit / BytesPerWord;
 369 }
 370 
 371 void MetaspaceGC::compute_new_size() {
 372   assert(_shrink_factor &lt;= 100, "invalid shrink factor");
 373   uint current_shrink_factor = _shrink_factor;
 374   _shrink_factor = 0;
 375 
 376   // Using committed_bytes() for used_after_gc is an overestimation, since the
 377   // chunk free lists are included in committed_bytes() and the memory in an
 378   // un-fragmented chunk free list is available for future allocations.
 379   // However, if the chunk free lists becomes fragmented, then the memory may
 380   // not be available for future allocations and the memory is therefore "in use".
 381   // Including the chunk free lists in the definition of "in use" is therefore
 382   // necessary. Not including the chunk free lists can cause capacity_until_GC to
 383   // shrink below committed_bytes() and this has caused serious bugs in the past.
 384   const size_t used_after_gc = MetaspaceUtils::committed_bytes();
 385   const size_t capacity_until_GC = MetaspaceGC::capacity_until_GC();
 386 
 387   const double minimum_free_percentage = MinMetaspaceFreeRatio / 100.0;
 388   const double maximum_used_percentage = 1.0 - minimum_free_percentage;
 389 
 390   const double min_tmp = used_after_gc / maximum_used_percentage;
 391   size_t minimum_desired_capacity =
 392     (size_t)MIN2(min_tmp, double(MaxMetaspaceSize));
 393   // Don't shrink less than the initial generation size
 394   minimum_desired_capacity = MAX2(minimum_desired_capacity,
 395                                   MetaspaceSize);
 396 
 397   log_trace(gc, metaspace)("MetaspaceGC::compute_new_size: ");
 398   log_trace(gc, metaspace)("    minimum_free_percentage: %6.2f  maximum_used_percentage: %6.2f",
 399                            minimum_free_percentage, maximum_used_percentage);
 400   log_trace(gc, metaspace)("     used_after_gc       : %6.1fKB", used_after_gc / (double) K);
 401 
 402 
 403   size_t shrink_bytes = 0;
 404   if (capacity_until_GC &lt; minimum_desired_capacity) {
 405     // If we have less capacity below the metaspace HWM, then
 406     // increment the HWM.
 407     size_t expand_bytes = minimum_desired_capacity - capacity_until_GC;
 408     expand_bytes = align_up(expand_bytes, Metaspace::commit_alignment());
 409     // Don't expand unless it's significant
 410     if (expand_bytes &gt;= MinMetaspaceExpansion) {
 411       size_t new_capacity_until_GC = 0;
 412       bool succeeded = MetaspaceGC::inc_capacity_until_GC(expand_bytes, &amp;new_capacity_until_GC);
 413       assert(succeeded, "Should always succesfully increment HWM when at safepoint");
 414 
 415       Metaspace::tracer()-&gt;report_gc_threshold(capacity_until_GC,
 416                                                new_capacity_until_GC,
 417                                                MetaspaceGCThresholdUpdater::ComputeNewSize);
 418       log_trace(gc, metaspace)("    expanding:  minimum_desired_capacity: %6.1fKB  expand_bytes: %6.1fKB  MinMetaspaceExpansion: %6.1fKB  new metaspace HWM:  %6.1fKB",
 419                                minimum_desired_capacity / (double) K,
 420                                expand_bytes / (double) K,
 421                                MinMetaspaceExpansion / (double) K,
 422                                new_capacity_until_GC / (double) K);
 423     }
 424     return;
 425   }
 426 
 427   // No expansion, now see if we want to shrink
 428   // We would never want to shrink more than this
 429   assert(capacity_until_GC &gt;= minimum_desired_capacity,
 430          SIZE_FORMAT " &gt;= " SIZE_FORMAT,
 431          capacity_until_GC, minimum_desired_capacity);
 432   size_t max_shrink_bytes = capacity_until_GC - minimum_desired_capacity;
 433 
 434   // Should shrinking be considered?
 435   if (MaxMetaspaceFreeRatio &lt; 100) {
 436     const double maximum_free_percentage = MaxMetaspaceFreeRatio / 100.0;
 437     const double minimum_used_percentage = 1.0 - maximum_free_percentage;
 438     const double max_tmp = used_after_gc / minimum_used_percentage;
 439     size_t maximum_desired_capacity = (size_t)MIN2(max_tmp, double(MaxMetaspaceSize));
 440     maximum_desired_capacity = MAX2(maximum_desired_capacity,
 441                                     MetaspaceSize);
 442     log_trace(gc, metaspace)("    maximum_free_percentage: %6.2f  minimum_used_percentage: %6.2f",
 443                              maximum_free_percentage, minimum_used_percentage);
 444     log_trace(gc, metaspace)("    minimum_desired_capacity: %6.1fKB  maximum_desired_capacity: %6.1fKB",
 445                              minimum_desired_capacity / (double) K, maximum_desired_capacity / (double) K);
 446 
 447     assert(minimum_desired_capacity &lt;= maximum_desired_capacity,
 448            "sanity check");
 449 
 450     if (capacity_until_GC &gt; maximum_desired_capacity) {
 451       // Capacity too large, compute shrinking size
 452       shrink_bytes = capacity_until_GC - maximum_desired_capacity;
 453       // We don't want shrink all the way back to initSize if people call
 454       // System.gc(), because some programs do that between "phases" and then
 455       // we'd just have to grow the heap up again for the next phase.  So we
 456       // damp the shrinking: 0% on the first call, 10% on the second call, 40%
 457       // on the third call, and 100% by the fourth call.  But if we recompute
 458       // size without shrinking, it goes back to 0%.
 459       shrink_bytes = shrink_bytes / 100 * current_shrink_factor;
 460 
 461       shrink_bytes = align_down(shrink_bytes, Metaspace::commit_alignment());
 462 
 463       assert(shrink_bytes &lt;= max_shrink_bytes,
 464              "invalid shrink size " SIZE_FORMAT " not &lt;= " SIZE_FORMAT,
 465              shrink_bytes, max_shrink_bytes);
 466       if (current_shrink_factor == 0) {
 467         _shrink_factor = 10;
 468       } else {
 469         _shrink_factor = MIN2(current_shrink_factor * 4, (uint) 100);
 470       }
 471       log_trace(gc, metaspace)("    shrinking:  initThreshold: %.1fK  maximum_desired_capacity: %.1fK",
 472                                MetaspaceSize / (double) K, maximum_desired_capacity / (double) K);
 473       log_trace(gc, metaspace)("    shrink_bytes: %.1fK  current_shrink_factor: %d  new shrink factor: %d  MinMetaspaceExpansion: %.1fK",
 474                                shrink_bytes / (double) K, current_shrink_factor, _shrink_factor, MinMetaspaceExpansion / (double) K);
 475     }
 476   }
 477 
 478   // Don't shrink unless it's significant
 479   if (shrink_bytes &gt;= MinMetaspaceExpansion &amp;&amp;
 480       ((capacity_until_GC - shrink_bytes) &gt;= MetaspaceSize)) {
 481     size_t new_capacity_until_GC = MetaspaceGC::dec_capacity_until_GC(shrink_bytes);
 482     Metaspace::tracer()-&gt;report_gc_threshold(capacity_until_GC,
 483                                              new_capacity_until_GC,
 484                                              MetaspaceGCThresholdUpdater::ComputeNewSize);
 485   }
 486 }
 487 
<a name="20" id="anc20"></a>

















































































































































































































































































































































































































































































































































































 488 
<a name="21" id="anc21"></a>







 489 
<a name="22" id="anc22"></a><span class="changed"> 490 //////  Metaspace methods /////</span>





























 491 
<a name="23" id="anc23"></a>
 492 
<a name="24" id="anc24"></a>

 493 
<a name="25" id="anc25"></a><span class="new"> 494 MetaWord* Metaspace::_compressed_class_space_base = NULL;</span>
<span class="new"> 495 size_t Metaspace::_compressed_class_space_size = 0;</span>
<span class="new"> 496 const MetaspaceTracer* Metaspace::_tracer = NULL;</span>
<span class="new"> 497 bool Metaspace::_initialized = false;</span>
 498 size_t Metaspace::_commit_alignment = 0;
 499 size_t Metaspace::_reserve_alignment = 0;
 500 
<a name="26" id="anc26"></a><span class="changed"> 501 DEBUG_ONLY(bool Metaspace::_frozen = false;)</span>






 502 
<a name="27" id="anc27"></a>
 503 
 504 #ifdef _LP64
 505 
 506 void Metaspace::print_compressed_class_space(outputStream* st) {
<a name="28" id="anc28"></a><span class="changed"> 507   if (VirtualSpaceList::vslist_class() != NULL) {</span>
<span class="changed"> 508     MetaWord* base = VirtualSpaceList::vslist_class()-&gt;base_of_first_node();</span>
<span class="changed"> 509     size_t size = VirtualSpaceList::vslist_class()-&gt;word_size_of_first_node();</span>
<span class="changed"> 510     MetaWord* top = base + size;</span>
<span class="changed"> 511     st-&gt;print("Compressed class space mapped at: " PTR_FORMAT "-" PTR_FORMAT ", reserved size: " SIZE_FORMAT,</span>
<span class="changed"> 512                p2i(base), p2i(top), (top - base) * BytesPerWord);</span>
 513     st-&gt;cr();
 514   }
 515 }
 516 
 517 // Given a prereserved space, use that to set up the compressed class space list.
 518 void Metaspace::initialize_class_space(ReservedSpace rs) {
<a name="29" id="anc29"></a><span class="new"> 519   assert(rs.size() &gt;= CompressedClassSpaceSize,</span>
<span class="new"> 520          SIZE_FORMAT " != " SIZE_FORMAT, rs.size(), CompressedClassSpaceSize);</span>
 521   assert(using_class_space(), "Must be using class space");
<a name="30" id="anc30"></a>
 522 
 523   assert(rs.size() == CompressedClassSpaceSize, SIZE_FORMAT " != " SIZE_FORMAT,
 524          rs.size(), CompressedClassSpaceSize);
 525   assert(is_aligned(rs.base(), Metaspace::reserve_alignment()) &amp;&amp;
 526          is_aligned(rs.size(), Metaspace::reserve_alignment()),
 527          "wrong alignment");
 528 
<a name="31" id="anc31"></a><span class="changed"> 529   MetaspaceContext::initialize_class_space_context(rs);</span>

 530 
 531   // This does currently not work because rs may be the result of a split
 532   // operation and NMT seems not to be able to handle splits.
 533   // Will be fixed with JDK-8243535.
 534   // MemTracker::record_virtual_memory_type((address)rs.base(), mtClass);
 535 
<a name="32" id="anc32"></a><span class="changed"> 536 }</span>


 537 
<a name="33" id="anc33"></a><span class="new"> 538 // Returns true if class space has been setup (initialize_class_space).</span>
<span class="new"> 539 bool Metaspace::class_space_is_initialized() {</span>
<span class="new"> 540   return MetaspaceContext::contect_class() != NULL;</span>
 541 }
 542 
 543 // Reserve a range of memory at an address suitable for en/decoding narrow
 544 // Klass pointers (see: CompressedClassPointers::is_valid_base()).
 545 // The returned address shall both be suitable as a compressed class pointers
 546 //  base, and aligned to Metaspace::reserve_alignment (which is equal to or a
 547 //  multiple of allocation granularity).
 548 // On error, returns an unreserved space.
 549 ReservedSpace Metaspace::reserve_address_space_for_compressed_classes(size_t size) {
 550 
 551 #ifdef AARCH64
 552   const size_t alignment = Metaspace::reserve_alignment();
 553 
 554   // AArch64: Try to align metaspace so that we can decode a compressed
 555   // klass with a single MOVK instruction. We can do this iff the
 556   // compressed class base is a multiple of 4G.
 557   // Additionally, above 32G, ensure the lower LogKlassAlignmentInBytes bits
 558   // of the upper 32-bits of the address are zero so we can handle a shift
 559   // when decoding.
 560 
 561   static const struct {
 562     address from;
 563     address to;
 564     size_t increment;
 565   } search_ranges[] = {
 566     {  (address)(4*G),   (address)(32*G),   4*G, },
 567     {  (address)(32*G),  (address)(1024*G), (4 &lt;&lt; LogKlassAlignmentInBytes) * G },
 568     {  NULL, NULL, 0 }
 569   };
 570 
 571   for (int i = 0; search_ranges[i].from != NULL; i ++) {
 572     address a = search_ranges[i].from;
 573     assert(CompressedKlassPointers::is_valid_base(a), "Sanity");
 574     while (a &lt; search_ranges[i].to) {
 575       ReservedSpace rs(size, Metaspace::reserve_alignment(),
 576                        false /*large_pages*/, (char*)a);
 577       if (rs.is_reserved()) {
 578         assert(a == (address)rs.base(), "Sanity");
 579         return rs;
 580       }
 581       a +=  search_ranges[i].increment;
 582     }
 583   }
 584 
 585   // Note: on AARCH64, if the code above does not find any good placement, we
 586   // have no recourse. We return an empty space and the VM will exit.
 587   return ReservedSpace();
 588 #else
 589   // Default implementation: Just reserve anywhere.
 590   return ReservedSpace(size, Metaspace::reserve_alignment(), false, (char*)NULL);
 591 #endif // AARCH64
 592 }
 593 
 594 #endif // _LP64
 595 
 596 
 597 void Metaspace::ergo_initialize() {
<a name="34" id="anc34"></a>



 598 
<a name="35" id="anc35"></a><span class="changed"> 599   // Must happen before using any setting from Settings::---</span>
<span class="changed"> 600   metaspace::Settings::ergo_initialize();</span>


 601 
<a name="36" id="anc36"></a><span class="changed"> 602   // Commit alignment: (I would rather hide this since this is an implementation detail but we need it</span>
<span class="changed"> 603   // when calculating the gc threshold).</span>
<span class="changed"> 604   _commit_alignment  = metaspace::Settings::commit_granule_bytes();</span>
<span class="changed"> 605 </span>
<span class="changed"> 606   // Reserve alignment: all Metaspace memory mappings are to be aligned to the size of a root chunk.</span>
<span class="changed"> 607   _reserve_alignment = MAX2((size_t)os::vm_allocation_granularity(), metaspace::chunklevel::MAX_CHUNK_BYTE_SIZE);</span>
 608 
<a name="37" id="anc37"></a>





 609 
<a name="38" id="anc38"></a><span class="changed"> 610   // MaxMetaspaceSize and CompressedClassSpaceSize:</span>
<span class="changed"> 611   //</span>
<span class="changed"> 612   // MaxMetaspaceSize is the maximum size, in bytes, of memory we are allowed</span>
<span class="changed"> 613   //  to commit for the Metaspace.</span>
<span class="changed"> 614   //  It is just a number; a limit we compare against before committing. It</span>
<span class="changed"> 615   //  does not have to be aligned to anything.</span>
<span class="changed"> 616   //  It gets used as compare value in class CommitLimiter.</span>
<span class="changed"> 617   //  It is set to max_uintx in globals.hpp by default, so by default it does</span>
<span class="changed"> 618   //  not limit anything.</span>
<span class="changed"> 619   //</span>
<span class="changed"> 620   // CompressedClassSpaceSize is the size, in bytes, of the address range we</span>
<span class="changed"> 621   //  pre-reserve for the compressed class space (if we use class space).</span>
<span class="changed"> 622   //  This size has to be aligned to the metaspace reserve alignment (to the</span>
<span class="changed"> 623   //  size of a root chunk). It gets aligned up from whatever value the caller</span>
<span class="changed"> 624   //  gave us to the next multiple of root chunk size.</span>
 625   //
<a name="39" id="anc39"></a><span class="changed"> 626   // Note: Strictly speaking MaxMetaspaceSize and CompressedClassSpaceSize have</span>
<span class="changed"> 627   //  very little to do with each other. The notion often encountered:</span>
<span class="changed"> 628   //  MaxMetaspaceSize = CompressedClassSpaceSize + &lt;non-class metadata size&gt;</span>
<span class="changed"> 629   //  is subtly wrong: MaxMetaspaceSize can besmaller than CompressedClassSpaceSize,</span>
<span class="changed"> 630   //  in which case we just would not be able to fully commit the class space range.</span>
<span class="changed"> 631   //</span>
<span class="changed"> 632   // We still adjust CompressedClassSpaceSize to reasonable limits, mainly to</span>
<span class="changed"> 633   //  save on reserved space, and to make ergnonomics less confusing.</span>
<span class="changed"> 634 </span>
<span class="changed"> 635   // (aligned just for cleanliness:)</span>
<span class="changed"> 636   MaxMetaspaceSize = MAX2(align_down(MaxMetaspaceSize, _commit_alignment), _commit_alignment);</span>
 637 
<a name="40" id="anc40"></a><span class="new"> 638   if (UseCompressedClassPointers) {</span>
<span class="new"> 639     // Let CCS size not be larger than 80% of MaxMetaspaceSize. Note that is</span>
<span class="new"> 640     // grossly over-dimensioned for most usage scenarios; typical ratio of</span>
<span class="new"> 641     // class space : non class space usage is about 1:6. With many small classes,</span>
<span class="new"> 642     // it can get as low as 1:2. It is not a big deal though since ccs is only</span>
<span class="new"> 643     // reserved and will be committed on demand only.</span>
<span class="new"> 644     size_t max_ccs_size = MaxMetaspaceSize * 0.8;</span>
<span class="new"> 645     size_t adjusted_ccs_size = MIN2(CompressedClassSpaceSize, max_ccs_size);</span>
<span class="new"> 646 </span>
<span class="new"> 647     // CCS must be aligned to root chunk size, and be at least the size of one</span>
<span class="new"> 648     //  root chunk.</span>
<span class="new"> 649     adjusted_ccs_size = align_up(adjusted_ccs_size, _reserve_alignment);</span>
<span class="new"> 650     adjusted_ccs_size = MAX2(adjusted_ccs_size, _reserve_alignment);</span>
<span class="new"> 651 </span>
<span class="new"> 652     // Note: re-adjusting may have us left with a CompressedClassSpaceSize</span>
<span class="new"> 653     //  larger than MaxMetaspaceSize for very small values of MaxMetaspaceSize.</span>
<span class="new"> 654     //  Lets just live with that, its not a big deal.</span>
<span class="new"> 655 </span>
<span class="new"> 656     if (adjusted_ccs_size != CompressedClassSpaceSize) {</span>
<span class="new"> 657       FLAG_SET_ERGO(CompressedClassSpaceSize, adjusted_ccs_size);</span>
<span class="new"> 658       log_info(metaspace)("Setting CompressedClassSpaceSize to " SIZE_FORMAT ".",</span>
<span class="new"> 659                           CompressedClassSpaceSize);</span>
<span class="new"> 660     }</span>
<span class="new"> 661   }</span>
<span class="new"> 662 </span>
<span class="new"> 663   // Set MetaspaceSize, MinMetaspaceExpansion and MaxMetaspaceExpansion</span>
 664   if (MetaspaceSize &gt; MaxMetaspaceSize) {
 665     MetaspaceSize = MaxMetaspaceSize;
 666   }
 667 
 668   MetaspaceSize = align_down_bounded(MetaspaceSize, _commit_alignment);
 669 
 670   assert(MetaspaceSize &lt;= MaxMetaspaceSize, "MetaspaceSize should be limited by MaxMetaspaceSize");
 671 
 672   MinMetaspaceExpansion = align_down_bounded(MinMetaspaceExpansion, _commit_alignment);
 673   MaxMetaspaceExpansion = align_down_bounded(MaxMetaspaceExpansion, _commit_alignment);
 674 
<a name="41" id="anc41"></a><span class="changed"> 675   _compressed_class_space_size = CompressedClassSpaceSize;</span>
 676 
<a name="42" id="anc42"></a>

















 677 }
 678 
 679 void Metaspace::global_initialize() {
<a name="43" id="anc43"></a><span class="changed"> 680   MetaspaceGC::initialize(); // &lt;- since we do not prealloc init chunks anymore is this still needed?</span>
 681 
 682   // If UseCompressedClassPointers=1, we have two cases:
 683   // a) if CDS is active (either dump time or runtime), it will create the ccs
 684   //    for us, initialize it and set up CompressedKlassPointers encoding.
 685   //    Class space will be reserved above the mapped archives.
 686   // b) if CDS is not active, we will create the ccs on our own. It will be
 687   //    placed above the java heap, since we assume it has been placed in low
 688   //    address regions. We may rethink this (see JDK-8244943). Failing that,
 689   //    it will be placed anywhere.
 690 
 691 #if INCLUDE_CDS
 692   // case (a)
 693   if (DumpSharedSpaces) {
 694     MetaspaceShared::initialize_dumptime_shared_and_meta_spaces();
 695   } else if (UseSharedSpaces) {
 696     // If any of the archived space fails to map, UseSharedSpaces
 697     // is reset to false.
 698     MetaspaceShared::initialize_runtime_shared_and_meta_spaces();
 699   }
 700 
 701   if (DynamicDumpSharedSpaces &amp;&amp; !UseSharedSpaces) {
 702     vm_exit_during_initialization("DynamicDumpSharedSpaces is unsupported when base CDS archive is not loaded", NULL);
 703   }
 704 #endif // INCLUDE_CDS
 705 
 706 #ifdef _LP64
 707 
 708   if (using_class_space() &amp;&amp; !class_space_is_initialized()) {
 709     assert(!UseSharedSpaces &amp;&amp; !DumpSharedSpaces, "CDS should be off at this point");
 710 
 711     // case (b)
 712     ReservedSpace rs;
 713 
 714     // If UseCompressedOops=1, java heap may have been placed in coops-friendly
 715     //  territory already (lower address regions), so we attempt to place ccs
 716     //  right above the java heap.
 717     // If UseCompressedOops=0, the heap has been placed anywhere - probably in
 718     //  high memory regions. In that case, try to place ccs at the lowest allowed
 719     //  mapping address.
 720     address base = UseCompressedOops ? CompressedOops::end() : (address)HeapBaseMinAddress;
 721     base = align_up(base, Metaspace::reserve_alignment());
 722 
 723     const size_t size = align_up(CompressedClassSpaceSize, Metaspace::reserve_alignment());
 724     if (base != NULL) {
 725       if (CompressedKlassPointers::is_valid_base(base)) {
 726         rs = ReservedSpace(size, Metaspace::reserve_alignment(),
 727                            false /* large */, (char*)base);
 728       }
 729     }
 730 
 731     // ...failing that, reserve anywhere, but let platform do optimized placement:
 732     if (!rs.is_reserved()) {
 733       rs = Metaspace::reserve_address_space_for_compressed_classes(size);
 734     }
 735 
 736     // ...failing that, give up.
 737     if (!rs.is_reserved()) {
 738       vm_exit_during_initialization(
 739           err_msg("Could not allocate compressed class space: " SIZE_FORMAT " bytes",
 740                    compressed_class_space_size()));
 741     }
 742 
 743     // Initialize space
 744     Metaspace::initialize_class_space(rs);
 745 
 746     // Set up compressed class pointer encoding.
 747     CompressedKlassPointers::initialize((address)rs.base(), rs.size());
 748   }
 749 
 750 #endif
 751 
<a name="44" id="anc44"></a><span class="changed"> 752   // Initialize non-class virtual space list, and its chunk manager:</span>
<span class="changed"> 753   MetaspaceContext::initialize_nonclass_space_context();</span>



















 754 
 755   _tracer = new MetaspaceTracer();
 756 
 757   _initialized = true;
 758 
<a name="45" id="anc45"></a><span class="new"> 759   // We must prevent the very first address of the ccs from being used to store</span>
<span class="new"> 760   // metadata, since that address would translate to a narrow pointer of 0, and the</span>
<span class="new"> 761   // VM does not distinguish between "narrow 0 as in NULL" and "narrow 0 as in start</span>
<span class="new"> 762   //  of ccs".</span>
<span class="new"> 763   // Before Elastic Metaspace that did not happen due to the fact that every Metachunk</span>
<span class="new"> 764   // had a header and therefore could not allocate anything at offset 0.</span>
<span class="new"> 765 #ifdef _LP64</span>
<span class="new"> 766   if (using_class_space()) {</span>
<span class="new"> 767     // The simplest way to fix this is to allocate a tiny dummy chunk right at the</span>
<span class="new"> 768     // start of ccs and do not use it for anything.</span>
<span class="new"> 769     MetaspaceContext::contect_class()-&gt;cm()-&gt;get_chunk(metaspace::chunklevel::HIGHEST_CHUNK_LEVEL);</span>
<span class="new"> 770   }</span>
<span class="new"> 771 #endif</span>
<span class="new"> 772 </span>
 773 #ifdef _LP64
 774   if (UseCompressedClassPointers) {
 775     // Note: "cds" would be a better fit but keep this for backward compatibility.
 776     LogTarget(Info, gc, metaspace) lt;
 777     if (lt.is_enabled()) {
 778       ResourceMark rm;
 779       LogStream ls(lt);
 780       CDS_ONLY(MetaspaceShared::print_on(&amp;ls);)
 781       Metaspace::print_compressed_class_space(&amp;ls);
 782       CompressedKlassPointers::print_mode(&amp;ls);
 783     }
 784   }
 785 #endif
 786 
 787 }
 788 
 789 void Metaspace::post_initialize() {
 790   MetaspaceGC::post_initialize();
 791 }
 792 
<a name="46" id="anc46"></a><span class="changed"> 793 size_t Metaspace::max_allocation_word_size() {</span>
<span class="changed"> 794   const size_t max_overhead_words = metaspace::get_raw_word_size_for_requested_word_size(1);</span>
<span class="changed"> 795   return metaspace::chunklevel::MAX_CHUNK_WORD_SIZE - max_overhead_words;</span>










 796 }
 797 
 798 MetaWord* Metaspace::allocate(ClassLoaderData* loader_data, size_t word_size,
 799                               MetaspaceObj::Type type, TRAPS) {
<a name="47" id="anc47"></a><span class="new"> 800   assert(word_size &lt;= Metaspace::max_allocation_word_size(),</span>
<span class="new"> 801          "allocation size too large (" SIZE_FORMAT ")", word_size);</span>
 802   assert(!_frozen, "sanity");
 803   assert(!(DumpSharedSpaces &amp;&amp; THREAD-&gt;is_VM_thread()), "sanity");
 804 
 805   if (HAS_PENDING_EXCEPTION) {
 806     assert(false, "Should not allocate with exception pending");
 807     return NULL;  // caller does a CHECK_NULL too
 808   }
 809 
 810   assert(loader_data != NULL, "Should never pass around a NULL loader_data. "
 811         "ClassLoaderData::the_null_class_loader_data() should have been used.");
 812 
<a name="48" id="anc48"></a><span class="changed"> 813   Metaspace::MetadataType mdtype = (type == MetaspaceObj::ClassType) ? Metaspace::ClassType : Metaspace::NonClassType;</span>
 814 
 815   // Try to allocate metadata.
 816   MetaWord* result = loader_data-&gt;metaspace_non_null()-&gt;allocate(word_size, mdtype);
 817 
 818   if (result == NULL) {
 819     tracer()-&gt;report_metaspace_allocation_failure(loader_data, word_size, type, mdtype);
 820 
 821     // Allocation failed.
 822     if (is_init_completed()) {
 823       // Only start a GC if the bootstrapping has completed.
 824       // Try to clean out some heap memory and retry. This can prevent premature
 825       // expansion of the metaspace.
 826       result = Universe::heap()-&gt;satisfy_failed_metadata_allocation(loader_data, word_size, mdtype);
 827     }
 828   }
 829 
 830   if (result == NULL) {
 831     if (DumpSharedSpaces) {
 832       // CDS dumping keeps loading classes, so if we hit an OOM we probably will keep hitting OOM.
 833       // We should abort to avoid generating a potentially bad archive.
 834       vm_exit_during_cds_dumping(err_msg("Failed allocating metaspace object type %s of size " SIZE_FORMAT ". CDS dump aborted.",
 835           MetaspaceObj::type_name(type), word_size * BytesPerWord),
 836         err_msg("Please increase MaxMetaspaceSize (currently " SIZE_FORMAT " bytes).", MaxMetaspaceSize));
 837     }
 838     report_metadata_oome(loader_data, word_size, type, mdtype, THREAD);
 839     assert(HAS_PENDING_EXCEPTION, "sanity");
 840     return NULL;
 841   }
 842 
 843   // Zero initialize.
 844   Copy::fill_to_words((HeapWord*)result, word_size, 0);
 845 
<a name="49" id="anc49"></a><span class="new"> 846   log_trace(metaspace)("Metaspace::allocate: type %d return " PTR_FORMAT ".", (int)type, p2i(result));</span>
<span class="new"> 847 </span>
 848   return result;
 849 }
 850 
 851 void Metaspace::report_metadata_oome(ClassLoaderData* loader_data, size_t word_size, MetaspaceObj::Type type, MetadataType mdtype, TRAPS) {
 852   tracer()-&gt;report_metadata_oom(loader_data, word_size, type, mdtype);
 853 
 854   // If result is still null, we are out of memory.
 855   Log(gc, metaspace, freelist, oom) log;
 856   if (log.is_info()) {
 857     log.info("Metaspace (%s) allocation failed for size " SIZE_FORMAT,
<a name="50" id="anc50"></a><span class="changed"> 858              metaspace::is_class(mdtype) ? "class" : "data", word_size);</span>
 859     ResourceMark rm;
 860     if (log.is_debug()) {
 861       if (loader_data-&gt;metaspace_or_null() != NULL) {
 862         LogStream ls(log.debug());
 863         loader_data-&gt;print_value_on(&amp;ls);
 864       }
 865     }
 866     LogStream ls(log.info());
 867     // In case of an OOM, log out a short but still useful report.
 868     MetaspaceUtils::print_basic_report(&amp;ls, 0);
 869   }
 870 
<a name="51" id="anc51"></a><span class="new"> 871   // Which limit did we hit? CompressedClassSpaceSize or MaxMetaspaceSize?</span>
 872   bool out_of_compressed_class_space = false;
<a name="52" id="anc52"></a><span class="changed"> 873   if (metaspace::is_class(mdtype)) {</span>
 874     ClassLoaderMetaspace* metaspace = loader_data-&gt;metaspace_non_null();
 875     out_of_compressed_class_space =
 876       MetaspaceUtils::committed_bytes(Metaspace::ClassType) +
<a name="53" id="anc53"></a><span class="changed"> 877       // TODO: Okay this is just cheesy.</span>
<span class="changed"> 878       // Of course this may fail and return incorrect results.</span>
<span class="changed"> 879       // Think this over - we need some clean way to remember which limit</span>
<span class="changed"> 880       // exactly we hit during an allocation. Some sort of allocation context structure?</span>
<span class="changed"> 881       align_up(word_size * BytesPerWord, 4 * M) &gt;</span>
 882       CompressedClassSpaceSize;
 883   }
 884 
 885   // -XX:+HeapDumpOnOutOfMemoryError and -XX:OnOutOfMemoryError support
 886   const char* space_string = out_of_compressed_class_space ?
 887     "Compressed class space" : "Metaspace";
 888 
 889   report_java_out_of_memory(space_string);
 890 
 891   if (JvmtiExport::should_post_resource_exhausted()) {
 892     JvmtiExport::post_resource_exhausted(
 893         JVMTI_RESOURCE_EXHAUSTED_OOM_ERROR,
 894         space_string);
 895   }
 896 
 897   if (!is_init_completed()) {
 898     vm_exit_during_initialization("OutOfMemoryError", space_string);
 899   }
 900 
 901   if (out_of_compressed_class_space) {
 902     THROW_OOP(Universe::out_of_memory_error_class_metaspace());
 903   } else {
 904     THROW_OOP(Universe::out_of_memory_error_metaspace());
 905   }
 906 }
 907 
<a name="54" id="anc54"></a>













 908 void Metaspace::purge() {
<a name="55" id="anc55"></a><span class="changed"> 909   ChunkManager* cm = ChunkManager::chunkmanager_nonclass();</span>
<span class="changed"> 910   if (cm != NULL) {</span>
<span class="changed"> 911     cm-&gt;purge();</span>
<span class="changed"> 912   }</span>
 913   if (using_class_space()) {
<a name="56" id="anc56"></a><span class="changed"> 914     cm = ChunkManager::chunkmanager_class();</span>
<span class="changed"> 915     if (cm != NULL) {</span>
<span class="changed"> 916       cm-&gt;purge();</span>
<span class="changed"> 917     }</span>
 918   }
 919 }
 920 
 921 bool Metaspace::contains(const void* ptr) {
 922   if (MetaspaceShared::is_in_shared_metaspace(ptr)) {
 923     return true;
 924   }
 925   return contains_non_shared(ptr);
 926 }
 927 
 928 bool Metaspace::contains_non_shared(const void* ptr) {
<a name="57" id="anc57"></a><span class="changed"> 929   if (using_class_space() &amp;&amp; VirtualSpaceList::vslist_class()-&gt;contains((MetaWord*)ptr)) {</span>
 930      return true;
 931   }
 932 
<a name="58" id="anc58"></a><span class="changed"> 933   return VirtualSpaceList::vslist_nonclass()-&gt;contains((MetaWord*)ptr);</span>













































































































































































































 934 }
<a name="59" id="anc59"></a><b style="font-size: large; color: red">--- EOF ---</b>















































































</pre><form name="eof"><input name="value" value="59" type="hidden" /></form></body></html>
