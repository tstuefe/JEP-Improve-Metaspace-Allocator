<?xml version="1.0"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head><meta charset="utf-8">
<meta http-equiv="cache-control" content="no-cache" />
<meta http-equiv="Pragma" content="no-cache" />
<meta http-equiv="Expires" content="-1" />
<!--
   Note to customizers: the body of the webrev is IDed as SUNWwebrev
   to allow easy overriding by users of webrev via the userContent.css
   mechanism available in some browsers.

   For example, to have all "removed" information be red instead of
   brown, set a rule in your userContent.css file like:

       body#SUNWwebrev span.removed { color: red ! important; }
-->
<style type="text/css" media="screen">
body {
    background-color: #eeeeee;
}
hr {
    border: none 0;
    border-top: 1px solid #aaa;
    height: 1px;
}
div.summary {
    font-size: .8em;
    border-bottom: 1px solid #aaa;
    padding-left: 1em;
    padding-right: 1em;
}
div.summary h2 {
    margin-bottom: 0.3em;
}
div.summary table th {
    text-align: right;
    vertical-align: top;
    white-space: nowrap;
}
span.lineschanged {
    font-size: 0.7em;
}
span.oldmarker {
    color: red;
    font-size: large;
    font-weight: bold;
}
span.newmarker {
    color: green;
    font-size: large;
    font-weight: bold;
}
span.removed {
    color: brown;
}
span.changed {
    color: blue;
}
span.new {
    color: blue;
    font-weight: bold;
}
a.print { font-size: x-small; }

</style>

<style type="text/css" media="print">
pre { font-size: 0.8em; font-family: courier, monospace; }
span.removed { color: #444; font-style: italic }
span.changed { font-weight: bold; }
span.new { font-weight: bold; }
span.newmarker { font-size: 1.2em; font-weight: bold; }
span.oldmarker { font-size: 1.2em; font-weight: bold; }
a.print {display: none}
hr { border: none 0; border-top: 1px solid #aaa; height: 1px; }
</style>

<title>New src/hotspot/share/memory/metaspace/virtualSpaceNode.cpp</title>
<body id="SUNWwebrev">
<pre>
   1 /*
   2  * Copyright (c) 2018, 2019, Oracle and/or its affiliates. All rights reserved.
   3  * Copyright (c) 2018, 2019 SAP SE. All rights reserved.
   4  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   5  *
   6  * This code is free software; you can redistribute it and/or modify it
   7  * under the terms of the GNU General Public License version 2 only, as
   8  * published by the Free Software Foundation.
   9  *
  10  * This code is distributed in the hope that it will be useful, but WITHOUT
  11  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  12  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  13  * version 2 for more details (a copy is included in the LICENSE file that
  14  * accompanied this code).
  15  *
  16  * You should have received a copy of the GNU General Public License version
  17  * 2 along with this work; if not, write to the Free Software Foundation,
  18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  19  *
  20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  21  * or visit www.oracle.com if you need additional information or have any
  22  * questions.
  23  *
  24  */
  25 
  26 
  27 
  28 #include "precompiled.hpp"
  29 
  30 #include "logging/log.hpp"
  31 
  32 #include "memory/metaspace/chunkLevel.hpp"
  33 #include "memory/metaspace/chunkHeaderPool.hpp"
  34 #include "memory/metaspace/commitLimiter.hpp"
  35 #include "memory/metaspace/counter.hpp"
  36 #include "memory/metaspace/freeChunkList.hpp"
  37 #include "memory/metaspace/internStat.hpp"
  38 #include "memory/metaspace/metachunk.hpp"
  39 #include "memory/metaspace/metaspaceCommon.hpp"
  40 #include "memory/metaspace/rootChunkArea.hpp"
  41 #include "memory/metaspace/runningCounters.hpp"
  42 #include "memory/metaspace/settings.hpp"
  43 #include "memory/metaspace/virtualSpaceNode.hpp"
  44 #include "memory/metaspace.hpp"
  45 
  46 #include "runtime/globals.hpp"
  47 #include "runtime/mutexLocker.hpp"
  48 #include "runtime/os.hpp"
  49 
  50 #include "utilities/align.hpp"
  51 #include "utilities/debug.hpp"
  52 #include "utilities/globalDefinitions.hpp"
  53 #include "utilities/ostream.hpp"
  54 
  55 namespace metaspace {
  56 
  57 #define LOGFMT         "VsListNode @" PTR_FORMAT " base " PTR_FORMAT " "
  58 #define LOGFMT_ARGS    p2i(this), p2i(_base)
  59 
  60 #ifdef ASSERT
  61 void check_pointer_is_aligned_to_commit_granule(const MetaWord* p) {
  62   assert(is_aligned(p, Settings::commit_granule_bytes()),
  63          "Pointer not aligned to commit granule size: " PTR_FORMAT ".",
  64          p2i(p));
  65 }
  66 void check_word_size_is_aligned_to_commit_granule(size_t word_size) {
  67   assert(is_aligned(word_size, Settings::commit_granule_words()),
  68          "Not aligned to commit granule size: " SIZE_FORMAT ".", word_size);
  69 }
  70 #endif
  71 
  72 
  73 // Given an address range, ensure it is committed.
  74 //
  75 // The range has to be aligned to granule size.
  76 //
  77 // Function will:
  78 // - check how many granules in that region are uncommitted; If all are committed, it
  79 //    returns true immediately.
  80 // - check if committing those uncommitted granules would bring us over the commit limit
  81 //    (GC threshold, MaxMetaspaceSize). If true, it returns false.
  82 // - commit the memory.
  83 // - mark the range as committed in the commit mask
  84 //
  85 // Returns true if success, false if it did hit a commit limit.
  86 bool VirtualSpaceNode::commit_range(MetaWord* p, size_t word_size) {
  87 
  88   DEBUG_ONLY(check_pointer_is_aligned_to_commit_granule(p);)
  89   DEBUG_ONLY(check_word_size_is_aligned_to_commit_granule(word_size);)
  90   assert_lock_strong(MetaspaceExpand_lock);
  91 
  92   // First calculate how large the committed regions in this range are
  93   const size_t committed_words_in_range = _commit_mask.get_committed_size_in_range(p, word_size);
  94   DEBUG_ONLY(check_word_size_is_aligned_to_commit_granule(committed_words_in_range);)
  95 
  96   // By how much words we would increase commit charge
  97   //  were we to commit the given address range completely.
  98   const size_t commit_increase_words = word_size - committed_words_in_range;
  99 
 100   UL2(debug, "committing range " PTR_FORMAT ".." PTR_FORMAT "(" SIZE_FORMAT " words)",
 101       p2i(p), p2i(p + word_size), word_size);
 102 
 103   if (commit_increase_words == 0) {
 104     UL(debug, "... already fully committed.");
 105     return true; // Already fully committed, nothing to do.
 106   }
 107 
 108   // Before committing any more memory, check limits.
 109   if (_commit_limiter-&gt;possible_expansion_words() &lt; commit_increase_words) {
 110     UL(debug, "... cannot commit (limit).");
 111     return false;
 112   }
 113 
 114   // Commit...
 115   if (os::commit_memory((char*)p, word_size * BytesPerWord, false) == false) {
 116     vm_exit_out_of_memory(word_size * BytesPerWord, OOM_MMAP_ERROR, "Failed to commit metaspace.");
 117   }
 118 
 119   if (AlwaysPreTouch) {
 120     os::pretouch_memory(p, p + word_size);
 121   }
 122 
 123   UL2(debug, "... committed " SIZE_FORMAT " additional words.", commit_increase_words);
 124 
 125   // ... tell commit limiter...
 126   _commit_limiter-&gt;increase_committed(commit_increase_words);
 127 
 128   // ... update counters in containing vslist ...
 129   _total_committed_words_counter-&gt;increment_by(commit_increase_words);
 130 
 131   // ... and update the commit mask.
 132   _commit_mask.mark_range_as_committed(p, word_size);
 133 
 134 #ifdef ASSERT
 135   // The commit boundary maintained in the CommitLimiter should be equal the sum of committed words
 136   // in both class and non-class vslist (outside gtests).
 137   if (_commit_limiter == CommitLimiter::globalLimiter()) {
 138     assert(_commit_limiter-&gt;committed_words() == RunningCounters::committed_words(), "counter mismatch");
 139   }
 140 #endif
 141 
 142   InternalStats::inc_num_space_committed();
 143 
 144   return true;
 145 
 146 }
 147 
 148 // Given an address range, ensure it is committed.
 149 //
 150 // The range does not have to be aligned to granule size. However, the function will always commit
 151 // whole granules.
 152 //
 153 // Function will:
 154 // - check how many granules in that region are uncommitted; If all are committed, it
 155 //    returns true immediately.
 156 // - check if committing those uncommitted granules would bring us over the commit limit
 157 //    (GC threshold, MaxMetaspaceSize). If true, it returns false.
 158 // - commit the memory.
 159 // - mark the range as committed in the commit mask
 160 //
 161 // !! Careful:
 162 //    calling ensure_range_is_committed on a range which contains both committed and uncommitted
 163 //    areas will commit the whole area, thus erase the content in the existing committed parts.
 164 //    Make sure you never call this on an address range containing live data. !!
 165 //
 166 // Returns true if success, false if it did hit a commit limit.
 167 bool VirtualSpaceNode::ensure_range_is_committed(MetaWord* p, size_t word_size) {
 168 
 169   assert_lock_strong(MetaspaceExpand_lock);
 170   assert(p != NULL &amp;&amp; word_size &gt; 0, "Sanity");
 171 
 172   MetaWord* p_start = align_down(p, Settings::commit_granule_bytes());
 173   MetaWord* p_end = align_up(p + word_size, Settings::commit_granule_bytes());
 174 
 175   // Todo: simple for now. Make it more intelligent late
 176   return commit_range(p_start, p_end - p_start);
 177 
 178 }
 179 
 180 // Given an address range (which has to be aligned to commit granule size):
 181 //  - uncommit it
 182 //  - mark it as uncommitted in the commit mask
 183 void VirtualSpaceNode::uncommit_range(MetaWord* p, size_t word_size) {
 184 
 185   DEBUG_ONLY(check_pointer_is_aligned_to_commit_granule(p);)
 186   DEBUG_ONLY(check_word_size_is_aligned_to_commit_granule(word_size);)
 187   assert_lock_strong(MetaspaceExpand_lock);
 188 
 189   // First calculate how large the committed regions in this range are
 190   const size_t committed_words_in_range = _commit_mask.get_committed_size_in_range(p, word_size);
 191   DEBUG_ONLY(check_word_size_is_aligned_to_commit_granule(committed_words_in_range);)
 192 
 193   UL2(debug, "uncommitting range " PTR_FORMAT ".." PTR_FORMAT "(" SIZE_FORMAT " words)",
 194       p2i(p), p2i(p + word_size), word_size);
 195 
 196   if (committed_words_in_range == 0) {
 197     UL(debug, "... already fully uncommitted.");
 198     return; // Already fully uncommitted, nothing to do.
 199   }
 200 
 201   // Uncommit...
 202   if (os::uncommit_memory((char*)p, word_size * BytesPerWord) == false) {
 203     // Note: this can actually happen, since uncommit may increase the number of mappings.
 204     fatal("Failed to uncommit metaspace.");
 205   }
 206 
 207   UL2(debug, "... uncommitted " SIZE_FORMAT " words.", committed_words_in_range);
 208 
 209   // ... tell commit limiter...
 210   _commit_limiter-&gt;decrease_committed(committed_words_in_range);
 211 
 212   // ... and global counters...
 213   _total_committed_words_counter-&gt;decrement_by(committed_words_in_range);
 214 
 215    // ... and update the commit mask.
 216   _commit_mask.mark_range_as_uncommitted(p, word_size);
 217 
 218 #ifdef ASSERT
 219   // The commit boundary maintained in the CommitLimiter should be equal the sum of committed words
 220   // in both class and non-class vslist (outside gtests).
 221   if (_commit_limiter == CommitLimiter::globalLimiter()) { // We are outside a test scenario
 222     assert(_commit_limiter-&gt;committed_words() == RunningCounters::committed_words(), "counter mismatch");
 223   }
 224 #endif
 225 
 226   InternalStats::inc_num_space_uncommitted();
 227 
 228 }
 229 
 230 //// creation, destruction ////
 231 
 232 VirtualSpaceNode::VirtualSpaceNode(ReservedSpace rs, bool owns_rs, CommitLimiter* limiter,
 233                                    SizeCounter* reserve_counter, SizeCounter* commit_counter)
 234   : _next(NULL),
 235     _rs(rs),
 236     _owns_rs(owns_rs),
 237     _base((MetaWord*)rs.base()),
 238     _word_size(rs.size() / BytesPerWord),
 239     _used_words(0),
 240     _commit_mask((MetaWord*)rs.base(), rs.size() / BytesPerWord),
 241     _root_chunk_area_lut((MetaWord*)rs.base(), rs.size() / BytesPerWord),
 242     _commit_limiter(limiter),
 243     _total_reserved_words_counter(reserve_counter),
 244     _total_committed_words_counter(commit_counter)
 245 {
 246   UL2(debug, "born (word_size " SIZE_FORMAT ").", _word_size);
 247 
 248   // Update reserved counter in vslist
 249   _total_reserved_words_counter-&gt;increment_by(_word_size);
 250 
 251   assert_is_aligned(_base, chunklevel::MAX_CHUNK_BYTE_SIZE);
 252   assert_is_aligned(_word_size, chunklevel::MAX_CHUNK_WORD_SIZE);
 253 
 254 }
 255 
 256 
 257 // Create a node of a given size (it will create its own space).
 258 VirtualSpaceNode* VirtualSpaceNode::create_node(size_t word_size,
 259                                                 CommitLimiter* limiter, SizeCounter* reserve_words_counter,
 260                                                 SizeCounter* commit_words_counter)
 261 {
 262 
 263   DEBUG_ONLY(assert_is_aligned(word_size, chunklevel::MAX_CHUNK_WORD_SIZE);)
 264 
 265 #ifdef ASSERT
 266   size_t alignment = chunklevel::MAX_CHUNK_BYTE_SIZE;
 267 #endif
 268 
 269   ReservedSpace rs(word_size * BytesPerWord,
 270                    Metaspace::reserve_alignment(),
 271                    false // large
 272                    );
 273 
 274   if (!rs.is_reserved()) {
 275     vm_exit_out_of_memory(word_size * BytesPerWord, OOM_MMAP_ERROR, "Failed to reserve memory for metaspace");
 276   }
 277 
 278   assert_is_aligned(rs.base(), chunklevel::MAX_CHUNK_BYTE_SIZE);
 279 
 280   InternalStats::inc_num_vsnodes_births();
 281   return new VirtualSpaceNode(rs, true, limiter, reserve_words_counter, commit_words_counter);
 282 
 283 }
 284 
 285 // Create a node over an existing space
 286 VirtualSpaceNode* VirtualSpaceNode::create_node(ReservedSpace rs, CommitLimiter* limiter,
 287                                                 SizeCounter* reserve_words_counter, SizeCounter* commit_words_counter)
 288 {
 289   InternalStats::inc_num_vsnodes_births();
 290   return new VirtualSpaceNode(rs, false, limiter, reserve_words_counter, commit_words_counter);
 291 }
 292 
 293 VirtualSpaceNode::~VirtualSpaceNode() {
 294 
 295   DEBUG_ONLY(verify_locked(true);)
 296 
 297   UL(debug, ": dies.");
 298 
 299   if (_owns_rs) {
 300     _rs.release();
 301   }
 302 
 303   // Update counters in vslist
 304   size_t committed = committed_words();
 305   _total_committed_words_counter-&gt;decrement_by(committed);
 306   _total_reserved_words_counter-&gt;decrement_by(_word_size);
 307 
 308   // ... and tell commit limiter
 309   _commit_limiter-&gt;decrease_committed(committed);
 310 
 311   InternalStats::inc_num_vsnodes_deaths();
 312 
 313 }
 314 
 315 
 316 
 317 //// Chunk allocation, splitting, merging /////
 318 
 319 // Allocate a root chunk from this node. Will fail and return NULL
 320 // if the node is full.
 321 // Note: this just returns a chunk whose memory is reserved; no memory is committed yet.
 322 // Hence, before using this chunk, it must be committed.
 323 // Also, no limits are checked, since no committing takes place.
 324 Metachunk* VirtualSpaceNode::allocate_root_chunk() {
 325 
 326   assert_lock_strong(MetaspaceExpand_lock);
 327 
 328   assert_is_aligned(free_words(), chunklevel::MAX_CHUNK_WORD_SIZE);
 329 
 330   if (free_words() &gt;= chunklevel::MAX_CHUNK_WORD_SIZE) {
 331 
 332     MetaWord* loc = _base + _used_words;
 333     _used_words += chunklevel::MAX_CHUNK_WORD_SIZE;
 334 
 335     RootChunkArea* rca = _root_chunk_area_lut.get_area_by_address(loc);
 336 
 337     // Create a root chunk header and initialize it;
 338     Metachunk* c = rca-&gt;alloc_root_chunk_header(this);
 339 
 340     assert(c-&gt;base() == loc &amp;&amp; c-&gt;vsnode() == this &amp;&amp;
 341            c-&gt;is_free(), "Sanity");
 342 
 343     DEBUG_ONLY(c-&gt;verify(true);)
 344 
 345     UL2(debug, "new root chunk " METACHUNK_FORMAT ".", METACHUNK_FORMAT_ARGS(c));
 346 
 347     if (Settings::newborn_root_chunks_are_fully_committed()) {
 348       // Note: use Metachunk::ensure_commit, do not commit directly. This makes sure the chunk knows
 349       // its commit range and does not ask needlessly.
 350       c-&gt;ensure_fully_committed_locked();
 351     }
 352 
 353     return c;
 354 
 355   }
 356 
 357   return NULL; // Node is full.
 358 
 359 }
 360 
 361 // Given a chunk c, split it recursively until you get a chunk of the given target_level.
 362 //
 363 // The resulting target chunk resides at the same address as the original chunk.
 364 // The resulting splinters are added to freelists.
 365 void VirtualSpaceNode::split(chunklevel_t target_level, Metachunk* c, FreeChunkListVector* freelists) {
 366 
 367   assert_lock_strong(MetaspaceExpand_lock);
 368 
 369   // Get the area associated with this chunk and let it handle the splitting
 370   RootChunkArea* rca = _root_chunk_area_lut.get_area_by_address(c-&gt;base());
 371 
 372   DEBUG_ONLY(rca-&gt;verify_area_is_ideally_merged();)
 373 
 374   rca-&gt;split(target_level, c, freelists);
 375 
 376 }
 377 
 378 // Given a chunk, attempt to merge it recursively with its neighboring chunks.
 379 //
 380 // If successful (merged at least once), returns address of
 381 // the merged chunk; NULL otherwise.
 382 //
 383 // The merged chunks are removed from the freelists.
 384 //
 385 // !!! Please note that if this method returns a non-NULL value, the
 386 // original chunk will be invalid and should not be accessed anymore! !!!
 387 Metachunk* VirtualSpaceNode::merge(Metachunk* c, FreeChunkListVector* freelists) {
 388 
 389   assert(c != NULL &amp;&amp; c-&gt;is_free(), "Sanity");
 390   assert_lock_strong(MetaspaceExpand_lock);
 391 
 392   // Get the rca associated with this chunk and let it handle the merging
 393   RootChunkArea* rca = _root_chunk_area_lut.get_area_by_address(c-&gt;base());
 394 
 395   Metachunk* c2 = rca-&gt;merge(c, freelists);
 396 
 397   DEBUG_ONLY(rca-&gt;verify_area_is_ideally_merged();)
 398 
 399   return c2;
 400 
 401 }
 402 
 403 // Given a chunk c, which must be "in use" and must not be a root chunk, attempt to
 404 // enlarge it in place by claiming its trailing buddy.
 405 //
 406 // This will only work if c is the leader of the buddy pair and the trailing buddy is free.
 407 //
 408 // If successful, the follower chunk will be removed from the freelists, the leader chunk c will
 409 // double in size (level decreased by one).
 410 //
 411 // On success, true is returned, false otherwise.
 412 bool VirtualSpaceNode::attempt_enlarge_chunk(Metachunk* c, FreeChunkListVector* freelists) {
 413 
 414   assert(c != NULL &amp;&amp; c-&gt;is_in_use() &amp;&amp; !c-&gt;is_root_chunk(), "Sanity");
 415   assert_lock_strong(MetaspaceExpand_lock);
 416 
 417   // Get the rca associated with this chunk and let it handle the merging
 418   RootChunkArea* rca = _root_chunk_area_lut.get_area_by_address(c-&gt;base());
 419 
 420   bool rc = rca-&gt;attempt_enlarge_chunk(c, freelists);
 421 
 422   DEBUG_ONLY(rca-&gt;verify_area_is_ideally_merged();)
 423 
 424   if (rc) {
 425     InternalStats::inc_num_chunks_enlarged();
 426   }
 427 
 428   return rc;
 429 
 430 }
 431 
 432 // Attempts to purge the node:
 433 //
 434 // If all chunks living in this node are free, they will all be removed from
 435 //  the freelist they currently reside in. Then, the node will be deleted.
 436 //
 437 // Returns true if the node has been deleted, false if not.
 438 // !! If this returns true, do not access the node from this point on. !!
 439 bool VirtualSpaceNode::attempt_purge(FreeChunkListVector* freelists) {
 440 
 441   assert_lock_strong(MetaspaceExpand_lock);
 442 
 443   if (!_owns_rs) {
 444     // We do not allow purging of nodes if we do not own the
 445     // underlying ReservedSpace (CompressClassSpace case).
 446     return false;
 447   }
 448 
 449   // First find out if all areas are empty. Since empty chunks collapse to root chunk
 450   // size, if all chunks in this node are free root chunks we are good to go.
 451   if (!_root_chunk_area_lut.is_free()) {
 452     return false;
 453   }
 454 
 455   UL(debug, ": purging.");
 456 
 457   // Okay, we can purge. Before we can do this, we need to remove all chunks from the freelist.
 458   for (int narea = 0; narea &lt; _root_chunk_area_lut.number_of_areas(); narea ++) {
 459     RootChunkArea* ra = _root_chunk_area_lut.get_area_by_index(narea);
 460     Metachunk* c = ra-&gt;first_chunk();
 461     if (c != NULL) {
 462       UL2(trace, "removing chunk from to-be-purged node: "
 463           METACHUNK_FULL_FORMAT ".", METACHUNK_FULL_FORMAT_ARGS(c));
 464       assert(c-&gt;is_free() &amp;&amp; c-&gt;is_root_chunk(), "Sanity");
 465       freelists-&gt;remove(c);
 466     }
 467   }
 468 
 469   // Now, delete the node, then right away return since this object is invalid.
 470   delete this;
 471 
 472   return true;
 473 
 474 }
 475 
 476 
 477 void VirtualSpaceNode::print_on(outputStream* st) const {
 478 
 479   size_t scale = K;
 480 
 481   st-&gt;print("base " PTR_FORMAT ": ", p2i(base()));
 482   st-&gt;print("reserved=");
 483   print_scaled_words(st, word_size(), scale);
 484   st-&gt;print(", committed=");
 485   print_scaled_words_and_percentage(st, committed_words(), word_size(), scale);
 486   st-&gt;print(", used=");
 487   print_scaled_words_and_percentage(st, used_words(), word_size(), scale);
 488 
 489   st-&gt;cr();
 490   _root_chunk_area_lut.print_on(st);
 491   _commit_mask.print_on(st);
 492 
 493 }
 494 
 495 // Returns size, in words, of committed space in this node alone.
 496 // Note: iterates over commit mask and hence may be a tad expensive on large nodes.
 497 size_t VirtualSpaceNode::committed_words() const {
 498   return _commit_mask.get_committed_size();
 499 }
 500 
 501 #ifdef ASSERT
 502 void VirtualSpaceNode::verify(bool slow) const {
 503   MutexLocker fcl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
 504   verify_locked(slow);
 505 }
 506 
 507 // Verify counters and basic structure. Slow mode: verify all chunks in depth
 508 void VirtualSpaceNode::verify_locked(bool slow) const {
 509 
 510   assert_lock_strong(MetaspaceExpand_lock);
 511 
 512   assert(base() != NULL, "Invalid base");
 513   assert(base() == (MetaWord*)_rs.base() &amp;&amp;
 514          word_size() == _rs.size() / BytesPerWord,
 515          "Sanity");
 516   assert_is_aligned(base(), chunklevel::MAX_CHUNK_BYTE_SIZE);
 517   assert(used_words() &lt;= word_size(), "Sanity");
 518 
 519   // Since we only ever hand out root chunks from a vsnode, top should always be aligned
 520   // to root chunk size.
 521   assert_is_aligned(used_words(), chunklevel::MAX_CHUNK_WORD_SIZE);
 522 
 523   _commit_mask.verify(slow);
 524   assert(committed_words() &lt;= word_size(), "Sanity");
 525   assert_is_aligned(committed_words(), Settings::commit_granule_words());
 526   _root_chunk_area_lut.verify(slow);
 527 
 528 }
 529 
 530 #endif
 531 
 532 
 533 } // namespace metaspace
</pre></body></html>
