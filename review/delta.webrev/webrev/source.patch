--- old/src/hotspot/share/gc/g1/g1CollectedHeap.cpp	2020-09-04 13:56:58.177010048 +0200
+++ new/src/hotspot/share/gc/g1/g1CollectedHeap.cpp	2020-09-04 13:56:57.789007593 +0200
@@ -1029,7 +1029,7 @@
 
   // Delete metaspaces for unloaded class loaders and clean up loader_data graph
   ClassLoaderDataGraph::purge();
-  DEBUG_ONLY(MetaspaceUtils::verify(false);)
+  DEBUG_ONLY(MetaspaceUtils::verify();)
 
   // Prepare heap for normal collections.
   assert(num_free_regions() == 0, "we should not have added any free regions");
--- old/src/hotspot/share/gc/parallel/psParallelCompact.cpp	2020-09-04 13:56:59.457018158 +0200
+++ new/src/hotspot/share/gc/parallel/psParallelCompact.cpp	2020-09-04 13:56:59.089015824 +0200
@@ -1057,7 +1057,7 @@
 
   // Delete metaspaces for unloaded class loaders and clean up loader_data graph
   ClassLoaderDataGraph::purge();
-  DEBUG_ONLY(MetaspaceUtils::verify(false);)
+  DEBUG_ONLY(MetaspaceUtils::verify();)
 
   heap->prune_scavengable_nmethods();
 
--- old/src/hotspot/share/gc/shared/gcTrace.cpp	2020-09-04 13:57:00.573025239 +0200
+++ new/src/hotspot/share/gc/shared/gcTrace.cpp	2020-09-04 13:57:00.193022827 +0200
@@ -30,7 +30,6 @@
 #include "gc/shared/gcTrace.hpp"
 #include "gc/shared/objectCountEventSender.hpp"
 #include "gc/shared/referenceProcessorStats.hpp"
-#include "memory/metaspace.hpp"
 #include "memory/heapInspection.hpp"
 #include "memory/resourceArea.hpp"
 #include "runtime/os.hpp"
--- old/src/hotspot/share/gc/shenandoah/shenandoahHeap.cpp	2020-09-04 13:57:01.801033043 +0200
+++ new/src/hotspot/share/gc/shenandoah/shenandoahHeap.cpp	2020-09-04 13:57:01.421030627 +0200
@@ -2202,7 +2202,7 @@
   }
   // Resize and verify metaspace
   MetaspaceGC::compute_new_size();
-  DEBUG_ONLY(MetaspaceUtils::verify(false);)
+  DEBUG_ONLY(MetaspaceUtils::verify();)
 }
 
 // Weak roots are either pre-evacuated (final mark) or updated (final updaterefs),
--- old/src/hotspot/share/gc/shenandoah/shenandoahUnload.cpp	2020-09-04 13:57:03.101041316 +0200
+++ new/src/hotspot/share/gc/shenandoah/shenandoahUnload.cpp	2020-09-04 13:57:02.721038897 +0200
@@ -197,5 +197,5 @@
 
 void ShenandoahUnload::finish() {
   MetaspaceGC::compute_new_size();
-  DEBUG_ONLY(MetaspaceUtils::verify(false);)
+  DEBUG_ONLY(MetaspaceUtils::verify();)
 }
--- old/src/hotspot/share/gc/z/zUnload.cpp	2020-09-04 13:57:04.253048660 +0200
+++ new/src/hotspot/share/gc/z/zUnload.cpp	2020-09-04 13:57:03.869046211 +0200
@@ -164,5 +164,5 @@
 void ZUnload::finish() {
   // Resize and verify metaspace
   MetaspaceGC::compute_new_size();
-  DEBUG_ONLY(MetaspaceUtils::verify(false);)
+  DEBUG_ONLY(MetaspaceUtils::verify();)
 }
--- old/src/hotspot/share/jfr/recorder/checkpoint/types/jfrType.cpp	2020-09-04 13:57:05.421056117 +0200
+++ new/src/hotspot/share/jfr/recorder/checkpoint/types/jfrType.cpp	2020-09-04 13:57:05.033053638 +0200
@@ -39,10 +39,9 @@
 #include "jfr/recorder/checkpoint/types/jfrThreadState.hpp"
 #include "jfr/support/jfrThreadLocal.hpp"
 #include "jfr/writers/jfrJavaEventWriter.hpp"
-#include "memory/metaspace.hpp"
-#include "memory/metaspace/metaspaceEnums.hpp"
 #include "jfr/utilities/jfrThreadIterator.hpp"
 #include "memory/iterator.hpp"
+#include "memory/metaspace.hpp"
 #include "memory/referenceType.hpp"
 #include "memory/universe.hpp"
 #include "oops/compressedOops.hpp"
@@ -197,7 +196,7 @@
   writer.write_count(nof_entries);
   for (u4 i = 0; i < nof_entries; ++i) {
     writer.write_key(i);
-    writer.write(metaspace::describe_mdtype((Metaspace::MetadataType)i));
+    writer.write(Metaspace::metadata_type_name((Metaspace::MetadataType)i));
   }
 }
 
--- old/src/hotspot/share/memory/metaspace.cpp	2020-09-04 13:57:06.433062586 +0200
+++ new/src/hotspot/share/memory/metaspace.cpp	2020-09-04 13:57:06.081060334 +0200
@@ -29,20 +29,19 @@
 #include "logging/log.hpp"
 #include "logging/logStream.hpp"
 #include "memory/filemap.hpp"
+#include "memory/metaspace/metaspaceSizesSnapshot.hpp"
+#include "memory/metaspace/msChunkHeaderPool.hpp"
+#include "memory/metaspace/msChunkManager.hpp"
+#include "memory/metaspace/msCommitLimiter.hpp"
+#include "memory/metaspace/msCommon.hpp"
+#include "memory/metaspace/msContext.hpp"
+#include "memory/metaspace/msReport.hpp"
+#include "memory/metaspace/msRunningCounters.hpp"
+#include "memory/metaspace/msSettings.hpp"
+#include "memory/metaspace/msVirtualSpaceList.hpp"
 #include "memory/metaspace.hpp"
 #include "memory/metaspaceShared.hpp"
 #include "memory/metaspaceTracer.hpp"
-#include "memory/metaspace/chunkHeaderPool.hpp"
-#include "memory/metaspace/chunkManager.hpp"
-#include "memory/metaspace/commitLimiter.hpp"
-#include "memory/metaspace/metaspaceCommon.hpp"
-#include "memory/metaspace/metaspaceContext.hpp"
-#include "memory/metaspace/metaspaceEnums.hpp"
-#include "memory/metaspace/metaspaceReport.hpp"
-#include "memory/metaspace/metaspaceSizesSnapshot.hpp"
-#include "memory/metaspace/runningCounters.hpp"
-#include "memory/metaspace/settings.hpp"
-#include "memory/metaspace/virtualSpaceList.hpp"
 #include "memory/universe.hpp"
 #include "oops/compressedOops.hpp"
 #include "runtime/atomic.hpp"
@@ -68,7 +67,7 @@
 }
 
 size_t MetaspaceUtils::used_words(Metaspace::MetadataType mdtype) {
-  return metaspace::is_class(mdtype) ? RunningCounters::used_words_class() : RunningCounters::used_words_nonclass();
+  return Metaspace::is_class_space_allocation(mdtype) ? RunningCounters::used_words_class() : RunningCounters::used_words_nonclass();
 }
 
 size_t MetaspaceUtils::reserved_words() {
@@ -76,7 +75,7 @@
 }
 
 size_t MetaspaceUtils::reserved_words(Metaspace::MetadataType mdtype) {
-  return metaspace::is_class(mdtype) ? RunningCounters::reserved_words_class() : RunningCounters::reserved_words_nonclass();
+  return Metaspace::is_class_space_allocation(mdtype) ? RunningCounters::reserved_words_class() : RunningCounters::reserved_words_nonclass();
 }
 
 size_t MetaspaceUtils::committed_words() {
@@ -84,7 +83,7 @@
 }
 
 size_t MetaspaceUtils::committed_words(Metaspace::MetadataType mdtype) {
-  return metaspace::is_class(mdtype) ? RunningCounters::committed_words_class() : RunningCounters::committed_words_nonclass();
+  return Metaspace::is_class_space_allocation(mdtype) ? RunningCounters::committed_words_class() : RunningCounters::committed_words_nonclass();
 }
 
 
@@ -143,9 +142,9 @@
 // convenient, use print_basic_report() instead.
 void MetaspaceUtils::print_report(outputStream* out, size_t scale) {
   const int flags =
-      MetaspaceReporter::rf_show_loaders |
-      MetaspaceReporter::rf_break_down_by_chunktype |
-      MetaspaceReporter::rf_show_classes;
+      (int)MetaspaceReporter::Option::ShowLoaders |
+      (int)MetaspaceReporter::Option::BreakDownByChunkType |
+      (int)MetaspaceReporter::Option::ShowClasses;
   MetaspaceReporter::print_report(out, scale, flags);
 }
 
@@ -174,27 +173,25 @@
 }
 
 #ifdef ASSERT
-void MetaspaceUtils::verify(bool slow) {
+void MetaspaceUtils::verify() {
   if (Metaspace::initialized()) {
 
     // Verify non-class chunkmanager...
     ChunkManager* cm = ChunkManager::chunkmanager_nonclass();
-    cm->verify(slow);
+    cm->verify();
 
     // ... and space list.
     VirtualSpaceList* vsl = VirtualSpaceList::vslist_nonclass();
-    vsl->verify(slow);
+    vsl->verify();
 
     if (Metaspace::using_class_space()) {
       // If we use compressed class pointers, verify class chunkmanager...
       cm = ChunkManager::chunkmanager_class();
-      assert(cm != NULL, "Sanity");
-      cm->verify(slow);
+      cm->verify();
 
       // ... and class spacelist.
-      VirtualSpaceList* vsl = VirtualSpaceList::vslist_nonclass();
-      assert(vsl != NULL, "Sanity");
-      vsl->verify(slow);
+      vsl = VirtualSpaceList::vslist_class();
+      vsl->verify();
     }
 
   }
@@ -798,7 +795,7 @@
   assert(loader_data != NULL, "Should never pass around a NULL loader_data. "
         "ClassLoaderData::the_null_class_loader_data() should have been used.");
 
-  Metaspace::MetadataType mdtype = (type == MetaspaceObj::ClassType) ? Metaspace::ClassType : Metaspace::NonClassType;
+  MetadataType mdtype = (type == MetaspaceObj::ClassType) ? ClassType : NonClassType;
 
   // Try to allocate metadata.
   MetaWord* result = loader_data->metaspace_non_null()->allocate(word_size, mdtype);
@@ -843,7 +840,7 @@
   Log(gc, metaspace, freelist, oom) log;
   if (log.is_info()) {
     log.info("Metaspace (%s) allocation failed for size " SIZE_FORMAT,
-             metaspace::is_class(mdtype) ? "class" : "data", word_size);
+             is_class_space_allocation(mdtype) ? "class" : "data", word_size);
     ResourceMark rm;
     if (log.is_debug()) {
       if (loader_data->metaspace_or_null() != NULL) {
@@ -856,16 +853,12 @@
     MetaspaceUtils::print_basic_report(&ls, 0);
   }
 
-  // Which limit did we hit? CompressedClassSpaceSize or MaxMetaspaceSize?
+  // TODO: this exception text may be wrong and misleading. This needs more thinking. See JDK-8252189.
   bool out_of_compressed_class_space = false;
-  if (metaspace::is_class(mdtype)) {
+  if (is_class_space_allocation(mdtype)) {
     ClassLoaderMetaspace* metaspace = loader_data->metaspace_non_null();
     out_of_compressed_class_space =
       MetaspaceUtils::committed_bytes(Metaspace::ClassType) +
-      // TODO: Okay this is just cheesy.
-      // Of course this may fail and return incorrect results.
-      // Think this over - we need some clean way to remember which limit
-      // exactly we hit during an allocation. Some sort of allocation context structure?
       align_up(word_size * BytesPerWord, 4 * M) >
       CompressedClassSpaceSize;
   }
@@ -893,6 +886,16 @@
   }
 }
 
+const char* Metaspace::metadata_type_name(Metaspace::MetadataType mdtype) {
+  switch (mdtype) {
+    case Metaspace::ClassType: return "Class";
+    case Metaspace::NonClassType: return "Metadata";
+    default:
+      assert(false, "Got bad mdtype: %d", (int) mdtype);
+      return NULL;
+  }
+}
+
 void Metaspace::purge() {
   ChunkManager* cm = ChunkManager::chunkmanager_nonclass();
   if (cm != NULL) {
--- old/src/hotspot/share/memory/metaspace.hpp	2020-09-04 13:57:07.629070242 +0200
+++ new/src/hotspot/share/memory/metaspace.hpp	2020-09-04 13:57:07.249067809 +0200
@@ -41,7 +41,7 @@
 namespace metaspace {
   class MetaspaceArena;
   class MetaspaceSizesSnapshot;
-  struct clms_stats_t;
+  struct ClmsStats;
 }
 
 ////////////////// Metaspace ///////////////////////
@@ -137,6 +137,8 @@
   static void report_metadata_oome(ClassLoaderData* loader_data, size_t word_size,
                                    MetaspaceObj::Type type, Metaspace::MetadataType mdtype, TRAPS);
 
+  static const char* metadata_type_name(Metaspace::MetadataType mdtype);
+
   static void print_compressed_class_space(outputStream* st) NOT_LP64({});
 
   // Return TRUE only if UseCompressedClassPointers is True.
@@ -144,6 +146,10 @@
     return NOT_LP64(false) LP64_ONLY(UseCompressedClassPointers);
   }
 
+  static bool is_class_space_allocation(MetadataType mdType) {
+    return mdType == ClassType && using_class_space();
+  }
+
   static bool initialized();
 
 };
@@ -213,7 +219,7 @@
   void deallocate(MetaWord* ptr, size_t word_size, bool is_class);
 
   // Update statistics. This walks all in-use chunks.
-  void add_to_statistics(metaspace::clms_stats_t* out) const;
+  void add_to_statistics(metaspace::ClmsStats* out) const;
 
   DEBUG_ONLY(void verify() const;)
 
@@ -336,7 +342,7 @@
 
   static void print_on(outputStream * out);
 
-  DEBUG_ONLY(static void verify(bool slow);)
+  DEBUG_ONLY(static void verify();)
 
 };
 
--- old/src/hotspot/share/memory/metaspace/metaspaceSizesSnapshot.cpp	2020-09-04 13:57:08.789077678 +0200
+++ new/src/hotspot/share/memory/metaspace/metaspaceSizesSnapshot.cpp	2020-09-04 13:57:08.397075165 +0200
@@ -25,9 +25,8 @@
 
 #include "precompiled.hpp"
 
-#include "memory/metaspace.hpp"
-#include "memory/metaspace.hpp"
 #include "memory/metaspace/metaspaceSizesSnapshot.hpp"
+#include "memory/metaspace.hpp"
 
 namespace metaspace {
 
--- old/src/hotspot/share/memory/metaspace/metaspaceSizesSnapshot.hpp	2020-09-04 13:57:09.881084689 +0200
+++ new/src/hotspot/share/memory/metaspace/metaspaceSizesSnapshot.hpp	2020-09-04 13:57:09.505082275 +0200
@@ -26,6 +26,8 @@
 #ifndef SHARE_MEMORY_METASPACE_METASPACESIZESSNAPSHOT_HPP
 #define SHARE_MEMORY_METASPACE_METASPACESIZESSNAPSHOT_HPP
 
+#include "utilities/globalDefinitions.hpp"
+
 namespace metaspace {
 
 // Todo: clean up after jep387, see JDK-8251392
--- old/src/hotspot/share/memory/universe.cpp	2020-09-04 13:57:11.069092326 +0200
+++ new/src/hotspot/share/memory/universe.cpp	2020-09-04 13:57:10.689089883 +0200
@@ -1163,7 +1163,7 @@
   }
   if (should_verify_subset(Verify_MetaspaceUtils)) {
     log_debug(gc, verify)("MetaspaceUtils");
-    DEBUG_ONLY(MetaspaceUtils::verify(true);)
+    DEBUG_ONLY(MetaspaceUtils::verify();)
   }
   if (should_verify_subset(Verify_JNIHandles)) {
     log_debug(gc, verify)("JNIHandles");
--- old/src/hotspot/share/prims/whitebox.cpp	2020-09-04 13:57:12.273100079 +0200
+++ new/src/hotspot/share/prims/whitebox.cpp	2020-09-04 13:57:11.897097657 +0200
@@ -46,7 +46,7 @@
 #include "memory/heapShared.inline.hpp"
 #include "memory/metaspaceShared.hpp"
 #include "memory/metadataFactory.hpp"
-#include "memory/metaspace/metaspace_test.hpp"
+#include "memory/metaspace/msTestHelpers.hpp"
 #include "memory/iterator.hpp"
 #include "memory/resourceArea.hpp"
 #include "memory/universe.hpp"
--- old/src/hotspot/share/runtime/globals.hpp	2020-09-04 13:57:13.465107765 +0200
+++ new/src/hotspot/share/runtime/globals.hpp	2020-09-04 13:57:13.061105158 +0200
@@ -1560,8 +1560,8 @@
           "Metapace allocations are guarded.")                              \
                                                                             \
   develop(bool, MetaspaceHandleDeallocations, true,                         \
-	        "Switch off Metapace deallocation handling.")                     \
-																		                                        \
+          "Switch off Metapace deallocation handling.")                     \
+                                                                            \
   manageable(uintx, MinHeapFreeRatio, 40,                                   \
           "The minimum percentage of heap free after GC to avoid expansion."\
           " For most GCs this applies to the old generation. In G1 and"     \
--- old/src/hotspot/share/runtime/vmOperations.cpp	2020-09-04 13:57:14.609115152 +0200
+++ new/src/hotspot/share/runtime/vmOperations.cpp	2020-09-04 13:57:14.233112722 +0200
@@ -33,7 +33,7 @@
 #include "logging/logStream.hpp"
 #include "logging/logConfiguration.hpp"
 #include "memory/heapInspection.hpp"
-#include "memory/metaspace/metaspaceReport.hpp"
+#include "memory/metaspace/msReport.hpp"
 #include "memory/resourceArea.hpp"
 #include "memory/universe.hpp"
 #include "oops/symbol.hpp"
--- old/src/hotspot/share/services/diagnosticCommand.cpp	2020-09-04 13:57:15.749122523 +0200
+++ new/src/hotspot/share/services/diagnosticCommand.cpp	2020-09-04 13:57:15.365120039 +0200
@@ -30,7 +30,7 @@
 #include "compiler/compileBroker.hpp"
 #include "compiler/directivesParser.hpp"
 #include "gc/shared/gcVMOperations.hpp"
-#include "memory/metaspace/metaspaceDCmd.hpp"
+#include "memory/metaspace/msDCmd.hpp"
 #include "memory/resourceArea.hpp"
 #include "memory/universe.hpp"
 #include "oops/objArrayOop.inline.hpp"
--- old/src/hotspot/share/services/memReporter.cpp	2020-09-04 13:57:16.925130137 +0200
+++ new/src/hotspot/share/services/memReporter.cpp	2020-09-04 13:57:16.545127676 +0200
@@ -26,7 +26,6 @@
 
 #include "memory/allocation.hpp"
 #include "memory/metaspace.hpp"
-#include "memory/metaspace/metaspaceEnums.hpp"
 #include "services/mallocTracker.hpp"
 #include "services/memReporter.hpp"
 #include "services/threadStackTracker.hpp"
@@ -212,26 +211,27 @@
   }
 }
 
-void MemSummaryReporter::report_metadata(Metaspace::MetadataType mdType) const {
-  DEBUG_ONLY(metaspace::check_valid_mdtype(mdType));
-  const char* const name = metaspace::describe_mdtype(mdType);
+void MemSummaryReporter::report_metadata(Metaspace::MetadataType type) const {
+  assert(type == Metaspace::NonClassType || type == Metaspace::ClassType,
+    "Invalid metadata type");
+  const char* name = (type == Metaspace::NonClassType) ?
+    "Metadata:   " : "Class space:";
 
   outputStream* out = output();
   const char* scale = current_scale();
-  size_t committed   = MetaspaceUtils::committed_bytes(mdType);
-  size_t used = MetaspaceUtils::used_bytes(mdType);
-  size_t free = 0; //
-      // TODO think this thru. What is free in this context?
-      // (MetaspaceUtils::capacity_bytes(type) - used)
-  //         + MetaspaceUtils::free_chunks_total_bytes(type)
-  //          + MetaspaceUtils::free_in_vs_bytes(type);
+  size_t committed   = MetaspaceUtils::committed_bytes(type);
+  size_t used = MetaspaceUtils::used_bytes(type);
+
+  // The answer to "what is free" in metaspace is complex and cannot be answered with a single number.
+  // Free as in available to all loaders? Free, pinned to one loader? For now, keep it simple.
+  size_t free = committed - used;
 
   assert(committed >= used + free, "Sanity");
   size_t waste = committed - (used + free);
 
   out->print_cr("%27s (  %s)", " ", name);
   out->print("%27s (    ", " ");
-  print_total(MetaspaceUtils::reserved_bytes(mdType), committed);
+  print_total(MetaspaceUtils::reserved_bytes(type), committed);
   out->print_cr(")");
   out->print_cr("%27s (    used=" SIZE_FORMAT "%s)", " ", amount_in_current_scale(used), scale);
   out->print_cr("%27s (    free=" SIZE_FORMAT "%s)", " ", amount_in_current_scale(free), scale);
@@ -602,37 +602,37 @@
   }
 }
 
-void MemSummaryDiffReporter::print_metaspace_diff(Metaspace::MetadataType mdType,
+void MemSummaryDiffReporter::print_metaspace_diff(Metaspace::MetadataType type,
                                                   const MetaspaceSnapshot* current_ms,
                                                   const MetaspaceSnapshot* early_ms) const {
-  DEBUG_ONLY(metaspace::check_valid_mdtype(mdType));
-  const char* const name = metaspace::describe_mdtype(mdType);
+  const char* name = (type == Metaspace::NonClassType) ?
+    "Metadata:   " : "Class space:";
 
   outputStream* out = output();
   const char* scale = current_scale();
 
   out->print_cr("%27s (  %s)", " ", name);
   out->print("%27s (    ", " ");
-  print_virtual_memory_diff(current_ms->reserved_in_bytes(mdType),
-                            current_ms->committed_in_bytes(mdType),
-                            early_ms->reserved_in_bytes(mdType),
-                            early_ms->committed_in_bytes(mdType));
+  print_virtual_memory_diff(current_ms->reserved_in_bytes(type),
+                            current_ms->committed_in_bytes(type),
+                            early_ms->reserved_in_bytes(type),
+                            early_ms->committed_in_bytes(type));
   out->print_cr(")");
 
-  long diff_used = diff_in_current_scale(current_ms->used_in_bytes(mdType),
-                                         early_ms->used_in_bytes(mdType));
-  long diff_free = diff_in_current_scale(current_ms->free_in_bytes(mdType),
-                                         early_ms->free_in_bytes(mdType));
-
-  size_t current_waste = current_ms->committed_in_bytes(mdType)
-    - (current_ms->used_in_bytes(mdType) + current_ms->free_in_bytes(mdType));
-  size_t early_waste = early_ms->committed_in_bytes(mdType)
-    - (early_ms->used_in_bytes(mdType) + early_ms->free_in_bytes(mdType));
+  long diff_used = diff_in_current_scale(current_ms->used_in_bytes(type),
+                                         early_ms->used_in_bytes(type));
+  long diff_free = diff_in_current_scale(current_ms->free_in_bytes(type),
+                                         early_ms->free_in_bytes(type));
+
+  size_t current_waste = current_ms->committed_in_bytes(type)
+    - (current_ms->used_in_bytes(type) + current_ms->free_in_bytes(type));
+  size_t early_waste = early_ms->committed_in_bytes(type)
+    - (early_ms->used_in_bytes(type) + early_ms->free_in_bytes(type));
   long diff_waste = diff_in_current_scale(current_waste, early_waste);
 
   // Diff used
   out->print("%27s (    used=" SIZE_FORMAT "%s", " ",
-    amount_in_current_scale(current_ms->used_in_bytes(mdType)), scale);
+    amount_in_current_scale(current_ms->used_in_bytes(type)), scale);
   if (diff_used != 0) {
     out->print(" %+ld%s", diff_used, scale);
   }
@@ -640,7 +640,7 @@
 
   // Diff free
   out->print("%27s (    free=" SIZE_FORMAT "%s", " ",
-    amount_in_current_scale(current_ms->free_in_bytes(mdType)), scale);
+    amount_in_current_scale(current_ms->free_in_bytes(type)), scale);
   if (diff_free != 0) {
     out->print(" %+ld%s", diff_free, scale);
   }
@@ -650,7 +650,7 @@
   // Diff waste
   out->print("%27s (    waste=" SIZE_FORMAT "%s =%2.2f%%", " ",
     amount_in_current_scale(current_waste), scale,
-    ((float)current_waste * 100) / current_ms->committed_in_bytes(mdType));
+    ((float)current_waste * 100) / current_ms->committed_in_bytes(type));
   if (diff_waste != 0) {
     out->print(" %+ld%s", diff_waste, scale);
   }
--- old/src/hotspot/share/services/virtualMemoryTracker.cpp	2020-09-04 13:57:18.093137711 +0200
+++ new/src/hotspot/share/services/virtualMemoryTracker.cpp	2020-09-04 13:57:17.717135273 +0200
@@ -667,10 +667,9 @@
   mss._committed_in_bytes[type]  = MetaspaceUtils::committed_bytes(type);
   mss._used_in_bytes[type]       = MetaspaceUtils::used_bytes(type);
 
-  size_t free_in_bytes = 0;// TODO fix(MetaspaceUtils::capacity_bytes(type) - MetaspaceUtils::used_bytes(type))
-                     //  + MetaspaceUtils::free_chunks_total_bytes(type)
-                     //  + MetaspaceUtils::free_in_vs_bytes(type);
-  mss._free_in_bytes[type] = free_in_bytes;
+  // The answer to "what is free" in metaspace is complex and cannot be answered with a single number.
+  // Free as in available to all loaders? Free, pinned to one loader? For now, keep it simple.
+  mss._free_in_bytes[type] = mss._committed_in_bytes[type] - mss._used_in_bytes[type];
 }
 
 void MetaspaceSnapshot::snapshot(MetaspaceSnapshot& mss) {
--- old/test/hotspot/gtest/metaspace/test_arenagrowthpolicy.cpp	2020-09-04 13:57:19.313145634 +0200
+++ new/test/hotspot/gtest/metaspace/test_arenagrowthpolicy.cpp	2020-09-04 13:57:18.937143191 +0200
@@ -1,6 +1,6 @@
 /*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
@@ -25,9 +25,16 @@
 
 #include "precompiled.hpp"
 
+#include "memory/metaspace.hpp"
+#include "memory/metaspace/msArenaGrowthPolicy.hpp"
+#include "memory/metaspace/msChunklevel.hpp"
+
 //#define LOG_PLEASE
+#include "metaspaceGtestCommon.hpp"
 
-#include "metaspaceTestsCommon.hpp"
+using metaspace::ArenaGrowthPolicy;
+using metaspace::chunklevel_t;
+using namespace metaspace::chunklevel;
 
 static void test_arena_growth_policy(Metaspace::MetaspaceType spacetype, bool is_class) {
 
@@ -42,7 +49,7 @@
     ASSERT_GE(lvl, CHUNK_LEVEL_4K);
   }
 
-  for (int step = 1; step < 100; step ++) {
+  for (int step = 1; step < 100; step++) {
     chunklevel_t lvl2 = a->get_level_at_step(step);
     ASSERT_TRUE(is_valid_level(lvl2));
     // limit steepness: no growth allowed beyond last chunksize * 2
@@ -53,7 +60,7 @@
 
 #define DEFINE_GROWTH_POLICY_TEST(spacetype, is_class) \
 TEST_VM(metaspace, arena_growth_policy_##spacetype##_##is_class) { \
-	test_arena_growth_policy(Metaspace::spacetype, is_class); \
+  test_arena_growth_policy(Metaspace::spacetype, is_class); \
 }
 
 DEFINE_GROWTH_POLICY_TEST(ReflectionMetaspaceType, true)
@@ -65,7 +72,3 @@
 DEFINE_GROWTH_POLICY_TEST(BootMetaspaceType, true)
 DEFINE_GROWTH_POLICY_TEST(BootMetaspaceType, false)
 
-
-
-
-
--- old/test/hotspot/gtest/metaspace/test_binlist.cpp	2020-09-04 13:57:20.517153464 +0200
+++ new/test/hotspot/gtest/metaspace/test_binlist.cpp	2020-09-04 13:57:20.129150939 +0200
@@ -1,6 +1,6 @@
 /*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
@@ -25,10 +25,15 @@
 
 #include "precompiled.hpp"
 
-//#define LOG_PLEASE
+#include "memory/metaspace/msBinList.hpp"
+#include "memory/metaspace/msCounter.hpp"
 
-#include "metaspaceTestsCommon.hpp"
+//#define LOG_PLEASE
+#include "metaspaceGtestCommon.hpp"
 
+using metaspace::BinList32;
+using metaspace::BinListImpl;
+using metaspace::MemRangeCounter;
 
 #define CHECK_BL_CONTENT(bl, expected_num, expected_size) { \
   EXPECT_EQ(bl.count(), (unsigned)expected_num); \
@@ -40,7 +45,6 @@
   } \
 }
 
-
 template <class BINLISTTYPE>
 struct BinListBasicTest {
 
@@ -59,7 +63,7 @@
 
     // Try to get a block from an empty list.
     size_t real_size = 4711;
-    MetaWord* p = bl.get_block(innocous_size, &real_size);
+    MetaWord* p = bl.remove_block(innocous_size, &real_size);
     EXPECT_EQ(p, (MetaWord*)NULL);
     EXPECT_EQ((size_t)0, real_size);
 
@@ -70,7 +74,7 @@
 
     // And retrieve it.
     real_size = 4711;
-    p = bl.get_block(innocous_size, &real_size);
+    p = bl.remove_block(innocous_size, &real_size);
     EXPECT_EQ(p, arr);
     EXPECT_EQ((size_t)innocous_size, real_size);
     CHECK_BL_CONTENT(bl, 0, 0);
@@ -86,15 +90,15 @@
 
     MetaWord arr[1000];
 
-    for (size_t s1 = minws; s1 < maxws; s1 ++) {
-      for (size_t s2 = minws; s2 < maxws; s2 ++) {
+    for (size_t s1 = minws; s1 <= maxws; s1++) {
+      for (size_t s2 = minws; s2 <= maxws; s2++) {
 
         bl.add_block(arr, s1);
         CHECK_BL_CONTENT(bl, 1, s1);
         DEBUG_ONLY(bl.verify();)
 
         size_t real_size = 4711;
-        MetaWord* p = bl.get_block(s2, &real_size);
+        MetaWord* p = bl.remove_block(s2, &real_size);
         if (s1 >= s2) {
           EXPECT_EQ(p, arr);
           EXPECT_EQ((size_t)s1, real_size);
@@ -106,7 +110,7 @@
           CHECK_BL_CONTENT(bl, 1, s1);
           DEBUG_ONLY(bl.verify();)
           // drain bl
-          p = bl.get_block(minws, &real_size);
+          p = bl.remove_block(minws, &real_size);
           EXPECT_EQ(p, arr);
           EXPECT_EQ((size_t)s1, real_size);
           CHECK_BL_CONTENT(bl, 0, 0);
@@ -127,7 +131,7 @@
   ASSERT_EQ(cnt[1].total_size(), bl[1].total_size());
 
     FeederBuffer fb(1024);
-    RandSizeGenerator rgen(minws, maxws);
+    RandSizeGenerator rgen(minws, maxws + 1);
 
     // feed all
     int which = 0;
@@ -148,13 +152,13 @@
     DEBUG_ONLY(bl[1].verify();)
 
     // play pingpong
-    for (int iter = 0; iter < 1000; iter ++) {
+    for (int iter = 0; iter < 1000; iter++) {
       size_t s = rgen.get();
       int taker = iter % 2;
       int giver = taker == 0 ? 1 : 0;
 
       size_t real_size = 4711;
-      MetaWord* p = bl[giver].get_block(s, &real_size);
+      MetaWord* p = bl[giver].remove_block(s, &real_size);
       if (p != NULL) {
 
         ASSERT_TRUE(fb.is_valid_range(p, real_size));
@@ -177,12 +181,12 @@
     DEBUG_ONLY(bl[1].verify();)
 
     // drain both lists.
-    for (int which = 0; which < 2; which ++) {
+    for (int which = 0; which < 2; which++) {
       size_t last_size = 0;
       while (bl[which].is_empty() == false) {
 
         size_t real_size = 4711;
-        MetaWord* p = bl[which].get_block(minws, &real_size);
+        MetaWord* p = bl[which].remove_block(minws, &real_size);
 
         ASSERT_NE(p, (MetaWord*) NULL);
         ASSERT_GE(real_size, minws);
@@ -200,33 +204,27 @@
       }
     }
 
-
   }
 };
 
-template <typename BINLISTTYPE> const size_t BinListBasicTest<BINLISTTYPE>::minws = BINLISTTYPE::minimal_word_size;
-template <typename BINLISTTYPE> const size_t BinListBasicTest<BINLISTTYPE>::maxws = BINLISTTYPE::maximal_word_size;
-
-
-TEST_VM(metaspace, BinList_basic_8)   { BinListBasicTest<metaspace::BinList8>::basic_test(); }
-TEST_VM(metaspace, BinList_basic_16)  { BinListBasicTest<metaspace::BinList16>::basic_test(); }
-TEST_VM(metaspace, BinList_basic_32)  { BinListBasicTest<metaspace::BinList32>::basic_test(); }
-//TEST_VM(metaspace, BinList_basic_64)  { BinListBasicTest<metaspace::BinList64>::basic_test(); }
-
-TEST_VM(metaspace, BinList_basic_1331)   { BinListBasicTest< metaspace::BinListImpl<13, 31> >::basic_test(); }
-TEST_VM(metaspace, BinList_basic_131)   { BinListBasicTest< metaspace::BinListImpl<13, 1> >::basic_test(); }
-
-TEST_VM(metaspace, BinList_basic2_8)   { BinListBasicTest<metaspace::BinList8>::basic_test_2(); }
-TEST_VM(metaspace, BinList_basic2_16)  { BinListBasicTest<metaspace::BinList16>::basic_test_2(); }
-TEST_VM(metaspace, BinList_basic2_32)  { BinListBasicTest<metaspace::BinList32>::basic_test_2(); }
-
-TEST_VM(metaspace, BinList_basic2_1331)   { BinListBasicTest< metaspace::BinListImpl<13, 31> >::basic_test_2(); }
-TEST_VM(metaspace, BinList_basic2_131)   { BinListBasicTest< metaspace::BinListImpl<13, 1> >::basic_test_2(); }
-
-TEST_VM(metaspace, BinList_random_test_8)   { BinListBasicTest<metaspace::BinList8>::random_test(); }
-TEST_VM(metaspace, BinList_random_test_16)  { BinListBasicTest<metaspace::BinList16>::random_test(); }
-TEST_VM(metaspace, BinList_random_test_32)  { BinListBasicTest<metaspace::BinList32>::random_test(); }
+template <typename BINLISTTYPE> const size_t BinListBasicTest<BINLISTTYPE>::minws = BINLISTTYPE::MinWordSize;
+template <typename BINLISTTYPE> const size_t BinListBasicTest<BINLISTTYPE>::maxws = BINLISTTYPE::MaxWordSize;
 
-TEST_VM(metaspace, BinList_random_test_1331)   { BinListBasicTest< metaspace::BinListImpl<13, 31> >::random_test(); }
-TEST_VM(metaspace, BinList_random_test_131)   { BinListBasicTest< metaspace::BinListImpl<13, 1> >::random_test(); }
+TEST_VM(metaspace, BinList_basic_8)     { BinListBasicTest< BinListImpl<2, 8> >::basic_test(); }
+TEST_VM(metaspace, BinList_basic_16)    { BinListBasicTest< BinListImpl<2, 16> >::basic_test(); }
+TEST_VM(metaspace, BinList_basic_32)    { BinListBasicTest<BinList32>::basic_test(); }
+TEST_VM(metaspace, BinList_basic_1331)  { BinListBasicTest< BinListImpl<13, 31> >::basic_test(); }
+TEST_VM(metaspace, BinList_basic_131)   { BinListBasicTest< BinListImpl<13, 1> >::basic_test(); }
+
+TEST_VM(metaspace, BinList_basic2_8)     { BinListBasicTest< BinListImpl<2, 8> >::basic_test_2(); }
+TEST_VM(metaspace, BinList_basic2_16)    { BinListBasicTest< BinListImpl<2, 16> >::basic_test_2(); }
+TEST_VM(metaspace, BinList_basic2_32)    { BinListBasicTest<BinList32 >::basic_test_2(); }
+TEST_VM(metaspace, BinList_basic2_1331)  { BinListBasicTest< BinListImpl<13, 31> >::basic_test_2(); }
+TEST_VM(metaspace, BinList_basic2_131)   { BinListBasicTest< BinListImpl<13, 1> >::basic_test_2(); }
+
+TEST_VM(metaspace, BinList_random_test_8)     { BinListBasicTest< BinListImpl<2, 8> >::random_test(); }
+TEST_VM(metaspace, BinList_random_test_16)    { BinListBasicTest< BinListImpl<2, 16> >::random_test(); }
+TEST_VM(metaspace, BinList_random_test_32)    { BinListBasicTest<BinList32>::random_test(); }
+TEST_VM(metaspace, BinList_random_test_1331)  { BinListBasicTest< BinListImpl<13, 31> >::random_test(); }
+TEST_VM(metaspace, BinList_random_test_131)   { BinListBasicTest< BinListImpl<13, 1> >::random_test(); }
 
--- old/test/hotspot/gtest/metaspace/test_blocktree.cpp	2020-09-04 13:57:21.701161175 +0200
+++ new/test/hotspot/gtest/metaspace/test_blocktree.cpp	2020-09-04 13:57:21.313158646 +0200
@@ -1,6 +1,6 @@
 /*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
@@ -25,10 +25,25 @@
 
 #include "precompiled.hpp"
 
-//#define LOG_PLEASE
-
-#include "metaspaceTestsCommon.hpp"
-
+#include "memory/metaspace/msBlockTree.hpp"
+#include "memory/metaspace/msCounter.hpp"
+#include "memory/resourceArea.hpp"
+
+// #define LOG_PLEASE
+#include "metaspaceGtestCommon.hpp"
+
+using metaspace::BlockTree;
+using metaspace::MemRangeCounter;
+
+// Small helper. Given a 0-terminated array of sizes, a feeder buffer and a tree,
+//  add blocks of these sizes to the tree in the order they appear in the array.
+static void create_nodes(const size_t sizes[], FeederBuffer& fb, BlockTree& bt) {
+  for (int i = 0; sizes[i] > 0; i ++) {
+    size_t s = sizes[i];
+    MetaWord* p = fb.get(s);
+    bt.add_block(p, s);
+  }
+}
 
 #define CHECK_BT_CONTENT(bt, expected_num, expected_size) { \
   EXPECT_EQ(bt.count(), (unsigned)expected_num); \
@@ -49,31 +64,32 @@
   MetaWord* p = NULL;
   MetaWord arr[10000];
 
-  const size_t minws = BlockTree::minimal_word_size;
-  const size_t maxws = 4096;
+  ASSERT_LE(BlockTree::MinWordSize, (size_t)6); // Sanity check. Adjust if Node is changed.
+
+  const size_t minws = BlockTree::MinWordSize;
 
-  // get_block from empty tree should yield nothing
-  p = bt.get_block(minws, &real_size);
-  EXPECT_EQ(p, (MetaWord*)NULL);
-  EXPECT_EQ(real_size, (size_t)0);
+  // remove_block from empty tree should yield nothing
+  p = bt.remove_block(minws, &real_size);
+  EXPECT_NULL(p);
+  EXPECT_0(real_size);
   CHECK_BT_CONTENT(bt, 0, 0);
 
   // Add some blocks and retrieve them right away.
   size_t sizes[] = {
-      minws + 10,
-      maxws - 10,
       minws, // smallest possible
-      maxws - 1, // largest possible
+      minws + 10,
+      1024,
+      4711,
       0
   };
 
-  for (int i = 0; sizes[i] > 0; i ++) {
+  for (int i = 0; sizes[i] > 0; i++) {
     bt.add_block(arr, sizes[i]);
     CHECK_BT_CONTENT(bt, 1, sizes[i]);
 
     DEBUG_ONLY(bt.verify();)
 
-    MetaWord* p = bt.get_block(sizes[i], &real_size);
+    MetaWord* p = bt.remove_block(sizes[i], &real_size);
     EXPECT_EQ(p, arr);
     EXPECT_EQ(real_size, (size_t)sizes[i]);
     CHECK_BT_CONTENT(bt, 0, 0);
@@ -81,73 +97,91 @@
 
 }
 
-TEST_VM(metaspace, BlockTree_closest_fit) {
+// Helper for test_find_nearest_fit_with_tree.
+// Out of an array of sizes return the closest upper match to a requested size.
+// Returns SIZE_MAX if none found.
+static size_t helper_find_nearest_fit(const size_t sizes[], size_t request_size) {
+  size_t best = SIZE_MAX;
+  for (int i = 0; sizes[i] > 0; i++) {
+    if (sizes[i] >= request_size && sizes[i] < best) {
+      best = sizes[i];
+    }
+  }
+  return best;
+}
+
+// Given a sequence of (0-terminated) sizes, add blocks of those sizes to the tree in the order given. Then, ask
+// for a request size and check that it is the expected result.
+static void test_find_nearest_fit_with_tree(const size_t sizes[], size_t request_size) {
 
-  // Test the fact that getting blocks should always return the closest fit
   BlockTree bt;
-  FeederBuffer fb(10000);
+  FeederBuffer fb(4 * K);
 
-  const size_t minws = BlockTree::minimal_word_size;
-  const size_t maxws = 256;
+  create_nodes(sizes, fb, bt);
 
-  size_t sizes[] = {
-      minws + 9,
-      minws + 3,
-      minws + 9,
-      minws,
-      minws + 8,
-      maxws - 2,
-      minws,
-      maxws - 1,
-      0
-  };
+  DEBUG_ONLY(bt.verify();)
 
-  size_t size_added = 0;
-  int num_added = 0;
+  size_t expected_size = helper_find_nearest_fit(sizes, request_size);
+  size_t real_size = 0;
+  MetaWord* p = bt.remove_block(request_size, &real_size);
 
-  for (int i = 0; sizes[i] > 0; i ++) {
-    const size_t s = sizes[i];
-    MetaWord* p = fb.get(s);
-    bt.add_block(p, s);
-    num_added ++; size_added += s;
-    CHECK_BT_CONTENT(bt, num_added, size_added);
+  if (expected_size != SIZE_MAX) {
+    EXPECT_NOT_NULL(p);
+    EXPECT_EQ(real_size, expected_size);
+  } else {
+    EXPECT_NULL(p);
+    EXPECT_0(real_size);
   }
 
-  DEBUG_ONLY(bt.verify();)
+  LOG(SIZE_FORMAT ": " SIZE_FORMAT ".", request_size, real_size);
 
-  size_t last_size = 0;
-  while (bt.is_empty() == false) {
-    size_t real_size = 0;
-    MetaWord* p = bt.get_block(minws, &real_size);
-    EXPECT_TRUE(fb.is_valid_range(p, real_size));
-
-    EXPECT_GE(real_size, last_size);
-    last_size = real_size;
-
-    num_added --;
-    size_added -= real_size;
-    CHECK_BT_CONTENT(bt, num_added, size_added);
-  }
+}
 
-  CHECK_BT_CONTENT(bt, 0, 0);
+TEST_VM(metaspace, BlockTree_find_nearest_fit) {
 
-}
+  // Test tree for test_find_nearest_fit looks like this
+  //                30
+  //               /  \
+  //              /    \
+  //             /      \
+  //            17       50
+  //           /  \     /  \
+  //          /    \   /    \
+  //         10    28 32     51
+  //                    \
+  //                     35
+
+  static const size_t sizes[] = {
+    30, 17, 10, 28,
+    50, 32, 51, 35,
+    0 // stop
+  };
+
+  BlockTree bt;
+  FeederBuffer fb(4 * K);
 
+  create_nodes(sizes, fb, bt);
 
+  for (int i = BlockTree::MinWordSize; i <= 60; i ++) {
+    test_find_nearest_fit_with_tree(sizes, i);
+  }
+
+}
+
+// Test repeated adding and removing of blocks of the same size, which
+// should exercise the list-part of the tree.
 TEST_VM(metaspace, BlockTree_basic_siblings)
 {
   BlockTree bt;
+  FeederBuffer fb(4 * K);
+
   CHECK_BT_CONTENT(bt, 0, 0);
 
-  const size_t minws = BlockTree::minimal_word_size;
-  const size_t maxws = 256;
-  const size_t test_size = minws + 17;
+  const size_t test_size = BlockTree::MinWordSize;
   const int num = 10;
 
-  MetaWord* arr = NEW_C_HEAP_ARRAY(MetaWord, num * test_size, mtInternal);
-
-  for (int i = 0; i < num; i ++) {
-    bt.add_block(arr + (i * test_size), test_size);
+  for (int i = 0; i < num; i++) {
+    bt.add_block(fb.get(test_size), test_size);
     CHECK_BT_CONTENT(bt, i + 1, (i + 1) * test_size);
   }
 
@@ -155,16 +189,38 @@
 
   for (int i = num; i > 0; i --) {
     size_t real_size = 4711;
-    MetaWord* p = bt.get_block(test_size, &real_size);
-    EXPECT_LT(p, arr + num * test_size);
-    EXPECT_GE(p, arr);
+    MetaWord* p = bt.remove_block(test_size, &real_size);
+    EXPECT_TRUE(fb.is_valid_pointer(p));
     EXPECT_EQ(real_size, (size_t)test_size);
     CHECK_BT_CONTENT(bt, i - 1, (i - 1) * test_size);
   }
 
-  FREE_C_HEAP_ARRAY(MetaWord, arr);
 }
 
+#ifdef ASSERT
+TEST_VM(metaspace, BlockTree_print_test) {
+
+  static const size_t sizes[] = {
+    30, 17, 10, 28,
+    50, 32, 51, 35,
+    0 // stop
+  };
+
+  BlockTree bt;
+  FeederBuffer fb(4 * K);
+
+  create_nodes(sizes, fb, bt);
+
+  ResourceMark rm;
+
+  stringStream ss;
+  bt.print_tree(&ss);
+
+  LOG("%s", ss.as_string());
+
+}
+#endif
+
 class BlockTreeTest {
 
   FeederBuffer _fb;
@@ -175,12 +231,12 @@
   RandSizeGenerator _rgen;
 
 #define CHECK_COUNTERS \
-		CHECK_BT_CONTENT(_bt[0], _cnt[0].count(), _cnt[0].total_size()) \
-    CHECK_BT_CONTENT(_bt[1], _cnt[1].count(), _cnt[1].total_size())
+  CHECK_BT_CONTENT(_bt[0], _cnt[0].count(), _cnt[0].total_size()) \
+  CHECK_BT_CONTENT(_bt[1], _cnt[1].count(), _cnt[1].total_size())
 
 #define CHECK_COUNTERS_ARE_0 \
-    CHECK_BT_CONTENT(_bt[0], 0, 0) \
-    CHECK_BT_CONTENT(_bt[1], 0, 0)
+  CHECK_BT_CONTENT(_bt[0], 0, 0) \
+  CHECK_BT_CONTENT(_bt[1], 0, 0)
 
 #ifdef ASSERT
   void verify_trees() {
@@ -195,9 +251,9 @@
     right_left = 3
   };
 
+  // Feed the whole feeder buffer to the trees, according to feeding_pattern.
   void feed_all(feeding_pattern_t feeding_pattern) {
 
-    // Feed the whole feaderbuffer space to the trees.
     MetaWord* p = NULL;
     unsigned added = 0;
 
@@ -213,7 +269,7 @@
         s =_rgen.get();
         break;
       case left_right:
-        // fill in ascending order to annoy trees.
+        // fill in ascending order to provoke a misformed tree.
         s = MIN2(_rgen.get(), old_feeding_size);
         old_feeding_size = s;
         break;
@@ -224,28 +280,29 @@
         break;
       }
 
+      // Get a block from the feeder buffer; feed it alternatingly to either tree.
       p = _fb.get(s);
       if (p != NULL) {
         int which = added % 2;
-        added ++;
+        added++;
         _bt[which].add_block(p, s);
         _cnt[which].add(s);
         CHECK_COUNTERS
       }
-      DEBUG_ONLY(verify_trees();)
-      CHECK_COUNTERS;
     } while (p != NULL && added < max_blocks);
 
-    // Trees should be populated in a balanced way, and not empty
-    EXPECT_TRUE( _bt[0].count() == _bt[1].count() ||
-                (_bt[0].count() == _bt[1].count() + 1 && _bt[0].count() > 0));
+    DEBUG_ONLY(verify_trees();)
+
+    // Trees should contain the same number of nodes (+-1)
+    EXPECT_TRUE(_bt[0].count() == _bt[1].count() ||
+                _bt[0].count() == _bt[1].count() + 1);
 
   }
 
   void ping_pong_loop(int iterations) {
 
     // We loop and in each iteration randomly retrieve a block from one tree and add it to another.
-    for (int i = 0; i < iterations; i ++) {
+    for (int i = 0; i < iterations; i++) {
       int taker = 0;
       int giver = 1;
       if ((os::random() % 10) > 5) {
@@ -253,10 +310,8 @@
       }
       size_t s =_rgen.get();
       size_t real_size = 0;
-      MetaWord* p = _bt[giver].get_block(s, &real_size);
-      if (p == NULL) {
-        // Todo: check that bt really has no larger block than this.
-      } else {
+      MetaWord* p = _bt[giver].remove_block(s, &real_size);
+      if (p != NULL) {
         ASSERT_TRUE(_fb.is_valid_range(p, real_size));
         ASSERT_GE(real_size, s);
         _bt[taker].add_block(p, real_size);
@@ -276,15 +331,15 @@
   // Drain the trees. While draining, observe the order of the drained items.
   void drain_all() {
 
-    for (int which = 0; which < 2; which ++) {
+    for (int which = 0; which < 2; which++) {
       BlockTree* bt = _bt + which;
       size_t last_size = 0;
       while(!bt->is_empty()) {
 
         // We only query for the minimal size. Actually returned size should be
-        // monotonously growing since get_block should always return the closest fit.
+        // monotonously growing since remove_block should always return the closest fit.
         size_t real_size = 4711;
-        MetaWord* p = bt->get_block(BlockTree::minimal_word_size, &real_size);
+        MetaWord* p = bt->remove_block(BlockTree::MinWordSize, &real_size);
         ASSERT_TRUE(_fb.is_valid_range(p, real_size));
 
         ASSERT_GE(real_size, last_size);
@@ -293,11 +348,8 @@
         _cnt[which].sub(real_size);
         CHECK_COUNTERS;
 
-#ifdef ASSERT
-        if (true) {//i % 1000 == 0) {
-          bt->verify();
-        }
-#endif
+        DEBUG_ONLY(bt->verify();)
+
       }
     }
 
@@ -313,7 +365,7 @@
         _bt[0].count(), _bt[0].total_size(),
         _bt[1].count(), _bt[1].total_size());
 
-    ping_pong_loop(2000);
+    ping_pong_loop(5000);
 
     LOG("After Pingpong: bt1=%d:" SIZE_FORMAT ", bt2=%d:" SIZE_FORMAT ".",
         _bt[0].count(), _bt[0].total_size(),
@@ -324,7 +376,6 @@
     CHECK_COUNTERS_ARE_0
   }
 
-
 public:
 
   BlockTreeTest(size_t min_word_size, size_t max_word_size) :
@@ -336,7 +387,6 @@
     DEBUG_ONLY(verify_trees();)
   }
 
-
   void test_scatter()      { test(scatter); }
   void test_right_left()   { test(right_left); }
   void test_left_right()   { test(left_right); }
@@ -344,21 +394,18 @@
 };
 
 #define DO_TEST(name, feedingpattern, min, max) \
-		TEST_VM(metaspace, BlockTree_##name##_##feedingpattern) { \
-      BlockTreeTest btt(min, max); \
-      btt.test_##feedingpattern(); \
-    }
+  TEST_VM(metaspace, BlockTree_##name##_##feedingpattern) { \
+    BlockTreeTest btt(min, max); \
+    btt.test_##feedingpattern(); \
+  }
 
 #define DO_TEST_ALL_PATTERNS(name, min, max) \
   DO_TEST(name, scatter, min, max) \
   DO_TEST(name, right_left, min, max) \
   DO_TEST(name, left_right, min, max)
 
-
-DO_TEST_ALL_PATTERNS(wide, BlockTree::minimal_word_size, 128 * K);
-DO_TEST_ALL_PATTERNS(narrow, BlockTree::minimal_word_size, 16)
-DO_TEST_ALL_PATTERNS(129, BlockTree::minimal_word_size, 129)
-DO_TEST_ALL_PATTERNS(4K, BlockTree::minimal_word_size, 4*K)
-
-
+DO_TEST_ALL_PATTERNS(wide, BlockTree::MinWordSize, 128 * K);
+DO_TEST_ALL_PATTERNS(narrow, BlockTree::MinWordSize, 16)
+DO_TEST_ALL_PATTERNS(129, BlockTree::MinWordSize, 129)
+DO_TEST_ALL_PATTERNS(4K, BlockTree::MinWordSize, 4*K)
 
--- old/test/hotspot/gtest/metaspace/test_chunkManager_stress.cpp	2020-09-04 13:57:22.841168608 +0200
+++ new/test/hotspot/gtest/metaspace/test_chunkManager_stress.cpp	2020-09-04 13:57:22.477166233 +0200
@@ -1,6 +1,6 @@
 /*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
@@ -25,18 +25,25 @@
 
 #include "precompiled.hpp"
 
+#include "memory/metaspace/msChunkManager.hpp"
+#include "memory/metaspace/msSettings.hpp"
+#include "memory/metaspace/msVirtualSpaceList.hpp"
+
 //#define LOG_PLEASE
+#include "metaspaceGtestCommon.hpp"
+#include "metaspaceGtestContexts.hpp"
+#include "metaspaceGtestRangeHelpers.hpp"
+#include "metaspaceGtestSparseArray.hpp"
 
-#include "metaspace/metaspace_sparsearray.hpp"
-#include "metaspace/metaspaceTestsCommon.hpp"
-#include "metaspace/metaspaceTestContexts.hpp"
 
+using metaspace::ChunkManager;
+using metaspace::Settings;
 
 class ChunkManagerRandomChunkAllocTest {
 
   static const size_t max_footprint_words = 8 * M;
 
-  ChunkTestsContext _helper;
+  ChunkGtestContext _context;
 
   // All allocated live chunks
   typedef SparseArray<Metachunk*> SparseArrayOfChunks;
@@ -59,7 +66,7 @@
 
   // Return true if, after an allocation error happened, a reserve error seems likely.
   bool could_be_reserve_error() {
-    return _helper.vslist().is_full();
+    return _context.vslist().is_full();
   }
 
   // Return true if, after an allocation error happened, a commit error seems likely.
@@ -84,10 +91,10 @@
     // (c) can be, by design, imprecise (too low).
     //
     // Here, I check (b) and trust it to be correct. We also call vslist::verify().
-    DEBUG_ONLY(_helper.verify();)
+    DEBUG_ONLY(_context.verify();)
 
     const size_t commit_add = align_up(additional_word_size, Settings::commit_granule_words());
-    if (_helper.commit_limit() <= (commit_add + _helper.vslist().committed_words())) {
+    if (_context.commit_limit() <= (commit_add + _context.vslist().committed_words())) {
       return true;
     }
 
@@ -104,7 +111,6 @@
     return MIN2(SizeRange(sz).random_value(), sz);
   }
 
-
   //// Chunk allocation ////
 
   // Given an slot index, allocate a random chunk and set it into that slot. Slot must be empty.
@@ -119,7 +125,7 @@
     const size_t min_committed = random_committed_words(max_level, _commit_factor);
 
     Metachunk* c = NULL;
-    _helper.alloc_chunk(&c, r.lowest(), r.highest(), min_committed);
+    _context.alloc_chunk(&c, r.lowest(), r.highest(), min_committed);
     if (c == NULL) {
       EXPECT_TRUE(could_be_reserve_error() ||
                   could_be_commit_error(min_committed));
@@ -163,7 +169,7 @@
   void return_chunk_at(int slot) {
     Metachunk* c = _chunks.at(slot);
     LOG("Returning chunk at %d: " METACHUNK_FORMAT ".", slot, METACHUNK_FORMAT_ARGS(c));
-    _helper.return_chunk(c);
+    _context.return_chunk(c);
     _chunks.set_at(slot, NULL);
   }
 
@@ -196,7 +202,7 @@
 
     IntRange rand(100);
 
-    for (int j = 0; j < 1000; j ++) {
+    for (int j = 0; j < 1000; j++) {
 
       bool force_alloc = false;
       bool force_free = true;
@@ -222,12 +228,11 @@
 
   }
 
-
 public:
 
   // A test with no limits
   ChunkManagerRandomChunkAllocTest(ChunkLevelRange r, float commit_factor)
-    : _helper(),
+    : _context(),
       _chunks(max_num_live_chunks(r, commit_factor)),
       _chunklevel_range(r),
       _commit_factor(commit_factor)
@@ -236,7 +241,7 @@
   // A test with no reserve limit but commit limit
   ChunkManagerRandomChunkAllocTest(size_t commit_limit,
                                    ChunkLevelRange r, float commit_factor)
-    : _helper(commit_limit),
+    : _context(commit_limit),
       _chunks(max_num_live_chunks(r, commit_factor)),
       _chunklevel_range(r),
       _commit_factor(commit_factor)
@@ -251,10 +256,9 @@
   // _commit_factor(commit_factor)
   // {}
 
-
   void do_tests() {
     const int num_runs = 5;
-    for (int n = 0; n < num_runs; n ++) {
+    for (int n = 0; n < num_runs; n++) {
       one_test();
     }
   }
@@ -263,8 +267,8 @@
 
 #define DEFINE_TEST(name, range, commit_factor) \
 TEST_VM(metaspace, chunkmanager_random_alloc_##name) { \
-	ChunkManagerRandomChunkAllocTest test(range, commit_factor); \
-	test.do_tests(); \
+  ChunkManagerRandomChunkAllocTest test(range, commit_factor); \
+  test.do_tests(); \
 }
 
 DEFINE_TEST(test_nolimit_1, ChunkLevelRanges::small_chunks(), 0.0f)
@@ -290,4 +294,3 @@
 DEFINE_TEST_2(test_with_limit_5, ChunkLevelRanges::all_chunks(), 0.5f)
 DEFINE_TEST_2(test_with_limit_6, ChunkLevelRanges::all_chunks(), 1.0f)
 
-
--- old/test/hotspot/gtest/metaspace/test_chunkheaderpool.cpp	2020-09-04 13:57:24.005176209 +0200
+++ new/test/hotspot/gtest/metaspace/test_chunkheaderpool.cpp	2020-09-04 13:57:23.625173727 +0200
@@ -1,6 +1,6 @@
 /*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
@@ -25,7 +25,17 @@
 
 #include "precompiled.hpp"
 
-#include "metaspaceTestsCommon.hpp"
+
+#include "memory/metaspace/msChunkHeaderPool.hpp"
+#include "memory/metaspace/msCounter.hpp"
+#include "memory/metaspace/msMetachunk.hpp"
+
+//#define LOG_PLEASE
+#include "metaspaceGtestCommon.hpp"
+
+using metaspace::ChunkHeaderPool;
+using metaspace::Metachunk;
+using metaspace::SizeCounter;
 
 class ChunkHeaderPoolTest {
 
@@ -51,7 +61,7 @@
     _num_allocated.decrement();
     DEBUG_ONLY(_num_allocated.check(_pool.used());)
 
-    DEBUG_ONLY(_pool.verify(true);)
+    DEBUG_ONLY(_pool.verify();)
 
   }
 
@@ -71,7 +81,7 @@
     _num_allocated.increment();
     DEBUG_ONLY(_num_allocated.check(_pool.used());)
 
-    DEBUG_ONLY(_pool.verify(true);)
+    DEBUG_ONLY(_pool.verify();)
   }
 
   void attempt_allocate_or_free_at(size_t index) {
@@ -85,12 +95,12 @@
   // Randomly allocate from the pool and free. Slight preference for allocation.
   void test_random_alloc_free(int num_iterations) {
 
-    for (int iter = 0; iter < num_iterations; iter ++) {
+    for (int iter = 0; iter < num_iterations; iter++) {
       size_t index = (size_t)os::random() % max_cap;
       attempt_allocate_or_free_at(index);
     }
 
-    DEBUG_ONLY(_pool.verify(true);)
+    DEBUG_ONLY(_pool.verify();)
 
   }
 
@@ -99,7 +109,6 @@
     test.test_random_alloc_free(100);
   }
 
-
 public:
 
   ChunkHeaderPoolTest() : _pool() {
@@ -107,7 +116,7 @@
   }
 
   static void run_tests() {
-    for (int i = 0; i < 1000; i ++) {
+    for (int i = 0; i < 1000; i++) {
       test_once();
     }
   }
@@ -142,7 +151,6 @@
 
 }
 
-
 TEST_VM(metaspace, chunk_header_pool) {
   ChunkHeaderPoolTest::run_tests();
 }
--- old/test/hotspot/gtest/metaspace/test_commitmask.cpp	2020-09-04 13:57:24.837181649 +0200
+++ new/test/hotspot/gtest/metaspace/test_commitmask.cpp	2020-09-04 13:57:24.521179583 +0200
@@ -1,6 +1,6 @@
 /*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
@@ -24,10 +24,18 @@
  */
 
 #include "precompiled.hpp"
+
+#include "memory/metaspace/msCommitMask.hpp"
+#include "memory/metaspace/msSettings.hpp"
 #include "runtime/os.hpp"
+#include "utilities/align.hpp"
+#include "utilities/debug.hpp"
+
+#include "metaspaceGtestCommon.hpp"
+#include "metaspaceGtestRangeHelpers.hpp"
 
-#include "metaspaceTestsCommon.hpp"
-#include "metaspace/metaspace_rangehelpers.hpp"
+using metaspace::CommitMask;
+using metaspace::Settings;
 
 static int get_random(int limit) { return os::random() % limit; }
 
@@ -40,7 +48,7 @@
   void verify_mask() {
     // Note: we omit the touch test since we operate on fictional
     // memory
-    DEBUG_ONLY(_mask.verify(false);)
+    DEBUG_ONLY(_mask.verify();)
   }
 
   // Return a random sub range within [_base.._base + word_size),
@@ -85,7 +93,7 @@
     ASSERT_EQ(_mask.get_committed_size_in_range(_base, _word_size),
               _word_size);
 
-    for (const MetaWord* p = _base; p < _base + _word_size; p ++) {
+    for (const MetaWord* p = _base; p < _base + _word_size; p++) {
       ASSERT_TRUE(_mask.is_committed_address(p));
     }
 
@@ -111,7 +119,7 @@
               _word_size - sr_word_size);
     ASSERT_EQ(_mask.get_committed_size_in_range(_base, _word_size),
               _word_size - sr_word_size);
-    for (const MetaWord* p = _base; p < _base + _word_size; p ++) {
+    for (const MetaWord* p = _base; p < _base + _word_size; p++) {
       if (p >= sr_base && p < sr_base + sr_word_size) {
         ASSERT_FALSE(_mask.is_committed_address(p));
       } else {
@@ -130,7 +138,7 @@
               _word_size);
     ASSERT_EQ(_mask.get_committed_size_in_range(_base, _word_size),
               _word_size);
-    for (const MetaWord* p = _base; p < _base + _word_size; p ++) {
+    for (const MetaWord* p = _base; p < _base + _word_size; p++) {
       ASSERT_TRUE(_mask.is_committed_address(p));
     }
 
@@ -163,7 +171,7 @@
 
     ASSERT_EQ(_mask.get_committed_size_in_range(sr_base, sr_word_size),
               (size_t)0);
-    for (const MetaWord* p = _base; p < _base + _word_size; p ++) {
+    for (const MetaWord* p = _base; p < _base + _word_size; p++) {
       ASSERT_FALSE(_mask.is_committed_address(p));
     }
 
@@ -182,7 +190,7 @@
         sr_word_size);
     ASSERT_EQ(_mask.get_committed_size_in_range(_base, _word_size),
         sr_word_size);
-    for (const MetaWord* p = _base; p < _base + _word_size; p ++) {
+    for (const MetaWord* p = _base; p < _base + _word_size; p++) {
       if (p >= sr_base && p < sr_base + sr_word_size) {
         ASSERT_TRUE(_mask.is_committed_address(p));
       } else {
@@ -201,13 +209,12 @@
         (size_t)0);
     EXPECT_EQ(_mask.get_committed_size_in_range(_base, _word_size),
         (size_t)0);
-    for (const MetaWord* p = _base; p < _base + _word_size; p ++) {
+    for (const MetaWord* p = _base; p < _base + _word_size; p++) {
       ASSERT_FALSE(_mask.is_committed_address(p));
     }
 
   }
 
-
   void test3() {
 
     // arbitrary ranges are set and cleared and compared with the test map
@@ -215,7 +222,7 @@
 
     _mask.clear_large();
 
-    for (int run = 0; run < 100; run ++) {
+    for (int run = 0; run < 100; run++) {
 
       // A random range
       SizeRange r = SizeRange(_word_size).random_aligned_subrange(Settings::commit_granule_words());
@@ -237,7 +244,6 @@
 
   }
 
-
 public:
 
   CommitMaskTest(const MetaWord* base, size_t size)
@@ -248,12 +254,11 @@
     LOG("mask range: " PTR_FORMAT "-" PTR_FORMAT
          " (" SIZE_FORMAT " words).",
          p2i(_base), p2i(_base + _word_size), _word_size);
-    for (int i = 0; i < 5; i ++) {
+    for (int i = 0; i < 5; i++) {
       test1(); test2(); test3();
     }
   }
 
-
 };
 
 TEST_VM(metaspace, commit_mask_basics) {
@@ -273,7 +278,7 @@
   mask3.mark_range_as_committed(base + (Settings::commit_granule_words() * 42), Settings::commit_granule_words());
 
   ASSERT_EQ(mask3.at(0), 1);
-  for (int i = 1; i < 42; i ++) {
+  for (int i = 1; i < 42; i++) {
     ASSERT_EQ(mask3.at(i), 0);
   }
   ASSERT_EQ(mask3.at(42), 1);
@@ -326,10 +331,9 @@
 
 }
 
-
 TEST_VM(metaspace, commit_mask_random) {
 
-  for (int i = 0; i < 5; i ++) {
+  for (int i = 0; i < 5; i++) {
 
     // make up a range out of thin air
     const MetaWord* const base =
--- old/test/hotspot/gtest/metaspace/test_freeblocks.cpp	2020-09-04 13:57:25.565186414 +0200
+++ new/test/hotspot/gtest/metaspace/test_freeblocks.cpp	2020-09-04 13:57:25.257184398 +0200
@@ -1,6 +1,6 @@
 /*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
@@ -25,9 +25,14 @@
 
 #include "precompiled.hpp"
 
+#include "memory/metaspace/msCounter.hpp"
+#include "memory/metaspace/msFreeBlocks.hpp"
+
 //#define LOG_PLEASE
+#include "metaspaceGtestCommon.hpp"
 
-#include "metaspaceTestsCommon.hpp"
+using metaspace::FreeBlocks;
+using metaspace::SizeCounter;
 
 #define CHECK_CONTENT(fb, num_blocks_expected, word_size_expected) \
 { \
@@ -90,8 +95,8 @@
 
   bool allocate() {
 
-    size_t word_size = MAX2(_rgen_allocations.get(), _freeblocks.minimal_word_size);
-    MetaWord* p = _freeblocks.get_block(word_size);
+    size_t word_size = MAX2(_rgen_allocations.get(), _freeblocks.MinWordSize);
+    MetaWord* p = _freeblocks.remove_block(word_size);
     if (p != NULL) {
       _allocated_words.increment_by(word_size);
       allocation_t* a = new allocation_t;
@@ -113,11 +118,11 @@
 
   void test_loop() {
     // We loop and in each iteration execute one of three operations:
-    // - allocation from lom
-    // - deallocation to lom of a previously allocated block
-    // - feeding a new larger block into the lom (mimicks chunk retiring)
-    // When we have fed all large blocks into the lom (feedbuffer empty), we
-    //  switch to draining the lom completely (only allocs)
+    // - allocation from fbl
+    // - deallocation to fbl of a previously allocated block
+    // - feeding a new larger block into the fbl (mimicks chunk retiring)
+    // When we have fed all large blocks into the fbl (feedbuffer empty), we
+    //  switch to draining the fbl completely (only allocs)
     bool forcefeed = false;
     bool draining = false;
     bool stop = false;
@@ -128,17 +133,17 @@
       if (!draining && (surprise >= 7 || forcefeed)) {
         forcefeed = false;
         if (feed_some()) {
-          _num_feeds ++;
+          _num_feeds++;
         } else {
-          // We fed all input memory into the LOM. Now lets proceed until the lom is drained.
+          // We fed all input memory into the fbl. Now lets proceed until the fbl is drained.
           draining = true;
         }
       } else if (!draining && surprise < 1) {
         deallocate_top();
-        _num_deallocs ++;
+        _num_deallocs++;
       } else {
         if (allocate()) {
-          _num_allocs ++;
+          _num_allocs++;
         } else {
           if (draining) {
             stop = _freeblocks.total_size() < 512;
@@ -160,11 +165,8 @@
 
     // Drain
 
-
   }
 
-
-
 public:
 
   FreeBlocksTest(size_t avg_alloc_size) :
@@ -180,7 +182,6 @@
     CHECK_CONTENT(_freeblocks, 1, 1024);
   }
 
-
   static void test_small_allocations() {
     FreeBlocksTest test(10);
     test.test_loop();
@@ -196,25 +197,23 @@
     test.test_loop();
   }
 
-
 };
 
-
 TEST_VM(metaspace, freeblocks_basics) {
 
-  FreeBlocks lom;
+  FreeBlocks fbl;
   MetaWord tmp[1024];
-  CHECK_CONTENT(lom, 0, 0);
+  CHECK_CONTENT(fbl, 0, 0);
 
-  lom.add_block(tmp, 1024);
-  DEBUG_ONLY(lom.verify();)
-  ASSERT_FALSE(lom.is_empty());
-  CHECK_CONTENT(lom, 1, 1024);
+  fbl.add_block(tmp, 1024);
+  DEBUG_ONLY(fbl.verify();)
+  ASSERT_FALSE(fbl.is_empty());
+  CHECK_CONTENT(fbl, 1, 1024);
 
-  MetaWord* p = lom.get_block(1024);
+  MetaWord* p = fbl.remove_block(1024);
   EXPECT_EQ(p, tmp);
-  DEBUG_ONLY(lom.verify();)
-  CHECK_CONTENT(lom, 0, 0);
+  DEBUG_ONLY(fbl.verify();)
+  CHECK_CONTENT(fbl, 0, 0);
 
 }
 
--- old/test/hotspot/gtest/metaspace/test_internstats.cpp	2020-09-04 13:57:26.245190866 +0200
+++ new/test/hotspot/gtest/metaspace/test_internstats.cpp	2020-09-04 13:57:25.937188849 +0200
@@ -1,6 +1,6 @@
 /*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
@@ -25,10 +25,10 @@
 
 #include "precompiled.hpp"
 
-//#define LOG_PLEASE
+#include "memory/metaspace/msInternalStats.hpp"
 
-#include "metaspaceTestsCommon.hpp"
-#include "memory/metaspace/internStat.hpp"
+//#define LOG_PLEASE
+#include "metaspaceGtestCommon.hpp"
 
 // Very simple test, since the VM is fired up we should see a little
 // Metaspace activity already which should show up in the stats.
--- old/test/hotspot/gtest/metaspace/test_is_metaspace_obj.cpp	2020-09-04 13:57:26.877195009 +0200
+++ new/test/hotspot/gtest/metaspace/test_is_metaspace_obj.cpp	2020-09-04 13:57:26.597193173 +0200
@@ -1,6 +1,6 @@
 /*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
@@ -27,7 +27,7 @@
 
 #include "memory/allocation.inline.hpp"
 #include "memory/metaspace.hpp"
-#include "memory/metaspace/virtualSpaceList.hpp"
+#include "memory/metaspace/msVirtualSpaceList.hpp"
 #include "runtime/mutex.hpp"
 #include "runtime/mutexLocker.hpp"
 #include "runtime/os.hpp"
@@ -35,8 +35,6 @@
 
 using namespace metaspace;
 
-
-
 // Test the cheerful multitude of metaspace-contains-functions.
 class MetaspaceIsMetaspaceObjTest {
   Mutex* _lock;
--- old/test/hotspot/gtest/metaspace/test_metachunk.cpp	2020-09-04 13:57:27.513199181 +0200
+++ new/test/hotspot/gtest/metaspace/test_metachunk.cpp	2020-09-04 13:57:27.233197344 +0200
@@ -1,6 +1,6 @@
 /*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
@@ -24,26 +24,39 @@
  */
 
 #include "precompiled.hpp"
-#include "metaspace/metaspaceTestsCommon.hpp"
-#include "metaspace/metaspaceTestContexts.hpp"
+
+#include "memory/metaspace/msChunkManager.hpp"
+#include "memory/metaspace/msFreeChunkList.hpp"
+#include "memory/metaspace/msMetachunk.hpp"
+#include "memory/metaspace/msSettings.hpp"
+#include "memory/metaspace/msVirtualSpaceNode.hpp"
 #include "runtime/mutexLocker.hpp"
 
+#include "metaspaceGtestCommon.hpp"
+#include "metaspaceGtestContexts.hpp"
+
+
+using metaspace::ChunkManager;
+using metaspace::FreeChunkListVector;
+using metaspace::Metachunk;
+using metaspace::Settings;
+using metaspace::VirtualSpaceNode;
 using namespace metaspace::chunklevel;
 
 // Test ChunkManager::get_chunk
 TEST_VM(metaspace, get_chunk) {
 
-  ChunkTestsContext helper(8 * M);
+  ChunkGtestContext context(8 * M);
   Metachunk* c = NULL;
 
-  for (chunklevel_t pref_lvl = LOWEST_CHUNK_LEVEL; pref_lvl <= HIGHEST_CHUNK_LEVEL; pref_lvl ++) {
+  for (chunklevel_t pref_lvl = LOWEST_CHUNK_LEVEL; pref_lvl <= HIGHEST_CHUNK_LEVEL; pref_lvl++) {
 
-    for (chunklevel_t max_lvl = pref_lvl; max_lvl <= HIGHEST_CHUNK_LEVEL; max_lvl ++) {
+    for (chunklevel_t max_lvl = pref_lvl; max_lvl <= HIGHEST_CHUNK_LEVEL; max_lvl++) {
 
       for (size_t min_committed_words = Settings::commit_granule_words();
            min_committed_words <= word_size_for_level(max_lvl); min_committed_words *= 2) {
-        helper.alloc_chunk_expect_success(&c, pref_lvl, max_lvl, min_committed_words);
-        helper.return_chunk(c);
+        context.alloc_chunk_expect_success(&c, pref_lvl, max_lvl, min_committed_words);
+        context.return_chunk(c);
       }
     }
   }
@@ -53,21 +66,21 @@
 TEST_VM(metaspace, get_chunk_with_commit_limit) {
 
   const size_t commit_limit_words = 1 * M;
-  ChunkTestsContext helper(commit_limit_words);
+  ChunkGtestContext context(commit_limit_words);
   Metachunk* c = NULL;
 
-  for (chunklevel_t pref_lvl = LOWEST_CHUNK_LEVEL; pref_lvl <= HIGHEST_CHUNK_LEVEL; pref_lvl ++) {
+  for (chunklevel_t pref_lvl = LOWEST_CHUNK_LEVEL; pref_lvl <= HIGHEST_CHUNK_LEVEL; pref_lvl++) {
 
-    for (chunklevel_t max_lvl = pref_lvl; max_lvl <= HIGHEST_CHUNK_LEVEL; max_lvl ++) {
+    for (chunklevel_t max_lvl = pref_lvl; max_lvl <= HIGHEST_CHUNK_LEVEL; max_lvl++) {
 
       for (size_t min_committed_words = Settings::commit_granule_words();
            min_committed_words <= word_size_for_level(max_lvl); min_committed_words *= 2) {
 
         if (min_committed_words <= commit_limit_words) {
-          helper.alloc_chunk_expect_success(&c, pref_lvl, max_lvl, min_committed_words);
-          helper.return_chunk(c);
+          context.alloc_chunk_expect_success(&c, pref_lvl, max_lvl, min_committed_words);
+          context.return_chunk(c);
         } else {
-          helper.alloc_chunk_expect_failure(pref_lvl, max_lvl, min_committed_words);
+          context.alloc_chunk_expect_failure(pref_lvl, max_lvl, min_committed_words);
         }
 
       }
@@ -78,13 +91,13 @@
 // Test that recommitting the used portion of a chunk will preserve the original content.
 TEST_VM(metaspace, get_chunk_recommit) {
 
-  ChunkTestsContext helper;
+  ChunkGtestContext context;
   Metachunk* c = NULL;
-  helper.alloc_chunk_expect_success(&c, ROOT_CHUNK_LEVEL, ROOT_CHUNK_LEVEL, 0);
-  helper.uncommit_chunk_with_test(c);
+  context.alloc_chunk_expect_success(&c, ROOT_CHUNK_LEVEL, ROOT_CHUNK_LEVEL, 0);
+  context.uncommit_chunk_with_test(c);
 
-  helper.commit_chunk_with_test(c, Settings::commit_granule_words());
-  helper.allocate_from_chunk(c, Settings::commit_granule_words());
+  context.commit_chunk_with_test(c, Settings::commit_granule_words());
+  context.allocate_from_chunk(c, Settings::commit_granule_words());
 
   c->ensure_committed(Settings::commit_granule_words());
   check_range_for_pattern(c->base(), c->used_words(), (uintx)c);
@@ -92,7 +105,7 @@
   c->ensure_committed(Settings::commit_granule_words() * 2);
   check_range_for_pattern(c->base(), c->used_words(), (uintx)c);
 
-  helper.return_chunk(c);
+  context.return_chunk(c);
 
 }
 
@@ -102,7 +115,7 @@
 
   const size_t reserve_limit_words = word_size_for_level(ROOT_CHUNK_LEVEL);
   const size_t commit_limit_words = 1024 * M; // just very high
-  ChunkTestsContext helper(commit_limit_words, reserve_limit_words);
+  ChunkGtestContext context(commit_limit_words, reserve_limit_words);
 
   // Reserve limit works at root chunk size granularity: if the chunk manager cannot satisfy
   //  a request for a chunk from its freelists, it will acquire a new root chunk from the
@@ -113,25 +126,25 @@
 
   // Cause allocation of the firstone root chunk, should still work:
   Metachunk* c = NULL;
-  helper.alloc_chunk_expect_success(&c, HIGHEST_CHUNK_LEVEL);
+  context.alloc_chunk_expect_success(&c, HIGHEST_CHUNK_LEVEL);
 
   // and this should need a new root chunk and hence fail:
-  helper.alloc_chunk_expect_failure(ROOT_CHUNK_LEVEL);
+  context.alloc_chunk_expect_failure(ROOT_CHUNK_LEVEL);
 
-  helper.return_chunk(c);
+  context.return_chunk(c);
 
 }
 
 // Test MetaChunk::allocate
 TEST_VM(metaspace, chunk_allocate_full) {
 
-  ChunkTestsContext helper;
+  ChunkGtestContext context;
 
-  for (chunklevel_t lvl = LOWEST_CHUNK_LEVEL; lvl <= HIGHEST_CHUNK_LEVEL; lvl ++) {
+  for (chunklevel_t lvl = LOWEST_CHUNK_LEVEL; lvl <= HIGHEST_CHUNK_LEVEL; lvl++) {
     Metachunk* c = NULL;
-    helper.alloc_chunk_expect_success(&c, lvl);
-    helper.allocate_from_chunk(c, c->word_size());
-    helper.return_chunk(c);
+    context.alloc_chunk_expect_success(&c, lvl);
+    context.allocate_from_chunk(c, c->word_size());
+    context.return_chunk(c);
   }
 
 }
@@ -139,13 +152,13 @@
 // Test MetaChunk::allocate
 TEST_VM(metaspace, chunk_allocate_random) {
 
-  ChunkTestsContext helper;
+  ChunkGtestContext context;
 
-  for (chunklevel_t lvl = LOWEST_CHUNK_LEVEL; lvl <= HIGHEST_CHUNK_LEVEL; lvl ++) {
+  for (chunklevel_t lvl = LOWEST_CHUNK_LEVEL; lvl <= HIGHEST_CHUNK_LEVEL; lvl++) {
 
     Metachunk* c = NULL;
-    helper.alloc_chunk_expect_success(&c, lvl);
-    helper.uncommit_chunk_with_test(c); // start out fully uncommitted
+    context.alloc_chunk_expect_success(&c, lvl);
+    context.uncommit_chunk_with_test(c); // start out fully uncommitted
 
     RandSizeGenerator rgen(1, c->word_size() / 30);
     bool stop = false;
@@ -153,14 +166,14 @@
     while (!stop) {
       const size_t s = rgen.get();
       if (s <= c->free_words()) {
-        helper.commit_chunk_with_test(c, s);
-        helper.allocate_from_chunk(c, s);
+        context.commit_chunk_with_test(c, s);
+        context.allocate_from_chunk(c, s);
       } else {
         stop = true;
       }
 
     }
-    helper.return_chunk(c);
+    context.return_chunk(c);
 
   }
 
@@ -168,9 +181,9 @@
 
 TEST_VM(metaspace, chunk_buddy_stuff) {
 
-  for (chunklevel_t l = ROOT_CHUNK_LEVEL + 1; l <= HIGHEST_CHUNK_LEVEL; l ++) {
+  for (chunklevel_t l = ROOT_CHUNK_LEVEL + 1; l <= HIGHEST_CHUNK_LEVEL; l++) {
 
-    ChunkTestsContext helper;
+    ChunkGtestContext context;
 
     // Allocate two chunks; since we know the first chunk is the first in its area,
     // it has to be a leader, and the next one of the same size its buddy.
@@ -179,11 +192,11 @@
     //  we know how the placement works so these tests make sense).
 
     Metachunk* c1 = NULL;
-    helper.alloc_chunk(&c1, CHUNK_LEVEL_1K);
+    context.alloc_chunk(&c1, CHUNK_LEVEL_1K);
     EXPECT_TRUE(c1->is_leader());
 
     Metachunk* c2 = NULL;
-    helper.alloc_chunk(&c2, CHUNK_LEVEL_1K);
+    context.alloc_chunk(&c2, CHUNK_LEVEL_1K);
     EXPECT_FALSE(c2->is_leader());
 
     // buddies are adjacent in memory
@@ -196,14 +209,13 @@
       EXPECT_EQ(c2->prev_in_vs(), c1);
     }
 
-    helper.return_chunk(c1);
-    helper.return_chunk(c2);
+    context.return_chunk(c1);
+    context.return_chunk(c2);
 
   }
 
 }
 
-
 TEST_VM(metaspace, chunk_allocate_with_commit_limit) {
 
   // This test does not make sense if commit-on-demand is off
@@ -213,29 +225,29 @@
 
   const size_t granule_sz = Settings::commit_granule_words();
   const size_t commit_limit = granule_sz * 3;
-  ChunkTestsContext helper(commit_limit);
+  ChunkGtestContext context(commit_limit);
 
   // A big chunk, but uncommitted.
   Metachunk* c = NULL;
-  helper.alloc_chunk_expect_success(&c, ROOT_CHUNK_LEVEL, ROOT_CHUNK_LEVEL, 0);
-  helper.uncommit_chunk_with_test(c); // ... just to make sure.
+  context.alloc_chunk_expect_success(&c, ROOT_CHUNK_LEVEL, ROOT_CHUNK_LEVEL, 0);
+  context.uncommit_chunk_with_test(c); // ... just to make sure.
 
   // first granule...
-  helper.commit_chunk_with_test(c, granule_sz);
-  helper.allocate_from_chunk(c, granule_sz);
+  context.commit_chunk_with_test(c, granule_sz);
+  context.allocate_from_chunk(c, granule_sz);
 
   // second granule...
-  helper.commit_chunk_with_test(c, granule_sz);
-  helper.allocate_from_chunk(c, granule_sz);
+  context.commit_chunk_with_test(c, granule_sz);
+  context.allocate_from_chunk(c, granule_sz);
 
   // third granule...
-  helper.commit_chunk_with_test(c, granule_sz);
-  helper.allocate_from_chunk(c, granule_sz);
+  context.commit_chunk_with_test(c, granule_sz);
+  context.allocate_from_chunk(c, granule_sz);
 
   // This should fail now.
-  helper.commit_chunk_expect_failure(c, granule_sz);
+  context.commit_chunk_expect_failure(c, granule_sz);
 
-  helper.return_chunk(c);
+  context.return_chunk(c);
 
 }
 
@@ -273,7 +285,7 @@
   // with a follower chunk, not a leader). Also, at any point in the merge
   // process we may arrive at a follower chunk. So, the fact that in this test
   // we only expect a leader merge is a feature of the test, and of the fact that we
-  // start each split test with a fresh MetaspaceTestHelper.
+  // start each split test with a fresh ChunkTestsContext.
 
   // Note: Splitting and merging chunks is usually done from within the ChunkManager and
   //  subject to a lot of assumptions and hence asserts. Here, we have to explicitly use
@@ -285,18 +297,18 @@
   //   in ~RootChunkArea()
   // - finally we have to lock manually
 
-  ChunkTestsContext helper;
+  ChunkGtestContext context;
 
   const chunklevel_t orig_lvl = ROOT_CHUNK_LEVEL;
-  for (chunklevel_t target_lvl = orig_lvl + 1; target_lvl <= HIGHEST_CHUNK_LEVEL; target_lvl ++) {
+  for (chunklevel_t target_lvl = orig_lvl + 1; target_lvl <= HIGHEST_CHUNK_LEVEL; target_lvl++) {
 
     // Split a fully committed chunk. The resulting chunk should be fully
     //  committed as well, and have its content preserved.
     Metachunk* c = NULL;
-    helper.alloc_chunk_expect_success(&c, orig_lvl);
+    context.alloc_chunk_expect_success(&c, orig_lvl);
 
     // We allocate from this chunk to be able to completely paint the payload.
-    helper.allocate_from_chunk(c, c->word_size());
+    context.allocate_from_chunk(c, c->word_size());
 
     const uintx canary = os::random();
     fill_range_with_pattern(c->base(), c->word_size(), canary);
@@ -313,7 +325,7 @@
       c->vsnode()->split(target_lvl, c, &splinters);
     }
 
-    DEBUG_ONLY(helper.verify();)
+    DEBUG_ONLY(context.verify();)
 
     EXPECT_EQ(c->level(), target_lvl);
     EXPECT_TRUE(c->is_fully_committed());
@@ -324,14 +336,14 @@
 
     // I expect splinter chunks (one for each splinter level:
     //  e.g. splitting a 1M chunk to get a 64K chunk should yield splinters: [512K, 256K, 128K, 64K]
-    for (chunklevel_t l = LOWEST_CHUNK_LEVEL; l < HIGHEST_CHUNK_LEVEL; l ++) {
+    for (chunklevel_t l = LOWEST_CHUNK_LEVEL; l < HIGHEST_CHUNK_LEVEL; l++) {
       const Metachunk* c2 = splinters.first_at_level(l);
       if (l > orig_lvl && l <= target_lvl) {
         EXPECT_NOT_NULL(c2);
         EXPECT_EQ(c2->level(), l);
         EXPECT_TRUE(c2->is_free());
         EXPECT_TRUE(!c2->is_leader());
-        DEBUG_ONLY(c2->verify(false));
+        DEBUG_ONLY(c2->verify());
         check_range_for_pattern(c2->base(), c2->word_size(), canary);
       } else {
         EXPECT_NULL(c2);
@@ -356,7 +368,7 @@
       EXPECT_EQ(splinters.num_chunks(), 0);
     }
 
-    helper.return_chunk(c);
+    context.return_chunk(c);
 
   }
 
@@ -364,13 +376,13 @@
 
 TEST_VM(metaspace, chunk_enlarge_in_place) {
 
-  ChunkTestsContext helper;
+  ChunkGtestContext context;
 
   // Starting with the smallest chunk size, attempt to enlarge the chunk in place until we arrive
   // at root chunk size. Since the state is clean, this should work.
 
   Metachunk* c = NULL;
-  helper.alloc_chunk_expect_success(&c, HIGHEST_CHUNK_LEVEL);
+  context.alloc_chunk_expect_success(&c, HIGHEST_CHUNK_LEVEL);
 
   chunklevel_t l = c->level();
 
@@ -378,15 +390,15 @@
 
     // commit and allocate from chunk to pattern it...
     const size_t original_chunk_size = c->word_size();
-    helper.commit_chunk_with_test(c, c->free_words());
-    helper.allocate_from_chunk(c, c->free_words());
+    context.commit_chunk_with_test(c, c->free_words());
+    context.allocate_from_chunk(c, c->free_words());
 
     size_t used_before = c->used_words();
     size_t free_before = c->free_words();
     size_t free_below_committed_before = c->free_below_committed_words();
     const MetaWord* top_before = c->top();
 
-    EXPECT_TRUE(helper.cm().attempt_enlarge_chunk(c));
+    EXPECT_TRUE(context.cm().attempt_enlarge_chunk(c));
     EXPECT_EQ(l - 1, c->level());
     EXPECT_EQ(c->word_size(), original_chunk_size * 2);
 
@@ -406,7 +418,7 @@
     l = c->level();
   }
 
-  helper.return_chunk(c);
+  context.return_chunk(c);
 
 }
 
--- old/test/hotspot/gtest/metaspace/test_metachunklist.cpp	2020-09-04 13:57:28.153203381 +0200
+++ new/test/hotspot/gtest/metaspace/test_metachunklist.cpp	2020-09-04 13:57:27.877201570 +0200
@@ -1,6 +1,6 @@
 /*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
@@ -25,23 +25,32 @@
 
 #include "precompiled.hpp"
 
+#include "memory/metaspace/msCounter.hpp"
+#include "memory/metaspace/msFreeChunkList.hpp"
+#include "memory/metaspace/msMetachunkList.hpp"
+
 //#define LOG_PLEASE
-#include "metaspace/metaspaceTestsCommon.hpp"
-#include "metaspace/metaspaceTestContexts.hpp"
-#include "metaspace/metaspace_rangehelpers.hpp"
+#include "metaspaceGtestCommon.hpp"
+#include "metaspaceGtestContexts.hpp"
+#include "metaspaceGtestRangeHelpers.hpp"
+
+using metaspace::MemRangeCounter;
+using metaspace::MetachunkList;
+using metaspace::FreeChunkListVector;
+
 
 TEST_VM(metaspace, metachunklist) {
 
-  ChunkTestsContext helper;
+  ChunkGtestContext context;
 
   MetachunkList lst;
 
   Metachunk* chunks[10];
   size_t total_size = 0;
 
-  for (int i = 0; i < 10; i ++) {
+  for (int i = 0; i < 10; i++) {
     Metachunk* c = NULL;
-    helper.alloc_chunk_expect_success(&c, ChunkLevelRanges::all_chunks().random_value());
+    context.alloc_chunk_expect_success(&c, ChunkLevelRanges::all_chunks().random_value());
     chunks[i] = c;
     total_size += c->committed_words();
 
@@ -58,14 +67,14 @@
 
   }
 
-  for (int i = 0; i < 10; i ++) {
+  for (int i = 0; i < 10; i++) {
     DEBUG_ONLY(EXPECT_TRUE(lst.contains(chunks[i]));)
   }
 
-  for (int i = 0; i < 10; i ++) {
+  for (int i = 0; i < 10; i++) {
     Metachunk* c = lst.remove_first();
     DEBUG_ONLY(EXPECT_FALSE(lst.contains(c));)
-    helper.return_chunk(c);
+    context.return_chunk(c);
   }
 
   EXPECT_EQ(lst.count(), 0);
@@ -73,10 +82,9 @@
 
 }
 
-
 TEST_VM(metaspace, freechunklist) {
 
-  ChunkTestsContext helper;
+  ChunkGtestContext context;
 
   FreeChunkListVector lst;
 
@@ -86,12 +94,12 @@
   // Add random chunks to list and check the counter apis (word_size, commited_word_size, num_chunks)
   // Make every other chunk randomly uncommitted, and later we check that committed chunks are sorted in at the front
   // of the lists.
-  for (int i = 0; i < 100; i ++) {
+  for (int i = 0; i < 100; i++) {
     Metachunk* c = NULL;
-    helper.alloc_chunk_expect_success(&c, ChunkLevelRanges::all_chunks().random_value());
+    context.alloc_chunk_expect_success(&c, ChunkLevelRanges::all_chunks().random_value());
     bool uncommitted_chunk = i % 3;
     if (uncommitted_chunk) {
-      helper.uncommit_chunk_with_test(c);
+      context.uncommit_chunk_with_test(c);
       c->set_in_use();
     }
 
@@ -108,7 +116,7 @@
   }
 
   // Drain each list separately
-  for (chunklevel_t lvl = LOWEST_CHUNK_LEVEL; lvl <= HIGHEST_CHUNK_LEVEL; lvl ++) {
+  for (chunklevel_t lvl = LOWEST_CHUNK_LEVEL; lvl <= HIGHEST_CHUNK_LEVEL; lvl++) {
     Metachunk* c = lst.remove_first(lvl);
     bool found_uncommitted = false;
     while (c != NULL) {
@@ -129,7 +137,7 @@
       EXPECT_EQ(lst.word_size(), cnt.total_size());
       EXPECT_EQ(lst.committed_word_size(), committed_cnt.total_size());
 
-      helper.return_chunk(c);
+      context.return_chunk(c);
 
       c = lst.remove_first(lvl);
     }
--- old/test/hotspot/gtest/metaspace/test_metaspaceUtils.cpp	2020-09-04 13:57:28.725207139 +0200
+++ new/test/hotspot/gtest/metaspace/test_metaspaceUtils.cpp	2020-09-04 13:57:28.465205431 +0200
@@ -1,6 +1,6 @@
 /*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
@@ -27,7 +27,6 @@
 #include "memory/metaspace.hpp"
 #include "unittest.hpp"
 
-
 TEST_VM(MetaspaceUtils, reserved) {
   size_t reserved = MetaspaceUtils::reserved_bytes();
   EXPECT_GT(reserved, 0UL);
--- old/test/hotspot/gtest/metaspace/test_metaspace_misc.cpp	2020-09-04 13:57:29.309210978 +0200
+++ new/test/hotspot/gtest/metaspace/test_metaspace_misc.cpp	2020-09-04 13:57:29.049209268 +0200
@@ -1,6 +1,6 @@
 /*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
@@ -25,12 +25,18 @@
 
 #include "precompiled.hpp"
 
-// #define LOG_PLEASE
 
 #include "classfile/classLoaderData.hpp"
-#include "metaspaceTestsCommon.hpp"
+#include "memory/metaspace/msChunklevel.hpp"
+#include "memory/metaspace/msSettings.hpp"
 #include "utilities/powerOfTwo.hpp"
 
+// #define LOG_PLEASE
+#include "metaspaceGtestCommon.hpp"
+
+using metaspace::chunklevel_t;
+using namespace metaspace::chunklevel;
+using metaspace::Settings;
 
 TEST_VM(metaspace, misc_sizes)   {
 
@@ -49,7 +55,6 @@
 
 }
 
-
 TEST_VM(metaspace, misc_max_alloc_size)   {
 
   // Make sure we can allocate what we promise to allocate
@@ -63,6 +68,8 @@
 
 TEST_VM(metaspace, chunklevel_utils)   {
 
+  // These tests seem to be really basic, but it is amazing what one can
+  // break accidentally...
   LOG(SIZE_FORMAT, MAX_CHUNK_BYTE_SIZE);
   LOG(SIZE_FORMAT, MIN_CHUNK_BYTE_SIZE);
   LOG(SIZE_FORMAT, MIN_CHUNK_WORD_SIZE);
@@ -98,10 +105,9 @@
   EXPECT_EQ(level_fitting_word_size((MAX_CHUNK_WORD_SIZE / 2) + 1), ROOT_CHUNK_LEVEL);
   EXPECT_EQ(level_fitting_word_size(MAX_CHUNK_WORD_SIZE / 2), ROOT_CHUNK_LEVEL + 1);
 
-  EXPECT_EQ(level_fitting_word_size(8 * K), CHUNK_LEVEL_64K);
-  EXPECT_EQ(level_fitting_word_size(8 * K + 13), CHUNK_LEVEL_64K - 1);
-  EXPECT_EQ(level_fitting_word_size(8 * K - 13), CHUNK_LEVEL_64K);
-
+  EXPECT_EQ(level_fitting_word_size(8 * K), LP64_ONLY(CHUNK_LEVEL_64K) NOT_LP64(CHUNK_LEVEL_32K));
+  EXPECT_EQ(level_fitting_word_size(8 * K + 13), LP64_ONLY(CHUNK_LEVEL_64K) NOT_LP64(CHUNK_LEVEL_32K) - 1);
+  EXPECT_EQ(level_fitting_word_size(8 * K - 13), LP64_ONLY(CHUNK_LEVEL_64K) NOT_LP64(CHUNK_LEVEL_32K));
 
 }
 
--- old/test/hotspot/gtest/metaspace/test_metaspacearena.cpp	2020-09-04 13:57:29.877214713 +0200
+++ new/test/hotspot/gtest/metaspace/test_metaspacearena.cpp	2020-09-04 13:57:29.625213056 +0200
@@ -1,6 +1,6 @@
 /*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
@@ -25,44 +25,76 @@
 
 #include "precompiled.hpp"
 
-//#define LOG_PLEASE
-
-#include "metaspace/metaspaceTestsCommon.hpp"
-#include "metaspace/metaspaceTestContexts.hpp"
-#include "metaspace/metaspace_sparsearray.hpp"
-#include "utilities/ostream.hpp"
+#include "memory/metaspace/msArena.hpp"
+#include "memory/metaspace/msArenaGrowthPolicy.hpp"
+#include "memory/metaspace/msCommitLimiter.hpp"
+#include "memory/metaspace/msCounter.hpp"
+#include "memory/metaspace/msInternalStats.hpp"
+#include "memory/metaspace/msSettings.hpp"
+#include "memory/metaspace/msStatistics.hpp"
+#include "runtime/mutex.hpp"
+#include "runtime/mutexLocker.hpp"
+#include "utilities/debug.hpp"
+#include "utilities/globalDefinitions.hpp"
 
+//#define LOG_PLEASE
+#include "metaspaceGtestCommon.hpp"
+#include "metaspaceGtestContexts.hpp"
+#include "metaspaceGtestRangeHelpers.hpp"
+
+using metaspace::ArenaGrowthPolicy;
+using metaspace::CommitLimiter;
+using metaspace::InternalStats;
+using metaspace::MemRangeCounter;
+using metaspace::MetaspaceArena;
+using metaspace::SizeAtomicCounter;
+using metaspace::Settings;
+using metaspace::ArenaStats;
+
+// See metaspaceArena.cpp : needed for predicting commit sizes.
+namespace metaspace {
+  extern size_t get_raw_word_size_for_requested_word_size(size_t net_word_size);
+}
 
-// TODO: this class is very similar to MetaspaceArenaTestBed in test_metaspacearena_stress.cpp.
-// should be unified.
 class MetaspaceArenaTestHelper {
 
-  MetaspaceTestContext& _helper;
+  MetaspaceGtestContext& _context;
 
   Mutex* _lock;
   const ArenaGrowthPolicy* _growth_policy;
   SizeAtomicCounter _used_words_counter;
   MetaspaceArena* _arena;
 
-public:
-
-  MetaspaceArenaTestHelper(MetaspaceTestContext& helper, Metaspace::MetaspaceType space_type, bool is_class,
-                         const char* name = "gtest-MetaspaceArena")
-    : _helper(helper),
-      _lock(NULL),
-      _growth_policy(NULL),
-      _used_words_counter(),
-      _arena(NULL)
-  {
-    _growth_policy = ArenaGrowthPolicy::policy_for_space_type(space_type, is_class);
+  void initialize(const ArenaGrowthPolicy* growth_policy, const char* name = "gtest-MetaspaceArena") {
+    _growth_policy = growth_policy;
     _lock = new Mutex(Monitor::native, "gtest-MetaspaceArenaTest-lock", false, Monitor::_safepoint_check_never);
     // Lock during space creation, since this is what happens in the VM too
     //  (see ClassLoaderData::metaspace_non_null(), which we mimick here).
     {
       MutexLocker ml(_lock,  Mutex::_no_safepoint_check_flag);
-      _arena = new MetaspaceArena(&_helper.cm(), _growth_policy, _lock, &_used_words_counter, name);
+      _arena = new MetaspaceArena(&_context.cm(), _growth_policy, _lock, &_used_words_counter, name);
     }
-    DEBUG_ONLY(_arena->verify(true));
+    DEBUG_ONLY(_arena->verify());
+
+  }
+
+public:
+
+  // Create a helper; growth policy for arena is determined by the given spacetype|class tupel
+  MetaspaceArenaTestHelper(MetaspaceGtestContext& helper,
+                            Metaspace::MetaspaceType space_type, bool is_class,
+                            const char* name = "gtest-MetaspaceArena")
+    :_context(helper)
+  {
+    initialize(ArenaGrowthPolicy::policy_for_space_type(space_type, is_class), name);
+  }
+
+  // Create a helper; growth policy is directly specified
+  MetaspaceArenaTestHelper(MetaspaceGtestContext& helper, const ArenaGrowthPolicy* growth_policy,
+                            const char* name = "gtest-MetaspaceArena")
+    :_context(helper)
+  {
+    initialize(growth_policy, name);
   }
 
   ~MetaspaceArenaTestHelper() {
@@ -70,7 +102,7 @@
     delete _lock;
   }
 
-  const CommitLimiter& limiter() const { return _helper.commit_limiter(); }
+  const CommitLimiter& limiter() const { return _context.commit_limiter(); }
   MetaspaceArena* arena() const { return _arena; }
   SizeAtomicCounter& used_words_counter() { return _used_words_counter; }
 
@@ -81,7 +113,7 @@
     if (_arena != NULL) {
       size_t used_words_before = _used_words_counter.get();
       size_t committed_words_before = limiter().committed_words();
-      DEBUG_ONLY(_arena->verify(true));
+      DEBUG_ONLY(_arena->verify());
       delete _arena;
       _arena = NULL;
       size_t used_words_after = _used_words_counter.get();
@@ -139,7 +171,7 @@
 
     MetaWord* p = _arena->allocate(word_size);
 
-    SOMETIMES(DEBUG_ONLY(_arena->verify(true);))
+    SOMETIMES(DEBUG_ONLY(_arena->verify();))
 
     size_t used2 = 0, committed2 = 0, capacity2 = 0;
     usage_numbers_with_test(&used2, &committed2, &capacity2);
@@ -176,14 +208,13 @@
     allocate_from_arena_with_tests(&dummy, word_size);
   }
 
-
   void deallocate_with_tests(MetaWord* p, size_t word_size) {
     size_t used = 0, committed = 0, capacity = 0;
     usage_numbers_with_test(&used, &committed, &capacity);
 
     _arena->deallocate(p, word_size);
 
-    SOMETIMES(DEBUG_ONLY(_arena->verify(true);))
+    SOMETIMES(DEBUG_ONLY(_arena->verify();))
 
     size_t used2 = 0, committed2 = 0, capacity2 = 0;
     usage_numbers_with_test(&used2, &committed2, &capacity2);
@@ -195,13 +226,22 @@
     ASSERT_EQ(capacity2, capacity);
   }
 
+  ArenaStats get_arena_statistics() const {
+    ArenaStats stats;
+    _arena->add_to_statistics(&stats);
+    return stats;
+  }
 
-};
+  // Convenience method to return number of chunks in arena (including current chunk)
+  int get_number_of_chunks() const {
+    return get_arena_statistics().totals()._num;
+  }
 
+};
 
 static void test_basics(size_t commit_limit, bool is_micro) {
-  MetaspaceTestContext msthelper(commit_limit);
-  MetaspaceArenaTestHelper helper(msthelper, is_micro ? Metaspace::ReflectionMetaspaceType : Metaspace::StandardMetaspaceType, false);
+  MetaspaceGtestContext context(commit_limit);
+  MetaspaceArenaTestHelper helper(context, is_micro ? Metaspace::ReflectionMetaspaceType : Metaspace::StandardMetaspaceType, false);
 
   helper.allocate_from_arena_with_tests(1);
   helper.allocate_from_arena_with_tests(128);
@@ -227,59 +267,155 @@
   test_basics(256 * K, false);
 }
 
+// Test chunk enlargement:
+//  A single MetaspaceArena, left undisturbed with place to grow. Slowly fill arena up.
+//  We should see at least some occurrences of chunk-in-place enlargement.
+static void test_chunk_enlargment_simple(Metaspace::MetaspaceType spacetype, bool is_class) {
+
+  MetaspaceGtestContext context;
+  MetaspaceArenaTestHelper helper(context, (Metaspace::MetaspaceType)spacetype, is_class);
 
-// Test: in a single undisturbed MetaspaceArena (so, we should have chunks enlarged in place)
-// we allocate a small amount, then the full amount possible. The sum of first and second
-// allocation bring us above root chunk size. This should work - chunk enlargement should
-// fail and a new root chunk should be allocated instead.
-TEST_VM(metaspace, MetaspaceArena_test_enlarge_in_place) {
+  uint64_t n1 = metaspace::InternalStats::num_chunks_enlarged();
+
+  size_t allocated = 0;
+  while (allocated <= MAX_CHUNK_WORD_SIZE &&
+         metaspace::InternalStats::num_chunks_enlarged() == n1) {
+    size_t s = IntRange(32, 128).random_value();
+    helper.allocate_from_arena_with_tests_expect_success(s);
+    allocated += metaspace::get_raw_word_size_for_requested_word_size(s);
+  }
+
+  EXPECT_GT(metaspace::InternalStats::num_chunks_enlarged(), n1);
+
+}
+
+// Do this test for some of the standard types; don't do it for the boot loader type
+//  since that one starts out with max chunk size so we would not see any enlargement.
+
+TEST_VM(metaspace, MetaspaceArena_test_enlarge_in_place_standard_c) {
+  test_chunk_enlargment_simple(Metaspace::StandardMetaspaceType, true);
+}
+
+TEST_VM(metaspace, MetaspaceArena_test_enlarge_in_place_standard_nc) {
+  test_chunk_enlargment_simple(Metaspace::StandardMetaspaceType, false);
+}
+
+TEST_VM(metaspace, MetaspaceArena_test_enlarge_in_place_micro_c) {
+  test_chunk_enlargment_simple(Metaspace::ReflectionMetaspaceType, true);
+}
+
+TEST_VM(metaspace, MetaspaceArena_test_enlarge_in_place_micro_nc) {
+  test_chunk_enlargment_simple(Metaspace::ReflectionMetaspaceType, false);
+}
+
+// Test chunk enlargement:
+// A single MetaspaceArena, left undisturbed with place to grow. Slowly fill arena up.
+//  We should see occurrences of chunk-in-place enlargement.
+//  Here, we give it an ideal policy which should enable the initial chunk to grow unmolested
+//  until finish.
+TEST_VM(metaspace, MetaspaceArena_test_enlarge_in_place_2) {
 
   if (Settings::use_allocation_guard()) {
     return;
   }
 
-  MetaspaceTestContext msthelper;
-  MetaspaceArenaTestHelper helper(msthelper, Metaspace::StandardMetaspaceType, false);
-  helper.allocate_from_arena_with_tests_expect_success(1);
-  helper.allocate_from_arena_with_tests_expect_success(MAX_CHUNK_WORD_SIZE);
-  helper.allocate_from_arena_with_tests_expect_success(MAX_CHUNK_WORD_SIZE / 2);
-  helper.allocate_from_arena_with_tests_expect_success(MAX_CHUNK_WORD_SIZE);
+  // Note: internally, chunk in-place enlargement is disallowed if growing the chunk
+  //  would cause the arena to claim more memory than its growth policy allows. This
+  //  is done to prevent the arena to grow too fast.
+  //
+  // In order to test in-place growth here without that restriction I give it an
+  //  artificial growth policy which starts out with a tiny chunk size, then balloons
+  //  right up to max chunk size. This will cause the initial chunk to be tiny, and
+  //  then the arena is able to grow it without violating growth policy.
+  chunklevel_t growth[] = { HIGHEST_CHUNK_LEVEL, ROOT_CHUNK_LEVEL };
+  ArenaGrowthPolicy growth_policy(growth, 2);
+
+  MetaspaceGtestContext context;
+  MetaspaceArenaTestHelper helper(context, &growth_policy);
+
+  uint64_t n1 = metaspace::InternalStats::num_chunks_enlarged();
+
+  size_t allocated = 0;
+  while (allocated <= MAX_CHUNK_WORD_SIZE) {
+    size_t s = IntRange(32, 128).random_value();
+    helper.allocate_from_arena_with_tests_expect_success(s);
+    allocated += metaspace::get_raw_word_size_for_requested_word_size(s);
+    if (allocated <= MAX_CHUNK_WORD_SIZE) {
+      // Chunk should have been enlarged in place
+      ASSERT_EQ(1, helper.get_number_of_chunks());
+    } else {
+      // Next chunk should have started
+      ASSERT_EQ(2, helper.get_number_of_chunks());
+    }
+  }
+
+  int times_chunk_were_enlarged = metaspace::InternalStats::num_chunks_enlarged() - n1;
+  LOG("chunk was enlarged %d times.", times_chunk_were_enlarged);
+
+  ASSERT_GT0(times_chunk_were_enlarged);
+
 }
 
-// Test allocating from smallest to largest chunk size, and one step beyond.
-// The first n allocations should happen in place, the ladder should open a new chunk.
-TEST_VM(metaspace, MetaspaceArena_test_enlarge_in_place_ladder_1) {
+// Regression test: Given a single MetaspaceArena, left undisturbed with place to grow,
+//  test that in place enlargement correctly fails if growing the chunk would bring us
+//  beyond the max. size of a chunk.
+TEST_VM(metaspace, MetaspaceArena_test_failing_to_enlarge_in_place_max_chunk_size) {
 
   if (Settings::use_allocation_guard()) {
     return;
   }
 
-  MetaspaceTestContext msthelper;
-  MetaspaceArenaTestHelper helper(msthelper, Metaspace::StandardMetaspaceType, false);
-  size_t size = MIN_CHUNK_WORD_SIZE;
-  while (size <= MAX_CHUNK_WORD_SIZE) {
-    helper.allocate_from_arena_with_tests_expect_success(size);
-    size *= 2;
-  }
-  helper.allocate_from_arena_with_tests_expect_success(MAX_CHUNK_WORD_SIZE);
+  MetaspaceGtestContext context;
+
+  for (size_t first_allocation_size = 1; first_allocation_size <= MAX_CHUNK_WORD_SIZE / 2; first_allocation_size *= 2) {
+
+    MetaspaceArenaTestHelper helper(context, Metaspace::StandardMetaspaceType, false);
+
+    // we allocate first a small amount, then the full amount possible.
+    // The sum of first and second allocation should bring us above root chunk size.
+    // This should work, we should not see any problems, but no chunk enlargement should
+    // happen.
+    int n1 = metaspace::InternalStats::num_chunks_enlarged();
+
+    helper.allocate_from_arena_with_tests_expect_success(first_allocation_size);
+    EXPECT_EQ(helper.get_number_of_chunks(), 1);
+
+    helper.allocate_from_arena_with_tests_expect_success(MAX_CHUNK_WORD_SIZE - first_allocation_size + 1);
+    EXPECT_EQ(helper.get_number_of_chunks(), 2);
+
+    int times_chunk_were_enlarged = metaspace::InternalStats::num_chunks_enlarged() - n1;
+    LOG("chunk was enlarged %d times.", times_chunk_were_enlarged);
+
+    EXPECT_0(times_chunk_were_enlarged);
+
+  }
 }
 
-// Same as MetaspaceArena_test_enlarge_in_place_ladder_1, but increase in *4 step size;
-// this way chunk-in-place-enlargement does not work and we should have new chunks at each allocation.
-TEST_VM(metaspace, MetaspaceArena_test_enlarge_in_place_ladder_2) {
+// Regression test: Given a single MetaspaceArena, left undisturbed with place to grow,
+//  test that in place enlargement correctly fails if growing the chunk would cause more
+//  than doubling its size
+TEST_VM(metaspace, MetaspaceArena_test_failing_to_enlarge_in_place_doubling_chunk_size) {
 
   if (Settings::use_allocation_guard()) {
     return;
   }
 
-  MetaspaceTestContext msthelper;
-  MetaspaceArenaTestHelper helper(msthelper, Metaspace::StandardMetaspaceType, false);
-  size_t size = MIN_CHUNK_WORD_SIZE;
-  while (size <= MAX_CHUNK_WORD_SIZE) {
-    helper.allocate_from_arena_with_tests_expect_success(size);
-    size *= 4;
-  }
-  helper.allocate_from_arena_with_tests_expect_success(MAX_CHUNK_WORD_SIZE);
+  MetaspaceGtestContext context;
+  MetaspaceArenaTestHelper helper(context, Metaspace::StandardMetaspaceType, false);
+
+  int n1 = metaspace::InternalStats::num_chunks_enlarged();
+
+  helper.allocate_from_arena_with_tests_expect_success(1000);
+  EXPECT_EQ(helper.get_number_of_chunks(), 1);
+
+  helper.allocate_from_arena_with_tests_expect_success(4000);
+  EXPECT_EQ(helper.get_number_of_chunks(), 2);
+
+  int times_chunk_were_enlarged = metaspace::InternalStats::num_chunks_enlarged() - n1;
+  LOG("chunk was enlarged %d times.", times_chunk_were_enlarged);
+
+  EXPECT_0(times_chunk_were_enlarged);
+
 }
 
 // Test the MetaspaceArenas' free block list:
@@ -290,8 +426,8 @@
     return;
   }
   for (size_t s = 2; s <= MAX_CHUNK_WORD_SIZE; s *= 2) {
-    MetaspaceTestContext msthelper;
-    MetaspaceArenaTestHelper helper(msthelper, Metaspace::StandardMetaspaceType, false);
+    MetaspaceGtestContext context;
+    MetaspaceArenaTestHelper helper(context, Metaspace::StandardMetaspaceType, false);
 
     MetaWord* p1 = NULL;
     helper.allocate_from_arena_with_tests_expect_success(&p1, s);
@@ -338,22 +474,22 @@
   // retire it and take a fresh chunk from the freelist.
 
   const size_t commit_limit = Settings::commit_granule_words() * 10;
-  MetaspaceTestContext msthelper(commit_limit);
+  MetaspaceGtestContext context(commit_limit);
 
   // The first MetaspaceArena mimicks a micro loader. This will fill the free
   //  chunk list with very small chunks. We allocate from them in an interleaved
   //  way to cause fragmentation.
-  MetaspaceArenaTestHelper helper1(msthelper, Metaspace::ReflectionMetaspaceType, false);
-  MetaspaceArenaTestHelper helper2(msthelper, Metaspace::ReflectionMetaspaceType, false);
+  MetaspaceArenaTestHelper helper1(context, Metaspace::ReflectionMetaspaceType, false);
+  MetaspaceArenaTestHelper helper2(context, Metaspace::ReflectionMetaspaceType, false);
 
   // This MetaspaceArena should hit the limit. We use BootMetaspaceType here since
   // it gets a large initial chunk which is committed
   // on demand and we are likely to hit a commit limit while trying to expand it.
-  MetaspaceArenaTestHelper helper3(msthelper, Metaspace::BootMetaspaceType, false);
+  MetaspaceArenaTestHelper helper3(context, Metaspace::BootMetaspaceType, false);
 
   // Allocate space until we have below two but above one granule left
   size_t allocated_from_1_and_2 = 0;
-  while (msthelper.commit_limiter().possible_expansion_words() >= Settings::commit_granule_words() * 2 &&
+  while (context.commit_limiter().possible_expansion_words() >= Settings::commit_granule_words() * 2 &&
       allocated_from_1_and_2 < commit_limit) {
     helper1.allocate_from_arena_with_tests_expect_success(1);
     helper2.allocate_from_arena_with_tests_expect_success(1);
@@ -369,7 +505,7 @@
   EXPECT_LE(allocated_from_3, Settings::commit_granule_words() * 2);
 
   // We expect the freelist to be empty of committed space...
-  EXPECT_0(msthelper.cm().total_committed_word_size());
+  EXPECT_0(context.cm().total_committed_word_size());
 
   //msthelper.cm().print_on(tty);
 
@@ -380,14 +516,13 @@
 
   // Should have populated the freelist with committed space
   // We expect the freelist to be empty of committed space...
-  EXPECT_GT(msthelper.cm().total_committed_word_size(), (size_t)0);
+  EXPECT_GT(context.cm().total_committed_word_size(), (size_t)0);
 
   // Repeat allocation from helper3, should now work.
   helper3.allocate_from_arena_with_tests_expect_success(1);
 
 }
 
-
 TEST_VM(metaspace, MetaspaceArena_recover_from_limit_hit) {
   test_recover_from_commit_limit_hit();
 }
@@ -406,10 +541,10 @@
   // large jumps. Also, different types of MetaspaceArena should
   // have different initial capacities.
 
-  MetaspaceTestContext msthelper;
-  MetaspaceArenaTestHelper smhelper(msthelper, type, is_class, "Grower");
+  MetaspaceGtestContext context;
+  MetaspaceArenaTestHelper smhelper(context, type, is_class, "Grower");
 
-  MetaspaceArenaTestHelper smhelper_harrasser(msthelper, Metaspace::ReflectionMetaspaceType, true, "Harasser");
+  MetaspaceArenaTestHelper smhelper_harrasser(context, Metaspace::ReflectionMetaspaceType, true, "Harasser");
 
   size_t used = 0, committed = 0, capacity = 0;
   const size_t alloc_words = 16;
@@ -433,7 +568,7 @@
 
   if (!(Settings::new_chunks_are_fully_committed() && type == Metaspace::BootMetaspaceType)) {
     // Initial commit charge for the whole context should be one granule
-    ASSERT_EQ(msthelper.committed_words(), Settings::commit_granule_words());
+    ASSERT_EQ(context.committed_words(), Settings::commit_granule_words());
     // Initial commit number for the arena should be less since - apart from boot loader - no
     //  space type has large initial chunks.
     ASSERT_LE(committed, Settings::commit_granule_words());
@@ -461,8 +596,8 @@
     }
 
     smhelper.allocate_from_arena_with_tests_expect_success(alloc_words);
-    words_allocated += alloc_words;
-    num_allocated ++;
+    words_allocated += metaspace::get_raw_word_size_for_requested_word_size(alloc_words);
+    num_allocated++;
 
     size_t used2 = 0, committed2 = 0, capacity2 = 0;
 
@@ -501,7 +636,7 @@
         */
         highest_capacity_jump = capacity_jump;
       }
-      num_capacity_jumps ++;
+      num_capacity_jumps++;
     }
 
     capacity = capacity2;
--- old/test/hotspot/gtest/metaspace/test_metaspacearena_stress.cpp	2020-09-04 13:57:30.469218610 +0200
+++ new/test/hotspot/gtest/metaspace/test_metaspacearena_stress.cpp	2020-09-04 13:57:30.209216899 +0200
@@ -1,6 +1,6 @@
 /*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
@@ -25,10 +25,28 @@
 
 #include "precompiled.hpp"
 
+#include "memory/metaspace/msArena.hpp"
+#include "memory/metaspace/msArenaGrowthPolicy.hpp"
+#include "memory/metaspace/msChunkManager.hpp"
+#include "memory/metaspace/msCounter.hpp"
+#include "memory/metaspace/msStatistics.hpp"
+#include "runtime/mutexLocker.hpp"
+#include "utilities/debug.hpp"
+#include "utilities/globalDefinitions.hpp"
+
 //#define LOG_PLEASE
-#include "metaspace/metaspaceTestsCommon.hpp"
-#include "metaspace/metaspaceTestContexts.hpp"
-#include "metaspace/metaspace_sparsearray.hpp"
+#include "metaspaceGtestCommon.hpp"
+#include "metaspaceGtestContexts.hpp"
+#include "metaspaceGtestSparseArray.hpp"
+
+using metaspace::ArenaGrowthPolicy;
+using metaspace::ChunkManager;
+using metaspace::IntCounter;
+using metaspace::MemRangeCounter;
+using metaspace::MetaspaceArena;
+using metaspace::SizeAtomicCounter;
+using metaspace::ArenaStats;
+using metaspace::InUseChunkStats;
 
 // Little randomness helper
 static bool fifty_fifty() {
@@ -78,18 +96,18 @@
   // overhead.
   void verify_arena_statistics() const {
 
-    arena_stats_t stats;
+    ArenaStats stats;
     _arena->add_to_statistics(&stats);
-    in_use_chunk_stats_t in_use_stats = stats.totals();
+    InUseChunkStats in_use_stats = stats.totals();
 
     assert(_dealloc_count.total_size() <= _alloc_count.total_size() &&
            _dealloc_count.count() <= _alloc_count.count(), "Sanity");
 
     // Check consistency of stats
-    ASSERT_GE(in_use_stats.word_size, in_use_stats.committed_words);
-    ASSERT_EQ(in_use_stats.committed_words,
-              in_use_stats.used_words + in_use_stats.free_words + in_use_stats.waste_words);
-    ASSERT_GE(in_use_stats.used_words, stats.free_blocks_word_size);
+    ASSERT_GE(in_use_stats._word_size, in_use_stats._committed_words);
+    ASSERT_EQ(in_use_stats._committed_words,
+              in_use_stats._used_words + in_use_stats._free_words + in_use_stats._waste_words);
+    ASSERT_GE(in_use_stats._used_words, stats._free_blocks_word_size);
 
     // Note: reasons why the outside alloc counter and the inside used counter can differ:
     // - alignment/padding of allocations
@@ -104,8 +122,8 @@
     const size_t max_word_overhead_per_alloc = 4;
     const size_t at_most_allocated = _alloc_count.total_size() + max_word_overhead_per_alloc * _alloc_count.count();
 
-    ASSERT_LE(at_least_allocated, in_use_stats.used_words - stats.free_blocks_word_size);
-    ASSERT_GE(at_most_allocated, in_use_stats.used_words - stats.free_blocks_word_size);
+    ASSERT_LE(at_least_allocated, in_use_stats._used_words - stats._free_blocks_word_size);
+    ASSERT_GE(at_most_allocated, in_use_stats._used_words - stats._free_blocks_word_size);
 
   }
 
@@ -141,7 +159,7 @@
       a = b;
     }
 
-    DEBUG_ONLY(_arena->verify(true);)
+    DEBUG_ONLY(_arena->verify();)
 
     // Delete MetaspaceArena. That should clean up all metaspace.
     delete _arena;
@@ -169,7 +187,7 @@
       _alloc_count.add(word_size);
       if ((_alloc_count.count() % 20) == 0) {
         verify_arena_statistics();
-        DEBUG_ONLY(_arena->verify(true);)
+        DEBUG_ONLY(_arena->verify();)
       }
       return true;
     } else {
@@ -191,17 +209,16 @@
       a->p = NULL; a->word_size = 0;
       if ((_dealloc_count.count() % 20) == 0) {
         verify_arena_statistics();
-        DEBUG_ONLY(_arena->verify(true);)
+        DEBUG_ONLY(_arena->verify();)
       }
     }
   }
 
 }; // End: MetaspaceArenaTestBed
 
-
 class MetaspaceArenaTest {
 
-  MetaspaceTestContext _helper;
+  MetaspaceGtestContext _context;
 
   SizeAtomicCounter _used_words_counter;
 
@@ -212,7 +229,7 @@
 
   void create_new_test_bed_at(int slotindex, const ArenaGrowthPolicy* growth_policy, SizeRange allocation_range) {
     DEBUG_ONLY(_testbeds.check_slot_is_null(slotindex));
-    MetaspaceArenaTestBed* bed = new MetaspaceArenaTestBed(&_helper.cm(), growth_policy,
+    MetaspaceArenaTestBed* bed = new MetaspaceArenaTestBed(&_context.cm(), growth_policy,
                                                        &_used_words_counter, allocation_range);
     _testbeds.set_at(slotindex, bed);
     _num_beds.increment();
@@ -238,7 +255,7 @@
 
   // Create test beds for all slots
   void create_all_test_beds() {
-    for (int slot = 0; slot < _testbeds.size(); slot ++) {
+    for (int slot = 0; slot < _testbeds.size(); slot++) {
       if (_testbeds.slot_is_null(slot)) {
         create_random_test_bed_at(slot);
       }
@@ -279,7 +296,7 @@
     bool success = bed->checked_random_allocate();
     if (success == false) {
       // We must have hit a limit.
-      EXPECT_LT(_helper.commit_limiter().possible_expansion_words(),
+      EXPECT_LT(_context.commit_limiter().possible_expansion_words(),
                 metaspace::get_raw_word_size_for_requested_word_size(bed->size_of_last_failed_allocation()));
     }
     return success;
@@ -291,7 +308,7 @@
     int n = 0;
     while (success && n < num_allocations) {
       success = random_allocate_from_testbed(slotindex);
-      n ++;
+      n++;
     }
     return success;
   }
@@ -343,7 +360,7 @@
 public:
 
   MetaspaceArenaTest(size_t commit_limit, int num_testbeds)
-    : _helper(commit_limit),
+    : _context(commit_limit),
       _testbeds(num_testbeds),
       _num_beds()
   {}
@@ -354,7 +371,6 @@
 
   }
 
-
   //////////////// Tests ////////////////////////
 
   void test() {
@@ -372,7 +388,7 @@
 
     bool force_bed_deletion = false;
 
-    for (int niter = 0; niter < iterations; niter ++) {
+    for (int niter = 0; niter < iterations; niter++) {
 
       const int r = IntRange(100).random_value();
 
@@ -408,10 +424,8 @@
 
   }
 
-
 };
 
-
 // 32 parallel MetaspaceArena objects, random allocating without commit limit
 TEST_VM(metaspace, MetaspaceArena_random_allocs_32_beds_no_commit_limit) {
   MetaspaceArenaTest test(max_uintx, 32);
@@ -431,7 +445,3 @@
   test.test();
 }
 
-
-
-
-
--- old/test/hotspot/gtest/metaspace/test_virtualspacenode.cpp	2020-09-04 13:57:31.057222482 +0200
+++ new/test/hotspot/gtest/metaspace/test_virtualspacenode.cpp	2020-09-04 13:57:30.797220770 +0200
@@ -1,6 +1,6 @@
 /*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
@@ -25,14 +25,29 @@
 
 #include "precompiled.hpp"
 
- #define LOG_PLEASE
-
-#include "metaspace/metaspaceTestsCommon.hpp"
-#include "metaspace/metaspace_rangehelpers.hpp"
-
-static int test_node_id = 100000; // start high to make it stick out in logs.
-
-
+#include "memory/metaspace/msChunklevel.hpp"
+#include "memory/metaspace/msCommitLimiter.hpp"
+#include "memory/metaspace/msCounter.hpp"
+#include "memory/metaspace/msFreeChunkList.hpp"
+#include "memory/metaspace/msMetachunk.hpp"
+#include "memory/metaspace/msMetachunkList.hpp"
+#include "memory/metaspace/msSettings.hpp"
+#include "memory/metaspace/msVirtualSpaceNode.hpp"
+#include "runtime/mutexLocker.hpp"
+#include "utilities/debug.hpp"
+
+//#define LOG_PLEASE
+#include "metaspaceGtestCommon.hpp"
+#include "metaspaceGtestRangeHelpers.hpp"
+
+using metaspace::chunklevel_t;
+using metaspace::CommitLimiter;
+using metaspace::FreeChunkListVector;
+using metaspace::Metachunk;
+using metaspace::MetachunkList;
+using metaspace::VirtualSpaceNode;
+using metaspace::Settings;
+using metaspace::SizeCounter;
 
 class VirtualSpaceNodeTest {
 
@@ -68,7 +83,7 @@
   void lock_and_verify_node() {
 #ifdef ASSERT
     MutexLocker fcl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
-    _node->verify_locked(true);
+    _node->verify_locked();
 #endif
   }
 
@@ -91,7 +106,7 @@
 
     } else {
 
-      DEBUG_ONLY(c->verify(true);)
+      DEBUG_ONLY(c->verify();)
       EXPECT_NOT_NULL(c);
       EXPECT_TRUE(c->is_root_chunk());
       EXPECT_TRUE(c->is_free());
@@ -120,7 +135,7 @@
     bool rc = c->ensure_committed(request_commit_words);
 
     verify();
-    DEBUG_ONLY(c->verify(true);)
+    DEBUG_ONLY(c->verify();)
 
     lock_and_verify_node();
 
@@ -162,7 +177,7 @@
 
     c->uncommit();
 
-    DEBUG_ONLY(c->verify(true);)
+    DEBUG_ONLY(c->verify();)
 
     lock_and_verify_node();
 
@@ -192,7 +207,7 @@
 
   Metachunk* split_chunk_with_checks(Metachunk* c, chunklevel_t target_level, FreeChunkListVector* freelist) {
 
-    DEBUG_ONLY(c->verify(true);)
+    DEBUG_ONLY(c->verify();)
 
     const chunklevel_t orig_level = c->level();
     assert(orig_level < target_level, "Sanity");
@@ -219,9 +234,9 @@
     // buddy chunk to appear of level + 1 (aka, half size).
     size_t expected_wordsize_increase = 0;
     int expected_num_chunks_increase = 0;
-    for (chunklevel_t l = orig_level + 1; l <= target_level; l ++) {
+    for (chunklevel_t l = orig_level + 1; l <= target_level; l++) {
       expected_wordsize_increase += metaspace::chunklevel::word_size_for_level(l);
-      expected_num_chunks_increase ++;
+      expected_num_chunks_increase++;
     }
 
     const int total_num_chunks_in_freelist_after = freelist->num_chunks();
@@ -234,7 +249,6 @@
 
   } // end: split_chunk_with_checks
 
-
   Metachunk* merge_chunk_with_checks(Metachunk* c, chunklevel_t expected_target_level, FreeChunkListVector* freelist) {
 
     const chunklevel_t orig_level = c->level();
@@ -261,7 +275,7 @@
     int expected_num_chunks_decrease = 0;
     for (chunklevel_t l = orig_level; l > expected_target_level; l --) {
       expected_wordsize_decrease += metaspace::chunklevel::word_size_for_level(l);
-      expected_num_chunks_decrease ++;
+      expected_num_chunks_decrease++;
     }
 
     const int total_num_chunks_in_freelist_after = freelist->num_chunks();
@@ -338,7 +352,7 @@
     TestMap testmap(c->word_size());
     assert(testmap.get_num_set() == 0, "Sanity");
 
-    for (int run = 0; run < 1000; run ++) {
+    for (int run = 0; run < 1000; run++) {
 
       const size_t committed_words_before = testmap.get_num_set();
       ASSERT_EQ(_commit_limiter.committed_words(), committed_words_before);
@@ -420,7 +434,7 @@
 
     const int granules_per_root_chunk = (int)(c->word_size() / Settings::commit_granule_words());
 
-    for (int granules_to_commit = 0; granules_to_commit < granules_per_root_chunk; granules_to_commit ++) {
+    for (int granules_to_commit = 0; granules_to_commit < granules_per_root_chunk; granules_to_commit++) {
 
       const size_t words_to_commit = Settings::commit_granule_words() * granules_to_commit;
 
@@ -435,7 +449,7 @@
       verify();
 
       for (chunklevel_t target_level = LOWEST_CHUNK_LEVEL + 1;
-           target_level <= HIGHEST_CHUNK_LEVEL; target_level ++) {
+           target_level <= HIGHEST_CHUNK_LEVEL; target_level++) {
 
         // Split:
         Metachunk* c2 = split_chunk_with_checks(c, target_level, &freelist);
@@ -471,13 +485,8 @@
 
   } // end: test_splitting_chunks
 
-
-
-
 };
 
-
-
 TEST_VM(metaspace, virtual_space_node_test_basics) {
 
   MutexLocker fcl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
@@ -492,19 +501,19 @@
   ASSERT_NOT_NULL(node);
   ASSERT_EQ(node->committed_words(), (size_t)0);
   ASSERT_EQ(node->committed_words(), scomm.get());
-  DEBUG_ONLY(node->verify_locked(true);)
+  DEBUG_ONLY(node->verify_locked();)
 
   bool b = node->ensure_range_is_committed(node->base(), node->word_size());
   ASSERT_TRUE(b);
   ASSERT_EQ(node->committed_words(), word_size);
   ASSERT_EQ(node->committed_words(), scomm.get());
-  DEBUG_ONLY(node->verify_locked(true);)
+  DEBUG_ONLY(node->verify_locked();)
   zap_range(node->base(), node->word_size());
 
   node->uncommit_range(node->base(), node->word_size());
   ASSERT_EQ(node->committed_words(), (size_t)0);
   ASSERT_EQ(node->committed_words(), scomm.get());
-  DEBUG_ONLY(node->verify_locked(true);)
+  DEBUG_ONLY(node->verify_locked();)
 
   const int num_granules = (int)(word_size / Settings::commit_granule_words());
   for (int i = 1; i < num_granules; i += 4) {
@@ -512,18 +521,17 @@
     ASSERT_TRUE(b);
     ASSERT_EQ(node->committed_words(), i * Settings::commit_granule_words());
     ASSERT_EQ(node->committed_words(), scomm.get());
-    DEBUG_ONLY(node->verify_locked(true);)
+    DEBUG_ONLY(node->verify_locked();)
     zap_range(node->base(), i * Settings::commit_granule_words());
   }
 
   node->uncommit_range(node->base(), node->word_size());
   ASSERT_EQ(node->committed_words(), (size_t)0);
   ASSERT_EQ(node->committed_words(), scomm.get());
-  DEBUG_ONLY(node->verify_locked(true);)
+  DEBUG_ONLY(node->verify_locked();)
 
 }
 
-
 // Note: we unfortunately need TEST_VM even though the system tested
 // should be pretty independent since we need things like os::vm_page_size()
 // which in turn need OS layer initialization.
@@ -544,7 +552,7 @@
 TEST_VM(metaspace, virtual_space_node_test_3) {
   double d = os::elapsedTime();
   // Test committing uncommitting arbitrary ranges
-  for (int run = 0; run < 100; run ++) {
+  for (int run = 0; run < 100; run++) {
     VirtualSpaceNodeTest test(metaspace::chunklevel::MAX_CHUNK_WORD_SIZE,
         metaspace::chunklevel::MAX_CHUNK_WORD_SIZE);
     test.test_split_and_merge_chunks();
--- old/test/hotspot/jtreg/gtest/MetaspaceGtests.java	2020-09-04 13:57:31.637226307 +0200
+++ new/test/hotspot/jtreg/gtest/MetaspaceGtests.java	2020-09-04 13:57:31.377224593 +0200
@@ -25,11 +25,12 @@
 
 /*
  * Note: This runs the metaspace-related parts of gtest in configurations which
- *  are not tested explicitely in the standard gtests.
+ *  are not tested explicitly in the standard gtests.
  *
  */
 
 /* @test id=reclaim-none-debug
+ * @bug 8251158
  * @summary Run metaspace-related gtests for reclaim policy none (with verifications)
  * @requires vm.debug
  * @library /test/lib
@@ -39,6 +40,7 @@
  */
 
 /* @test id=reclaim-none-ndebug
+ * @bug 8251158
  * @summary Run metaspace-related gtests for reclaim policy none
  * @library /test/lib
  * @modules java.base/jdk.internal.misc
@@ -50,6 +52,7 @@
 
 
 /* @test id=reclaim-aggressive-debug
+ * @bug 8251158
  * @summary Run metaspace-related gtests for reclaim policy aggressive (with verifications)
  * @requires vm.debug
  * @library /test/lib
@@ -59,6 +62,7 @@
  */
 
 /* @test id=reclaim-aggressive-ndebug
+ * @bug 8251158
  * @summary Run metaspace-related gtests for reclaim policy aggressive
  * @library /test/lib
  * @modules java.base/jdk.internal.misc
--- old/test/hotspot/jtreg/runtime/Metaspace/PrintMetaspaceDcmd.java	2020-09-04 13:57:32.201230026 +0200
+++ new/test/hotspot/jtreg/runtime/Metaspace/PrintMetaspaceDcmd.java	2020-09-04 13:57:31.949228363 +0200
@@ -27,19 +27,60 @@
 import jdk.test.lib.JDKToolFinder;
 
 /*
- * @test
+ * @test id=test-64bit-ccs
  * @summary Test the VM.metaspace command
- * @requires vm.gc != "Z" & vm.bits != "32"
+ * @requires vm.bits == "64"
  * @library /test/lib
  * @modules java.base/jdk.internal.misc
  *          java.management
  * @run main/othervm -XX:MaxMetaspaceSize=201M -Xmx100M -XX:+UseCompressedOops -XX:+UseCompressedClassPointers PrintMetaspaceDcmd with-compressed-class-space
+ */
+
+/*
+ * @test id=test-64bit-ccs-noreclaim
+ * @summary Test the VM.metaspace command
+ * @requires vm.bits == "64"
+ * @library /test/lib
+ * @modules java.base/jdk.internal.misc
+ *          java.management
+ * @run main/othervm -XX:MaxMetaspaceSize=201M -Xmx100M -XX:+UseCompressedOops -XX:+UseCompressedClassPointers -XX:MetaspaceReclaimPolicy=none PrintMetaspaceDcmd with-compressed-class-space
+ */
+
+/*
+ * @test id=test-64bit-ccs-aggressivereclaim
+ * @summary Test the VM.metaspace command
+ * @requires vm.bits == "64"
+ * @library /test/lib
+ * @modules java.base/jdk.internal.misc
+ *          java.management
+ * @run main/othervm -XX:MaxMetaspaceSize=201M -Xmx100M -XX:+UseCompressedOops -XX:+UseCompressedClassPointers -XX:MetaspaceReclaimPolicy=aggressive PrintMetaspaceDcmd with-compressed-class-space
+ */
+
+/*
+ * @test id=test-64bit-ccs-guarded
+ * @summary Test the VM.metaspace command
+ * @requires vm.bits == "64"
+ * @requires vm.debug == true
+ * @library /test/lib
+ * @modules java.base/jdk.internal.misc
+ *          java.management
+ * @run main/othervm -XX:MaxMetaspaceSize=201M -Xmx100M -XX:+UseCompressedOops -XX:+UseCompressedClassPointers -XX:+MetaspaceGuardAllocations PrintMetaspaceDcmd with-compressed-class-space
+ */
+
+/*
+ * @test id=test-64bit-noccs
+ * @summary Test the VM.metaspace command
+ * @requires vm.bits == "64"
+ * @library /test/lib
+ * @modules java.base/jdk.internal.misc
+ *          java.management
  * @run main/othervm -XX:MaxMetaspaceSize=201M -Xmx100M -XX:-UseCompressedOops -XX:-UseCompressedClassPointers PrintMetaspaceDcmd without-compressed-class-space
  */
+
 /*
- * @test
+ * @test test-32bit
  * @summary Test the VM.metaspace command
- * @requires vm.gc != "Z" & vm.bits == "32"
+ * @requires vm.bits == "32"
  * @library /test/lib
  * @modules java.base/jdk.internal.misc
  *          java.management
@@ -48,8 +89,6 @@
 
 public class PrintMetaspaceDcmd {
 
-    // Run jcmd VM.metaspace against a VM with CompressedClassPointers on.
-    // The report should detail Non-Class and Class portions separately.
     private static void doTheTest(boolean usesCompressedClassSpace) throws Exception {
         ProcessBuilder pb = new ProcessBuilder();
         OutputAnalyzer output;
--- old/test/hotspot/jtreg/runtime/Metaspace/elastic/AllocationProfile.java	2020-09-04 13:57:32.777233827 +0200
+++ new/test/hotspot/jtreg/runtime/Metaspace/elastic/AllocationProfile.java	2020-09-04 13:57:32.521232138 +0200
@@ -48,7 +48,6 @@
         return r.nextInt((int)(maximumSingleAllocationSize - minimumSingleAllocationSize + 1)) + minimumSingleAllocationSize;
     }
 
-
     // Some standard profiles
     static final List<AllocationProfile> standardProfiles = new ArrayList<>();
 
--- old/test/hotspot/jtreg/runtime/Metaspace/elastic/MetaspaceTestArena.java	2020-09-04 13:57:33.361237684 +0200
+++ new/test/hotspot/jtreg/runtime/Metaspace/elastic/MetaspaceTestArena.java	2020-09-04 13:57:33.089235887 +0200
@@ -102,7 +102,6 @@
         return arena != 0;
     }
 
-
     @Override
     public String toString() {
         return "arena=" + arena +
--- old/test/hotspot/jtreg/runtime/Metaspace/elastic/MetaspaceTestContext.java	2020-09-04 13:57:33.945241542 +0200
+++ new/test/hotspot/jtreg/runtime/Metaspace/elastic/MetaspaceTestContext.java	2020-09-04 13:57:33.677239772 +0200
@@ -23,7 +23,6 @@
     long numDeallocated;
     long allocationFailures;
 
-
     public MetaspaceTestContext(long commitLimit, long reserveLimit) {
         this.commitLimit = commitLimit;
         this.reserveLimit = reserveLimit;
@@ -126,7 +125,6 @@
      */
     public void checkStatistics() {
 
-
         // Note:
         // Estimating Used and Committed is fuzzy, and we only have limited information here
         // (we know the current state, but not the history, which determines fragmentation and
--- old/test/hotspot/jtreg/runtime/Metaspace/elastic/MetaspaceTestOneArenaManyThreads.java	2020-09-04 13:57:34.505245247 +0200
+++ new/test/hotspot/jtreg/runtime/Metaspace/elastic/MetaspaceTestOneArenaManyThreads.java	2020-09-04 13:57:34.253243580 +0200
@@ -32,7 +32,6 @@
     // Several threads allocate from a single arena.
     // This mimicks several threads loading classes via the same class loader.
 
-
     public MetaspaceTestOneArenaManyThreads(MetaspaceTestContext context, long testAllocationCeiling, int numThreads, int seconds) {
         super(context, testAllocationCeiling, numThreads, seconds);
     }
--- old/test/hotspot/jtreg/runtime/Metaspace/elastic/MetaspaceTestWithThreads.java	2020-09-04 13:57:35.093249137 +0200
+++ new/test/hotspot/jtreg/runtime/Metaspace/elastic/MetaspaceTestWithThreads.java	2020-09-04 13:57:34.821247336 +0200
@@ -104,5 +104,4 @@
                 ", seconds=" + seconds;
     }
 
-
 }
--- old/test/hotspot/jtreg/runtime/Metaspace/elastic/RandomAllocator.java	2020-09-04 13:57:35.677253004 +0200
+++ new/test/hotspot/jtreg/runtime/Metaspace/elastic/RandomAllocator.java	2020-09-04 13:57:35.425251336 +0200
@@ -102,7 +102,6 @@
         this.localRandom = new Random(RandomHelper.random().nextInt());
     }
 
-
     @Override
     public String toString() {
         return  arena.toString() + ", ticks=" + ticks;
--- old/test/hotspot/jtreg/runtime/Metaspace/elastic/RandomAllocatorThread.java	2020-09-04 13:57:36.253256821 +0200
+++ new/test/hotspot/jtreg/runtime/Metaspace/elastic/RandomAllocatorThread.java	2020-09-04 13:57:35.997255123 +0200
@@ -64,6 +64,4 @@
 
     }
 
-
-
 }
--- old/test/hotspot/jtreg/runtime/Metaspace/elastic/TestMetaspaceAllocation.java	2020-09-04 13:57:36.833260666 +0200
+++ new/test/hotspot/jtreg/runtime/Metaspace/elastic/TestMetaspaceAllocation.java	2020-09-04 13:57:36.573258942 +0200
@@ -25,6 +25,7 @@
 
 /*
  * @test id=debug
+ * @bug 8251158
  * @library /test/lib
  * @modules java.base/jdk.internal.misc
  *          java.management
@@ -42,6 +43,7 @@
 
 /*
  * @test id=ndebug
+ * @bug 8251158
  * @library /test/lib
  * @modules java.base/jdk.internal.misc
  *          java.management
--- old/test/hotspot/jtreg/runtime/Metaspace/elastic/TestMetaspaceAllocationMT1.java	2020-09-04 13:57:37.417264541 +0200
+++ new/test/hotspot/jtreg/runtime/Metaspace/elastic/TestMetaspaceAllocationMT1.java	2020-09-04 13:57:37.169262895 +0200
@@ -40,7 +40,6 @@
  *
  */
 
-
 /*
  * @test id=debug
  * @library /test/lib
--- old/test/hotspot/jtreg/runtime/Metaspace/elastic/TestMetaspaceAllocationMT2.java	2020-09-04 13:57:38.049268736 +0200
+++ new/test/hotspot/jtreg/runtime/Metaspace/elastic/TestMetaspaceAllocationMT2.java	2020-09-04 13:57:37.729266613 +0200
@@ -74,7 +74,6 @@
  * @run main/othervm/timeout=400 -Xbootclasspath/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI  -XX:MetaspaceReclaimPolicy=aggressive TestMetaspaceAllocationMT2
  */
 
-
 public class TestMetaspaceAllocationMT2 {
 
     public static void main(String[] args) throws Exception {
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msAllocationGuard.hpp	2020-09-04 13:57:38.397271049 +0200
@@ -0,0 +1,119 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#ifndef SHARE_MEMORY_METASPACE_MSALLOCATIONGUARD_HPP
+#define SHARE_MEMORY_METASPACE_MSALLOCATIONGUARD_HPP
+
+#include "memory/allocation.hpp"
+#include "memory/metaspace/msChunklevel.hpp"
+#include "utilities/debug.hpp"
+#include "utilities/globalDefinitions.hpp"
+
+// In Debug builds, Metadata in Metaspace can be optionally guarded - enclosed in canaries -
+// to detect memory overwriters.
+//
+// These canaries are periodically checked, e.g. when the Metaspace is purged in a context
+// of a GC.
+
+// The canaries precede any allocated block...
+//
+// +---------------+
+// |  'METAMETA'   |
+// +---------------+
+// |  block size   |
+// +---------------+
+// |  block...     |
+// .               .
+// .               .
+// .               .
+// |               |
+// +---------------+
+// . <padding>     .
+// +---------------+
+// |  'METAMETA'   |
+// +---------------+
+// |  block size   |
+// +---------------+
+// |  block...     |
+
+// ... and since the blocks are allocated via pointer bump and closely follow each other,
+// one block's prefix is its predecessor's suffix, so apart from the last block all
+// blocks have an overwriter canary on both ends.
+//
+
+// Note: this feature is only available in debug, and is activated using
+//  -XX:+MetaspaceGuardAllocations. When active, it disables deallocation handling - since
+//  freeblock handling in the freeblock lists would get too complex - so one may run leaks
+//  in deallocation-heavvy scenarios (e.g. lots of class redefinitions).
+//
+
+namespace metaspace {
+
+#ifdef ASSERT
+
+struct Prefix {
+  static const uintx EyeCatcher =
+      NOT_LP64(0x77698465) LP64_ONLY(0x7769846577698465ULL); // "META" resp "METAMETA"
+
+  const uintx _mark;
+  const size_t _word_size;   // raw word size including prefix
+  // MetaWord payload [0];   // varsized (but unfortunately not all our compilers understand that)
+
+  Prefix(size_t word_size)
+    : _mark(EyeCatcher),
+      _word_size(word_size)
+  {}
+
+  MetaWord* payload() const {
+    return (MetaWord*)(this + 1);
+  }
+
+  void check() const {
+    assert(_mark == EyeCatcher, "Corrupt block: missing eyecatcher (at " PTR_FORMAT ").", p2i(this));
+    assert(_word_size > 0 && _word_size < chunklevel::MAX_CHUNK_WORD_SIZE,
+           "Corrupt block: invalid size " SIZE_FORMAT " (at " PTR_FORMAT ").", _word_size, p2i(this));
+  }
+
+};
+
+// The prefix structure must be aligned to MetaWord size.
+STATIC_ASSERT((sizeof(Prefix) & WordAlignmentMask) == 0);
+
+inline size_t prefix_size() {
+  return sizeof(Prefix);
+}
+
+// Given a pointer to a memory area, establish the prefix at the start of that area and
+// return the starting pointer to the payload.
+inline MetaWord* establish_prefix(MetaWord* p_raw, size_t raw_word_size) {
+  const Prefix* pp = new(p_raw)Prefix(raw_word_size);
+  return pp->payload();
+}
+
+#endif
+
+} // namespace metaspace
+
+#endif // SHARE_MEMORY_METASPACE_MSALLOCATIONGUARD_HPP
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msArena.cpp	2020-09-04 13:57:38.973274876 +0200
@@ -0,0 +1,516 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+
+#include "logging/log.hpp"
+#include "logging/logStream.hpp"
+#include "memory/metaspace/msAllocationGuard.hpp"
+#include "memory/metaspace/msArena.hpp"
+#include "memory/metaspace/msArenaGrowthPolicy.hpp"
+#include "memory/metaspace/msChunkManager.hpp"
+#include "memory/metaspace/msCommon.hpp"
+#include "memory/metaspace/msFreeBlocks.hpp"
+#include "memory/metaspace/msInternalStats.hpp"
+#include "memory/metaspace/msMetachunk.hpp"
+#include "memory/metaspace/msSettings.hpp"
+#include "memory/metaspace/msStatistics.hpp"
+#include "memory/metaspace/msVirtualSpaceList.hpp"
+#include "runtime/atomic.hpp"
+#include "runtime/init.hpp"
+#include "services/memoryService.hpp"
+#include "utilities/align.hpp"
+#include "utilities/debug.hpp"
+#include "utilities/globalDefinitions.hpp"
+
+namespace metaspace {
+
+#define LOGFMT         "Arena @" PTR_FORMAT " (%s)"
+#define LOGFMT_ARGS    p2i(this), this->_name
+
+// Returns the level of the next chunk to be added, acc to growth policy.
+chunklevel_t MetaspaceArena::next_chunk_level() const {
+  const int growth_step = _chunks.count();
+  return _growth_policy->get_level_at_step(growth_step);
+}
+
+// Given a chunk, add its remaining free committed space to the free block list.
+void MetaspaceArena::salvage_chunk(Metachunk* c) {
+
+  if (Settings::handle_deallocations() == false) {
+    return;
+  }
+
+  assert_lock_strong(lock());
+
+  size_t remaining_words = c->free_below_committed_words();
+
+  if (remaining_words > FreeBlocks::MinWordSize) {
+
+    UL2(trace, "salvaging chunk " METACHUNK_FULL_FORMAT ".", METACHUNK_FULL_FORMAT_ARGS(c));
+
+    MetaWord* ptr = c->allocate(remaining_words);
+    assert(ptr != NULL, "Should have worked");
+    _total_used_words_counter->increment_by(remaining_words);
+
+    add_allocation_to_fbl(ptr, remaining_words);
+
+    // After this operation: the chunk should have no free committed space left.
+    assert(c->free_below_committed_words() == 0,
+           "Salvaging chunk failed (chunk " METACHUNK_FULL_FORMAT ").",
+           METACHUNK_FULL_FORMAT_ARGS(c));
+
+  }
+
+}
+
+// Allocate a new chunk from the underlying chunk manager able to hold at least
+// requested word size.
+Metachunk* MetaspaceArena::allocate_new_chunk(size_t requested_word_size) {
+
+  assert_lock_strong(lock());
+
+  // Should this ever happen, we need to increase the maximum possible chunk size.
+  guarantee(requested_word_size <= chunklevel::MAX_CHUNK_WORD_SIZE,
+            "Requested size too large (" SIZE_FORMAT ") - max allowed size per allocation is " SIZE_FORMAT ".",
+            requested_word_size, chunklevel::MAX_CHUNK_WORD_SIZE);
+
+  const int growth_step = _chunks.count();
+  const chunklevel_t max_level = chunklevel::level_fitting_word_size(requested_word_size);
+  const chunklevel_t preferred_level = MIN2(max_level, next_chunk_level());
+
+  Metachunk* c = _chunk_manager->get_chunk(preferred_level, max_level, requested_word_size);
+  if (c == NULL) {
+    return NULL;
+  }
+
+  assert(c->is_in_use(), "Wrong chunk state.");
+  assert(c->free_below_committed_words() >= requested_word_size, "Chunk not committed");
+
+  return c;
+
+}
+
+void MetaspaceArena::add_allocation_to_fbl(MetaWord* p, size_t word_size) {
+  assert(Settings::handle_deallocations(), "Sanity");
+  if (_fbl == NULL) {
+    _fbl = new FreeBlocks(); // Create only on demand
+  }
+  _fbl->add_block(p, word_size);
+}
+
+MetaspaceArena::MetaspaceArena(ChunkManager* chunk_manager,
+             const ArenaGrowthPolicy* growth_policy,
+             Mutex* lock,
+             SizeAtomicCounter* total_used_words_counter,
+             const char* name)
+: _lock(lock),
+  _chunk_manager(chunk_manager),
+  _growth_policy(growth_policy),
+  _chunks(),
+  _fbl(NULL),
+  _total_used_words_counter(total_used_words_counter),
+  _name(name)
+{
+  UL(debug, ": born.");
+
+  // Update statistics
+  InternalStats::inc_num_arena_births();
+}
+
+MetaspaceArena::~MetaspaceArena() {
+
+  DEBUG_ONLY(verify();)
+
+  MutexLocker fcl(lock(), Mutex::_no_safepoint_check_flag);
+
+  MemRangeCounter return_counter;
+
+  Metachunk* c = _chunks.first();
+  Metachunk* c2 = NULL;
+
+  while(c) {
+    c2 = c->next();
+    return_counter.add(c->used_words());
+    DEBUG_ONLY(c->set_prev(NULL);)
+    DEBUG_ONLY(c->set_next(NULL);)
+    UL2(debug, "return chunk: " METACHUNK_FORMAT ".", METACHUNK_FORMAT_ARGS(c));
+    _chunk_manager->return_chunk(c);
+    // c may be invalid after return_chunk(c) was called. Don't access anymore.
+    c = c2;
+  }
+
+  UL2(info, "returned %d chunks, total capacity " SIZE_FORMAT " words.",
+      return_counter.count(), return_counter.total_size());
+
+  _total_used_words_counter->decrement_by(return_counter.total_size());
+
+  DEBUG_ONLY(chunk_manager()->verify();)
+
+  delete _fbl;
+
+  UL(debug, ": dies.");
+
+  // Update statistics
+  InternalStats::inc_num_arena_deaths();
+
+}
+
+// Attempt to enlarge the current chunk to make it large enough to hold at least
+//  requested_word_size additional words.
+//
+// On success, true is returned, false otherwise.
+bool MetaspaceArena::attempt_enlarge_current_chunk(size_t requested_word_size) {
+
+  assert_lock_strong(lock());
+
+  Metachunk* c = current_chunk();
+  assert(c->free_words() < requested_word_size, "Sanity");
+
+  // Not if chunk enlargment is switched off...
+  if (Settings::enlarge_chunks_in_place() == false) {
+    return false;
+  }
+
+  // ... nor if we are already a root chunk ...
+  if (c->is_root_chunk()) {
+    return false;
+  }
+
+  // ... nor if the combined size of chunk content and new content would bring us above the size of a root chunk ...
+  if ((c->used_words() + requested_word_size) > metaspace::chunklevel::MAX_CHUNK_WORD_SIZE) {
+    return false;
+  }
+
+  const chunklevel_t new_level =
+      chunklevel::level_fitting_word_size(c->used_words() + requested_word_size);
+  assert(new_level < c->level(), "Sanity");
+
+  // Atm we only enlarge by one level (so, doubling the chunk in size). So, if the requested enlargement
+  // would require the chunk to more than double in size, we bail. But this covers about 99% of all cases,
+  // so this is good enough.
+  if (new_level < c->level() - 1) {
+    return false;
+  }
+
+  // This only works if chunk is the leader of its buddy pair (and also if buddy
+  // is free and unsplit, but that we cannot check outside of metaspace lock).
+  if (!c->is_leader()) {
+    return false;
+  }
+
+  // If the size added to the chunk would be larger than allowed for the next growth step
+  // dont enlarge.
+  if (next_chunk_level() > c->level()) {
+    return false;
+  }
+
+  bool success = _chunk_manager->attempt_enlarge_chunk(c);
+
+  assert(success == false || c->free_words() >= requested_word_size, "Sanity");
+
+  return success;
+
+}
+
+// Allocate memory from Metaspace.
+// 1) Attempt to allocate from the free block list.
+// 2) Attempt to allocate from the current chunk.
+// 3) Attempt to enlarge the current chunk in place if it is too small.
+// 4) Attempt to get a new chunk and allocate from that chunk.
+// At any point, if we hit a commit limit, we return NULL.
+MetaWord* MetaspaceArena::allocate(size_t requested_word_size) {
+
+  MutexLocker cl(lock(), Mutex::_no_safepoint_check_flag);
+
+  UL2(trace, "requested " SIZE_FORMAT " words.", requested_word_size);
+
+  MetaWord* p = NULL;
+
+  const size_t raw_word_size = get_raw_word_size_for_requested_word_size(requested_word_size);
+
+  // 1) Attempt to allocate from the free blocks list
+  if (Settings::handle_deallocations() && _fbl != NULL && !_fbl->is_empty()) {
+    p = _fbl->remove_block(raw_word_size);
+    if (p != NULL) {
+      DEBUG_ONLY(InternalStats::inc_num_allocs_from_deallocated_blocks();)
+      UL2(trace, "taken from fbl (now: %d, " SIZE_FORMAT ").",
+          _fbl->count(), _fbl->total_size());
+      // Note: Space in the freeblock dictionary counts as already used (see retire_current_chunk()) -
+      // that means that we do not modify any counters and therefore can skip the epilog.
+      return p;
+    }
+  }
+
+  bool current_chunk_too_small = false;
+  bool commit_failure = false;
+
+  if (current_chunk() != NULL) {
+
+    // 2) Attempt to satisfy the allocation from the current chunk.
+
+    // If the current chunk is too small to hold the requested size, attempt to enlarge it.
+    // If that fails, retire the chunk.
+    if (current_chunk()->free_words() < raw_word_size) {
+      if (!attempt_enlarge_current_chunk(raw_word_size)) {
+        current_chunk_too_small = true;
+      } else {
+        DEBUG_ONLY(InternalStats::inc_num_chunks_enlarged();)
+        UL(debug, "enlarged chunk.");
+      }
+    }
+
+    // Commit the chunk far enough to hold the requested word size. If that fails, we
+    // hit a limit (either GC threshold or MaxMetaspaceSize). In that case retire the
+    // chunk.
+    if (!current_chunk_too_small) {
+      if (!current_chunk()->ensure_committed_additional(raw_word_size)) {
+        UL2(info, "commit failure (requested size: " SIZE_FORMAT ")", raw_word_size);
+        commit_failure = true;
+      }
+    }
+
+    // Allocate from the current chunk. This should work now.
+    if (!current_chunk_too_small && !commit_failure) {
+      p = current_chunk()->allocate(raw_word_size);
+      assert(p != NULL, "Allocation from chunk failed.");
+    }
+
+  }
+
+  if (p == NULL) {
+
+    // If we are here, we either had no current chunk to begin with or it was deemed insufficient.
+    assert(current_chunk() == NULL ||
+           current_chunk_too_small || commit_failure, "Sanity");
+
+    Metachunk* new_chunk = allocate_new_chunk(raw_word_size);
+
+    if (new_chunk != NULL) {
+
+      UL2(debug, "allocated new chunk " METACHUNK_FORMAT " for requested word size " SIZE_FORMAT ".",
+          METACHUNK_FORMAT_ARGS(new_chunk), requested_word_size);
+
+      assert(new_chunk->free_below_committed_words() >= raw_word_size, "Sanity");
+
+      // We have a new chunk. Before making it the current chunk, retire the old one.
+      if (current_chunk() != NULL) {
+        salvage_chunk(current_chunk());
+        DEBUG_ONLY(InternalStats::inc_num_chunks_retired();)
+      }
+
+      _chunks.add(new_chunk);
+
+      // Now, allocate from that chunk. That should work.
+      p = current_chunk()->allocate(raw_word_size);
+      assert(p != NULL, "Allocation from chunk failed.");
+
+    } else {
+      UL2(info, "failed to allocate new chunk for requested word size " SIZE_FORMAT ".", requested_word_size);
+    }
+
+  }
+
+#ifdef ASSERT
+  // When using allocation guards, establish a prefix.
+  if (p != NULL && Settings::use_allocation_guard()) {
+    p = establish_prefix(p, raw_word_size);
+  }
+#endif
+
+  if (p == NULL) {
+    InternalStats::inc_num_allocs_failed_limit();
+  } else {
+    DEBUG_ONLY(InternalStats::inc_num_allocs();)
+    _total_used_words_counter->increment_by(raw_word_size);
+  }
+
+  SOMETIMES(verify_locked();)
+
+  if (p == NULL) {
+    UL(info, "allocation failed, returned NULL.");
+  } else {
+    UL2(trace, "after allocation: %u chunk(s), current:" METACHUNK_FULL_FORMAT, _chunks.count(), METACHUNK_FULL_FORMAT_ARGS(current_chunk()));
+    UL2(trace, "returning " PTR_FORMAT ".", p2i(p));
+  }
+
+  return p;
+
+}
+
+// Prematurely returns a metaspace allocation to the _block_freelists
+// because it is not needed anymore (requires CLD lock to be active).
+void MetaspaceArena::deallocate_locked(MetaWord* p, size_t word_size) {
+
+  if (Settings::handle_deallocations() == false) {
+    return;
+  }
+
+  assert_lock_strong(lock());
+
+  // At this point a current chunk must exist since we only deallocate if we did allocate before.
+  assert(current_chunk() != NULL, "stray deallocation?");
+
+  assert(is_valid_area(p, word_size),
+         "Pointer range not part of this Arena and cannot be deallocated: (" PTR_FORMAT ".." PTR_FORMAT ").",
+         p2i(p), p2i(p + word_size));
+
+  UL2(trace, "deallocating " PTR_FORMAT ", word size: " SIZE_FORMAT ".",
+      p2i(p), word_size);
+
+  size_t raw_word_size = get_raw_word_size_for_requested_word_size(word_size);
+  add_allocation_to_fbl(p, raw_word_size);
+
+  DEBUG_ONLY(verify_locked();)
+
+}
+
+// Prematurely returns a metaspace allocation to the _block_freelists because it is not
+// needed anymore.
+void MetaspaceArena::deallocate(MetaWord* p, size_t word_size) {
+  MutexLocker cl(lock(), Mutex::_no_safepoint_check_flag);
+  deallocate_locked(p, word_size);
+}
+
+// Update statistics. This walks all in-use chunks.
+void MetaspaceArena::add_to_statistics(ArenaStats* out) const {
+
+  MutexLocker cl(lock(), Mutex::_no_safepoint_check_flag);
+
+  for (const Metachunk* c = _chunks.first(); c != NULL; c = c->next()) {
+    InUseChunkStats& ucs = out->_stats[c->level()];
+    ucs._num++;
+    ucs._word_size += c->word_size();
+    ucs._committed_words += c->committed_words();
+    ucs._used_words += c->used_words();
+    // Note: for free and waste, we only count what's committed.
+    if (c == current_chunk()) {
+      ucs._free_words += c->free_below_committed_words();
+    } else {
+      ucs._waste_words += c->free_below_committed_words();
+    }
+  }
+
+  if (_fbl != NULL) {
+    out->_free_blocks_num += _fbl->count();
+    out->_free_blocks_word_size += _fbl->total_size();
+  }
+
+  SOMETIMES(out->verify();)
+
+}
+
+// Convenience method to get the most important usage statistics.
+// For deeper analysis use add_to_statistics().
+void MetaspaceArena::usage_numbers(size_t* p_used_words, size_t* p_committed_words, size_t* p_capacity_words) const {
+  MutexLocker cl(lock(), Mutex::_no_safepoint_check_flag);
+  size_t used = 0, comm = 0, cap = 0;
+  for (const Metachunk* c = _chunks.first(); c != NULL; c = c->next()) {
+    used += c->used_words();
+    comm += c->committed_words();
+    cap += c->word_size();
+  }
+  if (p_used_words != NULL) {
+    *p_used_words = used;
+  }
+  if (p_committed_words != NULL) {
+    *p_committed_words = comm;
+  }
+  if (p_capacity_words != NULL) {
+    *p_capacity_words = cap;
+  }
+}
+
+#ifdef ASSERT
+
+void MetaspaceArena::verify_locked() const {
+
+  assert_lock_strong(lock());
+
+  assert(_growth_policy != NULL && _chunk_manager != NULL, "Sanity");
+
+  _chunks.verify();
+
+  if (_fbl != NULL) {
+    _fbl->verify();
+  }
+
+  // Verify guard zones of all allocations.
+  SOMETIMES(
+    if (Settings::use_allocation_guard()) {
+      for (const Metachunk* c = _chunks.first(); c != NULL; c = c->next()) {
+        const MetaWord* p = c->base();
+        while (p < c->top()) {
+          const Prefix* pp = (const Prefix*)p;
+          pp->check();
+          p += pp->_word_size;
+        }
+      }
+    }
+  )
+
+}
+
+void MetaspaceArena::verify() const {
+
+  MutexLocker cl(lock(), Mutex::_no_safepoint_check_flag);
+  verify_locked();
+
+}
+
+// Returns true if the area indicated by pointer and size have actually been allocated
+// from this arena.
+bool MetaspaceArena::is_valid_area(MetaWord* p, size_t word_size) const {
+  assert(p != NULL && word_size > 0, "Sanity");
+  bool found = false;
+  if (!found) {
+    for (const Metachunk* c = _chunks.first(); c != NULL && !found; c = c->next()) {
+      assert(c->is_valid_committed_pointer(p) ==
+             c->is_valid_committed_pointer(p + word_size - 1), "range intersects");
+      found = c->is_valid_committed_pointer(p);
+    }
+  }
+  return found;
+}
+
+#endif // ASSERT
+
+void MetaspaceArena::print_on(outputStream* st) const {
+  MutexLocker fcl(_lock, Mutex::_no_safepoint_check_flag);
+  print_on_locked(st);
+}
+
+void MetaspaceArena::print_on_locked(outputStream* st) const {
+  assert_lock_strong(_lock);
+  st->print_cr("sm %s: %d chunks, total word size: " SIZE_FORMAT ", committed word size: " SIZE_FORMAT, _name,
+               _chunks.count(), _chunks.calc_word_size(), _chunks.calc_committed_word_size());
+  _chunks.print_on(st);
+  st->cr();
+  st->print_cr("growth-policy " PTR_FORMAT ", lock " PTR_FORMAT ", cm " PTR_FORMAT ", fbl " PTR_FORMAT,
+                p2i(_growth_policy), p2i(_lock), p2i(_chunk_manager), p2i(_fbl));
+}
+
+} // namespace metaspace
+
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msArena.hpp	2020-09-04 13:57:39.585278948 +0200
@@ -0,0 +1,181 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#ifndef SHARE_MEMORY_METASPACE_MSARENA_HPP
+#define SHARE_MEMORY_METASPACE_MSARENA_HPP
+
+#include "memory/allocation.hpp"
+#include "memory/metaspace/msChunkManager.hpp"
+#include "memory/metaspace/msCommon.hpp"
+#include "memory/metaspace/msCounter.hpp"
+#include "memory/metaspace/msMetachunk.hpp"
+#include "memory/metaspace/msMetachunkList.hpp"
+#include "memory/metaspace.hpp"
+
+class outputStream;
+class Mutex;
+
+namespace metaspace {
+
+class ArenaGrowthPolicy;
+class FreeBlocks;
+
+struct ArenaStats;
+
+// The MetaspaceArena is a growable metaspace memory pool belonging to a CLD;
+//  internally it consists of a list of metaspace chunks, of which the head chunk
+//  is the current chunk from which we allocate via pointer bump.
+//
+//  +---------------+
+//  |     Arena     |
+//  +---------------+
+//            |
+//            | _chunks                                               commit top
+//            |                                                       v
+//        +----------+      +----------+      +----------+      +----------+
+//        | retired  | ---> | retired  | ---> | retired  | ---> | current  |
+//        | chunk    |      | chunk    |      | chunk    |      | chunk    |
+//        +----------+      +----------+      +----------+      +----------+
+//                                                                  ^
+//                                                                  used top
+//
+//        +------------+
+//        | FreeBlocks | --> O -> O -> O -> O
+//        +------------+
+//
+//
+
+// When the current chunk is used up, MetaspaceArena requestes a new chunk from
+//  the associated ChunkManager.
+//
+// MetaspaceArena also keeps a FreeBlocks structure to manage memory blocks which
+//  had been deallocated prematurely.
+//
+
+class MetaspaceArena : public CHeapObj<mtClass> {
+
+  // Reference to an outside lock to use for synchronizing access to this arena.
+  //  This lock is normally owned by the CLD which owns the ClassLoaderMetaspace which
+  //  owns this arena.
+  // Todo: This should be changed. Either the CLD should synchronize access to the
+  //       CLMS and its arenas itself, or the arena should have an own lock. The latter
+  //       would allow for more fine granular locking since it would allow access to
+  //       both class- and non-class arena in the CLMS independently.
+  Mutex* const _lock;
+
+  // Reference to the chunk manager to allocate chunks from.
+  ChunkManager* const _chunk_manager;
+
+  // Reference to the growth policy to use.
+  const ArenaGrowthPolicy* const _growth_policy;
+
+  // List of chunks. Head of the list is the current chunk.
+  MetachunkList _chunks;
+
+  // Structure to take care of leftover/deallocated space in used chunks.
+  // Owned by the Arena. Gets allocated on demand only.
+  FreeBlocks* _fbl;
+
+  Metachunk* current_chunk()              { return _chunks.first(); }
+  const Metachunk* current_chunk() const  { return _chunks.first(); }
+
+  // Reference to an outside counter to keep track of used space.
+  SizeAtomicCounter* const _total_used_words_counter;
+
+  // A name for purely debugging/logging purposes.
+  const char* const _name;
+
+  Mutex* lock() const                           { return _lock; }
+  ChunkManager* chunk_manager() const           { return _chunk_manager; }
+
+  // free block list
+  FreeBlocks* fbl() const                       { return _fbl; }
+  void add_allocation_to_fbl(MetaWord* p, size_t word_size);
+
+  // Given a chunk, add its remaining free committed space to the free block list.
+  void salvage_chunk(Metachunk* c);
+
+  // Allocate a new chunk from the underlying chunk manager able to hold at least
+  // requested word size.
+  Metachunk* allocate_new_chunk(size_t requested_word_size);
+
+  // Returns the level of the next chunk to be added, acc to growth policy.
+  chunklevel_t next_chunk_level() const;
+
+  // Attempt to enlarge the current chunk to make it large enough to hold at least
+  //  requested_word_size additional words.
+  //
+  // On success, true is returned, false otherwise.
+  bool attempt_enlarge_current_chunk(size_t requested_word_size);
+
+  // Prematurely returns a metaspace allocation to the _block_freelists
+  // because it is not needed anymore (requires CLD lock to be active).
+  void deallocate_locked(MetaWord* p, size_t word_size);
+
+  // Returns true if the area indicated by pointer and size have actually been allocated
+  // from this arena.
+  DEBUG_ONLY(bool is_valid_area(MetaWord* p, size_t word_size) const;)
+
+public:
+
+  MetaspaceArena(ChunkManager* chunk_manager,
+               const ArenaGrowthPolicy* growth_policy,
+               Mutex* lock,
+               SizeAtomicCounter* total_used_words_counter,
+               const char* name);
+
+  ~MetaspaceArena();
+
+  // Allocate memory from Metaspace.
+  // 1) Attempt to allocate from the dictionary of deallocated blocks.
+  // 2) Attempt to allocate from the current chunk.
+  // 3) Attempt to enlarge the current chunk in place if it is too small.
+  // 4) Attempt to get a new chunk and allocate from that chunk.
+  // At any point, if we hit a commit limit, we return NULL.
+  MetaWord* allocate(size_t word_size);
+
+  // Prematurely returns a metaspace allocation to the _block_freelists because it is not
+  // needed anymore.
+  void deallocate(MetaWord* p, size_t word_size);
+
+  // Update statistics. This walks all in-use chunks.
+  void add_to_statistics(ArenaStats* out) const;
+
+  // Convenience method to get the most important usage statistics.
+  // For deeper analysis use add_to_statistics().
+  void usage_numbers(size_t* p_used_words, size_t* p_committed_words, size_t* p_capacity_words) const;
+
+  DEBUG_ONLY(void verify() const;)
+  DEBUG_ONLY(void verify_locked() const;)
+
+  void print_on(outputStream* st) const;
+  void print_on_locked(outputStream* st) const;
+
+};
+
+} // namespace metaspace
+
+#endif // SHARE_MEMORY_METASPACE_MSARENA_HPP
+
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msArenaGrowthPolicy.cpp	2020-09-04 13:57:40.169282834 +0200
@@ -0,0 +1,127 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+
+#include "memory/metaspace/msArenaGrowthPolicy.hpp"
+#include "utilities/globalDefinitions.hpp"
+
+namespace metaspace {
+
+// hard-coded chunk allocation sequences for various space types
+//  (Note: when modifying this, don't add jumps of more than double the
+//   last chunk size. There is a gtest testing this, see test_arenagrowthpolicy.cpp)
+
+static const chunklevel_t g_sequ_standard_non_class[] = {
+    chunklevel::CHUNK_LEVEL_4K,
+    chunklevel::CHUNK_LEVEL_4K,
+    chunklevel::CHUNK_LEVEL_4K,
+    chunklevel::CHUNK_LEVEL_8K,
+    chunklevel::CHUNK_LEVEL_16K
+    // .. repeat last
+};
+
+static const chunklevel_t g_sequ_standard_class[] = {
+    chunklevel::CHUNK_LEVEL_2K,
+    chunklevel::CHUNK_LEVEL_2K,
+    chunklevel::CHUNK_LEVEL_4K,
+    chunklevel::CHUNK_LEVEL_8K,
+    chunklevel::CHUNK_LEVEL_16K
+    // .. repeat last
+};
+
+static const chunklevel_t g_sequ_anon_non_class[] = {
+   chunklevel::CHUNK_LEVEL_1K,
+   // .. repeat last
+};
+
+static const chunklevel_t g_sequ_anon_class[] = {
+    chunklevel::CHUNK_LEVEL_1K,
+    // .. repeat last
+};
+
+static const chunklevel_t g_sequ_refl_non_class[] = {
+    chunklevel::CHUNK_LEVEL_2K,
+    chunklevel::CHUNK_LEVEL_1K
+    // .. repeat last
+};
+
+static const chunklevel_t g_sequ_refl_class[] = {
+    chunklevel::CHUNK_LEVEL_1K,
+    // .. repeat last
+};
+
+// Boot class loader: give it large chunks: beyond commit granule size
+// (typically 64K) the costs for large chunks largely diminishes since
+// they are committed on the fly.
+static const chunklevel_t g_sequ_boot_non_class[] = {
+    chunklevel::CHUNK_LEVEL_4M,
+    chunklevel::CHUNK_LEVEL_1M
+    // .. repeat last
+};
+
+static const chunklevel_t g_sequ_boot_class[] = {
+    chunklevel::CHUNK_LEVEL_256K
+    // .. repeat last
+};
+
+const ArenaGrowthPolicy* ArenaGrowthPolicy::policy_for_space_type(Metaspace::MetaspaceType space_type, bool is_class) {
+
+#define DEFINE_CLASS_FOR_ARRAY(what) \
+  static ArenaGrowthPolicy chunk_alloc_sequence_##what (g_sequ_##what, sizeof(g_sequ_##what)/sizeof(chunklevel_t));
+
+  DEFINE_CLASS_FOR_ARRAY(standard_non_class)
+  DEFINE_CLASS_FOR_ARRAY(standard_class)
+  DEFINE_CLASS_FOR_ARRAY(anon_non_class)
+  DEFINE_CLASS_FOR_ARRAY(anon_class)
+  DEFINE_CLASS_FOR_ARRAY(refl_non_class)
+  DEFINE_CLASS_FOR_ARRAY(refl_class)
+  DEFINE_CLASS_FOR_ARRAY(boot_non_class)
+  DEFINE_CLASS_FOR_ARRAY(boot_class)
+
+  if (is_class) {
+    switch(space_type) {
+    case Metaspace::StandardMetaspaceType:          return &chunk_alloc_sequence_standard_class;
+    case Metaspace::ReflectionMetaspaceType:        return &chunk_alloc_sequence_refl_class;
+    case Metaspace::ClassMirrorHolderMetaspaceType: return &chunk_alloc_sequence_anon_class;
+    case Metaspace::BootMetaspaceType:              return &chunk_alloc_sequence_boot_class;
+    default: ShouldNotReachHere();
+    }
+  } else {
+    switch(space_type) {
+    case Metaspace::StandardMetaspaceType:          return &chunk_alloc_sequence_standard_non_class;
+    case Metaspace::ReflectionMetaspaceType:        return &chunk_alloc_sequence_refl_non_class;
+    case Metaspace::ClassMirrorHolderMetaspaceType: return &chunk_alloc_sequence_anon_non_class;
+    case Metaspace::BootMetaspaceType:              return &chunk_alloc_sequence_boot_non_class;
+    default: ShouldNotReachHere();
+    }
+  }
+
+  return NULL;
+
+}
+
+} // namespace
+
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msArenaGrowthPolicy.hpp	2020-09-04 13:57:40.725286536 +0200
@@ -0,0 +1,77 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#ifndef SHARE_MEMORY_METASPACE_MSARENAGROWTHPOLICY_HPP
+#define SHARE_MEMORY_METASPACE_MSARENAGROWTHPOLICY_HPP
+
+#include "memory/metaspace/msChunklevel.hpp"
+#include "memory/metaspace.hpp" // For Metaspace::MetaspaceType
+#include "utilities/debug.hpp"
+
+namespace metaspace {
+
+// ArenaGrowthPolicy encodes the growth policy of a MetaspaceArena.
+//
+// These arenas grow in steps (by allocating new chunks). The coarseness of growth
+// (chunk size, level) depends on what the arena is used for. Used for a class loader
+// which is expected to load only one or very few classes should grow in tiny steps.
+// For normal classloaders, it can grow in coarser steps, and arenas used by
+// the boot loader will grow in even larger steps since we expect it to load a lot of
+// classes.
+// Note that when growing in large steps (in steps larger than a commit granule,
+// by default 64K), costs diminish somewhat since we do not commit the whole space
+// immediately.
+
+class ArenaGrowthPolicy {
+
+  // const array specifying chunk level allocation progression (growth steps). Last
+  //  chunk is to be an endlessly repeated allocation.
+  const chunklevel_t* const _entries;
+  const int _num_entries;
+
+public:
+
+  ArenaGrowthPolicy(const chunklevel_t* array, int num_entries)
+    : _entries(array), _num_entries(num_entries) {
+    assert(_num_entries > 0, "must not be empty.");
+  }
+
+  chunklevel_t get_level_at_step(int num_allocated) const {
+    if (num_allocated >= _num_entries) {
+      // Caller shall repeat last allocation
+      return _entries[_num_entries - 1];
+    }
+    return _entries[num_allocated];
+  }
+
+  // Given a space type, return the correct policy to use.
+  // The returned object is static and read only.
+  static const ArenaGrowthPolicy* policy_for_space_type(Metaspace::MetaspaceType space_type, bool is_class);
+
+};
+
+} // namespace metaspace
+
+#endif // SHARE_MEMORY_METASPACE_MSARENAGROWTHPOLICY_HPP
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msBinList.hpp	2020-09-04 13:57:41.293290322 +0200
@@ -0,0 +1,225 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#ifndef SHARE_MEMORY_METASPACE_MSBINLIST_HPP
+#define SHARE_MEMORY_METASPACE_MSBINLIST_HPP
+
+#include "memory/metaspace/msCommon.hpp"
+#include "memory/metaspace/msCounter.hpp"
+#include "utilities/align.hpp"
+#include "utilities/debug.hpp"
+#include "utilities/globalDefinitions.hpp"
+
+namespace metaspace {
+
+// BinList is a data structure to manage small to very small memory blocks
+// (only a few words). It is used to manage deallocated blocks - see
+// class FreeBlocks.
+
+// Memory blocks are kept in linked lists. Each list
+// contains blocks of only one size. There is a list for blocks of two words,
+// for blocks of three words, etc. The list heads are kept in a vector,
+// ordered by block size.
+//
+
+// wordsize
+//
+//       +---+   +---+   +---+      +---+
+//  1    |   |-->|   |-->|   |-...->|   |
+//       +---+   +---+   +---+      +---+
+//
+//       +----+   +----+   +----+      +----+
+//  2    |    |-->|    |-->|    |-...->|    |
+//       +----+   +----+   +----+      +----+
+//
+//       +-----+   +-----+   +-----+      +-----+
+//  3    |     |-->|     |-->|     |-...->|     |
+//       +-----+   +-----+   +-----+      +-----+
+//  .
+//  .
+//  .
+//
+//       +----------+   +----------+   +----------+      +----------+
+//  n    |          |-->|          |-->|          |-...->|          |
+//       +----------+   +----------+   +----------+      +----------+
+
+// Insertion is of course fast, O(1).
+//
+// On retrieval, we attempt to find the closest fit to a given size, walking the
+// list head vector (a bitmask is used to speed that part up).
+//
+// This structure is a bit expensive in memory costs (we pay one pointer per managed
+// block size) so we only use it for a small number of sizes.
+
+template <size_t smallest_word_size, int num_lists>
+class BinListImpl {
+
+  struct Block {
+    Block* const _next;
+    const size_t _word_size;
+    Block(Block* next, size_t word_size)
+      : _next(next), _word_size(word_size)
+    {}
+  };
+
+  // a mask to speed up searching for populated lists.
+  // 0 marks an empty list, 1 for a non-empty one.
+  typedef uint32_t mask_t;
+  STATIC_ASSERT(num_lists <= sizeof(mask_t) * 8);
+
+  mask_t _mask;
+
+  // Smallest block size must be large enough to hold a Block structure.
+  STATIC_ASSERT(smallest_word_size * sizeof(MetaWord) >= sizeof(Block));
+
+  STATIC_ASSERT(num_lists > 0);
+
+public:
+
+  // Minimal word size a block must have to be manageable by this structure.
+  const static size_t MinWordSize = smallest_word_size;
+
+  // Maximal (incl) word size a block can have to be manageable by this structure.
+  const static size_t MaxWordSize = MinWordSize + num_lists - 1;
+
+private:
+
+  Block* _blocks[num_lists];
+
+  MemRangeCounter _counter;
+
+  static int index_for_word_size(size_t word_size) {
+    int index = (int)(word_size - MinWordSize);
+    assert(index >= 0 && index < num_lists, "Invalid index %d", index);
+    return index;
+  }
+
+  static size_t word_size_for_index(int index) {
+    assert(index >= 0 && index < num_lists, "Invalid index %d", index);
+    return MinWordSize + index;
+  }
+
+  // Search the range [index, _num_lists) for the smallest non-empty list. Returns -1 on fail.
+  int index_for_next_non_empty_list(int index) {
+    assert(index >= 0 && index < num_lists, "Invalid index %d", index);
+    int i2 = index;
+    mask_t m = _mask >> i2;
+    if (m > 0) {
+      // count leading zeros would be helpful.
+      while ((m & 1) == 0) {
+        assert(_blocks[i2] == NULL, "mask mismatch");
+        i2++;
+        m >>= 1;
+      }
+      // We must have found something.
+      assert(i2 < num_lists, "sanity.");
+      assert(_blocks[i2] != NULL, "mask mismatch");
+      return i2;
+    }
+    return -1;
+  }
+
+  void mask_set_bit(int bit) { _mask |= (((mask_t)1) << bit); }
+  void mask_clr_bit(int bit) { _mask &= ~(((mask_t)1) << bit); }
+
+public:
+
+  BinListImpl() : _mask(0) {
+    for (int i = 0; i < num_lists; i++) {
+      _blocks[i] = NULL;
+    }
+  }
+
+  void add_block(MetaWord* p, size_t word_size) {
+    assert(word_size >= MinWordSize &&
+           word_size <= MaxWordSize, "bad block size");
+    const int index = index_for_word_size(word_size);
+    Block* old_head = _blocks[index];
+    Block* new_head = new(p)Block(old_head, word_size);
+    _blocks[index] = new_head;
+    _counter.add(word_size);
+    mask_set_bit(index);
+  }
+
+  // Given a word_size, searches and returns a block of at least that size.
+  // Block may be larger. Real block size is returned in *p_real_word_size.
+  MetaWord* remove_block(size_t word_size, size_t* p_real_word_size) {
+    assert(word_size >= MinWordSize &&
+           word_size <= MaxWordSize, "bad block size " SIZE_FORMAT ".", word_size);
+    int index = index_for_word_size(word_size);
+    index = index_for_next_non_empty_list(index);
+    if (index != -1) {
+      assert(_blocks[index] != NULL &&
+             _blocks[index]->_word_size >= word_size, "sanity");
+
+      MetaWord* const p = (MetaWord*)_blocks[index];
+      const size_t real_word_size = word_size_for_index(index);
+
+      _blocks[index] = _blocks[index]->_next;
+      if (_blocks[index] == NULL) {
+        mask_clr_bit(index);
+      }
+
+      _counter.sub(real_word_size);
+      *p_real_word_size = real_word_size;
+
+      return p;
+
+    } else {
+      *p_real_word_size = 0;
+      return NULL;
+    }
+  }
+
+  // Returns number of blocks in this structure
+  unsigned count() const { return _counter.count(); }
+
+  // Returns total size, in words, of all elements.
+  size_t total_size() const { return _counter.total_size(); }
+
+  bool is_empty() const { return _mask == 0; }
+
+#ifdef ASSERT
+  void verify() const {
+    MemRangeCounter local_counter;
+    for (int i = 0; i < num_lists; i++) {
+      assert(((_mask >> i) & 1) == ((_blocks[i] == 0) ? 0 : 1), "sanity");
+      const size_t s = MinWordSize + i;
+      for (Block* b = _blocks[i]; b != NULL; b = b->_next) {
+        assert(b->_word_size == s, "bad block size");
+        local_counter.add(s);
+      }
+    }
+    local_counter.check(_counter);
+  }
+#endif // ASSERT
+
+};
+
+typedef BinListImpl<2, 32> BinList32;
+
+} // namespace metaspace
+
+#endif // SHARE_MEMORY_METASPACE_MSBINLIST_HPP
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msBlockTree.cpp	2020-09-04 13:57:41.961294776 +0200
@@ -0,0 +1,205 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+
+#include "memory/metaspace/msBlockTree.hpp"
+#include "memory/resourceArea.hpp"
+#include "utilities/debug.hpp"
+#include "utilities/globalDefinitions.hpp"
+#include "utilities/growableArray.hpp"
+#include "utilities/ostream.hpp"
+
+namespace metaspace {
+
+#ifdef ASSERT
+
+// Tree verification
+
+// These asserts prints the tree, then asserts
+#define assrt(cond, format, ...) \
+  do { \
+    if (!(cond)) { \
+      print_tree(tty); \
+      assert(cond, format, __VA_ARGS__); \
+    } \
+  } while(0)
+
+  // This assert prints the tree, then stops (generic message)
+#define assrt0(cond) \
+  do { \
+    if (!(cond)) { \
+      print_tree(tty); \
+      assert(cond, "sanity"); \
+    } \
+  } while(0)
+
+
+
+// walkinfo keeps a node plus the size corridor it and its children
+//  are supposed to be in.
+struct BlockTree::walkinfo {
+  BlockTree::Node* n;
+  int depth;
+  size_t lim1; // (
+  size_t lim2; // )
+};
+
+void BlockTree::verify() const {
+
+  // Traverse the tree and test that all nodes are in the correct order.
+
+  MemRangeCounter counter;
+  int longest_edge = 0;
+
+  if (_root != NULL) {
+
+    ResourceMark rm;
+
+    GrowableArray<walkinfo> stack;
+
+    walkinfo info;
+    info.n = _root;
+    info.lim1 = 0;
+    info.lim2 = SIZE_MAX;
+    info.depth = 0;
+
+    stack.push(info);
+
+    while (stack.length() > 0) {
+
+      info = stack.pop();
+      const Node* n = info.n;
+
+      // Assume a (ridiculously large) edge limit to catch cases
+      //  of badly degenerated or circular trees.
+      assrt0(info.depth < 10000);
+
+      counter.add(n->_word_size);
+
+      // Verify node.
+      if (n == _root) {
+        assrt0(n->_parent == NULL);
+      } else {
+        assrt0(n->_parent != NULL);
+      }
+
+      // check size and ordering
+      assrt(n->_word_size >= MinWordSize, "bad node size " SIZE_FORMAT, n->_word_size);
+      assrt0(n->_word_size > info.lim1);
+      assrt0(n->_word_size < info.lim2);
+
+      // Check children
+      if (n->_left != NULL) {
+        assrt0(n->_left != n);
+        assrt0(n->_left->_parent == n);
+
+        walkinfo info2;
+        info2.n = n->_left;
+        info2.lim1 = info.lim1;
+        info2.lim2 = n->_word_size;
+        info2.depth = info.depth + 1;
+        stack.push(info2);
+      }
+
+      if (n->_right != NULL) {
+        assrt0(n->_right != n);
+        assrt0(n->_right->_parent == n);
+
+        walkinfo info2;
+        info2.n = n->_right;
+        info2.lim1 = n->_word_size;
+        info2.lim2 = info.lim2;
+        info2.depth = info.depth + 1;
+        stack.push(info2);
+      }
+
+      // If node has same-sized siblings check those too.
+      const Node* n2 = n->_next;
+      while (n2 != NULL) {
+        assrt0(n2 != n);
+        assrt0(n2->_word_size == n->_word_size);
+        counter.add(n2->_word_size);
+        n2 = n2->_next;
+      }
+    }
+  }
+
+  // At the end, check that counters match
+  _counter.check(counter);
+
+}
+
+void BlockTree::zap_range(MetaWord* p, size_t word_size) {
+  memset(p, 0xF3, word_size * sizeof(MetaWord));
+}
+
+#undef assrt
+#undef assrt0
+
+void BlockTree::print_tree(outputStream* st) const {
+
+  if (_root != NULL) {
+
+    ResourceMark rm;
+
+    GrowableArray<walkinfo> stack;
+
+    walkinfo info;
+    info.n = _root;
+    info.depth = 0;
+
+    stack.push(info);
+    while (stack.length() > 0) {
+      info = stack.pop();
+      const Node* n = info.n;
+      // Print node.
+      for (int i = 0; i < info.depth; i++) {
+         st->print("---");
+      }
+      st->print_cr("<" PTR_FORMAT " (size " SIZE_FORMAT ")", p2i(n), n->_word_size);
+      // Handle children.
+      if (n->_right != NULL) {
+        walkinfo info2;
+        info2.n = n->_right;
+        info2.depth = info.depth + 1;
+        stack.push(info2);
+      }
+      if (n->_left != NULL) {
+        walkinfo info2;
+        info2.n = n->_left;
+        info2.depth = info.depth + 1;
+        stack.push(info2);
+      }
+    }
+
+  } else {
+    st->print_cr("<no nodes>");
+  }
+}
+
+#endif // ASSERT
+
+} // namespace metaspace
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msBlockTree.hpp	2020-09-04 13:57:42.605299074 +0200
@@ -0,0 +1,407 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#ifndef SHARE_MEMORY_METASPACE_MSBLOCKTREE_HPP
+#define SHARE_MEMORY_METASPACE_MSBLOCKTREE_HPP
+
+#include "memory/allocation.hpp"
+#include "memory/metaspace/msChunklevel.hpp"
+#include "memory/metaspace/msCounter.hpp"
+#include "utilities/debug.hpp"
+#include "utilities/globalDefinitions.hpp"
+
+namespace metaspace {
+
+// BlockTree is a rather simple binary search tree. It is used to
+//  manage small to medium free memory blocks (see class FreeBlocks).
+//
+// There is no separation between payload (managed blocks) and nodes: the
+//  memory blocks themselves are the nodes, with the block size being the key.
+//
+// We store node pointer information in these blocks when storing them. That
+//  imposes a minimum size to the managed memory blocks.
+//  See get_raw_word_size_for_requested_word_size() (msCommon.hpp).
+//
+// We want to manage many memory blocks of the same size, but we want
+//  to prevent the tree from blowing up and degenerating into a list. Therefore
+//  there is only one node for each unique block size; subsequent blocks of the
+//  same size are stacked below that first node:
+//
+//                   +-----+
+//                   | 100 |
+//                   +-----+
+//                  /       \
+//           +-----+
+//           | 80  |
+//           +-----+
+//          /   |   \
+//         / +-----+ \
+//  +-----+  | 80  |  +-----+
+//  | 70  |  +-----+  | 85  |
+//  +-----+     |     +-----+
+//           +-----+
+//           | 80  |
+//           +-----+
+//
+//
+// Todo: This tree is unbalanced. It would be a good fit for a red-black tree.
+//  In order to make this a red-black tree, we need an algorithm which can deal
+//  with nodes which are their own payload (most red-black tree implementations
+//  swap payloads of their nodes at some point, see e.g. j.u.TreeSet).
+// A good example is the Linux kernel rbtree, which is a clean, easy-to-read
+//  implementation.
+
+class BlockTree: public CHeapObj<mtMetaspace> {
+
+  struct Node {
+
+    // Normal tree node stuff...
+    Node* _parent;
+    Node* _left;
+    Node* _right;
+
+    // Blocks with the same size are put in a list with this node as head.
+    Node* _next;
+
+    // Word size of node. Note that size cannot be larger than max metaspace size,
+    // so this could be very well a 32bit value (in case we ever make this a balancing
+    // tree and need additional space for weighting information).
+    const size_t _word_size;
+
+    Node(size_t word_size)
+      : _parent(NULL), _left(NULL), _right(NULL),
+        _next(NULL), _word_size(word_size)
+    {}
+
+  };
+
+  // Needed for verify() and print_tree()
+  struct walkinfo;
+
+public:
+
+  // Minimum word size a block has to be to be added to this structure (note ceil division).
+  const static size_t MinWordSize =
+      (sizeof(Node) + sizeof(MetaWord) - 1) / sizeof(MetaWord);
+
+private:
+
+  Node* _root;
+
+  MemRangeCounter _counter;
+
+  // Given a node n, add it to the list starting at head
+  static void add_to_list(Node* n, Node* head) {
+    assert(head->_word_size == n->_word_size, "sanity");
+    n->_next = head->_next;
+    head->_next = n;
+    DEBUG_ONLY(n->_left = n->_right = n->_parent = NULL;)
+  }
+
+  // Given a node list starting at head, remove one of the follow up nodes from
+  //  that list and return it. The head node gets not modified and remains in the
+  //  tree.
+  // List must contain at least one other node.
+  static Node* remove_from_list(Node* head) {
+    assert(head->_next != NULL, "sanity");
+    Node* n = head->_next;
+    head->_next = n->_next;
+    return n;
+  }
+
+  // Given a node c and a node p, wire up c as left child of p.
+  static void set_left_child(Node* p, Node* c) {
+    p->_left = c;
+    if (c != NULL) {
+      assert(c->_word_size < p->_word_size, "sanity");
+      c->_parent = p;
+    }
+  }
+
+  // Given a node c and a node p, wire up c as right child of p.
+  static void set_right_child(Node* p, Node* c) {
+    p->_right = c;
+    if (c != NULL) {
+      assert(c->_word_size > p->_word_size, "sanity");
+      c->_parent = p;
+    }
+  }
+
+  // Given a node n, return its predecessor in the tree
+  // (node with the next-smaller size).
+  static Node* predecessor(Node* n) {
+    Node* pred = NULL;
+    if (n->_left != NULL) {
+      pred = n->_left;
+      while (pred->_right != NULL) {
+        pred = pred->_right;
+      }
+    } else {
+      pred = n->_parent;
+      Node* n2 = n;
+      while (pred != NULL && n2 == pred->_left) {
+        n2 = pred;
+        pred = pred->_parent;
+      }
+    }
+    return pred;
+  }
+
+  // Given a node n, return its successor in the tree
+  // (node with the next-larger size).
+  static Node* successor(Node* n) {
+    Node* succ = NULL;
+    if (n->_right != NULL) {
+      // If there is a right child, search the left-most
+      // child of that child.
+      succ = n->_right;
+      while (succ->_left != NULL) {
+        succ = succ->_left;
+      }
+    } else {
+      succ = n->_parent;
+      Node* n2 = n;
+      // As long as I am the right child of my parent, search upward
+      while (succ != NULL && n2 == succ->_right) {
+        n2 = succ;
+        succ = succ->_parent;
+      }
+    }
+    return succ;
+  }
+
+  // Given a node, replace it with a replacement node as a child for its parent.
+  // If the node is root and has no parent, sets it as root.
+  void replace_node_in_parent(Node* child, Node* replace) {
+    Node* parent = child->_parent;
+    if (parent != NULL) {
+      if (parent->_left == child) { // Child is left child
+        set_left_child(parent, replace);
+      } else {
+        set_right_child(parent, replace);
+      }
+    } else {
+      assert(child == _root, "must be root");
+      _root = replace;
+      if (replace != NULL) {
+        replace->_parent = NULL;
+      }
+    }
+    return;
+  }
+
+  // Given a node n and an insertion point, insert n under insertion point.
+  void insert(Node* insertion_point, Node* n) {
+    assert(n->_parent == NULL, "Sanity");
+    for(;;) {
+      if (n->_word_size == insertion_point->_word_size) {
+        add_to_list(n, insertion_point); // parent stays NULL in this case.
+        break;
+      } else if (n->_word_size > insertion_point->_word_size) {
+        if (insertion_point->_right == NULL) {
+          set_right_child(insertion_point, n);
+          break;
+        } else {
+          insertion_point = insertion_point->_right;
+        }
+      } else {
+        if (insertion_point->_left == NULL) {
+          set_left_child(insertion_point, n);
+          break;
+        } else {
+          insertion_point = insertion_point->_left;
+        }
+      }
+    }
+  }
+
+  // Given a node and a wish size, search this node and all children for
+  // the node closest (equal or larger sized) to the size s.
+  static Node* find_closest_fit(Node* n, size_t s) {
+
+    Node* best_match = NULL;
+
+    while (n != NULL) {
+      if (n->_word_size >= s) {
+        best_match = n;
+        if (n->_word_size == s) {
+          break; // perfect match or max depth reached
+        }
+        n = n->_left;
+      } else {
+        n = n->_right;
+      }
+    }
+
+    return best_match;
+  }
+
+  // Given a wish size, search the whole tree for a
+  // node closest (equal or larger sized) to the size s.
+  Node* find_closest_fit(size_t s) {
+    if (_root != NULL) {
+      return find_closest_fit(_root, s);
+    }
+    return NULL;
+  }
+
+  // Given a node n, remove it from the tree and repair tree.
+  void remove_node_from_tree(Node* n) {
+
+    assert(n->_next == NULL, "do not delete a node which has a non-empty list");
+
+    if (n->_left == NULL && n->_right == NULL) {
+      replace_node_in_parent(n, NULL);
+
+    } else if (n->_left == NULL && n->_right != NULL) {
+      replace_node_in_parent(n, n->_right);
+
+    } else if (n->_left != NULL && n->_right == NULL) {
+      replace_node_in_parent(n, n->_left);
+
+    } else {
+
+      // Node has two children.
+
+      // 1) Find direct successor (the next larger node).
+      Node* succ = successor(n);
+
+      // There has to be a successor since n->right was != NULL...
+      assert(succ != NULL, "must be");
+
+      // ... and it should not have a left child since successor
+      //     is supposed to be the next larger node, so it must be the mostleft node
+      //     in the sub tree rooted at n->right
+      assert(succ->_left == NULL, "must be");
+
+      assert(succ->_word_size > n->_word_size, "sanity");
+
+      Node* successor_parent = succ->_parent;
+      Node* successor_right_child = succ->_right;
+
+      // Remove successor from its parent.
+      if (successor_parent == n) {
+
+        // special case: successor is a direct child of n. Has to be the right child then.
+        assert(n->_right == succ, "sanity");
+
+        // Just replace n with this successor.
+        replace_node_in_parent(n, succ);
+
+        // Take over n's old left child, too.
+        // We keep the successor's right child.
+        set_left_child(succ, n->_left);
+
+      } else {
+
+        // If the successors parent is not n, we are deeper in the tree,
+        //  the successor has to be the left child of its parent.
+        assert(successor_parent->_left == succ, "sanity");
+
+        // The right child of the successor (if there was one) replaces
+        //  the successor at its parent's left child.
+        set_left_child(successor_parent, succ->_right);
+
+        // and the successor replaces n at its parent
+        replace_node_in_parent(n, succ);
+
+        // and takes over n's old children
+        set_left_child(succ, n->_left);
+        set_right_child(succ, n->_right);
+
+      }
+    }
+  }
+
+#ifdef ASSERT
+  void zap_range(MetaWord* p, size_t word_size);
+#endif // ASSERT
+
+public:
+
+  BlockTree() : _root(NULL) {}
+
+  // Add a memory block to the tree. Its content will be overwritten.
+  void add_block(MetaWord* p, size_t word_size) {
+    DEBUG_ONLY(zap_range(p, word_size));
+    assert(word_size >= MinWordSize, "invalid block size " SIZE_FORMAT, word_size);
+    Node* n = new(p) Node(word_size);
+    if (_root == NULL) {
+      _root = n;
+    } else {
+      insert(_root, n);
+    }
+    _counter.add(word_size);
+  }
+
+  // Given a word_size, search and return the smallest block that is equal or
+  //  larger than that size. Upon return, *p_real_word_size contains the actual
+  //  block size.
+  MetaWord* remove_block(size_t word_size, size_t* p_real_word_size) {
+    assert(word_size >= MinWordSize, "invalid block size " SIZE_FORMAT, word_size);
+
+    Node* n = find_closest_fit(word_size);
+
+    if (n != NULL) {
+      assert(n->_word_size >= word_size, "sanity");
+
+      if (n->_next != NULL) {
+        // If the node is head of a chain of same sized nodes, we leave it alone
+        //  and instead remove one of the follow up nodes (which is simpler than
+        //  removing the chain head node and then having to graft the follow up
+        //  node into its place in the tree).
+        n = remove_from_list(n);
+      } else {
+        remove_node_from_tree(n);
+      }
+
+      MetaWord* p = (MetaWord*)n;
+      *p_real_word_size = n->_word_size;
+
+      _counter.sub(n->_word_size);
+
+      DEBUG_ONLY(zap_range(p, n->_word_size));
+
+      return p;
+    }
+    return NULL;
+  }
+
+  // Returns number of blocks in this structure
+  unsigned count() const { return _counter.count(); }
+
+  // Returns total size, in words, of all elements.
+  size_t total_size() const { return _counter.total_size(); }
+
+  bool is_empty() const { return _root == NULL; }
+
+  DEBUG_ONLY(void print_tree(outputStream* st) const;)
+  DEBUG_ONLY(void verify() const;)
+
+};
+
+} // namespace metaspace
+
+#endif // SHARE_MEMORY_METASPACE_MSBLOCKTREE_HPP
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msChunkHeaderPool.cpp	2020-09-04 13:57:43.185302947 +0200
@@ -0,0 +1,91 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+#include "memory/metaspace/msChunkHeaderPool.hpp"
+#include "runtime/os.hpp"
+#include "utilities/debug.hpp"
+#include "utilities/globalDefinitions.hpp"
+
+namespace metaspace {
+
+// Returns reference to the one global chunk header pool.
+ChunkHeaderPool* ChunkHeaderPool::_chunkHeaderPool = NULL;
+
+ChunkHeaderPool::ChunkHeaderPool()
+  : _num_slabs(), _first_slab(NULL), _current_slab(NULL)
+{
+}
+
+// Note: the global chunk header pool gets never deleted; so this destructor only
+// exists for the sake of tests.
+ChunkHeaderPool::~ChunkHeaderPool() {
+  Slab* s = _first_slab;
+  while (s != NULL) {
+    Slab* next_slab = s->_next;
+    os::free(s);
+     s = next_slab;
+  }
+}
+
+void ChunkHeaderPool::allocate_new_slab() {
+  Slab* slab = new Slab();
+  if (_current_slab != NULL) {
+    _current_slab->_next = slab;
+  }
+  _current_slab = slab;
+  if (_first_slab == NULL) {
+    _first_slab = slab;
+  }
+  _num_slabs.increment();
+}
+
+// Returns size of memory used.
+size_t ChunkHeaderPool::memory_footprint_words() const {
+  return (_num_slabs.get() * sizeof(Slab)) / BytesPerWord;
+}
+
+void ChunkHeaderPool::initialize() {
+  assert(_chunkHeaderPool == NULL, "only once");
+  _chunkHeaderPool = new ChunkHeaderPool();
+}
+
+#ifdef ASSERT
+void ChunkHeaderPool::verify() const {
+  const Slab* s = _first_slab;
+  int num = 0;
+  while (s != NULL) {
+    assert(s->_top >= 0 && s->_top <= SlabCapacity,
+           "invalid slab at " PTR_FORMAT ", top: %d, slab cap: %d",
+           p2i(s), s->_top, SlabCapacity );
+    s = s->_next;
+    num++;
+  }
+  _num_slabs.check(num);
+}
+#endif
+
+} // namespace metaspace
+
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msChunkHeaderPool.hpp	2020-09-04 13:57:43.745306689 +0200
@@ -0,0 +1,145 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#ifndef SHARE_MEMORY_METASPACE_MSCHUNKHEADERPOOL_HPP
+#define SHARE_MEMORY_METASPACE_MSCHUNKHEADERPOOL_HPP
+
+#include "memory/allocation.hpp"
+#include "memory/metaspace/msCounter.hpp"
+#include "memory/metaspace/msMetachunk.hpp"
+#include "memory/metaspace/msMetachunkList.hpp"
+#include "utilities/debug.hpp"
+#include "utilities/globalDefinitions.hpp"
+
+namespace metaspace {
+
+// Chunk headers (Metachunk objects) are separate entities from their payload.
+//  Since they are allocated and released frequently in the course of buddy allocation
+//  (splitting, merging chunks happens often) we want allocation of them fast. Therefore
+//  we keep them in a simple pool (somewhat like a primitive slab allocator).
+
+class ChunkHeaderPool : public CHeapObj<mtMetaspace> {
+
+  static const int SlabCapacity = 128;
+
+  struct Slab : public CHeapObj<mtMetaspace> {
+    Slab* _next;
+    int _top;
+    Metachunk _elems [SlabCapacity];
+    Slab() : _next(NULL), _top(0) {
+      for (int i = 0; i < SlabCapacity; i++) {
+        _elems[i].clear();
+      }
+    }
+  };
+
+  IntCounter _num_slabs;
+  Slab* _first_slab;
+  Slab* _current_slab;
+
+  IntCounter _num_handed_out;
+
+  MetachunkList _freelist;
+
+  void allocate_new_slab();
+
+  static ChunkHeaderPool* _chunkHeaderPool;
+
+public:
+
+  ChunkHeaderPool();
+
+  ~ChunkHeaderPool();
+
+  // Allocates a Metachunk structure. The structure is uninitialized.
+  Metachunk* allocate_chunk_header() {
+
+    Metachunk* c = NULL;
+
+    DEBUG_ONLY(verify());
+
+    c = _freelist.remove_first();
+    assert(c == NULL || c->is_dead(), "Not a freelist chunk header?");
+
+    if (c == NULL) {
+
+      if (_current_slab == NULL ||
+          _current_slab->_top == SlabCapacity) {
+        allocate_new_slab();
+        assert(_current_slab->_top < SlabCapacity, "Sanity");
+      }
+
+      c = _current_slab->_elems + _current_slab->_top;
+      _current_slab->_top++;
+
+    }
+
+    _num_handed_out.increment();
+
+    // By contract, the returned structure is uninitialized.
+    // Zap to make this clear.
+    DEBUG_ONLY(c->zap_header(0xBB);)
+
+    return c;
+
+  }
+
+  void return_chunk_header(Metachunk* c) {
+    // We only ever should return free chunks, since returning chunks
+    // happens only on merging and merging only works with free chunks.
+    assert(c != NULL && c->is_free(), "Sanity");
+#ifdef ASSERT
+    // In debug, fill dead header with pattern.
+    c->zap_header(0xCC);
+    c->set_next(NULL);
+    c->set_prev(NULL);
+#endif
+    c->set_dead();
+    _freelist.add(c);
+    _num_handed_out.decrement();
+
+  }
+
+  // Returns number of allocated elements.
+  int used() const                   { return _num_handed_out.get(); }
+
+  // Returns number of elements in free list.
+  int freelist_size() const          { return _freelist.count(); }
+
+  // Returns size of memory used.
+  size_t memory_footprint_words() const;
+
+  DEBUG_ONLY(void verify() const;)
+
+  static void initialize();
+
+  // Returns reference to the one global chunk header pool.
+  static ChunkHeaderPool* pool() { return _chunkHeaderPool; }
+
+};
+
+} // namespace metaspace
+
+#endif // SHARE_MEMORY_METASPACE_MSCHUNKHEADERPOOL_HPP
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msChunkManager.cpp	2020-09-04 13:57:44.317310515 +0200
@@ -0,0 +1,476 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+
+#include "logging/log.hpp"
+#include "logging/logStream.hpp"
+#include "memory/metaspace/msArenaGrowthPolicy.hpp"
+#include "memory/metaspace/msChunkManager.hpp"
+#include "memory/metaspace/msCommon.hpp"
+#include "memory/metaspace/msContext.hpp"
+#include "memory/metaspace/msInternalStats.hpp"
+#include "memory/metaspace/msMetachunk.hpp"
+#include "memory/metaspace/msSettings.hpp"
+#include "memory/metaspace/msStatistics.hpp"
+#include "memory/metaspace/msVirtualSpaceList.hpp"
+#include "memory/metaspace/msVirtualSpaceNode.hpp"
+#include "runtime/mutexLocker.hpp"
+#include "utilities/debug.hpp"
+#include "utilities/globalDefinitions.hpp"
+
+namespace metaspace {
+
+#define LOGFMT         "ChkMgr @" PTR_FORMAT " (%s)"
+#define LOGFMT_ARGS    p2i(this), this->_name
+
+// Return a single chunk to the freelist and adjust accounting. No merge is attempted.
+void ChunkManager::return_chunk_simple_locked(Metachunk* c) {
+
+  assert_lock_strong(MetaspaceExpand_lock);
+
+  DEBUG_ONLY(c->verify());
+
+  const chunklevel_t lvl = c->level();
+  _chunks.add(c);
+  c->reset_used_words();
+
+  // Tracing
+  log_debug(metaspace)("ChunkManager %s: returned chunk " METACHUNK_FORMAT ".",
+                       _name, METACHUNK_FORMAT_ARGS(c));
+
+}
+
+// Creates a chunk manager with a given name (which is for debug purposes only)
+// and an associated space list which will be used to request new chunks from
+// (see get_chunk())
+ChunkManager::ChunkManager(const char* name, VirtualSpaceList* space_list)
+  : _vslist(space_list),
+    _name(name),
+    _chunks()
+{
+}
+
+// Given a chunk, split it into a target chunk of a smaller size (higher target level)
+//  and at least one, possible several splinter chunks.
+// The original chunk must be outside of the freelist and its state must be free.
+// The splinter chunks are added to the freelist.
+// The resulting target chunk will be located at the same address as the original
+//  chunk, but it will of course be smaller (of a higher level).
+// The committed areas within the original chunk carry over to the resulting
+//  chunks.
+void ChunkManager::split_chunk_and_add_splinters(Metachunk* c, chunklevel_t target_level) {
+
+  assert_lock_strong(MetaspaceExpand_lock);
+
+  assert(c->is_free(), "chunk to be split must be free.");
+  assert(c->level() < target_level, "Target level must be higher than current level.");
+  assert(c->prev() == NULL && c->next() == NULL, "Chunk must be outside of any list.");
+
+  DEBUG_ONLY(chunklevel::check_valid_level(target_level);)
+  DEBUG_ONLY(c->verify();)
+
+  UL2(debug, "splitting chunk " METACHUNK_FORMAT " to " CHKLVL_FORMAT ".",
+      METACHUNK_FORMAT_ARGS(c), target_level);
+
+  DEBUG_ONLY(size_t committed_words_before = c->committed_words();)
+
+  const chunklevel_t orig_level = c->level();
+  c->vsnode()->split(target_level, c, &_chunks);
+
+  // Splitting should never fail.
+  assert(c->level() == target_level, "Sanity");
+
+  // The size of the committed portion should not change (subject to the reduced chunk size of course)
+#ifdef ASSERT
+  if (committed_words_before > c->word_size()) {
+    assert(c->is_fully_committed(), "Sanity");
+  } else {
+    assert(c->committed_words() == committed_words_before, "Sanity");
+  }
+#endif
+
+  DEBUG_ONLY(c->verify());
+
+  DEBUG_ONLY(verify_locked();)
+
+  SOMETIMES(c->vsnode()->verify_locked();)
+
+  InternalStats::inc_num_chunk_splits();
+
+}
+
+// On success, returns a chunk of level of <preferred_level>, but at most <max_level>.
+//  The first first <min_committed_words> of the chunk are guaranteed to be committed.
+// On error, will return NULL.
+//
+// This function may fail for two reasons:
+// - Either we are unable to reserve space for a new chunk (if the underlying VirtualSpaceList
+//   is non-expandable but needs expanding - aka out of compressed class space).
+// - Or, if the necessary space cannot be committed because we hit a commit limit.
+//   This may be either the GC threshold or MaxMetaspaceSize.
+Metachunk* ChunkManager::get_chunk(chunklevel_t preferred_level, chunklevel_t max_level, size_t min_committed_words) {
+
+  assert(preferred_level <= max_level, "Sanity");
+  assert(chunklevel::level_fitting_word_size(min_committed_words) >= max_level, "Sanity");
+
+  MutexLocker fcl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
+
+  DEBUG_ONLY(verify_locked();)
+
+  DEBUG_ONLY(chunklevel::check_valid_level(max_level);)
+  DEBUG_ONLY(chunklevel::check_valid_level(preferred_level);)
+  assert(max_level >= preferred_level, "invalid level.");
+
+  UL2(debug, "requested chunk: pref_level: " CHKLVL_FORMAT
+     ", max_level: " CHKLVL_FORMAT ", min committed size: " SIZE_FORMAT ".",
+     preferred_level, max_level, min_committed_words);
+
+  // First, optimistically look for a chunk which is already committed far enough to hold min_word_size.
+
+  // 1) Search best or smaller committed chunks (first attempt):
+  //    Start at the preferred chunk size and work your way down (level up).
+  //    But for now, only consider chunks larger than a certain threshold -
+  //    this is to prevent large loaders (eg boot) from unnecessarily gobbling up
+  //    all the tiny splinter chunks lambdas leave around.
+  Metachunk* c = NULL;
+  c = _chunks.search_chunk_ascending(preferred_level, MIN2((chunklevel_t)(preferred_level + 2), max_level), min_committed_words);
+
+  // 2) Search larger committed chunks:
+  //    If that did not yield anything, look at larger chunks, which may be committed. We would have to split
+  //    them first, of course.
+  if (c == NULL) {
+    c = _chunks.search_chunk_descending(preferred_level, min_committed_words);
+  }
+
+  // 3) Search best or smaller committed chunks (second attempt):
+  //    Repeat (1) but now consider even the tiniest chunks as long as they are large enough to hold the
+  //    committed min size.
+  if (c == NULL) {
+    c = _chunks.search_chunk_ascending(preferred_level, max_level, min_committed_words);
+  }
+
+  // if we did not get anything yet, there are no free chunks commmitted enough. Repeat search but look for uncommitted chunks too:
+
+  // 4) Search best or smaller chunks, can be uncommitted:
+  if (c == NULL) {
+    c = _chunks.search_chunk_ascending(preferred_level, max_level, 0);
+  }
+
+  // 5) Search a larger uncommitted chunk:
+  if (c == NULL) {
+    c = _chunks.search_chunk_descending(preferred_level, 0);
+  }
+
+  if (c != NULL) {
+    UL(trace, "taken from freelist.");
+  }
+
+  // Failing all that, allocate a new root chunk from the connected virtual space.
+  // This may fail if the underlying vslist cannot be expanded (e.g. compressed class space)
+  if (c == NULL) {
+    c = _vslist->allocate_root_chunk();
+    if (c == NULL) {
+      UL(info, "failed to get new root chunk.");
+    } else {
+      assert(c->level() == chunklevel::ROOT_CHUNK_LEVEL, "root chunk expected");
+      UL(debug, "allocated new root chunk.");
+    }
+  }
+
+  if (c == NULL) {
+    // If we end up here, we found no match in the freelists and were unable to get a new
+    // root chunk (so we used up all address space, e.g. out of CompressedClassSpace).
+    UL2(info, "failed to get chunk (preferred level: " CHKLVL_FORMAT
+       ", max level " CHKLVL_FORMAT ".", preferred_level, max_level);
+    c = NULL;
+  }
+
+  if (c != NULL) {
+
+    // Now we have a chunk.
+    //  It may be larger than what the caller wanted, so we may want to split it. This should
+    //  always work.
+    if (c->level() < preferred_level) {
+      split_chunk_and_add_splinters(c, preferred_level);
+      assert(c->level() == preferred_level, "split failed?");
+    }
+
+    // Attempt to commit the chunk (depending on settings, we either fully commit it or just
+    //  commit enough to get the caller going). That may fail if we hit a commit limit. In
+    //  that case put the chunk back to the freelist (re-merging it with its neighbors if we
+    //  did split it) and return NULL.
+    const size_t to_commit = Settings::new_chunks_are_fully_committed() ? c->word_size() : min_committed_words;
+    if (c->committed_words() < to_commit) {
+      if (c->ensure_committed_locked(to_commit) == false) {
+        UL2(info, "failed to commit " SIZE_FORMAT " words on chunk " METACHUNK_FORMAT ".",
+            to_commit,  METACHUNK_FORMAT_ARGS(c));
+        c->set_in_use(); // gets asserted in return_chunk().
+        return_chunk_locked(c);
+        c = NULL;
+      }
+    }
+
+    if (c != NULL) {
+
+      // Still here? We have now a good chunk, all is well.
+      assert(c->committed_words() >= min_committed_words, "Sanity");
+
+      // Any chunk returned from ChunkManager shall be marked as in use.
+      c->set_in_use();
+
+      UL2(debug, "handing out chunk " METACHUNK_FORMAT ".", METACHUNK_FORMAT_ARGS(c));
+
+      InternalStats::inc_num_chunks_taken_from_freelist();
+
+      SOMETIMES(c->vsnode()->verify_locked();)
+
+    }
+
+  }
+
+  DEBUG_ONLY(verify_locked();)
+
+  return c;
+
+}
+
+// Return a single chunk to the ChunkManager and adjust accounting. May merge chunk
+//  with neighbors.
+// As a side effect this removes the chunk from whatever list it has been in previously.
+// Happens after a Classloader was unloaded and releases its metaspace chunks.
+// !! Note: this may invalidate the chunk. Do not access the chunk after
+//    this function returns !!
+void ChunkManager::return_chunk(Metachunk* c) {
+  MutexLocker fcl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
+  return_chunk_locked(c);
+}
+
+// See return_chunk().
+void ChunkManager::return_chunk_locked(Metachunk* c) {
+
+  assert_lock_strong(MetaspaceExpand_lock);
+
+  UL2(debug, ": returning chunk " METACHUNK_FORMAT ".", METACHUNK_FORMAT_ARGS(c));
+
+  DEBUG_ONLY(c->verify();)
+
+  assert(contains_chunk(c) == false, "A chunk to be added to the freelist must not be in the freelist already.");
+
+  assert(c->is_in_use(), "Unexpected chunk state");
+  assert(!c->in_list(), "Remove from list first");
+  c->set_free();
+  c->reset_used_words();
+
+  const chunklevel_t orig_lvl = c->level();
+
+  Metachunk* merged = NULL;
+  if (!c->is_root_chunk()) {
+    // Only attempt merging if we are not of the lowest level already.
+    merged = c->vsnode()->merge(c, &_chunks);
+  }
+
+  if (merged != NULL) {
+
+    InternalStats::inc_num_chunk_merges();
+
+    DEBUG_ONLY(merged->verify());
+
+    // We did merge our chunk into a different chunk.
+
+    // We did merge chunks and now have a bigger chunk.
+    assert(merged->level() < orig_lvl, "Sanity");
+
+    UL2(debug, "merged into chunk " METACHUNK_FORMAT ".", METACHUNK_FORMAT_ARGS(merged));
+
+    c = merged;
+
+  }
+
+  if (Settings::uncommit_free_chunks() &&
+      c->word_size() >= Settings::commit_granule_words())
+  {
+    UL2(debug, "uncommitting free chunk " METACHUNK_FORMAT ".", METACHUNK_FORMAT_ARGS(c));
+    c->uncommit_locked();
+  }
+
+  return_chunk_simple_locked(c);
+
+  DEBUG_ONLY(verify_locked();)
+  SOMETIMES(c->vsnode()->verify_locked();)
+
+  InternalStats::inc_num_chunks_returned_to_freelist();
+
+}
+
+// Given a chunk c, whose state must be "in-use" and must not be a root chunk, attempt to
+// enlarge it in place by claiming its trailing buddy.
+//
+// This will only work if c is the leader of the buddy pair and the trailing buddy is free.
+//
+// If successful, the follower chunk will be removed from the freelists, the leader chunk c will
+// double in size (level decreased by one).
+//
+// On success, true is returned, false otherwise.
+bool ChunkManager::attempt_enlarge_chunk(Metachunk* c) {
+  MutexLocker fcl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
+  return c->vsnode()->attempt_enlarge_chunk(c, &_chunks);
+}
+
+static void print_word_size_delta(outputStream* st, size_t word_size_1, size_t word_size_2) {
+  if (word_size_1 == word_size_2) {
+    print_scaled_words(st, word_size_1);
+    st->print (" (no change)");
+  } else {
+    print_scaled_words(st, word_size_1);
+    st->print("->");
+    print_scaled_words(st, word_size_2);
+    st->print(" (");
+    if (word_size_2 <= word_size_1) {
+      st->print("-");
+      print_scaled_words(st, word_size_1 - word_size_2);
+    } else {
+      st->print("+");
+      print_scaled_words(st, word_size_2 - word_size_1);
+    }
+    st->print(")");
+  }
+}
+
+void ChunkManager::purge() {
+
+  MutexLocker fcl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
+
+  UL(info, ": reclaiming memory...");
+
+  const size_t reserved_before = _vslist->reserved_words();
+  const size_t committed_before = _vslist->committed_words();
+  int num_nodes_purged = 0;
+
+  // 1) purge virtual space list
+  num_nodes_purged = _vslist->purge(&_chunks);
+  InternalStats::inc_num_purges();
+
+  // 2) uncommit free chunks
+  if (Settings::uncommit_free_chunks()) {
+    const chunklevel_t max_level =
+        chunklevel::level_fitting_word_size(Settings::commit_granule_words());
+    for (chunklevel_t l = chunklevel::LOWEST_CHUNK_LEVEL;
+         l <= max_level;
+         l++)
+    {
+      // Since we uncommit all chunks at this level, we do not break the "committed chunks are
+      //  at the front of the list" condition.
+      for (Metachunk* c = _chunks.first_at_level(l); c != NULL; c = c->next()) {
+        c->uncommit_locked();
+      }
+    }
+  }
+
+  const size_t reserved_after = _vslist->reserved_words();
+  const size_t committed_after = _vslist->committed_words();
+
+  // Print a nice report.
+  if (reserved_after == reserved_before && committed_after == committed_before) {
+    UL(info, "nothing reclaimed.");
+  } else {
+    LogTarget(Info, metaspace) lt;
+    if (lt.is_enabled()) {
+      LogStream ls(lt);
+      ls.print_cr(LOGFMT ": finished reclaiming memory: ", LOGFMT_ARGS);
+
+      ls.print("reserved: ");
+      print_word_size_delta(&ls, reserved_before, reserved_after);
+      ls.cr();
+
+      ls.print("committed: ");
+      print_word_size_delta(&ls, committed_before, committed_after);
+      ls.cr();
+
+      ls.print_cr("full nodes purged: %d", num_nodes_purged);
+    }
+  }
+
+  DEBUG_ONLY(_vslist->verify_locked());
+  DEBUG_ONLY(verify_locked());
+
+}
+
+// Convenience methods to return the global class-space chunkmanager
+//  and non-class chunkmanager, respectively.
+ChunkManager* ChunkManager::chunkmanager_class() {
+  return MetaspaceContext::context_class() == NULL ? NULL : MetaspaceContext::context_class()->cm();
+}
+
+ChunkManager* ChunkManager::chunkmanager_nonclass() {
+  return MetaspaceContext::context_nonclass() == NULL ? NULL : MetaspaceContext::context_nonclass()->cm();
+}
+
+// Update statistics.
+void ChunkManager::add_to_statistics(ChunkManagerStats* out) const {
+
+  MutexLocker fcl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
+
+  for (chunklevel_t l = chunklevel::ROOT_CHUNK_LEVEL; l <= chunklevel::HIGHEST_CHUNK_LEVEL; l++) {
+    out->_num_chunks[l] += _chunks.num_chunks_at_level(l);
+    out->_committed_word_size[l] += _chunks.committed_word_size_at_level(l);
+  }
+
+  DEBUG_ONLY(out->verify();)
+
+}
+
+#ifdef ASSERT
+
+void ChunkManager::verify() const {
+  MutexLocker fcl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
+  verify_locked();
+}
+
+void ChunkManager::verify_locked() const {
+  assert_lock_strong(MetaspaceExpand_lock);
+  assert(_vslist != NULL, "No vslist");
+  _chunks.verify();
+}
+
+bool ChunkManager::contains_chunk(Metachunk* c) const {
+  return _chunks.contains(c);
+}
+
+#endif // ASSERT
+
+void ChunkManager::print_on(outputStream* st) const {
+  MutexLocker fcl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
+  print_on_locked(st);
+}
+
+void ChunkManager::print_on_locked(outputStream* st) const {
+  assert_lock_strong(MetaspaceExpand_lock);
+  st->print_cr("cm %s: %d chunks, total word size: " SIZE_FORMAT ", committed word size: " SIZE_FORMAT, _name,
+               total_num_chunks(), total_word_size(), _chunks.committed_word_size());
+  _chunks.print_on(st);
+}
+
+} // namespace metaspace
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msChunkManager.hpp	2020-09-04 13:57:44.869314208 +0200
@@ -0,0 +1,188 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#ifndef SHARE_MEMORY_METASPACE_MSCHUNKMANAGER_HPP
+#define SHARE_MEMORY_METASPACE_MSCHUNKMANAGER_HPP
+
+#include "memory/allocation.hpp"
+#include "memory/metaspace/msChunklevel.hpp"
+#include "memory/metaspace/msCounter.hpp"
+#include "memory/metaspace/msFreeChunkList.hpp"
+#include "memory/metaspace/msMetachunk.hpp"
+
+namespace metaspace {
+
+class VirtualSpaceList;
+struct ChunkManagerStats;
+
+// ChunkManager has a somewhat central role.
+
+// Arenas request chunks from it and, on death, return chunks back to it.
+//  It keeps freelists for chunks, one per chunk level, sorted by chunk
+//  commit state.
+//  To feed the freelists, it allocates root chunks from the associated
+//  VirtualSpace below it.
+//
+// ChunkManager directs splitting chunks, if a chunk request cannot be
+//  fulfilled directly. It also takes care of merging when chunks are
+//  returned to it, before they are added to the freelist.
+//
+// The freelists are double linked double headed; fully committed chunks
+//  are added to the front, others to the back.
+//
+// Level
+//          +--------------------+   +--------------------+
+//  0  +----|  free root chunk   |---|  free root chunk   |---...
+//     |    +--------------------+   +--------------------+
+//     |
+//     |    +----------+   +----------+
+//  1  +----|          |---|          |---...
+//     |    +----------+   +----------+
+//     |
+//  .
+//  .
+//  .
+//
+//     |    +-+   +-+
+//  12 +----| |---| |---...
+//          +-+   +-+
+
+class ChunkManager : public CHeapObj<mtMetaspace> {
+
+  // A chunk manager is connected to a virtual space list which is used
+  // to allocate new root chunks when no free chunks are found.
+  VirtualSpaceList* const _vslist;
+
+  // Name
+  const char* const _name;
+
+  // Freelists
+  FreeChunkListVector _chunks;
+
+  // Returns true if this manager contains the given chunk. Slow (walks free lists) and
+  // only needed for verifications.
+  DEBUG_ONLY(bool contains_chunk(Metachunk* c) const;)
+
+  // Given a chunk, split it into a target chunk of a smaller size (target level)
+  //  at least one, possible more splinter chunks. Splinter chunks are added to the
+  //  freelist.
+  // The original chunk must be outside of the freelist and its state must be free.
+  // The resulting target chunk will be located at the same address as the original
+  //  chunk, but it will of course be smaller (of a higher level).
+  // The committed areas within the original chunk carry over to the resulting
+  //  chunks.
+  void split_chunk_and_add_splinters(Metachunk* c, chunklevel_t target_level);
+
+  // See get_chunk(s,s,s)
+  Metachunk* get_chunk_locked(size_t preferred_word_size, size_t min_word_size, size_t min_committed_words);
+
+  // Uncommit all chunks equal or below the given level.
+  void uncommit_free_chunks(chunklevel_t max_level);
+
+  // Return a single chunk to the freelist without doing any merging, and adjust accounting.
+  void return_chunk_simple_locked(Metachunk* c);
+
+  // See return_chunk().
+  void return_chunk_locked(Metachunk* c);
+
+public:
+
+  // Creates a chunk manager with a given name (which is for debug purposes only)
+  // and an associated space list which will be used to request new chunks from
+  // (see get_chunk())
+  ChunkManager(const char* name, VirtualSpaceList* space_list);
+
+  // On success, returns a chunk of level of <preferred_level>, but at most <max_level>.
+  //  The first first <min_committed_words> of the chunk are guaranteed to be committed.
+  // On error, will return NULL.
+  //
+  // This function may fail for two reasons:
+  // - Either we are unable to reserve space for a new chunk (if the underlying VirtualSpaceList
+  //   is non-expandable but needs expanding - aka out of compressed class space).
+  // - Or, if the necessary space cannot be committed because we hit a commit limit.
+  //   This may be either the GC threshold or MaxMetaspaceSize.
+  Metachunk* get_chunk(chunklevel_t preferred_level, chunklevel_t max_level, size_t min_committed_words);
+
+  // Convenience function - get a chunk of a given level, uncommitted.
+  Metachunk* get_chunk(chunklevel_t lvl) { return get_chunk(lvl, lvl, 0); }
+
+  // Return a single chunk to the ChunkManager and adjust accounting. May merge chunk
+  //  with neighbors.
+  // Happens after a Classloader was unloaded and releases its metaspace chunks.
+  // !! Notes:
+  //    1) After this method returns, c may not be valid anymore. ** Do not access c after this function returns **.
+  //    2) This function will not remove c from its current chunk list. This has to be done by the caller prior to
+  //       calling this method.
+  void return_chunk(Metachunk* c);
+
+  // Given a chunk c, which must be "in use" and must not be a root chunk, attempt to
+  // enlarge it in place by claiming its trailing buddy.
+  //
+  // This will only work if c is the leader of the buddy pair and the trailing buddy is free.
+  //
+  // If successful, the follower chunk will be removed from the freelists, the leader chunk c will
+  // double in size (level decreased by one).
+  //
+  // On success, true is returned, false otherwise.
+  bool attempt_enlarge_chunk(Metachunk* c);
+
+  // Attempt to reclaim free areas in metaspace wholesale:
+  // - first, attempt to purge nodes of the backing virtual space list: nodes which are completely
+  //   unused get unmapped and deleted completely.
+  // - second, it will uncommit free chunks depending on commit granule size.
+  void purge();
+
+  // Run verifications. slow=true: verify chunk-internal integrity too.
+  DEBUG_ONLY(void verify() const;)
+  DEBUG_ONLY(void verify_locked() const;)
+
+  // Returns the name of this chunk manager.
+  const char* name() const                  { return _name; }
+
+  // Returns total number of chunks
+  int total_num_chunks() const              { return _chunks.num_chunks(); }
+
+  // Returns number of words in all free chunks (regardless of commit state).
+  size_t total_word_size() const            { return _chunks.word_size(); }
+
+  // Returns number of committed words in all free chunks.
+  size_t total_committed_word_size() const  { return _chunks.committed_word_size(); }
+
+  // Update statistics.
+  void add_to_statistics(ChunkManagerStats* out) const;
+
+  void print_on(outputStream* st) const;
+  void print_on_locked(outputStream* st) const;
+
+  // Convenience methods to return the global class-space chunkmanager
+  //  and non-class chunkmanager, respectively.
+  static ChunkManager* chunkmanager_class();
+  static ChunkManager* chunkmanager_nonclass();
+
+};
+
+} // namespace metaspace
+
+#endif // SHARE_MEMORY_METASPACE_MSCHUNKMANAGER_HPP
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msChunklevel.cpp	2020-09-04 13:57:45.417317876 +0200
@@ -0,0 +1,68 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+#include "memory/metaspace/msChunklevel.hpp"
+#include "utilities/debug.hpp"
+#include "utilities/globalDefinitions.hpp"
+#include "utilities/ostream.hpp"
+#include "utilities/powerOfTwo.hpp"
+
+namespace metaspace {
+
+using namespace chunklevel;
+
+chunklevel_t chunklevel::level_fitting_word_size(size_t word_size) {
+
+  assert(MAX_CHUNK_WORD_SIZE >= word_size,
+         SIZE_FORMAT " - too large allocation size.", word_size * BytesPerWord);
+
+  if (word_size <= MIN_CHUNK_WORD_SIZE) {
+    return HIGHEST_CHUNK_LEVEL;
+  }
+
+  const size_t v_pow2 = round_up_power_of_2(word_size);
+  const chunklevel_t lvl =  (chunklevel_t)(exact_log2(MAX_CHUNK_WORD_SIZE) - exact_log2(v_pow2));
+
+  return lvl;
+
+}
+
+void chunklevel::print_chunk_size(outputStream* st, chunklevel_t lvl) {
+  if (chunklevel::is_valid_level(lvl)) {
+    const size_t s = chunklevel::word_size_for_level(lvl) * BytesPerWord;
+    if (s < 1 * M) {
+      st->print("%3uk", (unsigned)(s / K));
+    } else {
+      st->print("%3um", (unsigned)(s / M));
+    }
+  } else {
+    st->print("?-?");
+  }
+
+}
+
+} // namespace metaspace
+
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msChunklevel.hpp	2020-09-04 13:57:45.965321546 +0200
@@ -0,0 +1,130 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#ifndef SHARE_MEMORY_METASPACE_MSCHUNKLEVEL_HPP
+#define SHARE_MEMORY_METASPACE_MSCHUNKLEVEL_HPP
+
+#include "utilities/globalDefinitions.hpp"
+
+// Constants for the chunk levels and some utility functions.
+
+class outputStream;
+
+namespace metaspace {
+
+// Chunks are managed by a binary buddy allocator.
+
+// Chunk sizes range from 1K to 4MB (64bit).
+//
+
+// Each chunk has a level; the level corresponds to its position in the tree
+// and describes its size.
+//
+// The largest chunks are called root chunks, of 4MB in size, and have level 0.
+// From there on it goes:
+//
+// size    level
+// 4MB     0
+// 2MB     1
+// 1MB     2
+// 512K    3
+// 256K    4
+// 128K    5
+// 64K     6
+// 32K     7
+// 16K     8
+// 8K      9
+// 4K      10
+// 2K      11
+// 1K      12
+
+// Metachunk level (must be signed)
+typedef signed char chunklevel_t;
+
+#define CHKLVL_FORMAT "lv%.2d"
+
+namespace chunklevel {
+
+static const size_t   MAX_CHUNK_BYTE_SIZE    = 4 * M;
+static const int      NUM_CHUNK_LEVELS       = 13;
+static const size_t   MIN_CHUNK_BYTE_SIZE    = (MAX_CHUNK_BYTE_SIZE >> ((size_t)NUM_CHUNK_LEVELS - 1));
+
+static const size_t   MIN_CHUNK_WORD_SIZE    = MIN_CHUNK_BYTE_SIZE / sizeof(MetaWord);
+static const size_t   MAX_CHUNK_WORD_SIZE    = MAX_CHUNK_BYTE_SIZE / sizeof(MetaWord);
+
+static const chunklevel_t ROOT_CHUNK_LEVEL       = 0;
+
+static const chunklevel_t HIGHEST_CHUNK_LEVEL    = NUM_CHUNK_LEVELS - 1;
+static const chunklevel_t LOWEST_CHUNK_LEVEL     = 0;
+
+static const chunklevel_t INVALID_CHUNK_LEVEL    = (chunklevel_t) -1;
+
+inline bool is_valid_level(chunklevel_t level) {
+  return level >= LOWEST_CHUNK_LEVEL &&
+         level <= HIGHEST_CHUNK_LEVEL;
+}
+
+inline void check_valid_level(chunklevel_t lvl) {
+  assert(is_valid_level(lvl), "invalid level (%d)", (int)lvl);
+}
+
+// Given a level return the chunk size, in words.
+inline size_t word_size_for_level(chunklevel_t level) {
+  return (MAX_CHUNK_BYTE_SIZE >> level) / BytesPerWord;
+}
+
+// Given an arbitrary word size smaller than the highest chunk size,
+// return the highest chunk level able to hold this size.
+// Returns INVALID_CHUNK_LEVEL if no fitting level can be found.
+chunklevel_t level_fitting_word_size(size_t word_size);
+
+// Shorthands to refer to exact sizes
+static const chunklevel_t CHUNK_LEVEL_4M =     ROOT_CHUNK_LEVEL;
+static const chunklevel_t CHUNK_LEVEL_2M =    (ROOT_CHUNK_LEVEL + 1);
+static const chunklevel_t CHUNK_LEVEL_1M =    (ROOT_CHUNK_LEVEL + 2);
+static const chunklevel_t CHUNK_LEVEL_512K =  (ROOT_CHUNK_LEVEL + 3);
+static const chunklevel_t CHUNK_LEVEL_256K =  (ROOT_CHUNK_LEVEL + 4);
+static const chunklevel_t CHUNK_LEVEL_128K =  (ROOT_CHUNK_LEVEL + 5);
+static const chunklevel_t CHUNK_LEVEL_64K =   (ROOT_CHUNK_LEVEL + 6);
+static const chunklevel_t CHUNK_LEVEL_32K =   (ROOT_CHUNK_LEVEL + 7);
+static const chunklevel_t CHUNK_LEVEL_16K =   (ROOT_CHUNK_LEVEL + 8);
+static const chunklevel_t CHUNK_LEVEL_8K =    (ROOT_CHUNK_LEVEL + 9);
+static const chunklevel_t CHUNK_LEVEL_4K =    (ROOT_CHUNK_LEVEL + 10);
+static const chunklevel_t CHUNK_LEVEL_2K =    (ROOT_CHUNK_LEVEL + 11);
+static const chunklevel_t CHUNK_LEVEL_1K =    (ROOT_CHUNK_LEVEL + 12);
+
+STATIC_ASSERT(CHUNK_LEVEL_1K == HIGHEST_CHUNK_LEVEL);
+STATIC_ASSERT(CHUNK_LEVEL_4M == LOWEST_CHUNK_LEVEL);
+STATIC_ASSERT(ROOT_CHUNK_LEVEL == LOWEST_CHUNK_LEVEL);
+
+/////////////////////////////////////////////////////////
+// print helpers
+void print_chunk_size(outputStream* st, chunklevel_t lvl);
+
+} // namespace chunklevel
+
+} // namespace metaspace
+
+#endif // SHARE_MEMORY_METASPACE_MSCHUNKLEVEL_HPP
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msClassLoaderMetaspace.cpp	2020-09-04 13:57:46.557325515 +0200
@@ -0,0 +1,203 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+
+#include "logging/log.hpp"
+#include "memory/metaspace/msArena.hpp"
+#include "memory/metaspace/msArenaGrowthPolicy.hpp"
+#include "memory/metaspace/msChunkManager.hpp"
+#include "memory/metaspace/msInternalStats.hpp"
+#include "memory/metaspace/msRunningCounters.hpp"
+#include "memory/metaspace/msSettings.hpp"
+#include "memory/metaspace/msStatistics.hpp"
+#include "memory/metaspace.hpp"
+#include "memory/metaspaceTracer.hpp"
+#include "runtime/atomic.hpp"
+#include "utilities/debug.hpp"
+
+using metaspace::ChunkManager;
+using metaspace::MetaspaceArena;
+using metaspace::ArenaGrowthPolicy;
+using metaspace::RunningCounters;
+using metaspace::InternalStats;
+
+#define LOGFMT         "CLMS @" PTR_FORMAT " "
+#define LOGFMT_ARGS    p2i(this)
+
+static bool use_class_space(bool is_class) {
+  if (Metaspace::using_class_space() && is_class) {
+    return true;
+  }
+  return false;
+}
+
+static bool use_class_space(Metaspace::MetadataType mdType) {
+  return use_class_space(Metaspace::is_class_space_allocation(mdType));
+}
+
+ClassLoaderMetaspace::ClassLoaderMetaspace(Mutex* lock, Metaspace::MetaspaceType space_type)
+  : _lock(lock)
+  , _space_type(space_type)
+  , _non_class_space_arena(NULL)
+  , _class_space_arena(NULL)
+{
+  ChunkManager* const non_class_cm =
+          ChunkManager::chunkmanager_nonclass();
+
+  // Initialize non-class Arena
+  _non_class_space_arena = new MetaspaceArena(
+      non_class_cm,
+      ArenaGrowthPolicy::policy_for_space_type(space_type, false),
+      lock,
+      RunningCounters::used_nonclass_counter(),
+      "non-class sm");
+
+  // If needed, initialize class arena
+  if (Metaspace::using_class_space()) {
+    ChunkManager* const class_cm =
+            ChunkManager::chunkmanager_class();
+    _class_space_arena = new MetaspaceArena(
+        class_cm,
+        ArenaGrowthPolicy::policy_for_space_type(space_type, true),
+        lock,
+        RunningCounters::used_class_counter(),
+        "class sm");
+  }
+
+  UL2(debug, "born (SpcMgr nonclass: " PTR_FORMAT ", SpcMgr class: " PTR_FORMAT ".",
+      p2i(_non_class_space_arena), p2i(_class_space_arena));
+}
+
+ClassLoaderMetaspace::~ClassLoaderMetaspace() {
+  Metaspace::assert_not_frozen();
+
+  UL(debug, "dies.");
+
+  delete _non_class_space_arena;
+  delete _class_space_arena;
+
+}
+
+// Allocate word_size words from Metaspace.
+MetaWord* ClassLoaderMetaspace::allocate(size_t word_size, Metaspace::MetadataType mdType) {
+  Metaspace::assert_not_frozen();
+  if (use_class_space(mdType)) {
+    return class_space_arena()->allocate(word_size);
+  } else {
+    return non_class_space_arena()->allocate(word_size);
+  }
+}
+
+// Attempt to expand the GC threshold to be good for at least another word_size words
+// and allocate. Returns NULL if failure. Used during Metaspace GC.
+MetaWord* ClassLoaderMetaspace::expand_and_allocate(size_t word_size, Metaspace::MetadataType mdType) {
+  Metaspace::assert_not_frozen();
+  size_t delta_bytes = MetaspaceGC::delta_capacity_until_GC(word_size * BytesPerWord);
+  assert(delta_bytes > 0, "Must be");
+
+  size_t before = 0;
+  size_t after = 0;
+  bool can_retry = true;
+  MetaWord* res;
+  bool incremented;
+
+  // Each thread increments the HWM at most once. Even if the thread fails to increment
+  // the HWM, an allocation is still attempted. This is because another thread must then
+  // have incremented the HWM and therefore the allocation might still succeed.
+  do {
+    incremented = MetaspaceGC::inc_capacity_until_GC(delta_bytes, &after, &before, &can_retry);
+    res = allocate(word_size, mdType);
+  } while (!incremented && res == NULL && can_retry);
+
+  if (incremented) {
+    Metaspace::tracer()->report_gc_threshold(before, after,
+                                  MetaspaceGCThresholdUpdater::ExpandAndAllocate);
+    // Keeping both for now until I am sure the old variant (gc + metaspace) is not needed anymore
+    log_trace(gc, metaspace)("Increase capacity to GC from " SIZE_FORMAT " to " SIZE_FORMAT, before, after);
+    UL2(info, "GC threshold increased: " SIZE_FORMAT "->" SIZE_FORMAT ".", before, after);
+  }
+
+  return res;
+}
+
+// Prematurely returns a metaspace allocation to the _block_freelists
+// because it is not needed anymore.
+void ClassLoaderMetaspace::deallocate(MetaWord* ptr, size_t word_size, bool is_class) {
+
+  Metaspace::assert_not_frozen();
+
+  if (use_class_space(is_class)) {
+    class_space_arena()->deallocate(ptr, word_size);
+  } else {
+    non_class_space_arena()->deallocate(ptr, word_size);
+  }
+
+  DEBUG_ONLY(InternalStats::inc_num_deallocs();)
+
+}
+
+// Update statistics. This walks all in-use chunks.
+void ClassLoaderMetaspace::add_to_statistics(metaspace::ClmsStats* out) const {
+  if (non_class_space_arena() != NULL) {
+    non_class_space_arena()->add_to_statistics(&out->_arena_stats_nonclass);
+  }
+  if (class_space_arena() != NULL) {
+    class_space_arena()->add_to_statistics(&out->_arena_stats_class);
+  }
+}
+
+#ifdef ASSERT
+void ClassLoaderMetaspace::verify() const {
+  if (non_class_space_arena() != NULL) {
+    non_class_space_arena()->verify();
+  }
+  if (class_space_arena() != NULL) {
+    class_space_arena()->verify();
+  }
+}
+#endif // ASSERT
+
+// This only exists for JFR and jcmd VM.classloader_stats. We may want to
+//  change this. Capacity as a stat is of questionable use since it may
+//  contain committed and uncommitted areas. For now we do this to maintain
+//  backward compatibility with JFR.
+void ClassLoaderMetaspace::calculate_jfr_stats(size_t* p_used_bytes, size_t* p_capacity_bytes) const {
+  // Implement this using the standard statistics objects.
+  size_t used_c = 0, cap_c = 0, used_nc = 0, cap_nc = 0;
+  if (non_class_space_arena() != NULL) {
+    non_class_space_arena()->usage_numbers(&used_nc, NULL, &cap_nc);
+  }
+  if (class_space_arena() != NULL) {
+    class_space_arena()->usage_numbers(&used_c, NULL, &cap_c);
+  }
+  if (p_used_bytes != NULL) {
+    *p_used_bytes = used_c + used_nc;
+  }
+  if (p_capacity_bytes != NULL) {
+    *p_capacity_bytes = cap_c + cap_nc;
+  }
+}
+
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msCommitLimiter.cpp	2020-09-04 13:57:47.353330855 +0200
@@ -0,0 +1,62 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+
+#include "memory/metaspace/msCommitLimiter.hpp"
+#include "memory/metaspace.hpp"
+#include "utilities/debug.hpp"
+#include "utilities/globalDefinitions.hpp"
+
+namespace metaspace {
+
+// Returns the size, in words, by which we may expand the metaspace committed area without:
+// - _cap == 0: hitting GC threshold or the MaxMetaspaceSize
+// - _cap > 0: hitting cap (this is just for testing purposes)
+size_t CommitLimiter::possible_expansion_words() const {
+
+  if (_cap > 0) { // Testing.
+    assert(_cnt.get() <= _cap, "Beyond limit?");
+    return _cap - _cnt.get();
+  }
+
+  assert(_cnt.get() * BytesPerWord <= MaxMetaspaceSize, "Beyond limit?");
+  const size_t words_left_below_max = MaxMetaspaceSize / BytesPerWord - _cnt.get();
+
+  const size_t words_left_below_gc_threshold = MetaspaceGC::allowed_expansion();
+
+  return MIN2(words_left_below_max, words_left_below_gc_threshold);
+
+}
+
+static CommitLimiter g_global_limiter(0);
+
+// Returns the global metaspace commit counter
+CommitLimiter* CommitLimiter::globalLimiter() {
+  return &g_global_limiter;
+}
+
+} // namespace metaspace
+
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msCommitLimiter.hpp	2020-09-04 13:57:48.117335984 +0200
@@ -0,0 +1,84 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#ifndef SHARE_MEMORY_METASPACE_MSCOMMITLIMITER_HPP
+#define SHARE_MEMORY_METASPACE_MSCOMMITLIMITER_HPP
+
+#include "memory/allocation.hpp"
+#include "memory/metaspace/msCounter.hpp"
+
+namespace metaspace {
+
+// The CommitLimiter encapsulates a limit we may want to impose on how much
+//  memory can be committed. This is a matter of separation of concerns:
+//
+// In metaspace, we have two limits to committing memory: the absolute limit,
+//  MaxMetaspaceSize; and the GC threshold. In both cases an allocation should
+//  fail if it would require committing memory and hit one of these limits.
+//
+// However, the actual Metaspace allocator is a generic one and this
+//  GC- and classloading specific logic should be kept separate. Therefore
+//  it is hidden inside this interface.
+//
+// This allows us to:
+//  - more easily write tests for metaspace, by providing a different implementation
+//    of the commit limiter, thus keeping test logic separate from VM state.
+//  - (potentially) use the metaspace for things other than class metadata,
+//    where different commit rules would apply.
+//
+class CommitLimiter : public CHeapObj<mtMetaspace> {
+
+  // Counts total words committed for metaspace
+  SizeCounter _cnt;
+
+  // Purely for testing purposes: cap, in words.
+  const size_t _cap;
+
+public:
+
+  // Create a commit limiter. This is only useful for testing, with a cap != 0,
+  // since normal code should use the global commit limiter.
+  // If cap != 0 (word size), the cap replaces the internal logic of limiting.
+  CommitLimiter(size_t cap = 0) : _cnt(), _cap(cap) {}
+
+  // Returns the size, in words, by which we may expand the metaspace committed area without:
+  // - _cap == 0: hitting GC threshold or the MaxMetaspaceSize
+  // - _cap > 0: hitting cap (this is just for testing purposes)
+  size_t possible_expansion_words() const;
+
+  void increase_committed(size_t word_size)   { _cnt.increment_by(word_size); }
+  void decrease_committed(size_t word_size)   { _cnt.decrement_by(word_size); }
+
+  size_t committed_words() const              { return _cnt.get(); }
+  size_t cap() const                          { return _cap; }
+
+  // Returns the global metaspace commit counter
+  static CommitLimiter* globalLimiter();
+
+};
+
+} // namespace metaspace
+
+#endif // SHARE_MEMORY_METASPACE_MSCOMMITLIMITER_HPP
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msCommitMask.cpp	2020-09-04 13:57:48.837340821 +0200
@@ -0,0 +1,77 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+
+#include "memory/metaspace/msCommitMask.hpp"
+#include "memory/metaspace/msCommon.hpp"
+#include "memory/metaspace/msSettings.hpp"
+#include "runtime/stubRoutines.hpp"
+
+#include "utilities/align.hpp"
+#include "utilities/debug.hpp"
+
+namespace metaspace {
+
+CommitMask::CommitMask(const MetaWord* start, size_t word_size)
+  : CHeapBitMap(mask_size(word_size, Settings::commit_granule_words()))
+  , _base(start)
+  , _word_size(word_size)
+  , _words_per_bit(Settings::commit_granule_words())
+{
+  assert(_word_size > 0 && _words_per_bit > 0 &&
+         is_aligned(_word_size, _words_per_bit), "Sanity");
+}
+
+#ifdef ASSERT
+
+void CommitMask::verify() const {
+
+  // Walk the whole commit mask.
+  // For each 1 bit, check if the associated granule is accessible.
+  // For each 0 bit, check if the associated granule is not accessible. Slow mode only.
+
+  assert(_base != NULL && _word_size > 0 && _words_per_bit > 0, "Sanity");
+  assert_is_aligned(_base, _words_per_bit * BytesPerWord);
+  assert_is_aligned(_word_size, _words_per_bit);
+
+}
+
+#endif // ASSERT
+
+void CommitMask::print_on(outputStream* st) const {
+
+  st->print("commit mask, base " PTR_FORMAT ":", p2i(base()));
+
+  for (idx_t i = 0; i < size(); i++) {
+    st->print("%c", at(i) ? 'X' : '-');
+  }
+
+  st->cr();
+
+}
+
+} // namespace metaspace
+
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msCommitMask.hpp	2020-09-04 13:57:49.433344829 +0200
@@ -0,0 +1,178 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#ifndef SHARE_MEMORY_METASPACE_MSCOMMITMASK_HPP
+#define SHARE_MEMORY_METASPACE_MSCOMMITMASK_HPP
+
+#include "utilities/debug.hpp"
+#include "utilities/bitMap.hpp"
+#include "utilities/globalDefinitions.hpp"
+
+class outputStream;
+
+namespace metaspace {
+
+// The CommitMask is a bitmask used to store the commit state of commit granules.
+// It keeps one bit per granule; 1 means committed, 0 means uncommitted.
+
+class CommitMask : public CHeapBitMap {
+
+  const MetaWord* const _base;
+  const size_t _word_size;
+  const size_t _words_per_bit;
+
+  // Given an offset, in words, into the area, return the number of the bit
+  // covering it.
+  static idx_t bitno_for_word_offset(size_t offset, size_t words_per_bit) {
+    return offset / words_per_bit;
+  }
+
+  idx_t bitno_for_address(const MetaWord* p) const {
+    // Note: we allow one-beyond since this is a typical need.
+    assert(p >= _base && p <= _base + _word_size, "Invalid address");
+    const size_t off = p - _base;
+    return bitno_for_word_offset(off, _words_per_bit);
+  }
+
+  static idx_t mask_size(size_t word_size, size_t words_per_bit) {
+    return bitno_for_word_offset(word_size, words_per_bit);
+  }
+
+#ifdef ASSERT
+  // Given a pointer, check if it points into the range this bitmap covers.
+  bool is_pointer_valid(const MetaWord* p) const {
+    return p >= _base && p < _base + _word_size;
+  }
+
+  // Given a pointer, check if it points into the range this bitmap covers.
+  void check_pointer(const MetaWord* p) const {
+    assert(is_pointer_valid(p),
+           "Pointer " PTR_FORMAT " not in range of this bitmap [" PTR_FORMAT ", " PTR_FORMAT ").",
+           p2i(p), p2i(_base), p2i(_base + _word_size));
+  }
+  // Given a pointer, check if it points into the range this bitmap covers,
+  // and if it is aligned to commit granule border.
+  void check_pointer_aligned(const MetaWord* p) const {
+    check_pointer(p);
+    assert(is_aligned(p, _words_per_bit * BytesPerWord),
+           "Pointer " PTR_FORMAT " should be aligned to commit granule size " SIZE_FORMAT ".",
+           p2i(p), _words_per_bit * BytesPerWord);
+  }
+  // Given a range, check if it points into the range this bitmap covers,
+  // and if its borders are aligned to commit granule border.
+  void check_range(const MetaWord* start, size_t word_size) const {
+    check_pointer_aligned(start);
+    assert(is_aligned(word_size, _words_per_bit),
+           "Range " SIZE_FORMAT " should be aligned to commit granule size " SIZE_FORMAT ".",
+           word_size, _words_per_bit);
+    check_pointer(start + word_size - 1);
+  }
+#endif
+
+  // Marks a single commit granule as committed (value == true)
+  // or uncomitted (value == false) and returns
+  // its prior state.
+  bool mark_granule(idx_t bitno, bool value) {
+    bool b = at(bitno);
+    at_put(bitno, value);
+    return b;
+  }
+
+public:
+
+  // Create a commit mask covering a range [start, start + word_size).
+  CommitMask(const MetaWord* start, size_t word_size);
+
+  const MetaWord* base() const  { return _base; }
+  size_t word_size() const      { return _word_size; }
+  const MetaWord* end() const   { return _base + word_size(); }
+
+  // Given an address, returns true if the address is committed, false if not.
+  bool is_committed_address(const MetaWord* p) const {
+    DEBUG_ONLY(check_pointer(p));
+    const idx_t bitno = bitno_for_address(p);
+    return at(bitno);
+  }
+
+  // Given an address range, return size, in number of words, of committed area within that range.
+  size_t get_committed_size_in_range(const MetaWord* start, size_t word_size) const {
+    DEBUG_ONLY(check_range(start, word_size));
+    assert(word_size > 0, "zero range");
+    const idx_t b1 = bitno_for_address(start);
+    const idx_t b2 = bitno_for_address(start + word_size);
+    const idx_t num_bits = count_one_bits(b1, b2);
+    return num_bits * _words_per_bit;
+  }
+
+  // Return total committed size, in number of words.
+  size_t get_committed_size() const {
+    return count_one_bits() * _words_per_bit;
+  }
+
+  // Mark a whole address range [start, end) as committed.
+  // Return the number of words which had already been committed before this operation.
+  size_t mark_range_as_committed(const MetaWord* start, size_t word_size) {
+    DEBUG_ONLY(check_range(start, word_size));
+    assert(word_size > 0, "zero range");
+    const idx_t b1 = bitno_for_address(start);
+    const idx_t b2 = bitno_for_address(start + word_size);
+    if (b1 == b2) { // Simple case, 1 granule
+      bool was_committed = mark_granule(b1, true);
+      return was_committed ? _words_per_bit : 0;
+    }
+    const idx_t one_bits_in_range_before = count_one_bits(b1, b2);
+    set_range(b1, b2);
+    return one_bits_in_range_before * _words_per_bit;
+  }
+
+  // Mark a whole address range [start, end) as uncommitted.
+  // Return the number of words which had already been uncommitted before this operation.
+  size_t mark_range_as_uncommitted(const MetaWord* start, size_t word_size) {
+    DEBUG_ONLY(check_range(start, word_size));
+    assert(word_size > 0, "zero range");
+    const idx_t b1 = bitno_for_address(start);
+    const idx_t b2 = bitno_for_address(start + word_size);
+    if (b1 == b2) { // Simple case, 1 granule
+      bool was_committed = mark_granule(b1, false);
+      return was_committed ? 0 : _words_per_bit;
+    }
+    const idx_t zero_bits_in_range_before =
+        (b2 - b1) - count_one_bits(b1, b2);
+    clear_range(b1, b2);
+    return zero_bits_in_range_before * _words_per_bit;
+  }
+
+  //// Debug stuff ////
+
+  // Verify internals.
+  DEBUG_ONLY(void verify() const;)
+
+  void print_on(outputStream* st) const;
+
+};
+
+} // namespace metaspace
+
+#endif // SHARE_MEMORY_METASPACE_MSCOMMITMASK_HPP
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msCommon.cpp	2020-09-04 13:57:50.005348677 +0200
@@ -0,0 +1,203 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+
+#include "memory/metaspace/msCommon.hpp"
+#include "memory/metaspace/msAllocationGuard.hpp"
+#include "memory/metaspace/msFreeBlocks.hpp"
+#include "memory/metaspace/msSettings.hpp"
+#include "memory/metaspace/msVirtualSpaceNode.hpp"
+#include "utilities/align.hpp"
+#include "utilities/debug.hpp"
+#include "utilities/globalDefinitions.hpp"
+#include "utilities/ostream.hpp"
+
+namespace metaspace {
+
+// Print a size, in words, scaled.
+void print_scaled_words(outputStream* st, size_t word_size, size_t scale, int width) {
+  print_human_readable_size(st, word_size * sizeof(MetaWord), scale, width);
+}
+
+// Convenience helper: prints a size value and a percentage.
+void print_scaled_words_and_percentage(outputStream* st, size_t word_size, size_t compare_word_size, size_t scale, int width) {
+  print_scaled_words(st, word_size, scale, width);
+  st->print(" (");
+  print_percentage(st, compare_word_size, word_size);
+  st->print(")");
+}
+
+static const char* display_unit_for_scale(size_t scale) {
+  const char* s = NULL;
+  switch(scale) {
+    case 1: s = "bytes"; break;
+    case BytesPerWord: s = "words"; break;
+    case K: s = "KB"; break;
+    case M: s = "MB"; break;
+    case G: s = "GB"; break;
+    default:
+      ShouldNotReachHere();
+  }
+  return s;
+}
+
+// Print a human readable size.
+// byte_size: size, in bytes, to be printed.
+// scale: one of 1 (byte-wise printing), sizeof(word) (word-size printing), K, M, G (scaled by KB, MB, GB respectively,
+//         or 0, which means the best scale is choosen dynamically.
+// width: printing width.
+void print_human_readable_size(outputStream* st, size_t byte_size, size_t scale, int width)  {
+  if (scale == 0) {
+    // Dynamic mode. Choose scale for this value.
+    if (byte_size == 0) {
+      // Zero values are printed as bytes.
+      scale = 1;
+    } else {
+      if (byte_size >= G) {
+        scale = G;
+      } else if (byte_size >= M) {
+        scale = M;
+      } else if (byte_size >= K) {
+        scale = K;
+      } else {
+        scale = 1;
+      }
+    }
+    return print_human_readable_size(st, byte_size, scale, width);
+  }
+
+#ifdef ASSERT
+  assert(scale == 1 || scale == BytesPerWord ||
+         scale == K || scale == M || scale == G, "Invalid scale");
+  // Special case: printing wordsize should only be done with word-sized values
+  if (scale == BytesPerWord) {
+    assert(byte_size % BytesPerWord == 0, "not word sized");
+  }
+#endif
+
+  if (width == -1) {
+    if (scale == 1) {
+      st->print(SIZE_FORMAT " bytes", byte_size);
+    } else if (scale == BytesPerWord) {
+      st->print(SIZE_FORMAT " words", byte_size / BytesPerWord);
+    } else {
+      const char* display_unit = display_unit_for_scale(scale);
+      float display_value = (float) byte_size / scale;
+      // Prevent very small but non-null values showing up as 0.00.
+      if (byte_size > 0 && display_value < 0.01f) {
+        st->print("<0.01 %s", display_unit);
+      } else {
+        st->print("%.2f %s", display_value, display_unit);
+      }
+    }
+  } else {
+    if (scale == 1) {
+      st->print("%*" PRIuPTR " bytes", width, byte_size);
+    } else if (scale == BytesPerWord) {
+      st->print("%*" PRIuPTR " words", width, byte_size / BytesPerWord);
+    } else {
+      const char* display_unit = display_unit_for_scale(scale);
+      float display_value = (float) byte_size / scale;
+      // Since we use width to display a number with two trailing digits, increase it a bit.
+      width += 3;
+      // Prevent very small but non-null values showing up as 0.00.
+      if (byte_size > 0 && display_value < 0.01f) {
+        st->print("%*s %s", width, "<0.01", display_unit);
+      } else {
+        st->print("%*.2f %s", width, display_value, display_unit);
+      }
+    }
+  }
+}
+
+// Prints a percentage value. Values smaller than 1% but not 0 are displayed as "<1%", values
+// larger than 99% but not 100% are displayed as ">100%".
+void print_percentage(outputStream* st, size_t total, size_t part) {
+  if (total == 0) {
+    st->print("  ?%%");
+  } else if (part == 0) {
+    st->print("  0%%");
+  } else if (part == total) {
+    st->print("100%%");
+  } else {
+    // Note: clearly print very-small-but-not-0% and very-large-but-not-100% percentages.
+    float p = ((float)part / total) * 100.0f;
+    if (p < 1.0f) {
+      st->print(" <1%%");
+    } else if (p > 99.0f){
+      st->print(">99%%");
+    } else {
+      st->print("%3.0f%%", p);
+    }
+  }
+}
+
+const char* loaders_plural(uintx num) {
+  return num == 1 ? "loader" : "loaders";
+}
+
+const char* classes_plural(uintx num) {
+  return num == 1 ? "class" : "classes";
+}
+
+void print_number_of_classes(outputStream* out, uintx classes, uintx classes_shared) {
+  out->print(UINTX_FORMAT " %s", classes, classes_plural(classes));
+  if (classes_shared > 0) {
+    out->print(" (" UINTX_FORMAT " shared)", classes_shared);
+  }
+}
+
+// Given a net allocation word size, return the raw word size we actually allocate.
+// Note: externally visible for gtests.
+//static
+size_t get_raw_word_size_for_requested_word_size(size_t word_size) {
+
+  size_t byte_size = word_size * BytesPerWord;
+
+  // Deallocated metablocks are kept in a binlist which limits their minimal
+  //  size to at least the size of a binlist item (2 words).
+  byte_size = MAX2(byte_size, FreeBlocks::MinWordSize * BytesPerWord);
+
+  // Metaspace allocations are aligned to word size.
+  byte_size = align_up(byte_size, AllocationAlignmentByteSize);
+
+  // If we guard allocations, we need additional space for a prefix.
+#ifdef ASSERT
+  if (Settings::use_allocation_guard()) {
+    byte_size += align_up(prefix_size(), AllocationAlignmentByteSize);
+  }
+#endif
+
+  size_t raw_word_size = byte_size / BytesPerWord;
+
+  assert(raw_word_size * BytesPerWord == byte_size, "Sanity");
+
+  return raw_word_size;
+
+}
+
+} // namespace metaspace
+
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msCommon.hpp	2020-09-04 13:57:50.605352717 +0200
@@ -0,0 +1,146 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#ifndef SHARE_MEMORY_METASPACE_MSCOMMON_HPP
+#define SHARE_MEMORY_METASPACE_MSCOMMON_HPP
+
+#include "runtime/globals.hpp"
+#include "utilities/align.hpp"
+#include "utilities/debug.hpp"
+#include "utilities/globalDefinitions.hpp"
+
+class outputStream;
+
+namespace metaspace {
+
+// Metaspace allocation alignment:
+
+// 1) Metaspace allocations have to be aligned such that 64bit values are aligned
+//  correctly.
+//
+// 2) Klass* structures allocated from Metaspace have to be aligned to KlassAlignmentInBytes.
+//
+// At the moment LogKlassAlignmentInBytes is 3, so KlassAlignmentInBytes == 8,
+//  so (1) and (2) can both be fulfilled with an alignment of 8. Should we increase
+//  KlassAlignmentInBytes at any time this will increase the necessary alignment as well. In
+//  that case we may think about introducing a separate alignment just for the class space
+//  since that alignment would only be needed for Klass structures.
+
+static const size_t AllocationAlignmentByteSize = 8;
+STATIC_ASSERT(AllocationAlignmentByteSize == (size_t)KlassAlignmentInBytes);
+
+static const size_t AllocationAlignmentWordSize = AllocationAlignmentByteSize / BytesPerWord;
+
+// Returns the raw word size allocated for a given net allocation
+size_t get_raw_word_size_for_requested_word_size(size_t word_size);
+
+// Utility functions
+
+// Print a size, in words, scaled.
+void print_scaled_words(outputStream* st, size_t word_size, size_t scale = 0, int width = -1);
+
+// Convenience helper: prints a size value and a percentage.
+void print_scaled_words_and_percentage(outputStream* st, size_t word_size, size_t compare_word_size, size_t scale = 0, int width = -1);
+
+// Print a human readable size.
+// byte_size: size, in bytes, to be printed.
+// scale: one of 1 (byte-wise printing), sizeof(word) (word-size printing), K, M, G (scaled by KB, MB, GB respectively,
+//         or 0, which means the best scale is choosen dynamically.
+// width: printing width.
+void print_human_readable_size(outputStream* st, size_t byte_size, size_t scale = 0, int width = -1);
+
+// Prints a percentage value. Values smaller than 1% but not 0 are displayed as "<1%", values
+// larger than 99% but not 100% are displayed as ">100%".
+void print_percentage(outputStream* st, size_t total, size_t part);
+
+#ifdef ASSERT
+#define assert_is_aligned(value, alignment)                  \
+  assert(is_aligned((value), (alignment)),                   \
+         SIZE_FORMAT_HEX " is not aligned to "               \
+         SIZE_FORMAT_HEX, (size_t)(uintptr_t)value, (size_t)(alignment))
+#else
+#define assert_is_aligned(value, alignment)
+#endif
+
+// Pretty printing helpers
+const char* classes_plural(uintx num);
+const char* loaders_plural(uintx num);
+void print_number_of_classes(outputStream* out, uintx classes, uintx classes_shared);
+
+// Since Metaspace verifications are expensive, we want to do them at a reduced rate,
+// but not completely avoiding them.
+// For that we introduce the macros SOMETIMES() and ASSERT_SOMETIMES() which will
+// execute code or assert at intervals controlled via VerifyMetaspaceInterval.
+#ifdef ASSERT
+
+#define EVERY_NTH(n)          \
+{ static int counter_ = 0;    \
+  if (n > 0) {                \
+    counter_++;              \
+    if (counter_ > n) {       \
+      counter_ = 0;           \
+
+#define END_EVERY_NTH         } } }
+
+#define SOMETIMES(code) \
+    EVERY_NTH(VerifyMetaspaceInterval) \
+    { code } \
+    END_EVERY_NTH
+
+#define ASSERT_SOMETIMES(condition, ...) \
+    EVERY_NTH(VerifyMetaspaceInterval) \
+    assert( (condition), __VA_ARGS__); \
+    END_EVERY_NTH
+
+#else
+
+#define SOMETIMES(code)
+#define ASSERT_SOMETIMES(condition, ...)
+
+#endif // ASSERT
+
+///////// Logging //////////////
+
+// What we log at which levels:
+
+// "info" : metaspace failed allocation, commit failure, reserve failure, metaspace oom, metaspace gc threshold changed, Arena created, destroyed, metaspace purged
+
+// "debug" : "info" + vslist extended, memory committed/uncommitted, chunk created/split/merged/enlarged, chunk returned
+
+// "trace" : "debug" + every single allocation and deallocation, internals
+
+#define HAVE_UL
+
+#ifdef HAVE_UL
+#define UL(level, message)        log_##level(metaspace)(LOGFMT ": " message, LOGFMT_ARGS);
+#define UL2(level, message, ...)  log_##level(metaspace)(LOGFMT ": " message, LOGFMT_ARGS, __VA_ARGS__);
+#else
+#define UL(level, ...)
+#define UL2(level, ...)
+#endif
+
+} // namespace metaspace
+
+#endif // SHARE_MEMORY_METASPACE_MSCOMMON_HPP
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msContext.cpp	2020-09-04 13:57:51.201356733 +0200
@@ -0,0 +1,87 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+
+#include "memory/metaspace/msChunkManager.hpp"
+#include "memory/metaspace/msCommitLimiter.hpp"
+#include "memory/metaspace/msContext.hpp"
+#include "memory/metaspace/msVirtualSpaceList.hpp"
+#include "utilities/debug.hpp"
+#include "utilities/globalDefinitions.hpp"
+#include "utilities/ostream.hpp"
+
+namespace metaspace {
+
+MetaspaceContext* MetaspaceContext::_class_space_context = NULL;
+MetaspaceContext* MetaspaceContext::_nonclass_space_context = NULL;
+
+// Destroys the context: deletes chunkmanager and virtualspacelist.
+//  If this is a non-expandable context over an existing space, that space remains
+//  untouched, otherwise all memory is unmapped.
+// Note: the standard metaspace contexts (non-class context and class context) are
+//  never deleted. This code only exists for the sake of tests and for future reuse
+//  of metaspace contexts in different scenarios.
+MetaspaceContext::~MetaspaceContext() {
+  delete _cm;
+  delete _vslist;
+}
+
+// Create a new, empty, expandable metaspace context.
+MetaspaceContext* MetaspaceContext::create_expandable_context(const char* name, CommitLimiter* commit_limiter) {
+  VirtualSpaceList* vsl = new VirtualSpaceList(name, commit_limiter);
+  ChunkManager* cm = new ChunkManager(name, vsl);
+  return new MetaspaceContext(name, vsl, cm);
+}
+
+// Create a new, empty, non-expandable metaspace context atop of an externally provided space.
+MetaspaceContext* MetaspaceContext::create_nonexpandable_context(const char* name, ReservedSpace rs, CommitLimiter* commit_limiter) {
+  VirtualSpaceList* vsl = new VirtualSpaceList(name, rs, commit_limiter);
+  ChunkManager* cm = new ChunkManager(name, vsl);
+  return new MetaspaceContext(name, vsl, cm);
+}
+
+void MetaspaceContext::initialize_class_space_context(ReservedSpace rs) {
+  _class_space_context = create_nonexpandable_context("class-space", rs, CommitLimiter::globalLimiter());
+}
+
+void MetaspaceContext::initialize_nonclass_space_context() {
+  _nonclass_space_context = create_expandable_context("non-class-space", CommitLimiter::globalLimiter());
+}
+
+void MetaspaceContext::print_on(outputStream* st) const {
+  _vslist->print_on(st);
+  _cm->print_on(st);
+}
+
+#ifdef ASSERT
+void MetaspaceContext::verify() const {
+  _vslist->verify();
+  _cm->verify();
+}
+#endif // ASSERT
+
+} // namespace metaspace
+
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msContext.hpp	2020-09-04 13:57:51.793360723 +0200
@@ -0,0 +1,108 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#ifndef SHARE_MEMORY_METASPACE_MSCONTEXT_HPP
+#define SHARE_MEMORY_METASPACE_MSCONTEXT_HPP
+
+#include "memory/allocation.hpp"
+#include "memory/virtualspace.hpp"
+#include "utilities/debug.hpp"
+
+class outputStream;
+
+namespace metaspace {
+
+class ChunkManager;
+class VirtualSpaceList;
+class CommitLimiter;
+
+// MetaspaceContext is a convenience bracket around:
+//
+// - a VirtualSpaceList managing a memory area used for Metaspace
+// - a ChunkManager sitting atop of that which manages chunk freelists
+//
+// In a normal VM only one or two of these contexts ever exist: one for the metaspace, and
+//  optionally another one for the compressed class space.
+//
+// For tests more contexts may be created, and this would also be a way to use Metaspace
+//  for things other than class metadata. We would have to work on the naming then.
+//
+// - (Future TODO): Context should own a lock to guard it. Currently this stuff is guarded
+//     by one global lock, the slightly misnamed Metaspace_expandlock, but that one
+//     should be split into one per context.
+// - (Future TODO): Context can/should have its own allocation alignment. That way we
+//     can have different alignment between class space and non-class metaspace. That could
+//     help optimize compressed class pointer encoding, see discussion for JDK-8244943).
+
+class MetaspaceContext : public CHeapObj<mtMetaspace> {
+
+  const char* const _name;
+  VirtualSpaceList* const _vslist;
+  ChunkManager* const _cm;
+
+  MetaspaceContext(const char* name, VirtualSpaceList* vslist, ChunkManager* cm)
+    : _name(name), _vslist(vslist), _cm(cm) {}
+
+  static MetaspaceContext* _nonclass_space_context;
+  static MetaspaceContext* _class_space_context;
+
+public:
+
+  // Destroys the context: deletes chunkmanager and virtualspacelist.
+  // If this is a non-expandable context over an existing space, that space remains
+  // untouched, otherwise all memory is unmapped.
+  ~MetaspaceContext();
+
+  VirtualSpaceList* vslist() { return _vslist; }
+  ChunkManager* cm() { return _cm; }
+
+  // Create a new, empty, expandable metaspace context.
+  static MetaspaceContext* create_expandable_context(const char* name, CommitLimiter* commit_limiter);
+
+  // Create a new, empty, non-expandable metaspace context atop of an externally provided space.
+  static MetaspaceContext* create_nonexpandable_context(const char* name, ReservedSpace rs, CommitLimiter* commit_limiter);
+
+  void print_on(outputStream* st) const;
+
+  DEBUG_ONLY(void verify() const;)
+
+  static void initialize_class_space_context(ReservedSpace rs);
+  static void initialize_nonclass_space_context();
+
+  // Returns pointer to the global metaspace context.
+  // If compressed class space is active, this contains the non-class-space allocations.
+  // If compressed class space is inactive, this contains all metaspace allocations.
+  static MetaspaceContext* context_nonclass()     { return _nonclass_space_context; }
+
+  // Returns pointer to the global class space context, if compressed class space is active,
+  // NULL otherwise.
+  static MetaspaceContext* context_class()        { return _class_space_context; }
+
+};
+
+} // end namespace
+
+#endif // SHARE_MEMORY_METASPACE_MSCONTEXT_HPP
+
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msCounter.hpp	2020-09-04 13:57:52.401364825 +0200
@@ -0,0 +1,183 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#ifndef SHARE_MEMORY_METASPACE_MSCOUNTER_HPP
+#define SHARE_MEMORY_METASPACE_MSCOUNTER_HPP
+
+#include "metaprogramming/isSigned.hpp"
+#include "runtime/atomic.hpp"
+#include "utilities/debug.hpp"
+#include "utilities/globalDefinitions.hpp"
+
+namespace metaspace {
+
+// We seem to be counting a lot of things which makes it worthwhile to
+// make helper classes for all that boilerplate coding.
+
+// AbstractCounter counts something and asserts overflow and underflow.
+template <class T>
+class AbstractCounter {
+
+  T _c;
+
+  // Only allow unsigned values for now
+  STATIC_ASSERT(IsSigned<T>::value == false);
+
+public:
+
+  AbstractCounter() : _c(0) {}
+
+  T get() const           { return _c; }
+
+  void increment() { increment_by(1); }
+  void decrement() { decrement_by(1); }
+
+  void increment_by(T v) {
+#ifdef ASSERT
+    T old = _c;
+    assert(old + v >= old,
+        "overflow (" UINT64_FORMAT "+" UINT64_FORMAT ")", (uint64_t)old, (uint64_t)v);
+#endif
+    _c += v;
+  }
+
+  void decrement_by(T v) {
+    assert(_c >= v,
+           "underflow (" UINT64_FORMAT "-" UINT64_FORMAT ")",
+           (uint64_t)_c, (uint64_t)v);
+    _c -= v;
+  }
+
+  void reset()                { _c = 0; }
+
+#ifdef ASSERT
+  void check(T expected) const {
+    assert(_c == expected, "Counter mismatch: %d, expected: %d.",
+           (int)_c, (int)expected);
+    }
+#endif
+
+};
+
+// Atomic variant of AbstractCounter.
+template <class T>
+class AbstractAtomicCounter {
+
+  volatile T _c;
+
+  // Only allow unsigned values for now
+  STATIC_ASSERT(IsSigned<T>::value == false);
+
+public:
+
+  AbstractAtomicCounter() : _c(0) {}
+
+  T get() const               { return _c; }
+
+  void increment() {
+    Atomic::inc(&_c);
+  }
+
+  void decrement() {
+#ifdef ASSERT
+    T old = Atomic::load_acquire(&_c);
+    assert(old >= 1,
+        "underflow (" UINT64_FORMAT "-1)", (uint64_t)old);
+#endif
+    Atomic::dec(&_c);
+  }
+
+  void increment_by(T v) {
+    Atomic::add(&_c, v);
+  }
+
+  void decrement_by(T v) {
+#ifdef ASSERT
+    T old = Atomic::load_acquire(&_c);
+    assert(old >= v,
+        "underflow (" UINT64_FORMAT "+" UINT64_FORMAT ")", (uint64_t)old, (uint64_t)v);
+#endif
+    Atomic::sub(&_c, v);
+  }
+
+#ifdef ASSERT
+  void check(T expected) const {
+    assert(_c == expected, "Counter mismatch: %d, expected: %d.",
+           (int)_c, (int)expected);
+    }
+#endif
+
+};
+
+typedef AbstractCounter<size_t>   SizeCounter;
+typedef AbstractCounter<unsigned> IntCounter;
+
+typedef AbstractAtomicCounter<size_t> SizeAtomicCounter;
+
+// We often count memory ranges (blocks, chunks etc).
+// Make a helper class for that.
+template <class T_num, class T_size>
+class AbstractMemoryRangeCounter {
+
+  AbstractCounter<T_num>  _count;
+  AbstractCounter<T_size> _total_size;
+
+public:
+
+  void add(T_size s) {
+    if(s > 0) {
+      _count.increment();
+      _total_size.increment_by(s);
+    }
+  }
+
+  void sub(T_size s) {
+    if(s > 0) {
+      _count.decrement();
+      _total_size.decrement_by(s);
+    }
+  }
+
+  T_num count() const       { return _count.get(); }
+  T_size total_size() const { return _total_size.get(); }
+
+#ifdef ASSERT
+  void check(T_num expected_count, T_size expected_size) const {
+    _count.check(expected_count);
+    _total_size.check(expected_size);
+  }
+  void check(const AbstractMemoryRangeCounter<T_num, T_size>& other) const {
+    check(other.count(), other.total_size());
+  }
+#endif
+
+};
+
+typedef AbstractMemoryRangeCounter<unsigned, size_t> MemRangeCounter;
+
+} // namespace metaspace
+
+#endif // SHARE_MEMORY_METASPACE_MSCOUNTER_HPP
+
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msDCmd.cpp	2020-09-04 13:57:52.945368496 +0200
@@ -0,0 +1,102 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+#include "memory/metaspace/msDCmd.hpp"
+#include "memory/metaspace/msReport.hpp"
+#include "memory/resourceArea.hpp"
+#include "services/diagnosticCommand.hpp"
+#include "services/nmtCommon.hpp"
+
+namespace metaspace {
+
+MetaspaceDCmd::MetaspaceDCmd(outputStream* output, bool heap)
+  : DCmdWithParser(output, heap)
+  , _basic("basic", "Prints a basic summary (does not need a safepoint).", "BOOLEAN", false, "false")
+  , _show_loaders("show-loaders", "Shows usage by class loader.", "BOOLEAN", false, "false")
+  , _by_spacetype("by-spacetype", "Break down numbers by loader type.", "BOOLEAN", false, "false")
+  , _by_chunktype("by-chunktype", "Break down numbers by chunk type.", "BOOLEAN", false, "false")
+  , _show_vslist("vslist", "Shows details about the underlying virtual space.", "BOOLEAN", false, "false")
+  , _scale("scale", "Memory usage in which to scale. Valid values are: 1, KB, MB or GB (fixed scale) "
+           "or \"dynamic\" for a dynamically choosen scale.",
+           "STRING", false, "dynamic")
+  , _show_classes("show-classes", "If show-loaders is set, shows loaded classes for each loader.", "BOOLEAN", false, "false")
+{
+  _dcmdparser.add_dcmd_option(&_basic);
+  _dcmdparser.add_dcmd_option(&_show_loaders);
+  _dcmdparser.add_dcmd_option(&_show_classes);
+  _dcmdparser.add_dcmd_option(&_by_chunktype);
+  _dcmdparser.add_dcmd_option(&_by_spacetype);
+  _dcmdparser.add_dcmd_option(&_show_vslist);
+  _dcmdparser.add_dcmd_option(&_scale);
+}
+
+int MetaspaceDCmd::num_arguments() {
+  ResourceMark rm;
+  MetaspaceDCmd* dcmd = new MetaspaceDCmd(NULL, false);
+  if (dcmd != NULL) {
+    DCmdMark mark(dcmd);
+    return dcmd->_dcmdparser.num_arguments();
+  } else {
+    return 0;
+  }
+}
+
+void MetaspaceDCmd::execute(DCmdSource source, TRAPS) {
+  // Parse scale value.
+  const char* scale_value = _scale.value();
+  size_t scale = 0;
+  if (scale_value != NULL) {
+    if (strcasecmp("dynamic", scale_value) == 0) {
+      scale = 0;
+    } else {
+      scale = NMT_ONLY(NMTUtil::scale_from_name(scale_value)) NOT_NMT(0);
+      if (scale == 0) {
+        output()->print_cr("Invalid scale: \"%s\". Will use dynamic scaling.", scale_value);
+      }
+    }
+  }
+  if (_basic.value() == true) {
+    if (_show_loaders.value() || _by_chunktype.value() || _by_spacetype.value() ||
+        _show_vslist.value()) {
+      // Basic mode. Just print essentials. Does not need to be at a safepoint.
+      output()->print_cr("In basic mode, additional arguments are ignored.");
+    }
+    MetaspaceUtils::print_basic_report(output(), scale);
+  } else {
+    // Full mode. Requires safepoint.
+    int flags = 0;
+    if (_show_loaders.value())         flags |= (int)MetaspaceReporter::Option::ShowLoaders;
+    if (_show_classes.value())         flags |= (int)MetaspaceReporter::Option::ShowClasses;
+    if (_by_chunktype.value())         flags |= (int)MetaspaceReporter::Option::BreakDownByChunkType;
+    if (_by_spacetype.value())         flags |= (int)MetaspaceReporter::Option::BreakDownBySpaceType;
+    if (_show_vslist.value())          flags |= (int)MetaspaceReporter::Option::ShowVSList;
+    VM_PrintMetadata op(output(), scale, flags);
+    VMThread::execute(&op);
+  }
+}
+
+} // namespace metaspace
+
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msDCmd.hpp	2020-09-04 13:57:53.497372225 +0200
@@ -0,0 +1,65 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#ifndef SHARE_MEMORY_METASPACE_MSDCMD_HPP
+#define SHARE_MEMORY_METASPACE_MSDCMD_HPP
+
+#include "services/diagnosticCommand.hpp"
+
+class outputStream;
+
+namespace metaspace {
+
+class MetaspaceDCmd : public DCmdWithParser {
+  DCmdArgument<bool> _basic;
+  DCmdArgument<bool> _show_loaders;
+  DCmdArgument<bool> _by_spacetype;
+  DCmdArgument<bool> _by_chunktype;
+  DCmdArgument<bool> _show_vslist;
+  DCmdArgument<char*> _scale;
+  DCmdArgument<bool> _show_classes;
+public:
+  MetaspaceDCmd(outputStream* output, bool heap);
+  static const char* name() {
+    return "VM.metaspace";
+  }
+  static const char* description() {
+    return "Prints the statistics for the metaspace";
+  }
+  static const char* impact() {
+      return "Medium: Depends on number of classes loaded.";
+  }
+  static const JavaPermission permission() {
+    JavaPermission p = {"java.lang.management.ManagementPermission",
+                        "monitor", NULL};
+    return p;
+  }
+  static int num_arguments();
+  virtual void execute(DCmdSource source, TRAPS);
+};
+
+} // namespace metaspace
+
+#endif // SHARE_MEMORY_METASPACE_MSDCMD_HPP
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msFreeBlocks.cpp	2020-09-04 13:57:54.069376089 +0200
@@ -0,0 +1,64 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+#include "memory/metaspace/msFreeBlocks.hpp"
+#include "utilities/globalDefinitions.hpp"
+#include "utilities/debug.hpp"
+
+namespace metaspace {
+
+void FreeBlocks::add_block(MetaWord* p, size_t word_size) {
+  assert(word_size >= MinWordSize, "sanity (" SIZE_FORMAT ")", word_size);
+  if (word_size > MaxSmallBlocksWordSize) {
+    _tree.add_block(p, word_size);
+  } else {
+    _small_blocks.add_block(p, word_size);
+  }
+}
+
+MetaWord* FreeBlocks::remove_block(size_t requested_word_size) {
+  assert(requested_word_size >= MinWordSize,
+      "requested_word_size too small (" SIZE_FORMAT ")", requested_word_size);
+  size_t real_size = 0;
+  MetaWord* p = NULL;
+  if (requested_word_size > MaxSmallBlocksWordSize) {
+    p = _tree.remove_block(requested_word_size, &real_size);
+  } else {
+    p = _small_blocks.remove_block(requested_word_size, &real_size);
+  }
+  if (p != NULL) {
+    // Blocks which are larger than a certain threshold are split and
+    //  the remainder is handed back to the manager.
+    const size_t waste = real_size - requested_word_size;
+    if (waste > MinWordSize) {
+      add_block(p + requested_word_size, waste);
+    }
+  }
+  return p;
+}
+
+} // namespace metaspace
+
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msFreeBlocks.hpp	2020-09-04 13:57:54.633379904 +0200
@@ -0,0 +1,115 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#ifndef SHARE_MEMORY_METASPACE_MSFREEBLOCKS_HPP
+#define SHARE_MEMORY_METASPACE_MSFREEBLOCKS_HPP
+
+#include "memory/allocation.hpp"
+
+#include "memory/metaspace/msBinList.hpp"
+#include "memory/metaspace/msBlockTree.hpp"
+#include "memory/metaspace/msCounter.hpp"
+
+#include "utilities/debug.hpp"
+#include "utilities/globalDefinitions.hpp"
+
+class outputStream;
+
+namespace metaspace {
+
+// Class FreeBlocks manages deallocated blocks in Metaspace.
+//
+// In Metaspace, allocated memory blocks may be release prematurely. This is
+//  uncommon (otherwise an arena-based allocation scheme would not make sense).
+//  It can happen e.g. when class loading fails or when bytecode gets rewritten.
+//
+// All these released blocks should be reused, so they are collected. Since these
+//  blocks are embedded into chunks which are still in use by a live arena,
+//  we cannot just give these blocks to anyone; only the owner of this arena can
+//  reuse these blocks. Therefore these blocks are kept at arena-level.
+//
+// The structure to manage these released blocks at arena level is class FreeBlocks.
+//
+// FreeBlocks is optimized toward the typical size and number of deallocated
+//  blocks. The vast majority of them (about 90%) are below 16 words in size,
+//  but there is a significant portion of memory blocks much larger than that,
+//  leftover space from retired chunks, see MetaspaceArena::retire_current_chunk().
+//
+// Since the vast majority of blocks are small or very small, FreeBlocks consists
+//  internally of two separate structures to keep very small blocks and other blocks.
+//  Very small blocks are kept in a bin list (see binlist.hpp) and larger blocks in
+//  a BST (see blocktree.hpp).
+
+class FreeBlocks : public CHeapObj<mtMetaspace> {
+
+  // _small_blocks takes care of small to very small blocks.
+  BinList32 _small_blocks;
+
+  // A BST for larger blocks, only for blocks which are too large
+  // to fit into _smallblocks.
+  BlockTree _tree;
+
+  // Cutoff point: blocks larger than this size are kept in the
+  // tree, blocks smaller than or equal to this size in the bin list.
+  const size_t MaxSmallBlocksWordSize = BinList32::MaxWordSize;
+
+public:
+
+  // Smallest blocks we can keep in this structure.
+  const static size_t MinWordSize = BinList32::MinWordSize;
+
+  // Add a block to the deallocation management.
+  void add_block(MetaWord* p, size_t word_size);
+
+  // Retrieve a block of at least requested_word_size.
+  MetaWord* remove_block(size_t requested_word_size);
+
+#ifdef ASSERT
+  void verify() const {
+    _tree.verify();
+    _small_blocks.verify();
+  };
+#endif
+
+  // Returns number of blocks.
+  int count() const {
+    return _small_blocks.count() + _tree.count();
+  }
+
+  // Returns total size, in words, of all elements.
+  size_t total_size() const {
+    return _small_blocks.total_size() + _tree.total_size();
+  }
+
+  // Returns true if empty.
+  bool is_empty() const {
+    return _small_blocks.is_empty() && _tree.is_empty();
+  }
+
+};
+
+} // namespace metaspace
+
+#endif // SHARE_MEMORY_METASPACE_MSFREEBLOCKS_HPP
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msFreeChunkList.cpp	2020-09-04 13:57:55.193383693 +0200
@@ -0,0 +1,175 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+#include "memory/metaspace/msFreeChunkList.hpp"
+#include "utilities/globalDefinitions.hpp"
+#include "utilities/debug.hpp"
+#include "utilities/ostream.hpp"
+
+namespace metaspace {
+
+void FreeChunkList::print_on(outputStream* st) const {
+
+  if (_num_chunks.get() > 0) {
+    for (const Metachunk* c = _first; c != NULL; c = c->next()) {
+      st->print(" - <");
+      c->print_on(st);
+      st->print(">");
+    }
+    st->print(" - total : %d chunks.", _num_chunks.get());
+  } else {
+    st->print("empty");
+  }
+
+}
+
+#ifdef ASSERT
+
+bool FreeChunkList::contains(const Metachunk* c) const {
+  for (Metachunk* c2 = _first; c2 != NULL; c2 = c2->next()) {
+    if (c2 == c) {
+      return true;
+    }
+  }
+  return false;
+}
+
+void FreeChunkList::verify() const {
+
+  if (_first == NULL) {
+    assert(_last == NULL, "Sanity");
+  } else {
+    assert(_last != NULL, "Sanity");
+    size_t committed = 0;
+    int num = 0;
+    bool uncommitted = (_first->committed_words() == 0);
+    for (Metachunk* c = _first; c != NULL; c = c->next()) {
+      assert(c->is_free(), "Chunks in freelist should be free");
+      assert(c->used_words() == 0, "Chunk in freelist should have not used words.");
+      assert(c->level() == _first->level(), "wrong level");
+      assert(c->next() == NULL || c->next()->prev() == c, "front link broken");
+      assert(c->prev() == NULL || c->prev()->next() == c, "back link broken");
+      assert(c != c->prev() && c != c->next(), "circle");
+      c->verify();
+      committed += c->committed_words();
+      num++;
+    }
+    _num_chunks.check(num);
+    _committed_word_size.check(committed);
+  }
+
+}
+
+#endif // ASSERT
+
+// Returns total size in all lists (regardless of commit state of underlying memory)
+size_t FreeChunkListVector::word_size() const {
+  size_t sum = 0;
+  for (chunklevel_t l = chunklevel::LOWEST_CHUNK_LEVEL; l <= chunklevel::HIGHEST_CHUNK_LEVEL; l++) {
+    sum += list_for_level(l)->num_chunks() * chunklevel::word_size_for_level(l);
+  }
+  return sum;
+}
+
+// Returns total committed size in all lists
+size_t FreeChunkListVector::committed_word_size() const {
+  size_t sum = 0;
+  for (chunklevel_t l = chunklevel::LOWEST_CHUNK_LEVEL; l <= chunklevel::HIGHEST_CHUNK_LEVEL; l++) {
+    sum += list_for_level(l)->committed_word_size();
+  }
+  return sum;
+}
+
+// Returns total committed size in all lists
+int FreeChunkListVector::num_chunks() const {
+  int n = 0;
+  for (chunklevel_t l = chunklevel::LOWEST_CHUNK_LEVEL; l <= chunklevel::HIGHEST_CHUNK_LEVEL; l++) {
+    n += list_for_level(l)->num_chunks();
+  }
+  return n;
+}
+
+// Look for a chunk: starting at level, up to and including max_level,
+//  return the first chunk whose committed words >= min_committed_words.
+// Return NULL if no such chunk was found.
+Metachunk* FreeChunkListVector::search_chunk_ascending(chunklevel_t level, chunklevel_t max_level, size_t min_committed_words) {
+  assert(min_committed_words <= chunklevel::word_size_for_level(max_level),
+         "min chunk size too small to hold min_committed_words");
+  for (chunklevel_t l = level; l <= max_level; l++) {
+    Metachunk* c = list_for_level(l)->first();
+    if (c != NULL && c->committed_words() >= min_committed_words) {
+      list_for_level(l)->remove(c);
+      return c;
+    }
+  }
+  return NULL;
+}
+
+// Look for a chunk: starting at level, down to (including) the root chunk level,
+// return the first chunk whose committed words >= min_committed_words.
+// Return NULL if no such chunk was found.
+Metachunk* FreeChunkListVector::search_chunk_descending(chunklevel_t level, size_t min_committed_words) {
+  for (chunklevel_t l = level; l >= chunklevel::LOWEST_CHUNK_LEVEL; l --) {
+    Metachunk* c = list_for_level(l)->first();
+    if (c != NULL && c->committed_words() >= min_committed_words) {
+      list_for_level(l)->remove(c);
+      return c;
+    }
+  }
+  return NULL;
+}
+
+void FreeChunkListVector::print_on(outputStream* st) const {
+  for (chunklevel_t l = chunklevel::LOWEST_CHUNK_LEVEL; l <= chunklevel::HIGHEST_CHUNK_LEVEL; l++) {
+    st->print("-- List[" CHKLVL_FORMAT "]: ", l);
+    list_for_level(l)->print_on(st);
+    st->cr();
+  }
+  st->print_cr("total chunks: %d, total word size: " SIZE_FORMAT ", committed word size: " SIZE_FORMAT ".",
+               num_chunks(), word_size(), committed_word_size());
+}
+
+#ifdef ASSERT
+
+void FreeChunkListVector::verify() const {
+  for (chunklevel_t l = chunklevel::LOWEST_CHUNK_LEVEL; l <= chunklevel::HIGHEST_CHUNK_LEVEL; l++) {
+    list_for_level(l)->verify();
+  }
+}
+
+bool FreeChunkListVector::contains(const Metachunk* c) const {
+  for (chunklevel_t l = chunklevel::LOWEST_CHUNK_LEVEL; l <= chunklevel::HIGHEST_CHUNK_LEVEL; l++) {
+    if (list_for_level(l)->contains(c)) {
+      return true;
+    }
+  }
+  return false;
+}
+
+#endif // ASSERT
+
+} // namespace metaspace
+
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msFreeChunkList.hpp	2020-09-04 13:57:55.745387431 +0200
@@ -0,0 +1,272 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#ifndef SHARE_MEMORY_METASPACE_MSFREECHUNKLIST_HPP
+#define SHARE_MEMORY_METASPACE_MSFREECHUNKLIST_HPP
+
+#include "memory/allocation.hpp"
+#include "memory/metaspace/msChunklevel.hpp"
+#include "memory/metaspace/msCounter.hpp"
+#include "memory/metaspace/msMetachunk.hpp"
+#include "memory/metaspace/msMetachunkList.hpp"
+
+class outputStream;
+
+namespace metaspace {
+
+// This is the free list underlying the ChunkManager.
+//
+// Chunks are kept in a vector of double-linked double-headed lists
+//  (using Metachunk::prev/next). One list per chunk level exists.
+//
+// Chunks in these lists are roughly ordered: uncommitted chunks
+//  are added to the back of the list, fully or partially committed
+//  chunks to the front.
+//
+// (Small caveat: commit state of a chunk may change as a result of
+//  actions on neighboring chunks, if the chunk is smaller than a commit
+//  granule and therefore shares its granule with neighbors. So it may change
+//  after the chunk has been added to the list.
+//  It will never involuntarily uncommit: only chunks >= granule size are uncommitted.
+//  But it may get involuntarily committed if an in-granule neighbor is committed and
+//  causes committing of the whole granule.
+//  In practice this is not a big deal; it has very little consequence.)
+//
+// Beyond adding at either front or at back, we do not sort on insert, since the
+//  insert path is used during Metaspace reclamation which may happen at GC pause.
+//
+// During retrieval (at class loading), we search the list for a chunk of at least
+//  n committed words to satisfy the caller requested committed word size. We stop
+//  searching at the first fully uncommitted chunk.
+//
+// Note that even though this is an O(n) search, in practice this is not a problem:
+//  - in all likelihood the requested commit word size is way smaller than even a single
+//    commit granule, so 99% of all searches would end at the first chunk (which is either
+//    uncommitted or committed to at least one commit granule size).
+//  - in all likelihood chunks, when added to this list, are either fully committed
+//    or fully uncommitted (see Settings::uncommit_on_return_min_word_size()).
+//
+// Should we ever encounter situations where the O(n) search is a bottleneck, this
+//  structure can easily be optimized (e.g. a BST). But for now lets keep this simple.
+
+class FreeChunkList {
+
+  Metachunk* _first;
+  Metachunk* _last;
+
+  IntCounter _num_chunks;
+  SizeCounter _committed_word_size;
+
+  void add_front(Metachunk* c) {
+    if (_first == NULL) {
+      assert(_last == NULL, "Sanity");
+      _first = _last = c;
+      c->set_prev(NULL);
+      c->set_next(NULL);
+    } else {
+      assert(_last != NULL, "Sanity");
+      c->set_next(_first);
+      c->set_prev(NULL);
+      _first->set_prev(c);
+      _first = c;
+    }
+  }
+
+  // Add chunk to the back of the list.
+  void add_back(Metachunk* c) {
+    if (_last == NULL) {
+      assert(_first == NULL, "Sanity");
+      _last = _first = c;
+      c->set_prev(NULL);
+      c->set_next(NULL);
+    } else {
+      assert(_first != NULL, "Sanity");
+      c->set_next(NULL);
+      c->set_prev(_last);
+      _last->set_next(c);
+      _last = c;
+    }
+  }
+
+public:
+
+  FreeChunkList() :
+    _first(NULL),
+    _last(NULL)
+    {}
+
+  // Remove given chunk from anywhere in the list.
+  Metachunk* remove(Metachunk* c) {
+    assert(contains(c), "Must be contained here");
+    Metachunk* pred = c->prev();
+    Metachunk* succ = c->next();
+    if (pred) {
+      pred->set_next(succ);
+    }
+    if (succ) {
+      succ->set_prev(pred);
+    }
+    if (_first == c) {
+      _first = succ;
+    }
+    if (_last == c) {
+      _last = pred;
+    }
+    c->set_next(NULL);
+    c->set_prev(NULL);
+    _committed_word_size.decrement_by(c->committed_words());
+    _num_chunks.decrement();
+    return c;
+  }
+
+  void add(Metachunk* c) {
+    assert(contains(c) == false, "Chunk already in freelist");
+    assert(_first == NULL || _first->level() == c->level(), "wrong level");
+    // Uncomitted chunks go to the back, fully or partially committed to the front.
+    if (c->committed_words() == 0) {
+      add_back(c);
+    } else {
+      add_front(c);
+    }
+    _committed_word_size.increment_by(c->committed_words());
+    _num_chunks.increment();
+  }
+
+  // Removes the first chunk from the list and returns it. Returns NULL if list is empty.
+  Metachunk* remove_first() {
+    Metachunk* c = _first;
+    if (c != NULL) {
+      remove(c);
+    }
+    return c;
+  }
+
+  // Find and removes a chunk in this list which has at least min_committed_words committed words.
+  // Returns NULL if not found.
+  Metachunk* find_matching(size_t min_committed_words) {
+    Metachunk* c = _first;
+    while (c != NULL && c->committed_words() > 0) {
+      if (c->committed_words() <= min_committed_words) {
+        remove(c);
+        return c;
+      }
+      c = c->next();
+    }
+    return NULL;
+  }
+
+  // Returns reference to the first chunk in the list, or NULL
+  Metachunk* first() const { return _first; }
+
+#ifdef ASSERT
+  bool contains(const Metachunk* c) const;
+  void verify() const;
+#endif
+
+  // Returns number of chunks
+  int num_chunks() const { return _num_chunks.get(); }
+
+  // Returns total committed word size
+  size_t committed_word_size() const { return _committed_word_size.get(); }
+
+  void print_on(outputStream* st) const;
+
+};
+
+// A vector of free chunk lists, one per chunk level
+class FreeChunkListVector {
+
+  FreeChunkList _lists[chunklevel::NUM_CHUNK_LEVELS];
+
+  const FreeChunkList* list_for_level(chunklevel_t lvl) const         { DEBUG_ONLY(chunklevel::check_valid_level(lvl)); return _lists + lvl; }
+  FreeChunkList* list_for_level(chunklevel_t lvl)                     { DEBUG_ONLY(chunklevel::check_valid_level(lvl)); return _lists + lvl; }
+
+  const FreeChunkList* list_for_chunk(const Metachunk* c) const       { return list_for_level(c->level()); }
+  FreeChunkList* list_for_chunk(const Metachunk* c)                   { return list_for_level(c->level()); }
+
+public:
+
+  // Remove given chunk from its list. List must contain that chunk.
+  void remove(Metachunk* c) {
+    list_for_chunk(c)->remove(c);
+  }
+
+  // Remove first node unless empty. Returns node or NULL.
+  Metachunk* remove_first(chunklevel_t lvl) {
+    Metachunk* c = list_for_level(lvl)->remove_first();
+    return c;
+  }
+
+  void add(Metachunk* c) {
+    list_for_chunk(c)->add(c);
+  }
+
+  // Returns number of chunks for a given level.
+  int num_chunks_at_level(chunklevel_t lvl) const {
+    return list_for_level(lvl)->num_chunks();
+  }
+
+  // Returns number of chunks for a given level.
+  size_t committed_word_size_at_level(chunklevel_t lvl) const {
+    return list_for_level(lvl)->committed_word_size();
+  }
+
+  // Returns reference to first chunk at this level, or NULL if sublist is empty.
+  Metachunk* first_at_level(chunklevel_t lvl) const {
+    return list_for_level(lvl)->first();
+  }
+
+  // Look for a chunk: starting at level, up to and including max_level,
+  //  return the first chunk whose committed words >= min_committed_words.
+  // Return NULL if no such chunk was found.
+  Metachunk* search_chunk_ascending(chunklevel_t level, chunklevel_t max_level,
+                                    size_t min_committed_words);
+
+  // Look for a chunk: starting at level, down to (including) the root chunk level,
+  // return the first chunk whose committed words >= min_committed_words.
+  // Return NULL if no such chunk was found.
+  Metachunk* search_chunk_descending(chunklevel_t level, size_t min_committed_words);
+
+  // Returns total size in all lists (regardless of commit state of underlying memory)
+  size_t word_size() const;
+
+  // Returns total committed size in all lists
+  size_t committed_word_size() const;
+
+  // Returns number of chunks in all lists
+  int num_chunks() const;
+
+#ifdef ASSERT
+  bool contains(const Metachunk* c) const;
+  void verify() const;
+#endif
+
+  void print_on(outputStream* st) const;
+
+};
+
+} // namespace metaspace
+
+#endif // SHARE_MEMORY_METASPACE_MSFREECHUNKLIST_HPP
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msInternalStats.cpp	2020-09-04 13:57:56.285391089 +0200
@@ -0,0 +1,51 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+#include "memory/metaspace/msInternalStats.hpp"
+#include "utilities/globalDefinitions.hpp"
+#include "utilities/ostream.hpp"
+
+namespace metaspace {
+
+#define MATERIALIZE_COUNTER(name)          uint64_t InternalStats::_##name;
+#define MATERIALIZE_ATOMIC_COUNTER(name)   volatile uint64_t InternalStats::_##name;
+  ALL_MY_COUNTERS(MATERIALIZE_COUNTER, MATERIALIZE_ATOMIC_COUNTER)
+#undef MATERIALIZE_COUNTER
+#undef MATERIALIZE_ATOMIC_COUNTER
+
+void InternalStats::print_on(outputStream* st) {
+
+#define xstr(s) str(s)
+#define str(s) #s
+
+#define PRINT_COUNTER(name)  st->print_cr("%s: " UINT64_FORMAT ".", xstr(name), _##name);
+  ALL_MY_COUNTERS(PRINT_COUNTER, PRINT_COUNTER)
+#undef PRINT_COUNTER
+
+}
+
+} // namespace metaspace
+
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msInternalStats.hpp	2020-09-04 13:57:56.829394776 +0200
@@ -0,0 +1,124 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#ifndef SHARE_MEMORY_METASPACE_MSINTERNALSTATS_HPP
+#define SHARE_MEMORY_METASPACE_MSINTERNALSTATS_HPP
+
+#include "memory/allocation.hpp"
+#include "runtime/atomic.hpp"
+#include "utilities/globalDefinitions.hpp"
+
+class outputStream;
+
+namespace metaspace {
+
+// These are some counters useful for debugging and analyzing Metaspace problems.
+// They get printed as part of the Metaspace report (e.g. via jcmd VM.metaspace)
+
+class InternalStats : public AllStatic {
+
+  // Note: all counters which are modified on the classloader local allocation path
+  //   (not under ExpandLock protection) have to be atomic.
+
+#define ALL_MY_COUNTERS(x, x_atomic)                \
+                                                    \
+  /* Number of allocations. */                      \
+  DEBUG_ONLY(x_atomic(num_allocs))                  \
+                                                    \
+  /* Number of external deallocations */            \
+  /* (excluding retired chunk remains) */           \
+  DEBUG_ONLY(x_atomic(num_deallocs))                \
+                                                    \
+  /* Number of times an allocation was satisfied */ \
+  /*  from deallocated blocks. */                   \
+  DEBUG_ONLY(x_atomic(num_allocs_from_deallocated_blocks)) \
+                                                    \
+  /* Number of times an arena retired a chunk */    \
+  DEBUG_ONLY(x_atomic(num_chunks_retired))          \
+                                                    \
+  /* Number of times an allocation failed */        \
+  /*  because we hit a limit. */                    \
+  x_atomic(num_allocs_failed_limit)                 \
+                                                    \
+  /* Number of times an arena was born ... */       \
+  x_atomic(num_arena_births)                        \
+  /* ... and died. */                               \
+  x_atomic(num_arena_deaths)                        \
+                                                    \
+  /* Number of times VirtualSpaceNode were */       \
+  /*  born...  */                                   \
+  x(num_vsnodes_births)                             \
+  /* ... and died. */                               \
+  x(num_vsnodes_deaths)                             \
+                                                    \
+  /* Number of times we committed space. */         \
+  x(num_space_committed)                            \
+  /* Number of times we uncommitted space. */       \
+  x(num_space_uncommitted)                          \
+                                                    \
+  /* Number of times a chunk was returned to the */ \
+  /*  freelist (external only). */                  \
+  x(num_chunks_returned_to_freelist)                \
+  /* Number of times a chunk was taken from */      \
+  /*  freelist (external only) */                   \
+  x(num_chunks_taken_from_freelist)                 \
+                                                    \
+  /* Number of successful chunk merges */           \
+  x(num_chunk_merges)                               \
+  /* Number of chunk splits */                      \
+  x(num_chunk_splits)                               \
+  /* Number of chunk in place enlargements */       \
+  x(num_chunks_enlarged)                            \
+                                                    \
+  /* Number of times we did a purge */              \
+  x(num_purges)                                     \
+
+#define DEFINE_COUNTER(name)          static uint64_t _##name;
+#define DEFINE_ATOMIC_COUNTER(name)   static volatile uint64_t _##name;
+  ALL_MY_COUNTERS(DEFINE_COUNTER, DEFINE_ATOMIC_COUNTER)
+#undef DEFINE_COUNTER
+#undef DEFINE_ATOMIC_COUNTER
+
+public:
+
+// incrementors
+#define INCREMENTOR(name)           static void inc_##name() { _##name++; }
+#define INCREMENTOR_ATOMIC(name)    static void inc_##name() { Atomic::inc(&_##name); }
+  ALL_MY_COUNTERS(INCREMENTOR, INCREMENTOR_ATOMIC)
+#undef INCREMENTOR
+#undef INCREMENTOR_ATOMIC
+
+// getters
+#define GETTER(name)                static uint64_t name() { return _##name; }
+  ALL_MY_COUNTERS(GETTER, GETTER)
+#undef GETTER
+
+  static void print_on(outputStream* st);
+
+};
+
+} // namespace metaspace
+
+#endif // SHARE_MEMORY_METASPACE_MSINTERNALSTATS_HPP
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msMetachunk.cpp	2020-09-04 13:57:57.389398574 +0200
@@ -0,0 +1,358 @@
+/*
+ * Copyright (c) 2012, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2017, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+
+#include "logging/log.hpp"
+#include "memory/metaspace/msCommon.hpp"
+#include "memory/metaspace/msMetachunk.hpp"
+#include "memory/metaspace/msSettings.hpp"
+#include "memory/metaspace/msVirtualSpaceNode.hpp"
+#include "runtime/mutexLocker.hpp"
+
+#include "utilities/align.hpp"
+#include "utilities/copy.hpp"
+#include "utilities/debug.hpp"
+
+namespace metaspace {
+
+// Return a single char presentation of the state ('f', 'u', 'd')
+char Metachunk::get_state_char() const {
+  switch (_state) {
+  case State::Free:   return 'f';
+  case State::InUse:  return 'u';
+  case State::Dead:   return 'd';
+  }
+  return '?';
+}
+
+#ifdef ASSERT
+void Metachunk::assert_have_expand_lock() {
+  assert_lock_strong(MetaspaceExpand_lock);
+}
+#endif
+
+// Commit uncommitted section of the chunk.
+// Fails if we hit a commit limit.
+bool Metachunk::commit_up_to(size_t new_committed_words) {
+
+  // Please note:
+  //
+  // VirtualSpaceNode::ensure_range_is_committed(), when called over a range containing both committed and uncommitted parts,
+  // will replace the whole range with a new mapping, thus erasing the existing content in the committed parts. Therefore
+  // we must make sure never to call VirtualSpaceNode::ensure_range_is_committed() over a range containing live data.
+  //
+  // Luckily, this cannot happen by design. We have two cases:
+  //
+  // 1) chunks equal or larger than a commit granule.
+  //    In this case, due to chunk geometry, the chunk should cover whole commit granules (in other words, a chunk equal or larger than
+  //    a commit granule will never share a granule with a neighbor). That means whatever we commit or uncommit here does not affect
+  //    neighboring chunks. We only have to take care not to re-commit used parts of ourself. We do this by moving the committed_words
+  //    limit in multiple of commit granules.
+  //
+  // 2) chunks smaller than a commit granule.
+  //    In this case, a chunk shares a single commit granule with its neighbors. But this never can be a problem:
+  //    - Either the commit granule is already committed (and maybe the neighbors contain live data). In that case calling
+  //      ensure_range_is_committed() will do nothing.
+  //    - Or the commit granule is not committed, but in this case, the neighbors are uncommitted too and cannot contain live data.
+
+#ifdef ASSERT
+  if (word_size() >= Settings::commit_granule_words()) {
+    // case (1)
+    assert(is_aligned(base(), Settings::commit_granule_bytes()) &&
+           is_aligned(end(), Settings::commit_granule_bytes()),
+           "Chunks larger than a commit granule must cover whole granules.");
+    assert(is_aligned(_committed_words, Settings::commit_granule_words()),
+           "The commit boundary must be aligned to commit granule size");
+    assert(_used_words <= _committed_words, "Sanity");
+  } else {
+    // case (2)
+    assert(_committed_words == 0 || _committed_words == word_size(), "Sanity");
+  }
+#endif
+
+  // We should hold the expand lock at this point.
+  assert_lock_strong(MetaspaceExpand_lock);
+
+  const size_t commit_from = _committed_words;
+  const size_t commit_to =   MIN2(align_up(new_committed_words, Settings::commit_granule_words()), word_size());
+
+  assert(commit_from >= used_words(), "Sanity");
+  assert(commit_to <= word_size(), "Sanity");
+
+  if (commit_to > commit_from) {
+    log_debug(metaspace)("Chunk " METACHUNK_FORMAT ": attempting to move commit line to "
+                         SIZE_FORMAT " words.", METACHUNK_FORMAT_ARGS(this), commit_to);
+
+    if (!_vsnode->ensure_range_is_committed(base() + commit_from, commit_to - commit_from)) {
+      DEBUG_ONLY(verify();)
+      return false;
+    }
+  }
+
+  // Remember how far we have committed.
+  _committed_words = commit_to;
+
+  DEBUG_ONLY(verify();)
+
+  return true;
+
+}
+
+// Ensure that chunk is committed up to at least new_committed_words words.
+// Fails if we hit a commit limit.
+bool Metachunk::ensure_committed(size_t new_committed_words) {
+
+  bool rc = true;
+
+  if (new_committed_words > committed_words()) {
+    MutexLocker cl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
+    rc = commit_up_to(new_committed_words);
+  }
+
+  return rc;
+
+}
+
+bool Metachunk::ensure_committed_locked(size_t new_committed_words) {
+
+  // the .._locked() variant should be called if we own the lock already.
+  assert_lock_strong(MetaspaceExpand_lock);
+
+  bool rc = true;
+
+  if (new_committed_words > committed_words()) {
+    rc = commit_up_to(new_committed_words);
+  }
+
+  return rc;
+
+}
+
+// Uncommit chunk area. The area must be a common multiple of the
+// commit granule size (in other words, we cannot uncommit chunks smaller than
+// a commit granule size).
+void Metachunk::uncommit() {
+  MutexLocker cl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
+  uncommit_locked();
+}
+
+void Metachunk::uncommit_locked() {
+  // Only uncommit chunks which are free, have no used words set (extra precaution) and are equal or larger in size than a single commit granule.
+  assert_lock_strong(MetaspaceExpand_lock);
+  assert(_state == State::Free && _used_words == 0 && word_size() >= Settings::commit_granule_words(),
+         "Only free chunks equal or larger than commit granule size can be uncommitted "
+         "(chunk " METACHUNK_FULL_FORMAT ").", METACHUNK_FULL_FORMAT_ARGS(this));
+  if (word_size() >= Settings::commit_granule_words()) {
+    _vsnode->uncommit_range(base(), word_size());
+    _committed_words = 0;
+  }
+}
+void Metachunk::set_committed_words(size_t v) {
+  // Set committed words. Since we know that we only commit whole commit granules, we can round up v here.
+  v = MIN2(align_up(v, Settings::commit_granule_words()), word_size());
+ _committed_words = v;
+}
+
+// Allocate word_size words from this chunk (word_size must be aligned to
+//  allocation_alignment_words).
+//
+// Caller must make sure the chunk is both large enough and committed far enough
+// to hold the allocation. Will always work.
+//
+MetaWord* Metachunk::allocate(size_t request_word_size) {
+
+  // Caller must have made sure this works
+  assert(free_words() >= request_word_size, "Chunk too small.");
+  assert(free_below_committed_words() >= request_word_size, "Chunk not committed.");
+
+  MetaWord* const p = top();
+
+  _used_words += request_word_size;
+
+  SOMETIMES(verify();)
+
+  return p;
+
+}
+
+#ifdef ASSERT
+
+// Zap this structure.
+void Metachunk::zap_header(uint8_t c) {
+  memset(this, c, sizeof(Metachunk));
+}
+
+// Verifies linking with neighbors in virtual space.
+// Can only be done under expand lock protection.
+void Metachunk::verify_neighborhood() const {
+
+  assert_lock_strong(MetaspaceExpand_lock);
+  assert(!is_dead(), "Do not call on dead chunks.");
+
+  if (is_root_chunk()) {
+
+    // Root chunks are all alone in the world.
+    assert(next_in_vs() == NULL || prev_in_vs() == NULL, "Root chunks should have no neighbors");
+
+  } else {
+
+    // Non-root chunks have neighbors, at least one, possibly two.
+
+    assert(next_in_vs() != NULL || prev_in_vs() != NULL,
+           "A non-root chunk should have neighbors (chunk @" PTR_FORMAT
+           ", base " PTR_FORMAT ", level " CHKLVL_FORMAT ".",
+           p2i(this), p2i(base()), level());
+
+    if (prev_in_vs() != NULL) {
+      assert(prev_in_vs()->end() == base(),
+             "Chunk " METACHUNK_FULL_FORMAT ": should be adjacent to predecessor: " METACHUNK_FULL_FORMAT ".",
+             METACHUNK_FULL_FORMAT_ARGS(this), METACHUNK_FULL_FORMAT_ARGS(prev_in_vs()));
+      assert(prev_in_vs()->next_in_vs() == this,
+             "Chunk " METACHUNK_FULL_FORMAT ": broken link to left neighbor: " METACHUNK_FULL_FORMAT " (" PTR_FORMAT ").",
+             METACHUNK_FULL_FORMAT_ARGS(this), METACHUNK_FULL_FORMAT_ARGS(prev_in_vs()), p2i(prev_in_vs()->next_in_vs()));
+    }
+
+    if (next_in_vs() != NULL) {
+      assert(end() == next_in_vs()->base(),
+             "Chunk " METACHUNK_FULL_FORMAT ": should be adjacent to successor: " METACHUNK_FULL_FORMAT ".",
+             METACHUNK_FULL_FORMAT_ARGS(this), METACHUNK_FULL_FORMAT_ARGS(next_in_vs()));
+      assert(next_in_vs()->prev_in_vs() == this,
+             "Chunk " METACHUNK_FULL_FORMAT ": broken link to right neighbor: " METACHUNK_FULL_FORMAT " (" PTR_FORMAT ").",
+             METACHUNK_FULL_FORMAT_ARGS(this), METACHUNK_FULL_FORMAT_ARGS(next_in_vs()), p2i(next_in_vs()->prev_in_vs()));
+    }
+
+    // One of the neighbors must be the buddy. It can be whole or splintered.
+
+    // The chunk following us or preceeding us may be our buddy or a splintered part of it.
+    Metachunk* buddy = is_leader() ? next_in_vs() : prev_in_vs();
+
+    assert(buddy != NULL, "Missing neighbor.");
+    assert(!buddy->is_dead(), "Invalid buddy state.");
+
+    // This neighbor is either or buddy (same level) or a splinter of our buddy - hence
+    // the level can never be smaller (aka the chunk size cannot be larger).
+    assert(buddy->level() >= level(), "Wrong level.");
+
+    if (buddy->level() == level()) {
+
+      // If the buddy is of the same size as us, it is unsplintered.
+      assert(buddy->is_leader() == !is_leader(),
+             "Only one chunk can be leader in a pair");
+
+      // When direct buddies are neighbors, one or both should be in use, otherwise they should
+      // have been merged.
+
+      // But since we call this verification function from internal functions where we are about to merge or just did split,
+      // do not test this. We have RootChunkArea::verify_area_is_ideally_merged() for testing that.
+
+      // assert(buddy->is_in_use() || is_in_use(), "incomplete merging?");
+
+      if (is_leader()) {
+        assert(buddy->base() == end(), "Sanity");
+        assert(is_aligned(base(), word_size() * 2 * BytesPerWord), "Sanity");
+      } else {
+        assert(buddy->end() == base(), "Sanity");
+        assert(is_aligned(buddy->base(), word_size() * 2 * BytesPerWord), "Sanity");
+      }
+
+    } else {
+
+      // Buddy, but splintered, and this is a part of it.
+      if (is_leader()) {
+        assert(buddy->base() == end(), "Sanity");
+      } else {
+        assert(buddy->end() > (base() - word_size()), "Sanity");
+      }
+
+    }
+  }
+}
+
+volatile MetaWord dummy = 0;
+
+void Metachunk::verify() const {
+
+  // Note. This should be called under CLD lock protection.
+
+  // We can verify everything except the _prev_in_vs/_next_in_vs pair.
+  // This is because neighbor chunks may be added concurrently, so we cannot rely
+  //  on the content of _next_in_vs/_prev_in_vs unless we have the expand lock.
+
+  assert(!is_dead(), "Do not call on dead chunks.");
+
+  if (is_free()) {
+    assert(used_words() == 0, "free chunks are not used.");
+  }
+
+  // Note: only call this on a life Metachunk.
+  chunklevel::check_valid_level(level());
+
+  assert(base() != NULL, "No base ptr");
+
+  assert(committed_words() >= used_words(),
+         "mismatch: committed: " SIZE_FORMAT ", used: " SIZE_FORMAT ".",
+         committed_words(), used_words());
+
+  assert(word_size() >= committed_words(),
+         "mismatch: word_size: " SIZE_FORMAT ", committed: " SIZE_FORMAT ".",
+         word_size(), committed_words());
+
+  // Test base pointer
+  assert(base() != NULL, "Base pointer NULL");
+  assert(vsnode() != NULL, "No space");
+  vsnode()->check_pointer(base());
+
+  // Starting address shall be aligned to chunk size.
+  const size_t required_alignment = word_size() * sizeof(MetaWord);
+  assert_is_aligned(base(), required_alignment);
+
+  // Test accessing the committed area.
+  SOMETIMES(
+    if (_committed_words > 0) {
+      for (const MetaWord* p = _base; p < _base + _committed_words; p += os::vm_page_size()) {
+        dummy = *p;
+      }
+      dummy = *(_base + _committed_words - 1);
+    }
+  )
+
+}
+#endif // ASSERT
+
+void Metachunk::print_on(outputStream* st) const {
+
+  // Note: must also work with invalid/random data. (e.g. do not call word_size())
+  st->print("Chunk @" PTR_FORMAT ", state %c, base " PTR_FORMAT ", "
+            "level " CHKLVL_FORMAT " (" SIZE_FORMAT " words), "
+            "used " SIZE_FORMAT " words, committed " SIZE_FORMAT " words.",
+            p2i(this), get_state_char(), p2i(base()), level(),
+            (chunklevel::is_valid_level(level()) ? chunklevel::word_size_for_level(level()) : (size_t)-1),
+            used_words(), committed_words());
+
+}
+
+} // namespace metaspace
+
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msMetachunk.hpp	2020-09-04 13:57:58.045403025 +0200
@@ -0,0 +1,314 @@
+/*
+ * Copyright (c) 2012, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2017, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#ifndef SHARE_MEMORY_METASPACE_MSMETACHUNK_HPP
+#define SHARE_MEMORY_METASPACE_MSMETACHUNK_HPP
+
+#include "memory/metaspace/msChunklevel.hpp"
+#include "memory/metaspace/msCounter.hpp"
+#include "utilities/debug.hpp"
+#include "utilities/globalDefinitions.hpp"
+
+class outputStream;
+
+namespace metaspace {
+
+class VirtualSpaceNode;
+
+// A Metachunk is a contiguous metaspace memory region. It is part of
+// a MetaspaceArena, which keeps a list of MetaChunk and allocates via
+// pointer bump from the top element in the list.
+//
+// The Metachunk object itself (the "chunk header") is separated from
+//  the memory region (the chunk payload) it describes. It also can have
+//  no payload (a "dead" chunk). In itself it lives in C-heap, managed
+//  as part of a pool of Metachunk headers (ChunkHeaderPool).
+//
+// -- Metachunk state --
+//
+// A Metachunk is "in-use" if it is part of a MetaspaceArena. That means
+//  its memory is used - or will be used shortly - to hold VM metadata
+//  on behalf of a class loader.
+//
+// A Metachunk is "free" if its payload is currently unused. In that
+//  case it is managed by a chunk freelist (the ChunkManager).
+// 
+// A Metachunk is "dead" if it does not have a corresponding payload.
+//  In that case it lives as part of a freelist-of-dead-chunk-headers
+//  in the ChunkHeaderPool.
+//
+// -- Level --
+//
+// Metachunks are managed as part of a buddy style allocation scheme.
+// Sized always in steps of power-of-2, ranging from the smallest chunk size
+// (1Kb) to the largest (4Mb) (see chunklevel.hpp).
+// Its size is encoded as level, with level 0 being the largest chunk
+// size ("root chunk").
+//
+// -- Payload commit state --
+//
+// A Metachunk payload may be committed, partly committed or completely
+// uncommitted. Technically, a payload may be committed "checkered" -
+// i.e. committed and uncommitted parts may interleave - but the
+// important part is how much contiguous space is committed starting
+// at the base of the payload (since that's where we allocate). 
+// 
+// The Metachunk keeps track of how much space is committed starting
+//  at the base of the payload - which is a performace optimization - 
+//  while underlying layers (VirtualSpaceNode->commitmask) keep track
+//  of the "real" commit state, aka which granules are committed,
+//  independent on what chunks reside above those granules.
+
+//            +--------------+ <- end    -----------+ ----------+
+//            |              |                      |           |
+//            |              |                      |           |
+//            |              |                      |           |
+//            |              |                      |           |
+//            |              |                      |           |
+//            | -----------  | <- committed_top  -- +           |
+//            |              |                      |           |
+//            |              |                      | "free"    |
+//            |              |                      |           | size 
+//            |              |     "free_below_     |           |
+//            |              |        committed"    |           |
+//            |              |                      |           |
+//            |              |                      |           |
+//            | -----------  | <- top     --------- + --------  |
+//            |              |                      |           |
+//            |              |     "used"           |           |
+//            |              |                      |           |
+//            +--------------+ <- start   ----------+ ----------+
+
+// Note: this is a chunk **descriptor**. The real Payload area lives in metaspace,
+// this class lives somewhere else.
+class Metachunk {
+
+  // start of chunk memory; NULL if dead.
+  MetaWord* _base;
+
+  // Used words.
+  size_t _used_words;
+
+  // Size of the region, starting from base, which is guaranteed to be committed. In words.
+  //  The actual size of committed regions may actually be larger.
+  //
+  //  (This is a performance optimization. The underlying VirtualSpaceNode knows
+  //   which granules are committed; but we want to avoid having to ask.)
+  size_t _committed_words;
+
+  chunklevel_t _level; // aka size.
+
+  // state_free:    free, owned by a ChunkManager
+  // state_in_use:  in-use, owned by a MetaspaceArena
+  // dead:          just a hollow chunk header without associated memory, owned
+  //                 by chunk header pool.
+  enum class State : uint8_t {
+    Free = 0,
+    InUse = 1,
+    Dead = 2
+  };
+  State _state;
+
+  // We need unfortunately a back link to the virtual space node
+  // for splitting and merging nodes.
+  VirtualSpaceNode* _vsnode;
+
+  // A chunk header is kept in a list:
+  // 1 in the list of used chunks inside a MetaspaceArena, if it is in use
+  // 2 in the list of free chunks inside a ChunkManager, if it is free
+  // 3 in the freelist of unused headers inside the ChunkHeaderPool,
+  //   if it is unused (e.g. result of chunk merging) and has no associated
+  //   memory area.
+  Metachunk* _prev;
+  Metachunk* _next;
+
+  // Furthermore, we keep, per chunk, information about the neighboring chunks.
+  // This is needed to split and merge chunks.
+  //
+  // Note: These members can be modified concurrently while a chunk is alive and in use.
+  // This can happen if a neighboring chunk is added or removed.
+  // This means only read or modify these members under expand lock protection.
+  Metachunk* _prev_in_vs;
+  Metachunk* _next_in_vs;
+
+  // Commit uncommitted section of the chunk.
+  // Fails if we hit a commit limit.
+  bool commit_up_to(size_t new_committed_words);
+
+  DEBUG_ONLY(static void assert_have_expand_lock();)
+
+public:
+
+  Metachunk()
+    : _base(NULL),
+      _used_words(0),
+      _committed_words(0),
+      _level(chunklevel::ROOT_CHUNK_LEVEL),
+      _state(State::Free),
+      _vsnode(NULL),
+      _prev(NULL), _next(NULL),
+      _prev_in_vs(NULL), _next_in_vs(NULL)
+  {}
+
+ void clear() {
+   _base = NULL;
+   _used_words = 0;
+   _committed_words = 0;
+   _level = chunklevel::ROOT_CHUNK_LEVEL;
+   _state = State::Free;
+   _vsnode = NULL;
+   _prev = NULL;
+   _next = NULL;
+   _prev_in_vs = NULL;
+   _next_in_vs = NULL;
+  }
+
+  size_t word_size() const        { return chunklevel::word_size_for_level(_level); }
+
+  MetaWord* base() const          { return _base; }
+  MetaWord* top() const           { return base() + _used_words; }
+  MetaWord* committed_top() const { return base() + _committed_words; }
+  MetaWord* end() const           { return base() + word_size(); }
+
+  // Chunk list wiring
+  void set_prev(Metachunk* c)     { _prev = c; }
+  Metachunk* prev() const         { return _prev; }
+  void set_next(Metachunk* c)     { _next = c; }
+  Metachunk* next() const         { return _next; }
+
+  DEBUG_ONLY(bool in_list() const { return _prev != NULL || _next != NULL; })
+
+  // Physical neighbors wiring
+  void set_prev_in_vs(Metachunk* c) { DEBUG_ONLY(assert_have_expand_lock()); _prev_in_vs = c; }
+  Metachunk* prev_in_vs() const     { DEBUG_ONLY(assert_have_expand_lock()); return _prev_in_vs; }
+  void set_next_in_vs(Metachunk* c) { DEBUG_ONLY(assert_have_expand_lock()); _next_in_vs = c; }
+  Metachunk* next_in_vs() const     { DEBUG_ONLY(assert_have_expand_lock()); return _next_in_vs; }
+
+  bool is_free() const            { return _state == State::Free; }
+  bool is_in_use() const          { return _state == State::InUse; }
+  bool is_dead() const            { return _state == State::Dead; }
+  void set_free()                 { _state = State::Free; }
+  void set_in_use()               { _state = State::InUse; }
+  void set_dead()                 { _state = State::Dead; }
+
+  // Return a single char presentation of the state ('f', 'u', 'd')
+  char get_state_char() const;
+
+  void inc_level()                { _level++; DEBUG_ONLY(chunklevel::is_valid_level(_level);) }
+  void dec_level()                { _level --; DEBUG_ONLY(chunklevel::is_valid_level(_level);) }
+  chunklevel_t level() const          { return _level; }
+
+  // Convenience functions for extreme levels.
+  bool is_root_chunk() const      { return chunklevel::ROOT_CHUNK_LEVEL == _level; }
+  bool is_leaf_chunk() const      { return chunklevel::HIGHEST_CHUNK_LEVEL == _level; }
+
+  VirtualSpaceNode* vsnode() const        { return _vsnode; }
+
+  size_t used_words() const                   { return _used_words; }
+  size_t free_words() const                   { return word_size() - used_words(); }
+  size_t free_below_committed_words() const   { return committed_words() - used_words(); }
+  void reset_used_words()                     { _used_words = 0; }
+
+  size_t committed_words() const      { return _committed_words; }
+  void set_committed_words(size_t v);
+  bool is_fully_committed() const     { return committed_words() == word_size(); }
+  bool is_fully_uncommitted() const   { return committed_words() == 0; }
+
+  // Ensure that chunk is committed up to at least new_committed_words words.
+  // Fails if we hit a commit limit.
+  bool ensure_committed(size_t new_committed_words);
+  bool ensure_committed_locked(size_t new_committed_words);
+
+  bool ensure_fully_committed()           { return ensure_committed(word_size()); }
+  bool ensure_fully_committed_locked()    { return ensure_committed_locked(word_size()); }
+
+  // Ensure that the chunk is committed far enough to serve an additional allocation of word_size.
+  bool ensure_committed_additional(size_t additional_word_size)   {
+    return ensure_committed(used_words() + additional_word_size);
+  }
+
+  // Uncommit chunk area. The area must be a common multiple of the
+  // commit granule size (in other words, we cannot uncommit chunks smaller than
+  // a commit granule size).
+  void uncommit();
+  void uncommit_locked();
+
+  // Allocation from a chunk
+
+  // Allocate word_size words from this chunk (word_size must be aligned to
+  //  allocation_alignment_words).
+  //
+  // Caller must make sure the chunk is both large enough and committed far enough
+  // to hold the allocation. Will always work.
+  //
+  MetaWord* allocate(size_t request_word_size);
+
+  // Initialize structure for reuse.
+  void initialize(VirtualSpaceNode* node, MetaWord* base, chunklevel_t lvl) {
+    _vsnode = node; _base = base; _level = lvl;
+    _used_words = _committed_words = 0; _state = State::Free;
+    _next = _prev = _next_in_vs = _prev_in_vs = NULL;
+  }
+
+  // Returns true if this chunk is the leader in its buddy pair, false if not.
+  // Do not call for root chunks.
+  bool is_leader() const {
+    assert(!is_root_chunk(), "Root chunks have no buddy."); // Bit harsh?
+    return is_aligned(base(), chunklevel::word_size_for_level(level() - 1) * BytesPerWord);
+  }
+
+  //// Debug stuff ////
+#ifdef ASSERT
+  void verify() const;
+  // Verifies linking with neighbors in virtual space. Needs expand lock protection.
+  void verify_neighborhood() const;
+  void zap_header(uint8_t c = 0x17);
+
+  // Returns true if given pointer points into the payload area of this chunk.
+  bool is_valid_pointer(const MetaWord* p) const {
+    return base() <= p && p < top();
+  }
+
+  // Returns true if given pointer points into the commmitted payload area of this chunk.
+  bool is_valid_committed_pointer(const MetaWord* p) const {
+    return base() <= p && p < committed_top();
+  }
+
+#endif // ASSERT
+
+  void print_on(outputStream* st) const;
+
+};
+
+// Little print helpers: since we often print out chunks, here some convenience macros
+#define METACHUNK_FORMAT                "@" PTR_FORMAT ", %c, base " PTR_FORMAT ", level " CHKLVL_FORMAT
+#define METACHUNK_FORMAT_ARGS(chunk)    p2i(chunk), chunk->get_state_char(), p2i(chunk->base()), chunk->level()
+
+#define METACHUNK_FULL_FORMAT                "@" PTR_FORMAT ", %c, base " PTR_FORMAT ", level " CHKLVL_FORMAT " (" SIZE_FORMAT "), used: " SIZE_FORMAT ", committed: " SIZE_FORMAT ", committed-free: " SIZE_FORMAT
+#define METACHUNK_FULL_FORMAT_ARGS(chunk)    p2i(chunk), chunk->get_state_char(), p2i(chunk->base()), chunk->level(), chunk->word_size(), chunk->used_words(), chunk->committed_words(), chunk->free_below_committed_words()
+
+} // namespace metaspace
+
+#endif // SHARE_MEMORY_METASPACE_MSMETACHUNK_HPP
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msMetachunkList.cpp	2020-09-04 13:57:58.785408051 +0200
@@ -0,0 +1,110 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+
+#include "memory/metaspace/msMetachunkList.hpp"
+#include "utilities/debug.hpp"
+#include "utilities/globalDefinitions.hpp"
+#include "utilities/ostream.hpp"
+
+namespace metaspace {
+
+#ifdef ASSERT
+
+bool MetachunkList::contains(const Metachunk* c) const {
+  for (Metachunk* c2 = _first; c2 != NULL; c2 = c2->next()) {
+    if (c == c2) {
+      return true;
+    }
+  }
+  return false;
+}
+
+void MetachunkList::verify() const {
+  int num = 0;
+  const Metachunk* last_c = NULL;
+  for (const Metachunk* c = _first; c != NULL; c = c->next()) {
+    num++;
+    assert(c->prev() != c && c->next() != c, "circularity");
+    assert(c->prev() == last_c,
+           "Broken link to predecessor. Chunk " METACHUNK_FULL_FORMAT ".",
+           METACHUNK_FULL_FORMAT_ARGS(c));
+    c->verify();
+    last_c = c;
+  }
+  _num_chunks.check(num);
+}
+
+#endif // ASSERT
+
+size_t MetachunkList::calc_committed_word_size() const {
+
+  if (_first != NULL && _first->is_dead()) {
+    // list used for chunk header pool; dead chunks have no size.
+    return 0;
+  }
+
+  size_t s = 0;
+  for (Metachunk* c = _first; c != NULL; c = c->next()) {
+    assert(c->is_dead() == false, "Sanity");
+    s += c->committed_words();
+  }
+  return s;
+}
+
+size_t MetachunkList::calc_word_size() const {
+
+  if (_first != NULL && _first->is_dead()) {
+    // list used for chunk header pool; dead chunks have no size.
+    return 0;
+  }
+
+  size_t s = 0;
+  for (Metachunk* c = _first; c != NULL; c = c->next()) {
+    assert(c->is_dead() == false, "Sanity");
+    s += c->committed_words();
+  }
+  return s;
+
+}
+
+void MetachunkList::print_on(outputStream* st) const {
+
+  if (_num_chunks.get() > 0) {
+    for (const Metachunk* c = _first; c != NULL; c = c->next()) {
+      st->print(" - <");
+      c->print_on(st);
+      st->print(">");
+    }
+    st->print(" - total : %d chunks.", _num_chunks.get());
+  } else {
+    st->print("empty");
+  }
+
+}
+
+} // namespace metaspace
+
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msMetachunkList.hpp	2020-09-04 13:57:59.421412373 +0200
@@ -0,0 +1,102 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#ifndef SHARE_MEMORY_METASPACE_MSMETACHUNKLIST_HPP
+#define SHARE_MEMORY_METASPACE_MSMETACHUNKLIST_HPP
+
+#include "memory/metaspace/msCommon.hpp"
+#include "memory/metaspace/msCounter.hpp"
+#include "memory/metaspace/msMetachunk.hpp"
+#include "utilities/debug.hpp"
+#include "utilities/globalDefinitions.hpp"
+
+class outputStream;
+
+namespace metaspace {
+
+// A simple single-linked list of chunks, used in MetaspaceArena to keep
+//  a list of retired chunks, as well as in the ChunkHeaderPool to keep
+//  a cache of unused chunk headers.
+
+class MetachunkList {
+
+  Metachunk* _first;
+  IntCounter _num_chunks;
+
+  // Note: The chunks inside this list may be dead (->chunk header pool).
+  // So, do not call c->word size on them or anything else which may not
+  // work with dead chunks.
+
+public:
+
+  MetachunkList() : _first(NULL), _num_chunks() {}
+
+  int count() const { return _num_chunks.get(); }
+
+  void add(Metachunk* c) {
+    // Note: contains is expensive (linear search).
+    ASSERT_SOMETIMES(contains(c) == false, "Chunk already in this list");
+    c->set_next(_first);
+    if (_first) {
+      _first->set_prev(c);
+    }
+    _first = c;
+    _num_chunks.increment();
+  }
+
+  Metachunk* remove_first() {
+    if (_first) {
+      Metachunk* c = _first;
+      _first = _first->next();
+      if (_first) {
+        _first->set_prev(NULL);
+      }
+      _num_chunks.decrement();
+      c->set_prev(NULL);
+      c->set_next(NULL);
+      return c;
+    }
+    return NULL;
+  }
+
+  Metachunk* first()              { return _first; }
+  const Metachunk* first() const  { return _first; }
+
+#ifdef ASSERT
+  // Note: linear search
+  bool contains(const Metachunk* c) const;
+  void verify() const;
+#endif
+
+  size_t calc_committed_word_size() const;
+  size_t calc_word_size() const;
+
+  void print_on(outputStream* st) const;
+
+};
+
+} // namespace metaspace
+
+#endif // SHARE_MEMORY_METASPACE_MSMETACHUNKLIST_HPP
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msPrintCLDMetaspaceInfoClosure.cpp	2020-09-04 13:58:00.045416616 +0200
@@ -0,0 +1,172 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+#include "classfile/classLoaderData.inline.hpp"
+#include "classfile/javaClasses.hpp"
+#include "memory/metaspace/msCommon.hpp"
+#include "memory/metaspace/msPrintCLDMetaspaceInfoClosure.hpp"
+#include "memory/metaspace/msPrintMetaspaceInfoKlassClosure.hpp"
+#include "memory/metaspace.hpp"
+#include "memory/resourceArea.hpp"
+#include "runtime/safepoint.hpp"
+#include "utilities/globalDefinitions.hpp"
+#include "utilities/ostream.hpp"
+
+namespace metaspace {
+
+PrintCLDMetaspaceInfoClosure::PrintCLDMetaspaceInfoClosure(outputStream* out, size_t scale, bool do_print,
+    bool do_print_classes, bool break_down_by_chunktype)
+: _out(out), _scale(scale), _do_print(do_print), _do_print_classes(do_print_classes)
+, _break_down_by_chunktype(break_down_by_chunktype)
+, _num_loaders(0), _num_loaders_without_metaspace(0), _num_loaders_unloading(0)
+,  _num_classes(0), _num_classes_shared(0)
+{
+  memset(_num_loaders_by_spacetype, 0, sizeof(_num_loaders_by_spacetype));
+  memset(_num_classes_by_spacetype, 0, sizeof(_num_classes_by_spacetype));
+  memset(_num_classes_shared_by_spacetype, 0, sizeof(_num_classes_shared_by_spacetype));
+}
+
+// A closure just to count classes
+class CountKlassClosure : public KlassClosure {
+public:
+
+  uintx _num_classes;
+  uintx _num_classes_shared;
+
+  CountKlassClosure() : _num_classes(0), _num_classes_shared(0) {}
+  void do_klass(Klass* k) {
+    _num_classes++;
+    if (k->is_shared()) {
+      _num_classes_shared++;
+    }
+  }
+
+}; // end: PrintKlassInfoClosure
+
+void PrintCLDMetaspaceInfoClosure::do_cld(ClassLoaderData* cld) {
+
+  assert(SafepointSynchronize::is_at_safepoint(), "Must be at a safepoint");
+
+  if (cld->is_unloading()) {
+    _num_loaders_unloading++;
+    return;
+  }
+
+  ClassLoaderMetaspace* msp = cld->metaspace_or_null();
+  if (msp == NULL) {
+    _num_loaders_without_metaspace++;
+    return;
+  }
+
+  // Collect statistics for this class loader metaspace
+  ClmsStats this_cld_stat;
+  msp->add_to_statistics(&this_cld_stat);
+
+  // And add it to the running totals
+  _stats_total.add(this_cld_stat);
+  _num_loaders++;
+  _stats_by_spacetype[msp->space_type()].add(this_cld_stat);
+  _num_loaders_by_spacetype[msp->space_type()] ++;
+
+  // Count classes loaded by this CLD.
+  CountKlassClosure ckc;
+  cld->classes_do(&ckc);
+  // accumulate.
+  _num_classes += ckc._num_classes;
+  _num_classes_by_spacetype[msp->space_type()] += ckc._num_classes;
+  _num_classes_shared += ckc._num_classes_shared;
+  _num_classes_shared_by_spacetype[msp->space_type()] += ckc._num_classes_shared;
+
+  // Optionally, print
+  if (_do_print) {
+
+    _out->print(UINTX_FORMAT_W(4) ": ", _num_loaders);
+
+    // Print "CLD for [<loader name>,] instance of <loader class name>"
+    // or    "CLD for <hidden or anonymous class>, loaded by [<loader name>,] instance of <loader class name>"
+
+    ResourceMark rm;
+    const char* name = NULL;
+    const char* class_name = NULL;
+
+    // Note: this should also work if unloading:
+    Klass* k = cld->class_loader_klass();
+    if (k != NULL) {
+      class_name = k->external_name();
+      Symbol* s = cld->name();
+      if (s != NULL) {
+        name = s->as_C_string();
+      }
+    } else {
+      name = "<bootstrap>";
+    }
+
+    // Print
+    _out->print("CLD " PTR_FORMAT, p2i(cld));
+    if (cld->is_unloading()) {
+      _out->print(" (unloading)");
+    }
+    _out->print(":");
+    if (cld->has_class_mirror_holder()) {
+      _out->print(" <hidden or anonymous class>, loaded by");
+    }
+    if (name != NULL) {
+      _out->print(" \"%s\"", name);
+    }
+    if (class_name != NULL) {
+      _out->print(" instance of %s", class_name);
+    }
+
+    if (_do_print_classes) {
+      // Print a detailed description of all loaded classes.
+      streamIndentor sti(_out, 6);
+      _out->cr_indent();
+      _out->print("Loaded classes");
+      if (ckc._num_classes_shared > 0) {
+        _out->print("('s' = shared)");
+      }
+      _out->print(":");
+      PrintMetaspaceInfoKlassClosure pkic(_out, true);
+      cld->classes_do(&pkic);
+      _out->cr_indent();
+      _out->print("-total-: ");
+      print_number_of_classes(_out, ckc._num_classes, ckc._num_classes_shared);
+    } else {
+      // Just print a summary about how many classes have been loaded.
+      _out->print(", ");
+      print_number_of_classes(_out, ckc._num_classes, ckc._num_classes_shared);
+    }
+
+    // Print statistics
+    this_cld_stat.print_on(_out, _scale, _break_down_by_chunktype);
+    _out->cr();
+
+  }
+
+}
+
+} // namespace metaspace
+
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msPrintCLDMetaspaceInfoClosure.hpp	2020-09-04 13:58:00.797421736 +0200
@@ -0,0 +1,69 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#ifndef SHARE_MEMORY_METASPACE_MSPRINTCLDMETASPACEINFOCLOSURE_HPP
+#define SHARE_MEMORY_METASPACE_MSPRINTCLDMETASPACEINFOCLOSURE_HPP
+
+#include "memory/iterator.hpp"
+#include "memory/metaspace/msStatistics.hpp"
+#include "memory/metaspace.hpp"
+#include "utilities/globalDefinitions.hpp"
+
+class outputStream;
+
+namespace metaspace {
+
+class PrintCLDMetaspaceInfoClosure : public CLDClosure {
+private:
+  outputStream* const _out;
+  const size_t        _scale;
+  const bool          _do_print;
+  const bool          _do_print_classes;
+  const bool          _break_down_by_chunktype;
+
+public:
+
+  uintx                           _num_loaders;
+  uintx                           _num_loaders_without_metaspace;
+  uintx                           _num_loaders_unloading;
+  ClmsStats                       _stats_total;
+
+  uintx                           _num_loaders_by_spacetype [Metaspace::MetaspaceTypeCount];
+  ClmsStats                       _stats_by_spacetype [Metaspace::MetaspaceTypeCount];
+
+  uintx                           _num_classes_by_spacetype [Metaspace::MetaspaceTypeCount];
+  uintx                           _num_classes_shared_by_spacetype [Metaspace::MetaspaceTypeCount];
+  uintx                           _num_classes;
+  uintx                           _num_classes_shared;
+
+  PrintCLDMetaspaceInfoClosure(outputStream* out, size_t scale, bool do_print,
+      bool do_print_classes, bool break_down_by_chunktype);
+  void do_cld(ClassLoaderData* cld);
+
+};
+
+} // namespace metaspace
+
+#endif // SHARE_MEMORY_METASPACE_MSPRINTCLDMETASPACEINFOCLOSURE_HPP
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msPrintMetaspaceInfoKlassClosure.cpp	2020-09-04 13:58:01.541426804 +0200
@@ -0,0 +1,59 @@
+/*
+ * Copyright (c) 2018, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, SAP and/or its affiliates.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+#include "precompiled.hpp"
+
+#include "memory/metaspaceShared.hpp"
+#include "memory/metaspace/msPrintMetaspaceInfoKlassClosure.hpp"
+#include "memory/resourceArea.hpp"
+#include "oops/reflectionAccessorImplKlassHelper.hpp"
+#include "utilities/globalDefinitions.hpp"
+#include "utilities/ostream.hpp"
+
+namespace metaspace {
+
+PrintMetaspaceInfoKlassClosure::PrintMetaspaceInfoKlassClosure(outputStream* out, bool do_print)
+: _out(out), _cnt(0)
+{}
+
+void PrintMetaspaceInfoKlassClosure::do_klass(Klass* k) {
+  _cnt++;
+  _out->cr_indent();
+  _out->print(UINTX_FORMAT_W(4) ": ", _cnt);
+
+  // Print a 's' for shared classes
+  _out->put(k->is_shared() ? 's': ' ');
+
+  ResourceMark rm;
+  _out->print("  %s", k->external_name());
+
+  // Special treatment for generated core reflection accessor classes: print invocation target.
+  if (ReflectionAccessorImplKlassHelper::is_generated_accessor(k)) {
+    _out->print(" (invokes: ");
+    ReflectionAccessorImplKlassHelper::print_invocation_target(_out, k);
+    _out->print(")");
+  }
+}
+
+} // namespace metaspace
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msPrintMetaspaceInfoKlassClosure.hpp	2020-09-04 13:58:02.389432584 +0200
@@ -0,0 +1,54 @@
+/*
+ * Copyright (c) 2018, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, SAP and/or its affiliates.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#ifndef SHARE_MEMORY_METASPACE_MSPRINTMETASPACEINFOKLASSCLOSURE_HPP
+#define SHARE_MEMORY_METASPACE_MSPRINTMETASPACEINFOKLASSCLOSURE_HPP
+
+#include "memory/iterator.hpp"
+#include "utilities/globalDefinitions.hpp"
+
+class outputStream;
+class InstanceKlass;
+
+namespace metaspace {
+
+// Helper class for MetaspaceUtils::print_report()
+class PrintMetaspaceInfoKlassClosure : public KlassClosure {
+private:
+  outputStream* const _out;
+  uintx _cnt;
+
+  bool print_reflection_invocation_target(outputStream* out, InstanceKlass* magic_accessor_impl_class);
+
+public:
+
+  PrintMetaspaceInfoKlassClosure(outputStream* out, bool do_print);
+  void do_klass(Klass* k);
+
+}; // end: PrintKlassInfoClosure
+
+} // namespace metaspace
+
+#endif // SHARE_MEMORY_METASPACE_MSPRINTMETASPACEINFOKLASSCLOSURE_HPP
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msReport.cpp	2020-09-04 13:58:03.057437141 +0200
@@ -0,0 +1,391 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+#include "classfile/classLoaderData.hpp"
+#include "classfile/classLoaderDataGraph.hpp"
+#include "memory/metaspace/msChunkHeaderPool.hpp"
+#include "memory/metaspace/msChunkManager.hpp"
+#include "memory/metaspace/msCommon.hpp"
+#include "memory/metaspace/msInternalStats.hpp"
+#include "memory/metaspace/msPrintCLDMetaspaceInfoClosure.hpp"
+#include "memory/metaspace/msReport.hpp"
+#include "memory/metaspace/msRunningCounters.hpp"
+#include "memory/metaspace/msSettings.hpp"
+#include "memory/metaspace/msStatistics.hpp"
+#include "memory/metaspace/msVirtualSpaceList.hpp"
+#include "memory/metaspace.hpp"
+#include "runtime/os.hpp"
+
+namespace metaspace {
+
+static const char* describe_spacetype(Metaspace::MetaspaceType st) {
+  const char* s = NULL;
+  switch (st) {
+    case Metaspace::StandardMetaspaceType: s = "Standard"; break;
+    case Metaspace::BootMetaspaceType: s = "Boot"; break;
+    case Metaspace::ClassMirrorHolderMetaspaceType: s = "ClassMirrorHolder"; break;
+    case Metaspace::ReflectionMetaspaceType: s = "Reflection"; break;
+    default: ShouldNotReachHere();
+  }
+  return s;
+}
+
+static void print_vs(outputStream* out, size_t scale) {
+
+  const size_t reserved_nc = RunningCounters::reserved_words_nonclass();
+  const size_t committed_nc = RunningCounters::committed_words_nonclass();
+  const int num_nodes_nc = VirtualSpaceList::vslist_nonclass()->num_nodes();
+
+  if (Metaspace::using_class_space()) {
+
+    const size_t reserved_c = RunningCounters::reserved_words_class();
+    const size_t committed_c = RunningCounters::committed_words_class();
+    const int num_nodes_c = VirtualSpaceList::vslist_class()->num_nodes();
+
+    out->print("  Non-class space:  ");
+    print_scaled_words(out, reserved_nc, scale, 7);
+    out->print(" reserved, ");
+    print_scaled_words_and_percentage(out, committed_nc, reserved_nc, scale, 7);
+    out->print(" committed, ");
+    out->print(" %d nodes.", num_nodes_nc);
+    out->cr();
+    out->print("      Class space:  ");
+    print_scaled_words(out, reserved_c, scale, 7);
+    out->print(" reserved, ");
+    print_scaled_words_and_percentage(out, committed_c, reserved_c, scale, 7);
+    out->print(" committed, ");
+    out->print(" %d nodes.", num_nodes_c);
+    out->cr();
+    out->print("              Both:  ");
+    print_scaled_words(out, reserved_c + reserved_nc, scale, 7);
+    out->print(" reserved, ");
+    print_scaled_words_and_percentage(out, committed_c + committed_nc, reserved_c + reserved_nc, scale, 7);
+    out->print(" committed. ");
+    out->cr();
+
+  } else {
+    print_scaled_words(out, reserved_nc, scale, 7);
+    out->print(" reserved, ");
+    print_scaled_words_and_percentage(out, committed_nc, reserved_nc, scale, 7);
+    out->print(" committed, ");
+    out->print(" %d nodes.", num_nodes_nc);
+    out->cr();
+  }
+}
+
+static void print_settings(outputStream* out, size_t scale) {
+  out->print("MaxMetaspaceSize: ");
+  if (MaxMetaspaceSize >= (max_uintx) - (2 * os::vm_page_size())) {
+    // aka "very big". Default is max_uintx, but due to rounding in arg parsing the real
+    // value is smaller.
+    out->print("unlimited");
+  } else {
+    print_human_readable_size(out, MaxMetaspaceSize, scale);
+  }
+  out->cr();
+  if (Metaspace::using_class_space()) {
+    out->print("CompressedClassSpaceSize: ");
+    print_human_readable_size(out, CompressedClassSpaceSize, scale);
+  }
+  out->cr();
+  Settings::print_on(out);
+}
+
+// This will print out a basic metaspace usage report but
+// unlike print_report() is guaranteed not to lock or to walk the CLDG.
+void MetaspaceReporter::print_basic_report(outputStream* out, size_t scale) {
+
+  if (!Metaspace::initialized()) {
+    out->print_cr("Metaspace not yet initialized.");
+    return;
+  }
+
+  out->cr();
+  out->print_cr("Usage:");
+
+  if (Metaspace::using_class_space()) {
+    out->print("  Non-class:  ");
+  }
+
+  // Note: since we want to purely rely on counters, without any locking or walking the CLDG,
+  // for Usage stats (statistics over in-use chunks) all we can print is the
+  // used words. We cannot print committed areas, or free/waste areas, of in-use chunks require
+  // walking.
+  const size_t used_nc = MetaspaceUtils::used_words(Metaspace::NonClassType);
+
+  print_scaled_words(out, used_nc, scale, 5);
+  out->print(" used.");
+  out->cr();
+
+  if (Metaspace::using_class_space()) {
+    const size_t used_c = MetaspaceUtils::used_words(Metaspace::ClassType);
+    out->print("      Class:  ");
+    print_scaled_words(out, used_c, scale, 5);
+    out->print(" used.");
+    out->cr();
+
+    out->print("       Both:  ");
+    const size_t used = used_nc + used_c;
+    print_scaled_words(out, used, scale, 5);
+    out->print(" used.");
+    out->cr();
+  }
+
+  out->cr();
+  out->print_cr("Virtual space:");
+
+  print_vs(out, scale);
+
+  out->cr();
+  out->print_cr("Chunk freelists:");
+
+  if (Metaspace::using_class_space()) {
+    out->print("   Non-Class:  ");
+  }
+  print_scaled_words(out, ChunkManager::chunkmanager_nonclass()->total_word_size(), scale);
+  out->cr();
+  if (Metaspace::using_class_space()) {
+    out->print("       Class:  ");
+    print_scaled_words(out, ChunkManager::chunkmanager_class()->total_word_size(), scale);
+    out->cr();
+    out->print("        Both:  ");
+    print_scaled_words(out, ChunkManager::chunkmanager_nonclass()->total_word_size() +
+                            ChunkManager::chunkmanager_class()->total_word_size(), scale);
+    out->cr();
+  }
+
+  out->cr();
+
+  // Print basic settings
+  print_settings(out, scale);
+
+  out->cr();
+
+  out->cr();
+  out->print_cr("Internal statistics:");
+  out->cr();
+  InternalStats::print_on(out);
+  out->cr();
+
+}
+
+void MetaspaceReporter::print_report(outputStream* out, size_t scale, int flags) {
+
+  if (!Metaspace::initialized()) {
+    out->print_cr("Metaspace not yet initialized.");
+    return;
+  }
+
+  const bool print_loaders = (flags & (int)Option::ShowLoaders) > 0;
+  const bool print_classes = (flags & (int)Option::ShowClasses) > 0;
+  const bool print_by_chunktype = (flags & (int)Option::BreakDownByChunkType) > 0;
+  const bool print_by_spacetype = (flags & (int)Option::BreakDownBySpaceType) > 0;
+
+  // Some report options require walking the class loader data graph.
+  metaspace::PrintCLDMetaspaceInfoClosure cl(out, scale, print_loaders, print_classes, print_by_chunktype);
+  if (print_loaders) {
+    out->cr();
+    out->print_cr("Usage per loader:");
+    out->cr();
+  }
+
+  ClassLoaderDataGraph::loaded_cld_do(&cl); // collect data and optionally print
+
+  // Print totals, broken up by space type.
+  if (print_by_spacetype) {
+    out->cr();
+    out->print_cr("Usage per space type:");
+    out->cr();
+    for (int space_type = (int)Metaspace::ZeroMetaspaceType;
+         space_type < (int)Metaspace::MetaspaceTypeCount; space_type++)
+    {
+      uintx num_loaders = cl._num_loaders_by_spacetype[space_type];
+      uintx num_classes = cl._num_classes_by_spacetype[space_type];
+      out->print("%s - " UINTX_FORMAT " %s",
+        describe_spacetype((Metaspace::MetaspaceType)space_type),
+        num_loaders, loaders_plural(num_loaders));
+      if (num_classes > 0) {
+        out->print(", ");
+
+        print_number_of_classes(out, num_classes, cl._num_classes_shared_by_spacetype[space_type]);
+        out->print(":");
+        cl._stats_by_spacetype[space_type].print_on(out, scale, print_by_chunktype);
+      } else {
+        out->print(".");
+        out->cr();
+      }
+      out->cr();
+    }
+  }
+
+  // Print totals for in-use data:
+  out->cr();
+  {
+    uintx num_loaders = cl._num_loaders;
+    out->print("Total Usage - " UINTX_FORMAT " %s, ",
+      num_loaders, loaders_plural(num_loaders));
+    print_number_of_classes(out, cl._num_classes, cl._num_classes_shared);
+    out->print(":");
+    cl._stats_total.print_on(out, scale, print_by_chunktype);
+    out->cr();
+  }
+
+  /////////////////////////////////////////////////
+  // -- Print Virtual space.
+  out->cr();
+  out->print_cr("Virtual space:");
+
+  print_vs(out, scale);
+
+  // -- Print VirtualSpaceList details.
+  if ((flags & (int)Option::ShowVSList) > 0) {
+    out->cr();
+    out->print_cr("Virtual space list%s:", Metaspace::using_class_space() ? "s" : "");
+
+    if (Metaspace::using_class_space()) {
+      out->print_cr("   Non-Class:");
+    }
+    VirtualSpaceList::vslist_nonclass()->print_on(out);
+    out->cr();
+    if (Metaspace::using_class_space()) {
+      out->print_cr("       Class:");
+      VirtualSpaceList::vslist_class()->print_on(out);
+      out->cr();
+    }
+  }
+  out->cr();
+
+  //////////// Freelists (ChunkManager) section ///////////////////////////
+
+  out->cr();
+  out->print_cr("Chunk freelist%s:", Metaspace::using_class_space() ? "s" : "");
+
+  ChunkManagerStats non_class_cm_stat;
+  ChunkManagerStats class_cm_stat;
+  ChunkManagerStats total_cm_stat;
+
+  ChunkManager::chunkmanager_nonclass()->add_to_statistics(&non_class_cm_stat);
+  if (Metaspace::using_class_space()) {
+    ChunkManager::chunkmanager_nonclass()->add_to_statistics(&non_class_cm_stat);
+    ChunkManager::chunkmanager_class()->add_to_statistics(&class_cm_stat);
+    total_cm_stat.add(non_class_cm_stat);
+    total_cm_stat.add(class_cm_stat);
+
+    out->print_cr("   Non-Class:");
+    non_class_cm_stat.print_on(out, scale);
+    out->cr();
+    out->print_cr("       Class:");
+    class_cm_stat.print_on(out, scale);
+    out->cr();
+    out->print_cr("        Both:");
+    total_cm_stat.print_on(out, scale);
+    out->cr();
+  } else {
+    ChunkManager::chunkmanager_nonclass()->add_to_statistics(&non_class_cm_stat);
+    non_class_cm_stat.print_on(out, scale);
+    out->cr();
+  }
+
+  //////////// Waste section ///////////////////////////
+  // As a convenience, print a summary of common waste.
+  out->cr();
+  out->print("Waste (unused committed space):");
+  // For all wastages, print percentages from total. As total use the total size of memory committed for metaspace.
+  const size_t committed_words = RunningCounters::committed_words();
+
+  out->print("(percentages refer to total committed size ");
+  print_scaled_words(out, committed_words, scale);
+  out->print_cr("):");
+
+  // Print waste for in-use chunks.
+  InUseChunkStats ucs_nonclass = cl._stats_total._arena_stats_nonclass.totals();
+  InUseChunkStats ucs_class = cl._stats_total._arena_stats_class.totals();
+  const size_t waste_in_chunks_in_use = ucs_nonclass._waste_words + ucs_class._waste_words;
+  const size_t free_in_chunks_in_use = ucs_nonclass._free_words + ucs_class._free_words;
+
+  out->print("        Waste in chunks in use: ");
+  print_scaled_words_and_percentage(out, waste_in_chunks_in_use, committed_words, scale, 6);
+  out->cr();
+  out->print("        Free in chunks in use: ");
+  print_scaled_words_and_percentage(out, free_in_chunks_in_use, committed_words, scale, 6);
+  out->cr();
+
+  // Print waste in free chunks.
+  const size_t committed_in_free_chunks = total_cm_stat.total_committed_word_size();
+  out->print("                In free chunks: ");
+  print_scaled_words_and_percentage(out, committed_in_free_chunks, committed_words, scale, 6);
+  out->cr();
+
+  // Print waste in deallocated blocks.
+  const uintx free_blocks_num =
+      cl._stats_total._arena_stats_nonclass._free_blocks_num +
+      cl._stats_total._arena_stats_class._free_blocks_num;
+  const size_t free_blocks_cap_words =
+      cl._stats_total._arena_stats_nonclass._free_blocks_word_size +
+      cl._stats_total._arena_stats_class._free_blocks_word_size;
+  out->print("Deallocated from chunks in use: ");
+  print_scaled_words_and_percentage(out, free_blocks_cap_words, committed_words, scale, 6);
+  out->print(" (" UINTX_FORMAT " blocks)", free_blocks_num);
+  out->cr();
+
+  // Print total waste.
+  const size_t total_waste =
+      waste_in_chunks_in_use +
+      free_in_chunks_in_use +
+      committed_in_free_chunks +
+      free_blocks_cap_words;
+  out->print("                       -total-: ");
+  print_scaled_words_and_percentage(out, total_waste, committed_words, scale, 6);
+  out->cr();
+
+  // Also print chunk header pool size.
+  out->cr();
+  out->print("chunk header pool: %u items, ", ChunkHeaderPool::pool()->used());
+  print_scaled_words(out, ChunkHeaderPool::pool()->memory_footprint_words(), scale);
+  out->print(".");
+  out->cr();
+
+  // Print internal statistics
+  out->cr();
+  out->print_cr("Internal statistics:");
+  out->cr();
+  InternalStats::print_on(out);
+  out->cr();
+
+  // Print some interesting settings
+  out->cr();
+  out->print_cr("Settings:");
+  print_settings(out, scale);
+
+  out->cr();
+  out->cr();
+
+  DEBUG_ONLY(MetaspaceUtils::verify();)
+
+} // MetaspaceUtils::print_report()
+
+} // namespace metaspace
+
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msReport.hpp	2020-09-04 13:58:03.785442112 +0200
@@ -0,0 +1,64 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#ifndef SHARE_MEMORY_METASPACE_MSREPORT_HPP
+#define SHARE_MEMORY_METASPACE_MSREPORT_HPP
+
+#include "memory/allocation.hpp"
+
+namespace metaspace {
+
+class MetaspaceReporter : public AllStatic {
+public:
+
+  // Flags for print_report().
+  enum class Option {
+    // Show usage by class loader.
+    ShowLoaders                 = (1 << 0),
+    // Breaks report down by chunk type (small, medium, ...).
+    BreakDownByChunkType        = (1 << 1),
+    // Breaks report down by space type (anonymous, reflection, ...).
+    BreakDownBySpaceType        = (1 << 2),
+    // Print details about the underlying virtual spaces.
+    ShowVSList                  = (1 << 3),
+    // If show_loaders: show loaded classes for each loader.
+    ShowClasses                 = (1 << 4)
+  };
+
+  // This will print out a basic metaspace usage report but
+  // unlike print_report() is guaranteed not to lock or to walk the CLDG.
+  static void print_basic_report(outputStream* st, size_t scale);
+
+  // Prints a report about the current metaspace state.
+  // Optional parts can be enabled via flags.
+  // Function will walk the CLDG and will lock the expand lock; if that is not
+  // convenient, use print_basic_report() instead.
+  static void print_report(outputStream* out, size_t scale = 0, int flags = 0);
+
+};
+
+} // namespace metaspace
+
+#endif // SHARE_MEMORY_METASPACE_MSREPORT_HPP
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msRootChunkArea.cpp	2020-09-04 13:58:04.349445965 +0200
@@ -0,0 +1,560 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+
+#include "logging/log.hpp"
+#include "memory/allocation.hpp"
+#include "memory/metaspace/msChunkHeaderPool.hpp"
+#include "memory/metaspace/msChunkManager.hpp"
+#include "memory/metaspace/msCommon.hpp"
+#include "memory/metaspace/msFreeChunkList.hpp"
+#include "memory/metaspace/msMetachunk.hpp"
+#include "memory/metaspace/msRootChunkArea.hpp"
+#include "runtime/mutexLocker.hpp"
+#include "utilities/debug.hpp"
+#include "utilities/globalDefinitions.hpp"
+
+namespace metaspace {
+
+RootChunkArea::RootChunkArea(const MetaWord* base)
+  : _base(base), _first_chunk(NULL)
+{}
+
+RootChunkArea::~RootChunkArea() {
+  // This is called when a VirtualSpaceNode is destructed (purged).
+  // All chunks should be free of course. In fact, there should only
+  // be one chunk, since all free chunks should have been merged.
+  if (_first_chunk != NULL) {
+    assert(_first_chunk->is_root_chunk() && _first_chunk->is_free(),
+           "Cannot delete root chunk area if not all chunks are free.");
+    ChunkHeaderPool::pool()->return_chunk_header(_first_chunk);
+  }
+}
+
+// Initialize: allocate a root node and a root chunk header; return the
+// root chunk header. It will be partly initialized.
+// Note: this just allocates a memory-less header; memory itself is allocated inside VirtualSpaceNode.
+Metachunk* RootChunkArea::alloc_root_chunk_header(VirtualSpaceNode* node) {
+
+  assert(_first_chunk == 0, "already have a root");
+
+  Metachunk* c = ChunkHeaderPool::pool()->allocate_chunk_header();
+  c->initialize(node, const_cast<MetaWord*>(_base), chunklevel::ROOT_CHUNK_LEVEL);
+
+  _first_chunk = c;
+
+  return c;
+
+}
+
+// Given a chunk c, split it recursively until you get a chunk of the given target_level.
+//
+// The resulting target chunk resides at the same address as the original chunk.
+// The resulting splinters are added to freelists.
+//
+// Returns pointer to the result chunk; the splitted-off chunks are added as
+//  free chunks to the freelists.
+void RootChunkArea::split(chunklevel_t target_level, Metachunk* c, FreeChunkListVector* freelists) {
+
+  // Splitting a chunk once works like this:
+  //
+  // For a given chunk we want to split:
+  // - increase the chunk level (which halves its size)
+  // - (but leave base address as it is since it will be the leader of the newly
+  //    created chunk pair)
+  // - then create a new chunk header of the same level, set its memory range
+  //   to cover the second halfof the old chunk.
+  // - wire them up (prev_in_vs/next_in_vs)
+  // - return the follower chunk as "splinter chunk" in the splinters array.
+
+  // Doing this multiple times will create a new free splinter chunk for every
+  // level we split:
+  //
+  // A  <- original chunk
+  //
+  // B B  <- split into two halves
+  //
+  // C C B  <- first half split again
+  //
+  // D D C B  <- first half split again ...
+  //
+
+  // As an optimization, since we usually do not split once but multiple times,
+  // to not do each split separately, since we would have to wire up prev_in_vs/next_in_vs
+  // on every level just to tear it open in the next level when we reintroduce a new
+  // half chunk splinter.
+  // Instead, just split split split and delay building up the double linked list of the
+  // new chunks at the end of all splits.
+
+  DEBUG_ONLY(check_pointer(c->base());)
+  DEBUG_ONLY(c->verify();)
+  assert(c->is_free(), "Can only split free chunks.");
+
+  DEBUG_ONLY(chunklevel::check_valid_level(target_level));
+  assert(target_level > c->level(), "Wrong target level");
+
+  const chunklevel_t starting_level = c->level();
+
+  while (c->level() < target_level) {
+
+    log_trace(metaspace)("Splitting chunk: " METACHUNK_FULL_FORMAT ".", METACHUNK_FULL_FORMAT_ARGS(c));
+
+    c->inc_level();
+    Metachunk* splinter_chunk = ChunkHeaderPool::pool()->allocate_chunk_header();
+    splinter_chunk->initialize(c->vsnode(), c->end(), c->level());
+
+    // Fix committed words info: If over the half of the original chunk was
+    // committed, committed area spills over into the follower chunk.
+    const size_t old_committed_words = c->committed_words();
+    if (old_committed_words > c->word_size()) {
+      c->set_committed_words(c->word_size());
+      splinter_chunk->set_committed_words(old_committed_words - c->word_size());
+    } else {
+      splinter_chunk->set_committed_words(0);
+    }
+
+    // Insert splinter chunk into vs list
+    if (c->next_in_vs() != NULL) {
+      c->next_in_vs()->set_prev_in_vs(splinter_chunk);
+    }
+    splinter_chunk->set_next_in_vs(c->next_in_vs());
+    splinter_chunk->set_prev_in_vs(c);
+    c->set_next_in_vs(splinter_chunk);
+
+    log_trace(metaspace)(".. Result chunk: " METACHUNK_FULL_FORMAT ".", METACHUNK_FULL_FORMAT_ARGS(c));
+    log_trace(metaspace)(".. Splinter chunk: " METACHUNK_FULL_FORMAT ".", METACHUNK_FULL_FORMAT_ARGS(splinter_chunk));
+
+    // Add splinter to free lists
+    freelists->add(splinter_chunk);
+
+  }
+
+  assert(c->level() == target_level, "Sanity");
+
+  DEBUG_ONLY(verify();)
+  DEBUG_ONLY(c->verify();)
+
+}
+
+// Given a chunk, attempt to merge it recursively with its neighboring chunks.
+//
+// If successful (merged at least once), returns address of
+// the merged chunk; NULL otherwise.
+//
+// The merged chunks are removed from the freelists.
+//
+// !!! Please note that if this method returns a non-NULL value, the
+// original chunk will be invalid and should not be accessed anymore! !!!
+Metachunk* RootChunkArea::merge(Metachunk* c, FreeChunkListVector* freelists) {
+
+  // Note rules:
+  //
+  // - a chunk always has a buddy, unless it is a root chunk.
+  // - In that buddy pair, a chunk is either leader or follower.
+  // - a chunk's base address is always aligned at its size.
+  // - if chunk is leader, its base address is also aligned to the size of the next
+  //   lower level, at least. A follower chunk is not.
+
+  // How we merge once:
+  //
+  // For a given chunk c, which has to be free and non-root, we do:
+  // - find out if we are the leader or the follower chunk
+  // - if we are leader, next_in_vs must be the follower; if we are follower,
+  //   prev_in_vs must be the leader. Now we have the buddy chunk.
+  // - However, if the buddy chunk itself is split (of a level higher than us)
+  //   we cannot merge.
+  // - we can only merge if the buddy is of the same level as we are and it is
+  //   free.
+  // - Then we merge by simply removing the follower chunk from the address range
+  //   linked list (returning the now useless header to the pool) and decreasing
+  //   the leader chunk level by one. That makes it double the size.
+
+  // Example:
+  // (lower case chunks are free, the * indicates the chunk we want to merge):
+  //
+  // ........................
+  // d d*c   b       A           <- we return the second (d*) chunk...
+  //
+  // c*  c   b       A           <- we merge it with its predecessor and decrease its level...
+  //
+  // b*      b       A           <- we merge it again, since its new neighbor was free too...
+  //
+  // a*              A           <- we merge it again, since its new neighbor was free too...
+  //
+  // And we are done, since its new neighbor, (A), is not free. We would also be done
+  // if the new neighbor itself is splintered.
+
+  DEBUG_ONLY(check_pointer(c->base());)
+  assert(!c->is_root_chunk(), "Cannot be merged further.");
+  assert(c->is_free(), "Can only merge free chunks.");
+
+  DEBUG_ONLY(c->verify();)
+
+  log_trace(metaspace)("Attempting to merge chunk " METACHUNK_FORMAT ".", METACHUNK_FORMAT_ARGS(c));
+
+  const chunklevel_t starting_level = c->level();
+
+  bool stop = false;
+  Metachunk* result = NULL;
+
+  do {
+
+    // First find out if this chunk is the leader of its pair
+    const bool is_leader = c->is_leader();
+
+    // Note: this is either our buddy or a splinter of the buddy.
+    Metachunk* const buddy = c->is_leader() ? c->next_in_vs() : c->prev_in_vs();
+    DEBUG_ONLY(buddy->verify();)
+
+    // A buddy chunk must be of the same or higher level (so, same size or smaller)
+    // never be larger.
+    assert(buddy->level() >= c->level(), "Sanity");
+
+    // Is this really my buddy (same level) or a splinter of it (higher level)?
+    // Also, is it free?
+    if (buddy->level() != c->level() || buddy->is_free() == false) {
+
+      log_trace(metaspace)("cannot merge with chunk " METACHUNK_FORMAT ".", METACHUNK_FORMAT_ARGS(buddy));
+
+      stop = true;
+
+    } else {
+
+      log_trace(metaspace)("will merge with chunk " METACHUNK_FORMAT ".", METACHUNK_FORMAT_ARGS(buddy));
+
+      // We can merge with the buddy.
+
+      // First, remove buddy from the chunk manager.
+      assert(buddy->is_free(), "Sanity");
+      freelists->remove(buddy);
+
+      // Determine current leader and follower
+      Metachunk* leader;
+      Metachunk* follower;
+      if (is_leader) {
+        leader = c; follower = buddy;
+      } else {
+        leader = buddy; follower = c;
+      }
+
+      // Last checkpoint
+      assert(leader->end() == follower->base() &&
+             leader->level() == follower->level() &&
+             leader->is_free() && follower->is_free(), "Sanity");
+
+      // The new merged chunk is as far committed as possible (if leader
+      // chunk is fully committed, as far as the follower chunk).
+      size_t merged_committed_words = leader->committed_words();
+      if (merged_committed_words == leader->word_size()) {
+        merged_committed_words += follower->committed_words();
+      }
+
+      // Leader survives, follower chunk is freed. Remove follower from vslist ..
+      leader->set_next_in_vs(follower->next_in_vs());
+      if (follower->next_in_vs() != NULL) {
+        follower->next_in_vs()->set_prev_in_vs(leader);
+      }
+
+      // .. and return follower chunk header to pool for reuse.
+      ChunkHeaderPool::pool()->return_chunk_header(follower);
+
+      // Leader level gets decreased (leader chunk doubles in size) but
+      // base address stays the same.
+      leader->dec_level();
+
+      // set commit boundary
+      leader->set_committed_words(merged_committed_words);
+
+      // If the leader is now of root chunk size, stop merging
+      if (leader->is_root_chunk()) {
+        stop = true;
+      }
+
+      result = c = leader;
+
+      DEBUG_ONLY(leader->verify();)
+
+    }
+
+  } while (!stop);
+
+#ifdef ASSERT
+  verify();
+  if (result != NULL) {
+    result->verify();
+  }
+#endif // ASSERT
+
+  return result;
+
+}
+
+// Given a chunk c, which must be "in use" and must not be a root chunk, attempt to
+// enlarge it in place by claiming its trailing buddy.
+//
+// This will only work if c is the leader of the buddy pair and the trailing buddy is free.
+//
+// If successful, the follower chunk will be removed from the freelists, the leader chunk c will
+// double in size (level decreased by one).
+//
+// On success, true is returned, false otherwise.
+bool RootChunkArea::attempt_enlarge_chunk(Metachunk* c, FreeChunkListVector* freelists) {
+
+  DEBUG_ONLY(check_pointer(c->base());)
+  assert(!c->is_root_chunk(), "Cannot be merged further.");
+
+  // There is no real reason for this limitation other than it is not
+  // needed on free chunks since they should be merged already:
+  assert(c->is_in_use(), "Can only enlarge in use chunks.");
+
+  DEBUG_ONLY(c->verify();)
+
+  if (!c->is_leader()) {
+    return false;
+  }
+
+  // We are the leader, so the buddy must follow us.
+  Metachunk* const buddy = c->next_in_vs();
+  DEBUG_ONLY(buddy->verify();)
+
+  // Of course buddy cannot be larger than us.
+  assert(buddy->level() >= c->level(), "Sanity");
+
+  // We cannot merge buddy in if it is not free...
+  if (!buddy->is_free()) {
+    return false;
+  }
+
+  // ... nor if it is splintered.
+  if (buddy->level() != c->level()) {
+    return false;
+  }
+
+  // Okay, lets enlarge c.
+
+  log_trace(metaspace)("Enlarging chunk " METACHUNK_FULL_FORMAT " by merging in follower " METACHUNK_FULL_FORMAT ".",
+                       METACHUNK_FULL_FORMAT_ARGS(c), METACHUNK_FULL_FORMAT_ARGS(buddy));
+
+  // the enlarged c is as far committed as possible:
+  size_t merged_committed_words = c->committed_words();
+  if (merged_committed_words == c->word_size()) {
+    merged_committed_words += buddy->committed_words();
+  }
+
+  // Remove buddy from vs list...
+  Metachunk* successor = buddy->next_in_vs();
+  if (successor != NULL) {
+    successor->set_prev_in_vs(c);
+  }
+  c->set_next_in_vs(successor);
+
+  // .. and from freelist ...
+  freelists->remove(buddy);
+
+  // .. and return its empty husk to the pool...
+  ChunkHeaderPool::pool()->return_chunk_header(buddy);
+
+  // Then decrease level of c.
+  c->dec_level();
+
+  // and correct committed words if needed.
+  c->set_committed_words(merged_committed_words);
+
+  log_debug(metaspace)("Enlarged chunk " METACHUNK_FULL_FORMAT ".", METACHUNK_FULL_FORMAT_ARGS(c));
+//  log_debug(metaspace)("Enlarged chunk " METACHUNK_FORMAT ".", METACHUNK_FORMAT_ARGS(c));
+
+  DEBUG_ONLY(verify());
+
+  return true;
+
+}
+
+// Returns true if this root chunk area is completely free:
+//  In that case, it should only contain one chunk (maximally merged, so a root chunk)
+//  and it should be free.
+bool RootChunkArea::is_free() const {
+  return _first_chunk == NULL ||
+      (_first_chunk->is_root_chunk() && _first_chunk->is_free());
+}
+
+#ifdef ASSERT
+
+#define assrt_(cond, ...) \
+  if (!(cond)) { \
+    fdStream errst(2); \
+    this->print_on(&errst); \
+    vmassert(cond, __VA_ARGS__); \
+  }
+
+void RootChunkArea::verify() const {
+
+  assert_lock_strong(MetaspaceExpand_lock);
+  assert_is_aligned(_base, chunklevel::MAX_CHUNK_BYTE_SIZE);
+
+  // Iterate thru all chunks in this area. They must be ordered correctly,
+  // being adjacent to each other, and cover the complete area
+  int num_chunk = 0;
+
+  if (_first_chunk != NULL) {
+
+    assrt_(_first_chunk->prev_in_vs() == NULL, "Sanity");
+
+    const Metachunk* c = _first_chunk;
+    const MetaWord* expected_next_base = _base;
+    const MetaWord* const area_end = _base + word_size();
+
+    while (c != NULL) {
+
+      assrt_(c->is_free() || c->is_in_use(),
+          "Chunk No. %d " METACHUNK_FORMAT " - invalid state.",
+          num_chunk, METACHUNK_FORMAT_ARGS(c));
+
+      assrt_(c->base() == expected_next_base,
+             "Chunk No. %d " METACHUNK_FORMAT " - unexpected base.",
+             num_chunk, METACHUNK_FORMAT_ARGS(c));
+
+      assrt_(c->base() >= base() && c->end() <= end(),
+             "chunk %d " METACHUNK_FORMAT " oob for this root area [" PTR_FORMAT ".." PTR_FORMAT ").",
+             num_chunk, METACHUNK_FORMAT_ARGS(c), p2i(base()), p2i(end()));
+
+      assrt_(is_aligned(c->base(), c->word_size()),
+             "misaligned chunk %d " METACHUNK_FORMAT ".", num_chunk, METACHUNK_FORMAT_ARGS(c));
+
+      c->verify_neighborhood();
+      c->verify();
+
+      expected_next_base = c->end();
+      num_chunk++;
+
+      c = c->next_in_vs();
+
+    }
+    assrt_(expected_next_base == _base + word_size(), "Sanity");
+  }
+
+}
+
+void RootChunkArea::verify_area_is_ideally_merged() const {
+
+  SOMETIMES(assert_lock_strong(MetaspaceExpand_lock);)
+
+  int num_chunk = 0;
+  for (const Metachunk* c = _first_chunk; c != NULL; c = c->next_in_vs()) {
+    if (!c->is_root_chunk() && c->is_free()) {
+      // If a chunk is free, it must not have a buddy which is also free, because
+      // those chunks should have been merged.
+      // In other words, a buddy shall be either in-use or splintered
+      // (which in turn would mean part of it are in use).
+      Metachunk* const buddy = c->is_leader() ? c->next_in_vs() : c->prev_in_vs();
+      assrt_(buddy->is_in_use() || buddy->level() > c->level(),
+             "Chunk No. %d " METACHUNK_FORMAT " : missed merge opportunity with neighbor " METACHUNK_FORMAT ".",
+             num_chunk, METACHUNK_FORMAT_ARGS(c), METACHUNK_FORMAT_ARGS(buddy));
+    }
+    num_chunk++;
+  }
+}
+
+#endif
+
+void RootChunkArea::print_on(outputStream* st) const {
+
+  st->print(PTR_FORMAT ": ", p2i(base()));
+  if (_first_chunk != NULL) {
+    const Metachunk* c = _first_chunk;
+    //                                    01234567890123
+    const char* letters_for_levels_cap = "ABCDEFGHIJKLMNOPQRSTUVWXYZ";
+    const char* letters_for_levels =     "abcdefghijklmnopqrstuvwxyz";
+    while (c != NULL) {
+      const chunklevel_t l = c->level();
+      if (l >= 0 && (size_t)l < strlen(letters_for_levels)) {
+//        c->print_on(st); st->cr();
+        st->print("%c", c->is_free() ? letters_for_levels[c->level()] : letters_for_levels_cap[c->level()]);
+      } else {
+        // Obviously garbage, but lets not crash.
+        st->print("?");
+      }
+      c = c->next_in_vs();
+    }
+  } else {
+    st->print(" (no chunks)");
+  }
+  st->cr();
+
+}
+
+// Create an array of ChunkTree objects, all initialized to NULL, covering
+// a given memory range. Memory range must be a multiple of root chunk size.
+RootChunkAreaLUT::RootChunkAreaLUT(const MetaWord* base, size_t word_size)
+  : _base(base),
+    _num((int)(word_size / chunklevel::MAX_CHUNK_WORD_SIZE)),
+    _arr(NULL)
+{
+  assert_is_aligned(word_size, chunklevel::MAX_CHUNK_WORD_SIZE);
+  _arr = NEW_C_HEAP_ARRAY(RootChunkArea, _num, mtClass);
+  const MetaWord* this_base = _base;
+  for (int i = 0; i < _num; i++) {
+    RootChunkArea* rca = new(_arr + i) RootChunkArea(this_base);
+    assert(rca == _arr + i, "Sanity");
+    this_base += chunklevel::MAX_CHUNK_WORD_SIZE;
+  }
+}
+
+RootChunkAreaLUT::~RootChunkAreaLUT() {
+  for (int i = 0; i < _num; i++) {
+    _arr[i].~RootChunkArea();
+  }
+  FREE_C_HEAP_ARRAY(RootChunkArea, _arr);
+}
+
+// Returns true if all areas in this area table are free (only contain free chunks).
+bool RootChunkAreaLUT::is_free() const {
+  for (int i = 0; i < _num; i++) {
+    if (!_arr[i].is_free()) {
+      return false;
+    }
+  }
+  return true;
+}
+
+#ifdef ASSERT
+
+void RootChunkAreaLUT::verify() const {
+  for (int i = 0; i < _num; i++) {
+    check_pointer(_arr[i].base());
+    _arr[i].verify();
+  }
+}
+
+#endif
+
+void RootChunkAreaLUT::print_on(outputStream* st) const {
+  for (int i = 0; i < _num; i++) {
+    st->print("%2d:", i);
+    _arr[i].print_on(st);
+  }
+}
+
+} // end: namespace metaspace
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msRootChunkArea.hpp	2020-09-04 13:58:05.185451681 +0200
@@ -0,0 +1,207 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#ifndef SHARE_MEMORY_METASPACE_MSROOTCHUNKAREA_HPP
+#define SHARE_MEMORY_METASPACE_MSROOTCHUNKAREA_HPP
+
+#include "memory/allocation.hpp"
+#include "memory/metaspace/msChunklevel.hpp"
+#include "utilities/debug.hpp"
+#include "utilities/globalDefinitions.hpp"
+
+class outputStream;
+
+namespace metaspace {
+
+class Metachunk;
+class MetachunkClosure;
+class FreeChunkListVector;
+class VirtualSpaceNode;
+
+// RootChunkArea manages a memory area covering a single root chunk.
+//
+// Such an area may contain a single root chunk, or a number of chunks the
+//  root chunk was split into.
+//
+// RootChunkArea contains the functionality to merge and split chunks in
+//  buddy allocator fashion.
+//
+
+class RootChunkArea {
+
+  // The base address of this area.
+  // Todo: this may be somewhat superfluous since RootChunkArea only exist in the
+  //  context of a series of chunks, so the address is somewhat implicit. Remove?
+  const MetaWord* const _base;
+
+  // The first chunk in this area; if this area is maximally
+  // folded, this is the root chunk covering the whole area size.
+  Metachunk* _first_chunk;
+
+public:
+
+  RootChunkArea(const MetaWord* base);
+  ~RootChunkArea();
+
+  // Initialize: allocate a root node and a root chunk header; return the
+  // root chunk header. It will be partly initialized.
+  // Note: this just allocates a memory-less header; memory itself is allocated inside VirtualSpaceNode.
+  Metachunk* alloc_root_chunk_header(VirtualSpaceNode* node);
+
+  // Given a chunk c, split it recursively until you get a chunk of the given target_level.
+  //
+  // The resulting target chunk resides at the same address as the original chunk.
+  // The resulting splinters are added to freelists.
+  //
+  // Returns pointer to the result chunk; the splitted-off chunks are added as
+  //  free chunks to the freelists.
+  void split(chunklevel_t target_level, Metachunk* c, FreeChunkListVector* freelists);
+
+  // Given a chunk, attempt to merge it recursively with its neighboring chunks.
+  //
+  // If successful (merged at least once), returns address of
+  // the merged chunk; NULL otherwise.
+  //
+  // The merged chunks are removed from the freelists.
+  //
+  // !!! Please note that if this method returns a non-NULL value, the
+  // original chunk will be invalid and should not be accessed anymore! !!!
+  Metachunk* merge(Metachunk* c, FreeChunkListVector* freelists);
+
+  // Given a chunk c, which must be "in use" and must not be a root chunk, attempt to
+  // enlarge it in place by claiming its trailing buddy.
+  //
+  // This will only work if c is the leader of the buddy pair and the trailing buddy is free.
+  //
+  // If successful, the follower chunk will be removed from the freelists, the leader chunk c will
+  // double in size (level decreased by one).
+  //
+  // On success, true is returned, false otherwise.
+  bool attempt_enlarge_chunk(Metachunk* c, FreeChunkListVector* freelists);
+
+  /// range ///
+
+  const MetaWord* base() const  { return _base; }
+  size_t word_size() const      { return chunklevel::MAX_CHUNK_WORD_SIZE; }
+  const MetaWord* end() const   { return _base + word_size(); }
+
+  // Direct access to the first chunk (use with care)
+  Metachunk* first_chunk()              { return _first_chunk; }
+  const Metachunk* first_chunk() const  { return _first_chunk; }
+
+  // Returns true if this root chunk area is completely free:
+  //  In that case, it should only contain one chunk (maximally merged, so a root chunk)
+  //  and it should be free.
+  bool is_free() const;
+
+  //// Debug stuff ////
+
+#ifdef ASSERT
+  void check_pointer(const MetaWord* p) const {
+    assert(p >= _base && p < _base + word_size(),
+           "pointer " PTR_FORMAT " oob for this root area [" PTR_FORMAT ".." PTR_FORMAT ")",
+           p2i(p), p2i(_base), p2i(_base + word_size()));
+  }
+  void verify() const;
+
+  // This is a separate operation from verify(). We should be able to call verify()
+  // from almost anywhere, regardless of state, but verify_area_is_ideally_merged()
+  // can only be called outside split and merge ops.
+  void verify_area_is_ideally_merged() const;
+#endif // ASSERT
+
+  void print_on(outputStream* st) const;
+
+};
+
+// RootChunkAreaLUT (lookup table) manages a series of contiguous root chunk areas
+//  in memory (in the context of a VirtualSpaceNode). It allows finding the containing
+//  root chunk for any given memory address. It allows for easy iteration over all
+//  root chunks.
+// Beyond that it is unexciting.
+class RootChunkAreaLUT {
+
+  // Base address of the whole area.
+  const MetaWord* const _base;
+
+  // Number of root chunk areas.
+  const int _num;
+
+  // Array of RootChunkArea objects.
+  RootChunkArea* _arr;
+
+#ifdef ASSERT
+  void check_pointer(const MetaWord* p) const {
+    assert(p >= base() && p < base() + word_size(), "Invalid pointer");
+  }
+#endif
+
+  // Given an address into this range, return the index into the area array for the
+  // area this address falls into.
+  int index_by_address(const MetaWord* p) const {
+    DEBUG_ONLY(check_pointer(p);)
+    int idx = (int)((p - base()) / chunklevel::MAX_CHUNK_WORD_SIZE);
+    assert(idx >= 0 && idx < _num, "Sanity");
+    return idx;
+  }
+
+public:
+
+  RootChunkAreaLUT(const MetaWord* base, size_t word_size);
+  ~RootChunkAreaLUT();
+
+  // Given a memory address into the range this array covers, return the
+  // corresponding area object. If none existed at this position, create it
+  // on demand.
+  RootChunkArea* get_area_by_address(const MetaWord* p) const {
+    const int idx = index_by_address(p);
+    RootChunkArea* ra = _arr + idx;
+    DEBUG_ONLY(ra->check_pointer(p);)
+    return _arr + idx;
+  }
+
+  // Access area by its index
+  int number_of_areas() const                               { return _num; }
+  RootChunkArea* get_area_by_index(int index)               { assert(index >= 0 && index < _num, "oob"); return _arr + index; }
+  const RootChunkArea* get_area_by_index(int index) const   { assert(index >= 0 && index < _num, "oob"); return _arr + index; }
+
+  /// range ///
+
+  const MetaWord* base() const  { return _base; }
+  size_t word_size() const      { return _num * chunklevel::MAX_CHUNK_WORD_SIZE; }
+  const MetaWord* end() const   { return _base + word_size(); }
+
+  // Returns true if all areas in this area table are free (only contain free chunks).
+  bool is_free() const;
+
+  DEBUG_ONLY(void verify() const;)
+
+  void print_on(outputStream* st) const;
+
+};
+
+} // namespace metaspace
+
+#endif // SHARE_MEMORY_METASPACE_MSROOTCHUNKAREA_HPP
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msRunningCounters.cpp	2020-09-04 13:58:05.893456525 +0200
@@ -0,0 +1,97 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+#include "memory/metaspace/msChunkManager.hpp"
+#include "memory/metaspace/msCounter.hpp"
+#include "memory/metaspace/msRunningCounters.hpp"
+#include "memory/metaspace/msVirtualSpaceList.hpp"
+
+namespace metaspace {
+
+SizeAtomicCounter RunningCounters::_used_class_counter;
+SizeAtomicCounter RunningCounters::_used_nonclass_counter;
+
+// Return reserved size, in words, for Metaspace
+size_t RunningCounters::reserved_words() {
+  return reserved_words_class() + reserved_words_nonclass();
+}
+
+size_t RunningCounters::reserved_words_class() {
+  VirtualSpaceList* vs = VirtualSpaceList::vslist_class();
+  return vs != NULL ? vs->reserved_words() : 0;
+}
+
+size_t RunningCounters::reserved_words_nonclass() {
+  return VirtualSpaceList::vslist_nonclass()->reserved_words();
+}
+
+// Return total committed size, in words, for Metaspace
+size_t RunningCounters::committed_words() {
+  return committed_words_class() + committed_words_nonclass();
+}
+
+size_t RunningCounters::committed_words_class() {
+  VirtualSpaceList* vs = VirtualSpaceList::vslist_class();
+  return vs != NULL ? vs->committed_words() : 0;
+}
+
+size_t RunningCounters::committed_words_nonclass() {
+  return VirtualSpaceList::vslist_nonclass()->committed_words();
+}
+
+// ---- used chunks -----
+
+// Returns size, in words, used for metadata.
+size_t RunningCounters::used_words() {
+  return used_words_class() + used_words_nonclass();
+}
+
+size_t RunningCounters::used_words_class() {
+  return _used_class_counter.get();
+}
+
+size_t RunningCounters::used_words_nonclass() {
+  return _used_nonclass_counter.get();
+}
+
+// ---- free chunks -----
+
+// Returns size, in words, of all chunks in all freelists.
+size_t RunningCounters::free_chunks_words() {
+  return free_chunks_words_class() + free_chunks_words_nonclass();
+}
+
+size_t RunningCounters::free_chunks_words_class() {
+  ChunkManager* cm = ChunkManager::chunkmanager_class();
+  return cm != NULL ? cm->total_word_size() : 0;
+}
+
+size_t RunningCounters::free_chunks_words_nonclass() {
+  return ChunkManager::chunkmanager_nonclass()->total_word_size();
+}
+
+} // namespace metaspace
+
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msRunningCounters.hpp	2020-09-04 13:58:06.457460387 +0200
@@ -0,0 +1,77 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#ifndef SHARE_MEMORY_METASPACE_MSRUNNINGCOUNTERS_HPP
+#define SHARE_MEMORY_METASPACE_MSRUNNINGCOUNTERS_HPP
+
+#include "memory/allocation.hpp"
+#include "memory/metaspace/msCounter.hpp"
+
+namespace metaspace {
+
+// This class is a convenience interface for accessing global metaspace counters.
+class RunningCounters : public AllStatic {
+
+  static SizeAtomicCounter _used_class_counter;
+  static SizeAtomicCounter _used_nonclass_counter;
+
+public:
+
+  // ---- virtual memory -----
+
+  // Return reserved size, in words, for Metaspace
+  static size_t reserved_words();
+  static size_t reserved_words_class();
+  static size_t reserved_words_nonclass();
+
+  // Return total committed size, in words, for Metaspace
+  static size_t committed_words();
+  static size_t committed_words_class();
+  static size_t committed_words_nonclass();
+
+  // ---- used chunks -----
+
+  // Returns size, in words, used for metadata.
+  static size_t used_words();
+  static size_t used_words_class();
+  static size_t used_words_nonclass();
+
+  // ---- free chunks -----
+
+  // Returns size, in words, of all chunks in all freelists.
+  static size_t free_chunks_words();
+  static size_t free_chunks_words_class();
+  static size_t free_chunks_words_nonclass();
+
+  // Direct access to the counters.
+  static SizeAtomicCounter* used_nonclass_counter()     { return &_used_nonclass_counter; }
+  static SizeAtomicCounter* used_class_counter()        { return &_used_class_counter; }
+
+};
+
+} // namespace metaspace
+
+#endif // SHARE_MEMORY_METASPACE_MSRUNNINGCOUNTERS_HPP
+
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msSettings.cpp	2020-09-04 13:58:07.009464168 +0200
@@ -0,0 +1,136 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+
+#include "logging/log.hpp"
+#include "logging/logStream.hpp"
+
+#include "memory/metaspace/msSettings.hpp"
+
+#include "runtime/java.hpp"
+#include "utilities/globalDefinitions.hpp"
+#include "utilities/debug.hpp"
+
+namespace metaspace {
+
+size_t Settings::_commit_granule_bytes = 0;
+size_t Settings::_commit_granule_words = 0;
+
+bool Settings::_new_chunks_are_fully_committed = false;
+bool Settings::_uncommit_free_chunks = false;
+
+DEBUG_ONLY(bool Settings::_use_allocation_guard = false;)
+DEBUG_ONLY(bool Settings::_handle_deallocations = true;)
+
+void Settings::ergo_initialize() {
+
+  if (strcmp(MetaspaceReclaimPolicy, "none") == 0) {
+
+    log_info(metaspace)("Initialized with strategy: no reclaim.");
+
+    _commit_granule_bytes = MAX2((size_t)os::vm_page_size(), 64 * K);
+    _commit_granule_words = _commit_granule_bytes / BytesPerWord;
+
+    // In "none" reclamation mode, we do not uncommit, and we commit new chunks fully;
+    // that very closely mimicks the behaviour of old Metaspace.
+    _new_chunks_are_fully_committed = true;
+    _uncommit_free_chunks = false;
+
+  } else if (strcmp(MetaspaceReclaimPolicy, "aggressive") == 0) {
+
+    log_info(metaspace)("Initialized with strategy: aggressive reclaim.");
+
+    // Set the granule size rather small; may increase
+    // mapping fragmentation but also increase chance to uncommit.
+    _commit_granule_bytes = MAX2((size_t)os::vm_page_size(), 16 * K);
+    _commit_granule_words = _commit_granule_bytes / BytesPerWord;
+
+    _new_chunks_are_fully_committed = false;
+    _uncommit_free_chunks = true;
+
+  } else if (strcmp(MetaspaceReclaimPolicy, "balanced") == 0) {
+
+    log_info(metaspace)("Initialized with strategy: balanced reclaim.");
+
+    _commit_granule_bytes = MAX2((size_t)os::vm_page_size(), 64 * K);
+    _commit_granule_words = _commit_granule_bytes / BytesPerWord;
+
+    _new_chunks_are_fully_committed = false;
+    _uncommit_free_chunks = true;
+
+  } else {
+
+    vm_exit_during_initialization("Invalid value for MetaspaceReclaimPolicy: \"%s\".", MetaspaceReclaimPolicy);
+
+  }
+
+  // Sanity checks.
+  assert(commit_granule_words() <= chunklevel::MAX_CHUNK_WORD_SIZE, "Too large granule size");
+  assert(is_power_of_2(commit_granule_words()), "granule size must be a power of 2");
+
+  // Should always be true since root chunk size should be much larger than alloc granularity
+  assert(is_aligned(VirtualSpaceNodeReserveAlignmentWordSize * BytesPerWord,
+                    os::vm_allocation_granularity()), "Sanity");
+
+#ifdef ASSERT
+  // Off for release builds, and by default for debug builds, but can be switched on manually to aid
+  // error analysis.
+  _use_allocation_guard = MetaspaceGuardAllocations;
+
+  // Deallocations can be manually switched off to aid error analysis, since this removes one layer of complexity
+  //  from allocation.
+  _handle_deallocations = MetaspaceHandleDeallocations;
+
+  // We also switch it off automatically if we use allocation guards. This is to keep prefix handling in MetaspaceArena simple.
+  if (_use_allocation_guard) {
+    _handle_deallocations = false;
+  }
+#endif
+
+  LogStream ls(Log(metaspace)::info());
+  Settings::print_on(&ls);
+
+}
+
+void Settings::print_on(outputStream* st) {
+
+  st->print_cr(" - commit_granule_bytes: " SIZE_FORMAT ".", commit_granule_bytes());
+  st->print_cr(" - commit_granule_words: " SIZE_FORMAT ".", commit_granule_words());
+
+  st->print_cr(" - virtual_space_node_default_size: " SIZE_FORMAT ".", virtual_space_node_default_word_size());
+
+  st->print_cr(" - enlarge_chunks_in_place: %d.", (int)enlarge_chunks_in_place());
+
+  st->print_cr(" - new_chunks_are_fully_committed: %d.", (int)new_chunks_are_fully_committed());
+  st->print_cr(" - uncommit_free_chunks: %d.", (int)uncommit_free_chunks());
+
+  st->print_cr(" - use_allocation_guard: %d.", (int)use_allocation_guard());
+  st->print_cr(" - handle_deallocations: %d.", (int)handle_deallocations());
+
+}
+
+} // namespace metaspace
+
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msSettings.hpp	2020-09-04 13:58:07.561467953 +0200
@@ -0,0 +1,90 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#ifndef SHARE_MEMORY_METASPACE_MSSETTINGS_HPP
+#define SHARE_MEMORY_METASPACE_MSSETTINGS_HPP
+
+#include "memory/allocation.hpp"
+#include "memory/metaspace/msChunklevel.hpp"
+#include "utilities/globalDefinitions.hpp"
+
+namespace metaspace {
+
+class Settings : public AllStatic {
+
+  // Granularity, in bytes, metaspace is committed with.
+  static size_t _commit_granule_bytes;
+
+  // Granularity, in words, metaspace is committed with.
+  static size_t _commit_granule_words;
+
+  // The default size of a non-class VirtualSpaceNode (unless created differently).
+  // Must be a multiple of the root chunk size.
+  static const size_t VirtualSpaceNodeDefaultWordSize = chunklevel::MAX_CHUNK_WORD_SIZE * 2; // lets go with 8mb virt size. Seems a good compromise betw. virt and mapping fragmentation.
+
+  // Alignment of the base address of a virtual space node
+  static const size_t VirtualSpaceNodeReserveAlignmentWordSize = chunklevel::MAX_CHUNK_WORD_SIZE;
+
+  // When allocating from a chunk, if the remaining area in the chunk is too small to hold
+  // the requested size, we attempt to double the chunk size in place...
+  static const bool EnlargeChunksInPlace = true;
+
+  // Whether or not chunks handed out to an arena start out fully committed;
+  // if true, this deactivates committing-on-demand (irregardless of whether
+  // we uncommit free chunks).
+  static bool _new_chunks_are_fully_committed;
+
+  // If true, chunks equal or larger than a commit granule are uncommitted
+  // after being returned to the freelist.
+  static bool _uncommit_free_chunks;
+
+  // If true, metablock allocations are guarded and periodically checked.
+  DEBUG_ONLY(static bool _use_allocation_guard;)
+
+  // If true, we handle deallocated blocks (default).
+  DEBUG_ONLY(static bool _handle_deallocations;)
+
+public:
+
+  static size_t commit_granule_bytes()                        { return _commit_granule_bytes; }
+  static size_t commit_granule_words()                        { return _commit_granule_words; }
+  static bool new_chunks_are_fully_committed()                { return _new_chunks_are_fully_committed; }
+  static size_t virtual_space_node_default_word_size()        { return VirtualSpaceNodeDefaultWordSize; }
+  static size_t virtual_space_node_reserve_alignment_words()  { return VirtualSpaceNodeReserveAlignmentWordSize; }
+  static bool enlarge_chunks_in_place()                       { return EnlargeChunksInPlace; }
+  static bool uncommit_free_chunks()                          { return _uncommit_free_chunks; }
+
+  static bool use_allocation_guard()                          { return DEBUG_ONLY(_use_allocation_guard) NOT_DEBUG(false); }
+  static bool handle_deallocations()                          { return DEBUG_ONLY(_handle_deallocations) NOT_DEBUG(true); }
+
+  static void ergo_initialize();
+
+  static void print_on(outputStream* st);
+
+};
+
+} // namespace metaspace
+
+#endif // SHARE_MEMORY_METASPACE_MSSETTINGS_HPP
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msStatistics.cpp	2020-09-04 13:58:08.121471794 +0200
@@ -0,0 +1,247 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+
+#include "memory/metaspace/msCommon.hpp"
+#include "memory/metaspace/msStatistics.hpp"
+
+#include "utilities/debug.hpp"
+#include "utilities/globalDefinitions.hpp"
+#include "utilities/ostream.hpp"
+
+namespace metaspace {
+
+// Returns total word size of all chunks in this manager.
+void ChunkManagerStats::add(const ChunkManagerStats& other) {
+  for (chunklevel_t l = chunklevel::LOWEST_CHUNK_LEVEL; l <= chunklevel::HIGHEST_CHUNK_LEVEL; l++) {
+    _num_chunks[l] += other._num_chunks[l];
+    _committed_word_size[l] += other._committed_word_size[l];
+  }
+}
+
+// Returns total word size of all chunks in this manager.
+size_t ChunkManagerStats::total_word_size() const {
+  size_t s = 0;
+  for (chunklevel_t l = chunklevel::LOWEST_CHUNK_LEVEL; l <= chunklevel::HIGHEST_CHUNK_LEVEL; l++) {
+    s += _num_chunks[l] * chunklevel::word_size_for_level(l);
+  }
+  return s;
+}
+
+// Returns total committed word size of all chunks in this manager.
+size_t ChunkManagerStats::total_committed_word_size() const {
+  size_t s = 0;
+  for (chunklevel_t l = chunklevel::LOWEST_CHUNK_LEVEL; l <= chunklevel::HIGHEST_CHUNK_LEVEL; l++) {
+    s += _committed_word_size[l];
+  }
+  return s;
+}
+
+void ChunkManagerStats::print_on(outputStream* st, size_t scale) const {
+  // Note: used as part of MetaspaceReport so formatting matters.
+  size_t total_size = 0;
+  size_t total_committed_size = 0;
+  for (chunklevel_t l = chunklevel::LOWEST_CHUNK_LEVEL; l <= chunklevel::HIGHEST_CHUNK_LEVEL; l++) {
+    st->cr();
+    chunklevel::print_chunk_size(st, l);
+    st->print(": ");
+    if (_num_chunks[l] > 0) {
+      const size_t word_size = _num_chunks[l] * chunklevel::word_size_for_level(l);
+
+      st->print("%4d, capacity=", _num_chunks[l]);
+      print_scaled_words(st, word_size, scale);
+
+      st->print(", committed=");
+      print_scaled_words_and_percentage(st, _committed_word_size[l], word_size, scale);
+
+      total_size += word_size;
+      total_committed_size += _committed_word_size[l];
+    } else {
+      st->print("(none)");
+    }
+  }
+  st->cr();
+  st->print("Total word size: ");
+  print_scaled_words(st, total_size, scale);
+  st->print(", committed: ");
+  print_scaled_words_and_percentage(st, total_committed_size, total_size, scale);
+  st->cr();
+}
+
+#ifdef ASSERT
+void ChunkManagerStats::verify() const {
+  assert(total_committed_word_size() <= total_word_size(),
+         "Sanity");
+}
+#endif
+
+void InUseChunkStats::print_on(outputStream* st, size_t scale) const {
+  int col = st->position();
+  st->print("%4d chunk%s, ", _num, _num != 1 ? "s" : "");
+  if (_num > 0) {
+    col += 14; st->fill_to(col);
+
+    print_scaled_words(st, _word_size, scale, 5);
+    st->print(" capacity,");
+
+    col += 20; st->fill_to(col);
+    print_scaled_words_and_percentage(st, _committed_words, _word_size, scale, 5);
+    st->print(" committed, ");
+
+    col += 18; st->fill_to(col);
+    print_scaled_words_and_percentage(st, _used_words, _word_size, scale, 5);
+    st->print(" used, ");
+
+    col += 20; st->fill_to(col);
+    print_scaled_words_and_percentage(st, _free_words, _word_size, scale, 5);
+    st->print(" free, ");
+
+    col += 20; st->fill_to(col);
+    print_scaled_words_and_percentage(st, _waste_words, _word_size, scale, 5);
+    st->print(" waste ");
+
+  }
+}
+
+#ifdef ASSERT
+void InUseChunkStats::verify() const {
+  assert(_word_size >= _committed_words &&
+      _committed_words == _used_words + _free_words + _waste_words,
+         "Sanity: cap " SIZE_FORMAT ", committed " SIZE_FORMAT ", used " SIZE_FORMAT ", free " SIZE_FORMAT ", waste " SIZE_FORMAT ".",
+         _word_size, _committed_words, _used_words, _free_words, _waste_words);
+}
+#endif
+
+void ArenaStats::add(const ArenaStats& other) {
+  for (chunklevel_t l = chunklevel::LOWEST_CHUNK_LEVEL; l <= chunklevel::HIGHEST_CHUNK_LEVEL; l++) {
+    _stats[l].add(other._stats[l]);
+  }
+  _free_blocks_num += other._free_blocks_num;
+  _free_blocks_word_size += other._free_blocks_word_size;
+}
+
+// Returns total chunk statistics over all chunk types.
+InUseChunkStats ArenaStats::totals() const {
+  InUseChunkStats out;
+  for (chunklevel_t l = chunklevel::LOWEST_CHUNK_LEVEL; l <= chunklevel::HIGHEST_CHUNK_LEVEL; l++) {
+    out.add(_stats[l]);
+  }
+  return out;
+}
+
+void ArenaStats::print_on(outputStream* st, size_t scale,  bool detailed) const {
+  streamIndentor sti(st);
+  if (detailed) {
+    st->cr_indent();
+    st->print("Usage by chunk level:");
+    {
+      streamIndentor sti2(st);
+      for (chunklevel_t l = chunklevel::LOWEST_CHUNK_LEVEL; l <= chunklevel::HIGHEST_CHUNK_LEVEL; l++) {
+        st->cr_indent();
+        chunklevel::print_chunk_size(st, l);
+        st->print(" chunks: ");
+        if (_stats[l]._num == 0) {
+          st->print(" (none)");
+        } else {
+          _stats[l].print_on(st, scale);
+        }
+      }
+
+      st->cr_indent();
+      st->print("%15s: ", "-total-");
+      totals().print_on(st, scale);
+    }
+    if (_free_blocks_num > 0) {
+      st->cr_indent();
+      st->print("deallocated: " UINTX_FORMAT " blocks with ", _free_blocks_num);
+      print_scaled_words(st, _free_blocks_word_size, scale);
+    }
+  } else {
+    totals().print_on(st, scale);
+    st->print(", ");
+    st->print("deallocated: " UINTX_FORMAT " blocks with ", _free_blocks_num);
+    print_scaled_words(st, _free_blocks_word_size, scale);
+  }
+}
+
+#ifdef ASSERT
+
+void ArenaStats::verify() const {
+  size_t total_used = 0;
+  for (chunklevel_t l = chunklevel::LOWEST_CHUNK_LEVEL; l <= chunklevel::HIGHEST_CHUNK_LEVEL; l++) {
+    _stats[l].verify();
+    total_used += _stats[l]._used_words;
+  }
+  // Deallocated allocations still count as used
+  assert(total_used >= _free_blocks_word_size,
+         "Sanity");
+}
+#endif
+
+// Returns total arena statistics for both class and non-class metaspace
+ArenaStats ClmsStats::totals() const {
+  ArenaStats out;
+  out.add(_arena_stats_nonclass);
+  out.add(_arena_stats_class);
+  return out;
+}
+
+void ClmsStats::print_on(outputStream* st, size_t scale, bool detailed) const {
+  streamIndentor sti(st);
+  st->cr_indent();
+  if (Metaspace::using_class_space()) {
+    st->print("Non-Class: ");
+  }
+  _arena_stats_nonclass.print_on(st, scale, detailed);
+  if (detailed) {
+    st->cr();
+  }
+  if (Metaspace::using_class_space()) {
+    st->cr_indent();
+    st->print("    Class: ");
+    _arena_stats_class.print_on(st, scale, detailed);
+    if (detailed) {
+      st->cr();
+    }
+    st->cr_indent();
+    st->print("     Both: ");
+    totals().print_on(st, scale, detailed);
+    if (detailed) {
+      st->cr();
+    }
+  }
+  st->cr();
+}
+
+#ifdef ASSERT
+void ClmsStats::verify() const {
+  _arena_stats_nonclass.verify();
+  _arena_stats_class.verify();
+}
+#endif
+
+} // end namespace metaspace
+
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msStatistics.hpp	2020-09-04 13:58:08.673475582 +0200
@@ -0,0 +1,165 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#ifndef SHARE_MEMORY_METASPACE_MSSTATISTICS_HPP
+#define SHARE_MEMORY_METASPACE_MSSTATISTICS_HPP
+
+#include "memory/metaspace/msChunklevel.hpp"
+#include "memory/metaspace.hpp"             // for MetadataType enum
+#include "utilities/globalDefinitions.hpp"
+
+class outputStream;
+
+namespace metaspace {
+
+// Contains a number of data output structures:
+//
+// - cm_stats_t
+// - clms_stats_t -> arena_stats_t -> in_use_chunk_stats_t
+//
+// used for the various XXXX::add_to_statistic() methods in MetaspaceArena, ClassLoaderMetaspace
+//  and ChunkManager, respectively.
+
+struct ChunkManagerStats {
+
+  // How many chunks per level are checked in.
+  int _num_chunks[chunklevel::NUM_CHUNK_LEVELS];
+
+  // Size, in words, of the sum of all committed areas in this chunk manager, per level.
+  size_t _committed_word_size[chunklevel::NUM_CHUNK_LEVELS];
+
+  ChunkManagerStats() : _num_chunks(), _committed_word_size() {}
+
+  void add(const ChunkManagerStats& other);
+
+  // Returns total word size of all chunks in this manager.
+  size_t total_word_size() const;
+
+  // Returns total committed word size of all chunks in this manager.
+  size_t total_committed_word_size() const;
+
+  void print_on(outputStream* st, size_t scale) const;
+
+  DEBUG_ONLY(void verify() const;)
+
+};
+
+// Contains statistics for one or multiple chunks in use.
+struct InUseChunkStats {
+
+  // Number of chunks
+  int _num;
+
+  // Note:
+  // capacity = committed + uncommitted
+  //            committed = used + free + waste
+
+  // Capacity (total sum of all chunk sizes) in words.
+  // May contain committed and uncommitted space.
+  size_t _word_size;
+
+  // Total committed area, in words.
+  size_t _committed_words;
+
+  // Total used area, in words.
+  size_t _used_words;
+
+  // Total free committed area, in words.
+  size_t _free_words;
+
+  // Total waste committed area, in words.
+  size_t _waste_words;
+
+  InUseChunkStats()
+    : _num(0), _word_size(0), _committed_words(0),
+      _used_words(0), _free_words(0), _waste_words(0)
+  {}
+
+  void add(const InUseChunkStats& other) {
+    _num += other._num;
+    _word_size += other._word_size;
+    _committed_words += other._committed_words;
+    _used_words += other._used_words;
+    _free_words += other._free_words;
+    _waste_words += other._waste_words;
+
+  }
+
+  void print_on(outputStream* st, size_t scale) const;
+
+  DEBUG_ONLY(void verify() const;)
+
+};
+
+// Class containing statistics for one or more MetaspaceArena objects.
+struct  ArenaStats {
+
+  // chunk statistics by chunk level
+  InUseChunkStats _stats[chunklevel::NUM_CHUNK_LEVELS];
+  uintx _free_blocks_num;
+  size_t _free_blocks_word_size;
+
+  ArenaStats()
+    : _stats(),
+      _free_blocks_num(0),
+      _free_blocks_word_size(0)
+  {}
+
+  void add(const ArenaStats& other);
+
+  void print_on(outputStream* st, size_t scale = K,  bool detailed = true) const;
+
+  InUseChunkStats totals() const;
+
+  DEBUG_ONLY(void verify() const;)
+
+};
+
+// Statistics for one or multiple ClassLoaderMetaspace objects
+struct ClmsStats {
+
+  ArenaStats _arena_stats_nonclass;
+  ArenaStats _arena_stats_class;
+
+  ClmsStats() : _arena_stats_nonclass(), _arena_stats_class() {}
+
+  void add(const ClmsStats& other) {
+    _arena_stats_nonclass.add(other._arena_stats_nonclass);
+    _arena_stats_class.add(other._arena_stats_class);
+  }
+
+  void print_on(outputStream* st, size_t scale, bool detailed) const;
+
+  // Returns total statistics for both class and non-class metaspace
+  ArenaStats totals() const;
+
+  DEBUG_ONLY(void verify() const;)
+
+};
+
+} // namespace metaspace
+
+#endif // SHARE_MEMORY_METASPACE_MSSTATISTICS_HPP
+
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msTestHelpers.cpp	2020-09-04 13:58:09.229479400 +0200
@@ -0,0 +1,119 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+
+
+#include "memory/metaspace/msArena.hpp"
+#include "memory/metaspace/msArenaGrowthPolicy.hpp"
+#include "memory/metaspace/msContext.hpp"
+#include "memory/metaspace/msTestHelpers.hpp"
+#include "runtime/mutexLocker.hpp"
+#include "utilities/debug.hpp"
+#include "utilities/ostream.hpp"
+#include "utilities/globalDefinitions.hpp"
+
+namespace metaspace {
+
+///// MetaspaceTestArena //////
+
+MetaspaceTestArena::MetaspaceTestArena(Mutex* lock, MetaspaceArena* arena)
+  : _lock(lock), _arena(arena) {}
+
+MetaspaceTestArena::~MetaspaceTestArena() {
+  delete _arena;
+  delete _lock;
+}
+
+MetaWord* MetaspaceTestArena::allocate(size_t word_size) {
+  return _arena->allocate(word_size);
+}
+
+void MetaspaceTestArena::deallocate(MetaWord* p, size_t word_size) {
+  return _arena->deallocate(p, word_size);
+}
+
+///// MetaspaceTestArea //////
+
+MetaspaceTestContext::MetaspaceTestContext(const char* name, size_t commit_limit, size_t reserve_limit)
+  : _name(name), _reserve_limit(reserve_limit), _commit_limit(commit_limit),
+    _context(NULL),
+    _commit_limiter(commit_limit == 0 ? max_uintx : commit_limit), // commit_limit == 0 -> no limit
+    _used_words_counter(),
+    _rs()
+{
+  assert(is_aligned(reserve_limit, Metaspace::reserve_alignment_words()), "reserve_limit (" SIZE_FORMAT ") "
+                    "not aligned to metaspace reserve alignment (" SIZE_FORMAT ")",
+                    reserve_limit, Metaspace::reserve_alignment_words());
+  if (reserve_limit > 0) {
+    // have reserve limit -> non-expandable context
+    _rs = ReservedSpace(reserve_limit * BytesPerWord, Metaspace::reserve_alignment(), false);
+    _context = MetaspaceContext::create_nonexpandable_context(name, _rs, &_commit_limiter);
+  } else {
+    // no reserve limit -> expandable vslist
+    _context = MetaspaceContext::create_expandable_context(name, &_commit_limiter);
+  }
+
+}
+
+MetaspaceTestContext::~MetaspaceTestContext() {
+  DEBUG_ONLY(verify();)
+  MutexLocker fcl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
+  delete _context;
+  if (_rs.is_reserved()) {
+    _rs.release();
+  }
+}
+
+// Create an arena, feeding off this area.
+MetaspaceTestArena* MetaspaceTestContext::create_arena(Metaspace::MetaspaceType type) {
+  const ArenaGrowthPolicy* growth_policy = ArenaGrowthPolicy::policy_for_space_type(type, false);
+  Mutex* lock = new Mutex(Monitor::native, "MetaspaceTestArea-lock", false, Monitor::_safepoint_check_never);
+  MetaspaceArena* arena = NULL;
+  {
+    MutexLocker ml(lock,  Mutex::_no_safepoint_check_flag);
+    arena = new MetaspaceArena(_context->cm(), growth_policy, lock, &_used_words_counter, _name);
+  }
+  return new MetaspaceTestArena(lock, arena);
+}
+
+void MetaspaceTestContext::purge_area() {
+  _context->cm()->purge();
+}
+
+#ifdef ASSERT
+void MetaspaceTestContext::verify() const {
+  if (_context != NULL) {
+    _context->verify();
+  }
+}
+#endif
+
+void MetaspaceTestContext::print_on(outputStream* st) const {
+  _context->print_on(st);
+}
+
+} // namespace metaspace
+
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msTestHelpers.hpp	2020-09-04 13:58:09.781483192 +0200
@@ -0,0 +1,120 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#ifndef SHARE_MEMORY_METASPACE_MSTESTHELPERS_HPP
+#define SHARE_MEMORY_METASPACE_MSTESTHELPERS_HPP
+
+#include "memory/allocation.hpp"
+#include "memory/metaspace/msCommitLimiter.hpp"
+#include "memory/metaspace/msContext.hpp"
+#include "memory/metaspace/msCounter.hpp"
+#include "memory/metaspace.hpp"
+#include "memory/virtualspace.hpp"
+#include "utilities/globalDefinitions.hpp"
+
+// This is just convenience classes for metaspace-related tests
+//  (jtreg, via whitebox API, and gtests)
+
+class ReservedSpace;
+class Mutex;
+class outputStream;
+
+namespace metaspace {
+
+class MetaspaceContext;
+class MetaspaceArena;
+
+// Wraps a MetaspaceTestArena with its own lock for testing purposes.
+class MetaspaceTestArena : public CHeapObj<mtInternal> {
+
+  Mutex* const _lock;
+  MetaspaceArena* const _arena;
+
+public:
+
+  const MetaspaceArena* arena() const {
+    return _arena;
+  }
+
+  MetaspaceTestArena(Mutex* lock, MetaspaceArena* arena);
+  ~MetaspaceTestArena();
+
+  MetaWord* allocate(size_t word_size);
+  void deallocate(MetaWord* p, size_t word_size);
+
+};
+
+// Wraps an instance of a MetaspaceContext together with some side objects for easy use in test beds (whitebox, gtests)
+class MetaspaceTestContext : public CHeapObj<mtInternal> {
+
+  const char* const _name;
+  const size_t _reserve_limit;
+  const size_t _commit_limit;
+
+  MetaspaceContext* _context;
+  CommitLimiter _commit_limiter;
+  SizeAtomicCounter _used_words_counter;
+
+  // For non-expandable contexts we keep track of the space
+  // and delete it at destruction time.
+  ReservedSpace _rs;
+
+public:
+
+  // Note: limit == 0 means unlimited
+  // Reserve limit > 0 simulates a non-expandable VirtualSpaceList (like CompressedClassSpace)
+  // Commit limit > 0 simulates a limit to max commitable space (like MaxMetaspaceSize)
+  MetaspaceTestContext(const char* name, size_t commit_limit = 0, size_t reserve_limit = 0);
+  ~MetaspaceTestContext();
+
+  // Create an arena, feeding off this area.
+  MetaspaceTestArena* create_arena(Metaspace::MetaspaceType type);
+
+  void purge_area();
+
+  // Accessors
+  const CommitLimiter& commit_limiter() const { return _commit_limiter; }
+  const VirtualSpaceList& vslist() const      { return *(_context->vslist()); }
+  ChunkManager& cm()                          { return *(_context->cm()); }
+
+  // Returns reserve- and commit limit we run the test with (in the real world,
+  // these would be equivalent to CompressedClassSpaceSize resp MaxMetaspaceSize)
+  size_t reserve_limit() const    { return _reserve_limit == 0 ? max_uintx : 0; }
+  size_t commit_limit() const     { return _commit_limit == 0 ? max_uintx : 0; }
+
+  // Convenience function to retrieve total committed/used words
+  size_t used_words() const       { return _used_words_counter.get(); }
+  size_t committed_words() const  { return _commit_limiter.committed_words(); }
+
+  DEBUG_ONLY(void verify() const;)
+
+  void print_on(outputStream* st) const;
+
+};
+
+} // namespace metaspace
+
+#endif // SHARE_MEMORY_METASPACE_MSTESTHELPERS_HPP
+
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msVirtualSpaceList.cpp	2020-09-04 13:58:10.337487015 +0200
@@ -0,0 +1,270 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+#include "logging/log.hpp"
+#include "memory/metaspace/msChunkManager.hpp"
+#include "memory/metaspace/msCommitLimiter.hpp"
+#include "memory/metaspace/msContext.hpp"
+#include "memory/metaspace/msCounter.hpp"
+#include "memory/metaspace/msFreeChunkList.hpp"
+#include "memory/metaspace/msVirtualSpaceList.hpp"
+#include "memory/metaspace/msVirtualSpaceNode.hpp"
+#include "memory/metaspace.hpp"
+#include "runtime/mutexLocker.hpp"
+
+namespace metaspace {
+
+#define LOGFMT         "VsList @" PTR_FORMAT " (%s)"
+#define LOGFMT_ARGS    p2i(this), this->_name
+
+// Create a new, empty, expandable list.
+VirtualSpaceList::VirtualSpaceList(const char* name, CommitLimiter* commit_limiter)
+  : _name(name),
+    _first_node(NULL),
+    _can_expand(true),
+    _can_purge(true),
+    _commit_limiter(commit_limiter),
+    _reserved_words_counter(),
+    _committed_words_counter()
+{
+}
+
+// Create a new list. The list will contain one node only, which uses the given ReservedSpace.
+// It will be not expandable beyond that first node.
+VirtualSpaceList::VirtualSpaceList(const char* name, ReservedSpace rs, CommitLimiter* commit_limiter)
+: _name(name),
+  _first_node(NULL),
+  _can_expand(false),
+  _can_purge(false),
+  _commit_limiter(commit_limiter),
+  _reserved_words_counter(),
+  _committed_words_counter()
+{
+  // Create the first node spanning the existing ReservedSpace. This will be the only node created
+  // for this list since we cannot expand.
+  VirtualSpaceNode* vsn = VirtualSpaceNode::create_node(rs, _commit_limiter,
+                                                        &_reserved_words_counter, &_committed_words_counter);
+  assert(vsn != NULL, "node creation failed");
+  _first_node = vsn;
+  _first_node->set_next(NULL);
+  _nodes_counter.increment();
+}
+
+VirtualSpaceList::~VirtualSpaceList() {
+  assert_lock_strong(MetaspaceExpand_lock);
+  // Note: normally, there is no reason ever to delete a vslist since they are
+  // global objects, but for gtests it makes sense to allow this.
+  VirtualSpaceNode* vsn = _first_node;
+  VirtualSpaceNode* vsn2 = vsn;
+  while (vsn != NULL) {
+    vsn2 = vsn->next();
+    delete vsn;
+    vsn = vsn2;
+  }
+}
+
+// Create a new node and append it to the list. After
+// this function, _current_node shall point to a new empty node.
+// List must be expandable for this to work.
+void VirtualSpaceList::create_new_node() {
+  assert(_can_expand, "List is not expandable");
+  assert_lock_strong(MetaspaceExpand_lock);
+
+  VirtualSpaceNode* vsn = VirtualSpaceNode::create_node(Settings::virtual_space_node_default_word_size(),
+                                                        _commit_limiter,
+                                                        &_reserved_words_counter, &_committed_words_counter);
+  assert(vsn != NULL, "node creation failed");
+  vsn->set_next(_first_node);
+  _first_node = vsn;
+  _nodes_counter.increment();
+}
+
+// Allocate a root chunk from this list.
+// Note: this just returns a chunk whose memory is reserved; no memory is committed yet.
+// Hence, before using this chunk, it must be committed.
+// Also, no limits are checked, since no committing takes place.
+Metachunk*  VirtualSpaceList::allocate_root_chunk() {
+  assert_lock_strong(MetaspaceExpand_lock);
+
+  if (_first_node == NULL ||
+      _first_node->free_words() == 0) {
+
+    // Since all allocations from a VirtualSpaceNode happen in
+    // root-chunk-size units, and the node size must be root-chunk-size aligned,
+    // we should never have left-over space.
+    assert(_first_node == NULL ||
+           _first_node->free_words() == 0, "Sanity");
+
+    if (_can_expand) {
+      create_new_node();
+      UL2(debug, "added new node (now: %d).", num_nodes());
+    } else {
+      UL(debug, "list cannot expand.");
+      return NULL; // We cannot expand this list.
+    }
+  }
+
+  Metachunk* c = _first_node->allocate_root_chunk();
+
+  assert(c != NULL, "This should have worked");
+
+  return c;
+
+}
+
+// Attempts to purge nodes. This will remove and delete nodes which only contain free chunks.
+// The free chunks are removed from the freelists before the nodes are deleted.
+// Return number of purged nodes.
+int VirtualSpaceList::purge(FreeChunkListVector* freelists) {
+
+  assert_lock_strong(MetaspaceExpand_lock);
+
+  if (_can_purge == false) {
+    return 0;
+  }
+
+  UL(debug, "purging.");
+
+  VirtualSpaceNode* vsn = _first_node;
+  VirtualSpaceNode* prev_vsn = NULL;
+  int num = 0, num_purged = 0;
+  while (vsn != NULL) {
+    VirtualSpaceNode* next_vsn = vsn->next();
+    bool purged = vsn->attempt_purge(freelists);
+    if (purged) {
+      // Note: from now on do not dereference vsn!
+      UL2(debug, "purged node @" PTR_FORMAT ".", p2i(vsn));
+      if (_first_node == vsn) {
+        _first_node = next_vsn;
+      }
+      DEBUG_ONLY(vsn = (VirtualSpaceNode*)((uintptr_t)(0xdeadbeef));)
+      if (prev_vsn != NULL) {
+        prev_vsn->set_next(next_vsn);
+      }
+      num_purged++;
+      _nodes_counter.decrement();
+    } else {
+      prev_vsn = vsn;
+    }
+    vsn = next_vsn;
+    num++;
+  }
+
+  UL2(debug, "purged %d nodes (now: %d)", num_purged, num_nodes());
+
+  return num_purged;
+
+}
+
+// Print all nodes in this space list.
+void VirtualSpaceList::print_on(outputStream* st) const {
+  MutexLocker fcl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
+
+  st->print_cr("vsl %s:", _name);
+  const VirtualSpaceNode* vsn = _first_node;
+  int n = 0;
+  while (vsn != NULL) {
+    st->print("- node #%d: ", n);
+    vsn->print_on(st);
+    vsn = vsn->next();
+    n++;
+  }
+  st->print_cr("- total %d nodes, " SIZE_FORMAT " reserved words, " SIZE_FORMAT " committed words.",
+               n, reserved_words(), committed_words());
+}
+
+#ifdef ASSERT
+void VirtualSpaceList::verify_locked() const {
+
+  assert_lock_strong(MetaspaceExpand_lock);
+
+  assert(_name != NULL, "Sanity");
+
+  int n = 0;
+
+  if (_first_node != NULL) {
+
+    size_t total_reserved_words = 0;
+    size_t total_committed_words = 0;
+    const VirtualSpaceNode* vsn = _first_node;
+    while (vsn != NULL) {
+      n++;
+      vsn->verify_locked();
+      total_reserved_words += vsn->word_size();
+      total_committed_words += vsn->committed_words();
+      vsn = vsn->next();
+    }
+
+    _nodes_counter.check(n);
+    _reserved_words_counter.check(total_reserved_words);
+    _committed_words_counter.check(total_committed_words);
+
+  } else {
+
+    _reserved_words_counter.check(0);
+    _committed_words_counter.check(0);
+
+  }
+}
+
+void VirtualSpaceList::verify() const {
+  MutexLocker fcl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
+  verify_locked();
+}
+#endif
+
+// Returns true if this pointer is contained in one of our nodes.
+bool VirtualSpaceList::contains(const MetaWord* p) const {
+  const VirtualSpaceNode* vsn = _first_node;
+  while (vsn != NULL) {
+    if (vsn->contains(p)) {
+      return true;
+    }
+    vsn = vsn->next();
+  }
+  return false;
+}
+
+// Returns true if the vslist is not expandable and no more root chunks
+// can be allocated.
+bool VirtualSpaceList::is_full() const {
+  if (!_can_expand && _first_node != NULL && _first_node->free_words() == 0) {
+    return true;
+  }
+  return false;
+}
+
+// Convenience methods to return the global class-space chunkmanager
+//  and non-class chunkmanager, respectively.
+VirtualSpaceList* VirtualSpaceList::vslist_class() {
+  return MetaspaceContext::context_class() == NULL ? NULL : MetaspaceContext::context_class()->vslist();
+}
+
+VirtualSpaceList* VirtualSpaceList::vslist_nonclass() {
+  return MetaspaceContext::context_nonclass() == NULL ? NULL : MetaspaceContext::context_nonclass()->vslist();
+}
+
+} // namespace metaspace
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msVirtualSpaceList.hpp	2020-09-04 13:58:10.889490811 +0200
@@ -0,0 +1,153 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#ifndef SHARE_MEMORY_METASPACE_MSVIRTUALSPACELIST_HPP
+#define SHARE_MEMORY_METASPACE_MSVIRTUALSPACELIST_HPP
+
+#include "memory/allocation.hpp"
+#include "memory/metaspace/msCounter.hpp"
+#include "memory/metaspace/msCommitLimiter.hpp"
+#include "memory/metaspace/msVirtualSpaceNode.hpp"
+#include "memory/virtualspace.hpp"
+#include "utilities/globalDefinitions.hpp"
+
+class outputStream;
+
+namespace metaspace {
+
+class Metachunk;
+class FreeChunkListVector;
+
+// VirtualSpaceList manages a single (if its non-expandable) or
+//  a series of (if its expandable) virtual memory regions used
+//  for metaspace.
+//
+// Internally it holds a list of nodes (VirtualSpaceNode) each
+//  managing a single contiguous memory region. The first node of
+//  this list is the current node and used for allocation of new
+//  root chunks.
+//
+// Beyond access to those nodes and the ability to grow new nodes
+//  (if expandable) it allows for purging: purging this list means
+//  removing and unmapping all memory regions which are unused.
+
+class VirtualSpaceList : public CHeapObj<mtClass> {
+
+  // Name
+  const char* const _name;
+
+  // Head of the list.
+  VirtualSpaceNode* _first_node;
+
+  // Number of nodes (kept for statistics only).
+  IntCounter _nodes_counter;
+
+  // Whether this list can expand by allocating new nodes.
+  const bool _can_expand;
+
+  // Whether this list can be purged.
+  const bool _can_purge;
+
+  // Used to check limits before committing memory.
+  CommitLimiter* const _commit_limiter;
+
+  // Statistics
+
+  // Holds sum of reserved space, in words, over all list nodes.
+  SizeCounter _reserved_words_counter;
+
+  // Holds sum of committed space, in words, over all list nodes.
+  SizeCounter _committed_words_counter;
+
+  // Create a new node and append it to the list. After
+  // this function, _current_node shall point to a new empty node.
+  // List must be expandable for this to work.
+  void create_new_node();
+
+public:
+
+  // Create a new, empty, expandable list.
+  VirtualSpaceList(const char* name, CommitLimiter* commit_limiter);
+
+  // Create a new list. The list will contain one node only, which uses the given ReservedSpace.
+  // It will be not expandable beyond that first node.
+  VirtualSpaceList(const char* name, ReservedSpace rs, CommitLimiter* commit_limiter);
+
+  virtual ~VirtualSpaceList();
+
+  // Allocate a root chunk from this list.
+  // Note: this just returns a chunk whose memory is reserved; no memory is committed yet.
+  // Hence, before using this chunk, it must be committed.
+  // May return NULL if vslist would need to be expanded to hold the new root node but
+  // the list cannot be expanded (in practice this means we reached CompressedClassSpaceSize).
+  Metachunk* allocate_root_chunk();
+
+  // Attempts to purge nodes. This will remove and delete nodes which only contain free chunks.
+  // The free chunks are removed from the freelists before the nodes are deleted.
+  // Return number of purged nodes.
+  int purge(FreeChunkListVector* freelists);
+
+  //// Statistics ////
+
+  // Return sum of reserved words in all nodes.
+  size_t reserved_words() const     { return _reserved_words_counter.get(); }
+
+  // Return sum of committed words in all nodes.
+  size_t committed_words() const    { return _committed_words_counter.get(); }
+
+  // Return number of nodes in this list.
+  int num_nodes() const             { return _nodes_counter.get(); }
+
+  //// Debug stuff ////
+  DEBUG_ONLY(void verify() const;)
+  DEBUG_ONLY(void verify_locked() const;)
+
+  // Print all nodes in this space list.
+  void print_on(outputStream* st) const;
+
+  // Returns true if this pointer is contained in one of our nodes.
+  bool contains(const MetaWord* p) const;
+
+  // Returns true if the list is not expandable and no more root chunks
+  // can be allocated.
+  bool is_full() const;
+
+  // Convenience methods to return the global class-space vslist
+  //  and non-class vslist, respectively.
+  static VirtualSpaceList* vslist_class();
+  static VirtualSpaceList* vslist_nonclass();
+
+  // These exist purely to print limits of the compressed class space;
+  // if we ever change the ccs to not use a degenerated-list-of-one-node this
+  // will go away.
+  MetaWord* base_of_first_node() const { return _first_node != NULL ? _first_node->base() : NULL; }
+  size_t word_size_of_first_node() const { return _first_node != NULL ? _first_node->word_size() : 0; }
+
+};
+
+} // namespace metaspace
+
+#endif // SHARE_MEMORY_METASPACE_MSVIRTUALSPACELIST_HPP
+
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msVirtualSpaceNode.cpp	2020-09-04 13:58:11.437494584 +0200
@@ -0,0 +1,528 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+
+#include "logging/log.hpp"
+
+#include "memory/metaspace/msChunkHeaderPool.hpp"
+#include "memory/metaspace/msChunklevel.hpp"
+#include "memory/metaspace/msCommitLimiter.hpp"
+#include "memory/metaspace/msCommon.hpp"
+#include "memory/metaspace/msCounter.hpp"
+#include "memory/metaspace/msFreeChunkList.hpp"
+#include "memory/metaspace/msInternalStats.hpp"
+#include "memory/metaspace/msMetachunk.hpp"
+#include "memory/metaspace/msRootChunkArea.hpp"
+#include "memory/metaspace/msRunningCounters.hpp"
+#include "memory/metaspace/msSettings.hpp"
+#include "memory/metaspace/msVirtualSpaceNode.hpp"
+#include "memory/metaspace.hpp"
+
+#include "runtime/globals.hpp"
+#include "runtime/mutexLocker.hpp"
+#include "runtime/os.hpp"
+
+#include "utilities/align.hpp"
+#include "utilities/debug.hpp"
+#include "utilities/globalDefinitions.hpp"
+#include "utilities/ostream.hpp"
+
+namespace metaspace {
+
+#define LOGFMT         "VsListNode @" PTR_FORMAT " base " PTR_FORMAT " "
+#define LOGFMT_ARGS    p2i(this), p2i(_base)
+
+#ifdef ASSERT
+void check_pointer_is_aligned_to_commit_granule(const MetaWord* p) {
+  assert(is_aligned(p, Settings::commit_granule_bytes()),
+         "Pointer not aligned to commit granule size: " PTR_FORMAT ".",
+         p2i(p));
+}
+void check_word_size_is_aligned_to_commit_granule(size_t word_size) {
+  assert(is_aligned(word_size, Settings::commit_granule_words()),
+         "Not aligned to commit granule size: " SIZE_FORMAT ".", word_size);
+}
+#endif
+
+// Given an address range, ensure it is committed.
+//
+// The range has to be aligned to granule size.
+//
+// Function will:
+// - check how many granules in that region are uncommitted; If all are committed, it
+//    returns true immediately.
+// - check if committing those uncommitted granules would bring us over the commit limit
+//    (GC threshold, MaxMetaspaceSize). If true, it returns false.
+// - commit the memory.
+// - mark the range as committed in the commit mask
+//
+// Returns true if success, false if it did hit a commit limit.
+bool VirtualSpaceNode::commit_range(MetaWord* p, size_t word_size) {
+
+  DEBUG_ONLY(check_pointer_is_aligned_to_commit_granule(p);)
+  DEBUG_ONLY(check_word_size_is_aligned_to_commit_granule(word_size);)
+  assert_lock_strong(MetaspaceExpand_lock);
+
+  // First calculate how large the committed regions in this range are
+  const size_t committed_words_in_range = _commit_mask.get_committed_size_in_range(p, word_size);
+  DEBUG_ONLY(check_word_size_is_aligned_to_commit_granule(committed_words_in_range);)
+
+  // By how much words we would increase commit charge
+  //  were we to commit the given address range completely.
+  const size_t commit_increase_words = word_size - committed_words_in_range;
+
+  UL2(debug, "committing range " PTR_FORMAT ".." PTR_FORMAT "(" SIZE_FORMAT " words)",
+      p2i(p), p2i(p + word_size), word_size);
+
+  if (commit_increase_words == 0) {
+    UL(debug, "... already fully committed.");
+    return true; // Already fully committed, nothing to do.
+  }
+
+  // Before committing any more memory, check limits.
+  if (_commit_limiter->possible_expansion_words() < commit_increase_words) {
+    UL(debug, "... cannot commit (limit).");
+    return false;
+  }
+
+  // Commit...
+  if (os::commit_memory((char*)p, word_size * BytesPerWord, false) == false) {
+    vm_exit_out_of_memory(word_size * BytesPerWord, OOM_MMAP_ERROR, "Failed to commit metaspace.");
+  }
+
+  if (AlwaysPreTouch) {
+    os::pretouch_memory(p, p + word_size);
+  }
+
+  UL2(debug, "... committed " SIZE_FORMAT " additional words.", commit_increase_words);
+
+  // ... tell commit limiter...
+  _commit_limiter->increase_committed(commit_increase_words);
+
+  // ... update counters in containing vslist ...
+  _total_committed_words_counter->increment_by(commit_increase_words);
+
+  // ... and update the commit mask.
+  _commit_mask.mark_range_as_committed(p, word_size);
+
+#ifdef ASSERT
+  // The commit boundary maintained in the CommitLimiter should be equal the sum of committed words
+  // in both class and non-class vslist (outside gtests).
+  if (_commit_limiter == CommitLimiter::globalLimiter()) {
+    assert(_commit_limiter->committed_words() == RunningCounters::committed_words(), "counter mismatch");
+  }
+#endif
+
+  InternalStats::inc_num_space_committed();
+
+  return true;
+
+}
+
+// Given an address range, ensure it is committed.
+//
+// The range does not have to be aligned to granule size. However, the function will always commit
+// whole granules.
+//
+// Function will:
+// - check how many granules in that region are uncommitted; If all are committed, it
+//    returns true immediately.
+// - check if committing those uncommitted granules would bring us over the commit limit
+//    (GC threshold, MaxMetaspaceSize). If true, it returns false.
+// - commit the memory.
+// - mark the range as committed in the commit mask
+//
+// !! Careful:
+//    calling ensure_range_is_committed on a range which contains both committed and uncommitted
+//    areas will commit the whole area, thus erase the content in the existing committed parts.
+//    Make sure you never call this on an address range containing live data. !!
+//
+// Returns true if success, false if it did hit a commit limit.
+bool VirtualSpaceNode::ensure_range_is_committed(MetaWord* p, size_t word_size) {
+
+  assert_lock_strong(MetaspaceExpand_lock);
+  assert(p != NULL && word_size > 0, "Sanity");
+
+  MetaWord* p_start = align_down(p, Settings::commit_granule_bytes());
+  MetaWord* p_end = align_up(p + word_size, Settings::commit_granule_bytes());
+
+  // Todo: simple for now. Make it more intelligent late
+  return commit_range(p_start, p_end - p_start);
+
+}
+
+// Given an address range (which has to be aligned to commit granule size):
+//  - uncommit it
+//  - mark it as uncommitted in the commit mask
+void VirtualSpaceNode::uncommit_range(MetaWord* p, size_t word_size) {
+
+  DEBUG_ONLY(check_pointer_is_aligned_to_commit_granule(p);)
+  DEBUG_ONLY(check_word_size_is_aligned_to_commit_granule(word_size);)
+  assert_lock_strong(MetaspaceExpand_lock);
+
+  // First calculate how large the committed regions in this range are
+  const size_t committed_words_in_range = _commit_mask.get_committed_size_in_range(p, word_size);
+  DEBUG_ONLY(check_word_size_is_aligned_to_commit_granule(committed_words_in_range);)
+
+  UL2(debug, "uncommitting range " PTR_FORMAT ".." PTR_FORMAT "(" SIZE_FORMAT " words)",
+      p2i(p), p2i(p + word_size), word_size);
+
+  if (committed_words_in_range == 0) {
+    UL(debug, "... already fully uncommitted.");
+    return; // Already fully uncommitted, nothing to do.
+  }
+
+  // Uncommit...
+  if (os::uncommit_memory((char*)p, word_size * BytesPerWord) == false) {
+    // Note: this can actually happen, since uncommit may increase the number of mappings.
+    fatal("Failed to uncommit metaspace.");
+  }
+
+  UL2(debug, "... uncommitted " SIZE_FORMAT " words.", committed_words_in_range);
+
+  // ... tell commit limiter...
+  _commit_limiter->decrease_committed(committed_words_in_range);
+
+  // ... and global counters...
+  _total_committed_words_counter->decrement_by(committed_words_in_range);
+
+   // ... and update the commit mask.
+  _commit_mask.mark_range_as_uncommitted(p, word_size);
+
+#ifdef ASSERT
+  // The commit boundary maintained in the CommitLimiter should be equal the sum of committed words
+  // in both class and non-class vslist (outside gtests).
+  if (_commit_limiter == CommitLimiter::globalLimiter()) { // We are outside a test scenario
+    assert(_commit_limiter->committed_words() == RunningCounters::committed_words(), "counter mismatch");
+  }
+#endif
+
+  InternalStats::inc_num_space_uncommitted();
+
+}
+
+//// creation, destruction ////
+
+VirtualSpaceNode::VirtualSpaceNode(ReservedSpace rs, bool owns_rs, CommitLimiter* limiter,
+                                   SizeCounter* reserve_counter, SizeCounter* commit_counter)
+  : _next(NULL),
+    _rs(rs),
+    _owns_rs(owns_rs),
+    _base((MetaWord*)rs.base()),
+    _word_size(rs.size() / BytesPerWord),
+    _used_words(0),
+    _commit_mask((MetaWord*)rs.base(), rs.size() / BytesPerWord),
+    _root_chunk_area_lut((MetaWord*)rs.base(), rs.size() / BytesPerWord),
+    _commit_limiter(limiter),
+    _total_reserved_words_counter(reserve_counter),
+    _total_committed_words_counter(commit_counter)
+{
+  UL2(debug, "born (word_size " SIZE_FORMAT ").", _word_size);
+
+  // Update reserved counter in vslist
+  _total_reserved_words_counter->increment_by(_word_size);
+
+  assert_is_aligned(_base, chunklevel::MAX_CHUNK_BYTE_SIZE);
+  assert_is_aligned(_word_size, chunklevel::MAX_CHUNK_WORD_SIZE);
+
+}
+
+// Create a node of a given size (it will create its own space).
+VirtualSpaceNode* VirtualSpaceNode::create_node(size_t word_size,
+                                                CommitLimiter* limiter, SizeCounter* reserve_words_counter,
+                                                SizeCounter* commit_words_counter)
+{
+
+  DEBUG_ONLY(assert_is_aligned(word_size, chunklevel::MAX_CHUNK_WORD_SIZE);)
+
+  ReservedSpace rs(word_size * BytesPerWord,
+                   Settings::virtual_space_node_reserve_alignment_words() * BytesPerWord,
+                   false // large
+                   );
+
+  if (!rs.is_reserved()) {
+    vm_exit_out_of_memory(word_size * BytesPerWord, OOM_MMAP_ERROR, "Failed to reserve memory for metaspace");
+  }
+
+  assert_is_aligned(rs.base(), chunklevel::MAX_CHUNK_BYTE_SIZE);
+
+  InternalStats::inc_num_vsnodes_births();
+  return new VirtualSpaceNode(rs, true, limiter, reserve_words_counter, commit_words_counter);
+
+}
+
+// Create a node over an existing space
+VirtualSpaceNode* VirtualSpaceNode::create_node(ReservedSpace rs, CommitLimiter* limiter,
+                                                SizeCounter* reserve_words_counter, SizeCounter* commit_words_counter)
+{
+  InternalStats::inc_num_vsnodes_births();
+  return new VirtualSpaceNode(rs, false, limiter, reserve_words_counter, commit_words_counter);
+}
+
+VirtualSpaceNode::~VirtualSpaceNode() {
+
+  DEBUG_ONLY(verify_locked();)
+
+  UL(debug, ": dies.");
+
+  if (_owns_rs) {
+    _rs.release();
+  }
+
+  // Update counters in vslist
+  size_t committed = committed_words();
+  _total_committed_words_counter->decrement_by(committed);
+  _total_reserved_words_counter->decrement_by(_word_size);
+
+  // ... and tell commit limiter
+  _commit_limiter->decrease_committed(committed);
+
+  InternalStats::inc_num_vsnodes_deaths();
+
+}
+
+//// Chunk allocation, splitting, merging /////
+
+// Allocate a root chunk from this node. Will fail and return NULL if the node is full
+//  - if we used up the whole address space of this node's memory region.
+//    (in case this node backs compressed class space, this is how we hit
+//     CompressedClassSpaceSize).
+// Note that this just returns reserved memory; caller must take care of committing this
+//  chunk before using it.
+Metachunk* VirtualSpaceNode::allocate_root_chunk() {
+
+  assert_lock_strong(MetaspaceExpand_lock);
+
+  assert_is_aligned(free_words(), chunklevel::MAX_CHUNK_WORD_SIZE);
+
+  if (free_words() >= chunklevel::MAX_CHUNK_WORD_SIZE) {
+
+    MetaWord* loc = _base + _used_words;
+    _used_words += chunklevel::MAX_CHUNK_WORD_SIZE;
+
+    RootChunkArea* rca = _root_chunk_area_lut.get_area_by_address(loc);
+
+    // Create a root chunk header and initialize it;
+    Metachunk* c = rca->alloc_root_chunk_header(this);
+
+    assert(c->base() == loc && c->vsnode() == this &&
+           c->is_free(), "Sanity");
+
+    DEBUG_ONLY(c->verify();)
+
+    UL2(debug, "new root chunk " METACHUNK_FORMAT ".", METACHUNK_FORMAT_ARGS(c));
+
+    return c;
+
+  }
+
+  return NULL; // Node is full.
+
+}
+
+// Given a chunk c, split it recursively until you get a chunk of the given target_level.
+//
+// The resulting target chunk resides at the same address as the original chunk.
+// The resulting splinters are added to freelists.
+void VirtualSpaceNode::split(chunklevel_t target_level, Metachunk* c, FreeChunkListVector* freelists) {
+
+  assert_lock_strong(MetaspaceExpand_lock);
+
+  // Get the area associated with this chunk and let it handle the splitting
+  RootChunkArea* rca = _root_chunk_area_lut.get_area_by_address(c->base());
+
+  DEBUG_ONLY(rca->verify_area_is_ideally_merged();)
+
+  rca->split(target_level, c, freelists);
+
+}
+
+// Given a chunk, attempt to merge it recursively with its neighboring chunks.
+//
+// If successful (merged at least once), returns address of
+// the merged chunk; NULL otherwise.
+//
+// The merged chunks are removed from the freelists.
+//
+// !!! Please note that if this method returns a non-NULL value, the
+// original chunk will be invalid and should not be accessed anymore! !!!
+Metachunk* VirtualSpaceNode::merge(Metachunk* c, FreeChunkListVector* freelists) {
+
+  assert(c != NULL && c->is_free(), "Sanity");
+  assert_lock_strong(MetaspaceExpand_lock);
+
+  // Get the rca associated with this chunk and let it handle the merging
+  RootChunkArea* rca = _root_chunk_area_lut.get_area_by_address(c->base());
+
+  Metachunk* c2 = rca->merge(c, freelists);
+
+  DEBUG_ONLY(rca->verify_area_is_ideally_merged();)
+
+  return c2;
+
+}
+
+// Given a chunk c, which must be "in use" and must not be a root chunk, attempt to
+// enlarge it in place by claiming its trailing buddy.
+//
+// This will only work if c is the leader of the buddy pair and the trailing buddy is free.
+//
+// If successful, the follower chunk will be removed from the freelists, the leader chunk c will
+// double in size (level decreased by one).
+//
+// On success, true is returned, false otherwise.
+bool VirtualSpaceNode::attempt_enlarge_chunk(Metachunk* c, FreeChunkListVector* freelists) {
+
+  assert(c != NULL && c->is_in_use() && !c->is_root_chunk(), "Sanity");
+  assert_lock_strong(MetaspaceExpand_lock);
+
+  // Get the rca associated with this chunk and let it handle the merging
+  RootChunkArea* rca = _root_chunk_area_lut.get_area_by_address(c->base());
+
+  bool rc = rca->attempt_enlarge_chunk(c, freelists);
+
+  DEBUG_ONLY(rca->verify_area_is_ideally_merged();)
+
+  if (rc) {
+    InternalStats::inc_num_chunks_enlarged();
+  }
+
+  return rc;
+
+}
+
+// Attempts to purge the node:
+//
+// If all chunks living in this node are free, they will all be removed from
+//  the freelist they currently reside in. Then, the node will be deleted.
+//
+// Returns true if the node has been deleted, false if not.
+// !! If this returns true, do not access the node from this point on. !!
+bool VirtualSpaceNode::attempt_purge(FreeChunkListVector* freelists) {
+
+  assert_lock_strong(MetaspaceExpand_lock);
+
+  if (!_owns_rs) {
+    // We do not allow purging of nodes if we do not own the
+    // underlying ReservedSpace (CompressClassSpace case).
+    return false;
+  }
+
+  // First find out if all areas are empty. Since empty chunks collapse to root chunk
+  // size, if all chunks in this node are free root chunks we are good to go.
+  if (!_root_chunk_area_lut.is_free()) {
+    return false;
+  }
+
+  UL(debug, ": purging.");
+
+  // Okay, we can purge. Before we can do this, we need to remove all chunks from the freelist.
+  for (int narea = 0; narea < _root_chunk_area_lut.number_of_areas(); narea++) {
+    RootChunkArea* ra = _root_chunk_area_lut.get_area_by_index(narea);
+    Metachunk* c = ra->first_chunk();
+    if (c != NULL) {
+      UL2(trace, "removing chunk from to-be-purged node: "
+          METACHUNK_FULL_FORMAT ".", METACHUNK_FULL_FORMAT_ARGS(c));
+      assert(c->is_free() && c->is_root_chunk(), "Sanity");
+      freelists->remove(c);
+    }
+  }
+
+  // Now, delete the node, then right away return since this object is invalid.
+  delete this;
+
+  return true;
+
+}
+
+void VirtualSpaceNode::print_on(outputStream* st) const {
+
+  size_t scale = K;
+
+  st->print("base " PTR_FORMAT ": ", p2i(base()));
+  st->print("reserved=");
+  print_scaled_words(st, word_size(), scale);
+  st->print(", committed=");
+  print_scaled_words_and_percentage(st, committed_words(), word_size(), scale);
+  st->print(", used=");
+  print_scaled_words_and_percentage(st, used_words(), word_size(), scale);
+
+  st->cr();
+  _root_chunk_area_lut.print_on(st);
+  _commit_mask.print_on(st);
+
+}
+
+// Returns size, in words, of committed space in this node alone.
+// Note: iterates over commit mask and hence may be a tad expensive on large nodes.
+size_t VirtualSpaceNode::committed_words() const {
+  return _commit_mask.get_committed_size();
+}
+
+#ifdef ASSERT
+void VirtualSpaceNode::verify() const {
+  MutexLocker fcl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
+  verify_locked();
+}
+
+volatile int test_access = 0;
+
+// Verify counters and basic structure. Slow mode: verify all chunks in depth
+void VirtualSpaceNode::verify_locked() const {
+
+  assert_lock_strong(MetaspaceExpand_lock);
+
+  assert(base() != NULL, "Invalid base");
+  assert(base() == (MetaWord*)_rs.base() &&
+         word_size() == _rs.size() / BytesPerWord,
+         "Sanity");
+  assert_is_aligned(base(), chunklevel::MAX_CHUNK_BYTE_SIZE);
+  assert(used_words() <= word_size(), "Sanity");
+
+  // Since we only ever hand out root chunks from a vsnode, top should always be aligned
+  // to root chunk size.
+  assert_is_aligned(used_words(), chunklevel::MAX_CHUNK_WORD_SIZE);
+
+  _commit_mask.verify();
+
+  // Verify memory against commit mask.
+  SOMETIMES(
+    for (MetaWord* p = base(); p < base() + used_words(); p += os::vm_page_size()) {
+      if (_commit_mask.is_committed_address(p)) {
+        test_access += *(int*)p;
+      }
+    }
+  )
+
+  assert(committed_words() <= word_size(), "Sanity");
+  assert_is_aligned(committed_words(), Settings::commit_granule_words());
+  _root_chunk_area_lut.verify();
+
+}
+
+#endif
+
+} // namespace metaspace
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/src/hotspot/share/memory/metaspace/msVirtualSpaceNode.hpp	2020-09-04 13:58:11.989498384 +0200
@@ -0,0 +1,289 @@
+/*
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#ifndef SHARE_MEMORY_METASPACE_MSVIRTUALSPACENODE_HPP
+#define SHARE_MEMORY_METASPACE_MSVIRTUALSPACENODE_HPP
+
+#include "memory/allocation.hpp"
+#include "memory/metaspace/msCommitMask.hpp"
+#include "memory/metaspace/msCounter.hpp"
+#include "memory/metaspace/msRootChunkArea.hpp"
+#include "memory/metaspace/msSettings.hpp"
+#include "memory/memRegion.hpp"
+#include "memory/virtualspace.hpp"
+#include "utilities/debug.hpp"
+#include "utilities/bitMap.hpp"
+#include "utilities/globalDefinitions.hpp"
+
+class outputStream;
+
+namespace metaspace {
+
+class CommitLimiter;
+class FreeChunkListVector;
+
+// VirtualSpaceNode manages a single contiguous address range of metaspace. Logically that memory
+//  region is split up into a sequence of "root chunk areas", each one containing one root chunk
+//  or splinters of a root chunk.
+//
+// The underlying memory is also logically divided into a number of "commit granules", units of memory
+//  which may be committed or uncommitted independently from each other.
+//
+// (Both root chunk areas and commit granules have not much to do with each other - one is a way to
+//   reserve memory for the upper regions, see ChunkManager. One is a way to manage commited memory.)
+//
+// VirtualSpaceNode:
+//  - exposes a function to allocate a new root chunk (see VirtualSpaceNode::allocate_root_chunk()).
+//
+//  - knows about the commit state of the memory region - which commit granule are committed, which
+//    are not. It exposes functions to commit and uncommit regions (without actively committing
+//    itself)
+//
+//  - It has a reference to a "CommitLimiter", an interface to query whether committing is
+//    possible. That interface hides the various ways committing may be limited (GC threshold,
+//    MaxMetaspaceSize, ...)
+//
+//  - It uses ReservedSpace to reserve its memory. It either owns the ReservedSpace or that
+//    space got handed in from outside (ccs).
+//
+//
+//
+//
+// | root chunk area               | root chunk area               | root chunk area               | <-- root chunk areas
+//
+// +-----------------------------------------------------------------------------------------------+
+// |                                                                                               |
+// |                                   `VirtualSpaceNode` memory                                   |
+// |                                                                                               |
+// +-----------------------------------------------------------------------------------------------+
+//
+// |x| |x|x|x| | | | |x|x|x| | | |x|x| | | |x|x|x|x| | | | | | | | |x| | | |x|x|x|x| | | |x| | | |x| <-- commit granules
+//
+// (x = committed)
+//
+
+class VirtualSpaceNode : public CHeapObj<mtClass> {
+
+  // Link to next VirtualSpaceNode
+  VirtualSpaceNode* _next;
+
+  // The underlying space. This has been either created by this node
+  //  and is owned by it, or has been handed in from outside (e.g. in
+  //  case of CompressedClassSpace).
+  ReservedSpace _rs;
+
+  // True if the node owns the reserved space, false if not.
+  const bool _owns_rs;
+
+  // Start pointer of the area.
+  MetaWord* const _base;
+
+  // Size, in words, of the whole node
+  const size_t _word_size;
+
+  // Size, in words, of the range of this node which has been handed out in
+  // the form of root chunks.
+  size_t _used_words;
+
+  // The bitmap describing the commit state of the region:
+  // Each bit covers a region of 64K (see constants::commit_granule_size).
+  CommitMask _commit_mask;
+
+  // An array/lookup table of RootChunkArea objects. Each one describes a root chunk area.
+  RootChunkAreaLUT _root_chunk_area_lut;
+
+  // Limiter object to ask before expanding the committed size of this node.
+  CommitLimiter* const _commit_limiter;
+
+  // Points to outside size counters which we are to increase/decrease when we commit/uncommit
+  // space from this node.
+  SizeCounter* const _total_reserved_words_counter;
+  SizeCounter* const _total_committed_words_counter;
+
+  /// committing, uncommitting ///
+
+  // Given a pointer into this node, calculate the start of the commit granule
+  // the pointer points into.
+  MetaWord* calc_start_of_granule(MetaWord* p) const {
+    DEBUG_ONLY(check_pointer(p));
+    return align_down(p, Settings::commit_granule_bytes());
+  }
+
+  // Given an address range, ensure it is committed.
+  //
+  // The range has to be aligned to granule size.
+  //
+  // Function will:
+  // - check how many granules in that region are uncommitted; If all are committed, it
+  //    returns true immediately.
+  // - check if committing those uncommitted granules would bring us over the commit limit
+  //    (GC threshold, MaxMetaspaceSize). If true, it returns false.
+  // - commit the memory.
+  // - mark the range as committed in the commit mask
+  //
+  // Returns true if success, false if it did hit a commit limit.
+  bool commit_range(MetaWord* p, size_t word_size);
+
+  //// creation ////
+
+  // Create a new empty node spanning the given given reserved space.
+  VirtualSpaceNode(ReservedSpace rs, bool owns_rs, CommitLimiter* limiter,
+                   SizeCounter* reserve_counter, SizeCounter* commit_counter);
+
+public:
+
+  // Create a node of a given size (it will create its own space).
+  static VirtualSpaceNode* create_node(size_t word_size, CommitLimiter* limiter, SizeCounter* reserve_words_counter,
+                                       SizeCounter* commit_words_counter);
+
+  // Create a node over an existing space
+  static VirtualSpaceNode* create_node(ReservedSpace rs, CommitLimiter* limiter, SizeCounter* reserve_words_counter,
+                                       SizeCounter* commit_words_counter);
+
+  ~VirtualSpaceNode();
+
+  // Note: public for gtests only, could be private.
+  MetaWord* base() const        { return _base; }
+
+  // Reserved size of the whole node.
+  size_t word_size() const      { return _word_size; }
+
+  //// Chunk allocation, splitting, merging /////
+
+  // Allocate a root chunk from this node. Will fail and return NULL if the node is full
+  //  - if we used up the whole address space of this node's memory region.
+  //    (in case this node backs compressed class space, this is how we hit
+  //     CompressedClassSpaceSize).
+  // Note that this just returns reserved memory; caller must take care of committing this
+  //  chunk before using it.
+  Metachunk* allocate_root_chunk();
+
+  // Given a chunk c, split it recursively until you get a chunk of the given target_level.
+  //
+  // The resulting target chunk resides at the same address as the original chunk.
+  // The resulting splinters are added to freelists.
+  void split(chunklevel_t target_level, Metachunk* c, FreeChunkListVector* freelists);
+
+  // Given a chunk, attempt to merge it recursively with its neighboring chunks.
+  //
+  // If successful (merged at least once), returns address of
+  // the merged chunk; NULL otherwise.
+  //
+  // The merged chunks are removed from the freelists.
+  //
+  // !!! Please note that if this method returns a non-NULL value, the
+  // original chunk will be invalid and should not be accessed anymore! !!!
+  Metachunk* merge(Metachunk* c, FreeChunkListVector* freelists);
+
+  // Given a chunk c, which must be "in use" and must not be a root chunk, attempt to
+  // enlarge it in place by claiming its trailing buddy.
+  //
+  // This will only work if c is the leader of the buddy pair and the trailing buddy is free.
+  //
+  // If successful, the follower chunk will be removed from the freelists, the leader chunk c will
+  // double in size (level decreased by one).
+  //
+  // On success, true is returned, false otherwise.
+  bool attempt_enlarge_chunk(Metachunk* c, FreeChunkListVector* freelists);
+
+  // Attempts to purge the node:
+  //
+  // If all chunks living in this node are free, they will all be removed from
+  //  the freelist they currently reside in. Then, the node will be deleted.
+  //
+  // Returns true if the node has been deleted, false if not.
+  // !! If this returns true, do not access the node from this point on. !!
+  bool attempt_purge(FreeChunkListVector* freelists);
+
+  // Attempts to uncommit free areas according to the rules set in settings.
+  // Returns number of words uncommitted.
+  size_t uncommit_free_areas();
+
+  /// misc /////
+
+  // Returns size, in words, of the used space in this node alone.
+  // (Notes:
+  //  - This is the space handed out to the ChunkManager, so it is "used" from the viewpoint of this node,
+  //    but not necessarily used for Metadata.
+  //  - This may or may not be committed memory.
+  size_t used_words() const             { return _used_words; }
+
+  // Returns size, in words, of how much space is left in this node alone.
+  size_t free_words() const             { return _word_size - _used_words; }
+
+  // Returns size, in words, of committed space in this node alone.
+  // Note: iterates over commit mask and hence may be a tad expensive on large nodes.
+  size_t committed_words() const;
+
+  //// Committing/uncommitting memory /////
+
+  // Given an address range, ensure it is committed.
+  //
+  // The range does not have to be aligned to granule size. However, the function will always commit
+  // whole granules.
+  //
+  // Function will:
+  // - check how many granules in that region are uncommitted; If all are committed, it
+  //    returns true immediately.
+  // - check if committing those uncommitted granules would bring us over the commit limit
+  //    (GC threshold, MaxMetaspaceSize). If true, it returns false.
+  // - commit the memory.
+  // - mark the range as committed in the commit mask
+  //
+  // Returns true if success, false if it did hit a commit limit.
+  bool ensure_range_is_committed(MetaWord* p, size_t word_size);
+
+  // Given an address range (which has to be aligned to commit granule size):
+  //  - uncommit it
+  //  - mark it as uncommitted in the commit mask
+  void uncommit_range(MetaWord* p, size_t word_size);
+
+  //// List stuff ////
+  VirtualSpaceNode* next() const        { return _next; }
+  void set_next(VirtualSpaceNode* vsn)  { _next = vsn; }
+
+  /// Debug stuff ////
+
+  // Print a description about this node.
+  void print_on(outputStream* st) const;
+
+  // Verify counters and basic structure. Slow mode: verify all chunks in depth
+  bool contains(const MetaWord* p) const {
+    return p >= _base && p < _base + _used_words;
+  }
+
+#ifdef ASSERT
+  void check_pointer(const MetaWord* p) const {
+    assert(contains(p), "invalid pointer");
+  }
+  void verify() const;
+  void verify_locked() const;
+#endif
+
+};
+
+} // namespace metaspace
+
+#endif // SHARE_MEMORY_METASPACE_MSVIRTUALSPACENODE_HPP
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/test/hotspot/gtest/metaspace/metaspaceGtestCommon.cpp	2020-09-04 13:58:12.549502244 +0200
@@ -0,0 +1,101 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+
+#include "runtime/os.hpp"
+
+#include "metaspaceGtestCommon.hpp"
+#include "metaspaceGtestRangeHelpers.hpp"
+
+
+void zap_range(MetaWord* p, size_t word_size) {
+  for (MetaWord* pzap = p; pzap < p + word_size; pzap += os::vm_page_size() / BytesPerWord) {
+    *pzap = (MetaWord)NOT_LP64(0xFEFEFEFE) LP64_ONLY(0xFEFEFEFEEFEFEFEFULL);
+  }
+}
+
+// Writes a unique pattern to p
+void mark_address(MetaWord* p, uintx pattern) {
+  MetaWord x = (MetaWord)((uintx) p ^ pattern);
+  *p = x;
+}
+
+// checks pattern at address
+void check_marked_address(const MetaWord* p, uintx pattern) {
+  MetaWord x = (MetaWord)((uintx) p ^ pattern);
+  EXPECT_EQ(*p, x);
+}
+
+// "fill_range_with_pattern" fills a range of heap words with pointers to itself.
+//
+// The idea is to fill a memory range with a pattern which is both marked clearly to the caller
+// and cannot be moved without becoming invalid.
+//
+// The filled range can be checked with check_range_for_pattern. One also can only check
+// a sub range of the original range.
+void fill_range_with_pattern(MetaWord* p, size_t word_size, uintx pattern) {
+  assert(word_size > 0 && p != NULL, "sanity");
+  for (MetaWord* p2 = p; p2 < p + word_size; p2++) {
+    mark_address(p2, pattern);
+  }
+}
+
+void check_range_for_pattern(const MetaWord* p, size_t word_size, uintx pattern) {
+  assert(p != NULL, "sanity");
+  const MetaWord* p2 = p;
+  while (p2 < p + word_size) {
+    check_marked_address(p2, pattern);
+    p2++;
+  }
+}
+
+// Similar to fill_range_with_pattern, but only marks start and end. This is optimized for cases
+// where fill_range_with_pattern just is too slow.
+// Use check_marked_range to check the range. In contrast to check_range_for_pattern, only the original
+// range can be checked.
+void mark_range(MetaWord* p, size_t word_size, uintx pattern) {
+  assert(word_size > 0 && p != NULL, "sanity");
+  mark_address(p, pattern);
+  mark_address(p + word_size - 1, pattern);
+}
+
+void check_marked_range(const MetaWord* p, size_t word_size, uintx pattern) {
+  assert(word_size > 0 && p != NULL, "sanity");
+  check_marked_address(p, pattern);
+  check_marked_address(p + word_size - 1, pattern);
+}
+
+void mark_range(MetaWord* p, size_t word_size) {
+  assert(word_size > 0 && p != NULL, "sanity");
+  uintx pattern = (uintx)p2i(p);
+  mark_range(p, word_size, pattern);
+}
+
+void check_marked_range(const MetaWord* p, size_t word_size) {
+  uintx pattern = (uintx)p2i(p);
+  check_marked_range(p, word_size, pattern);
+}
+
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/test/hotspot/gtest/metaspace/metaspaceGtestCommon.hpp	2020-09-04 13:58:13.105506077 +0200
@@ -0,0 +1,212 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#ifndef GTEST_METASPACE_METASPACEGTESTCOMMON_HPP
+#define GTEST_METASPACE_METASPACEGTESTCOMMON_HPP
+
+#include "memory/allocation.hpp"
+#include "utilities/globalDefinitions.hpp"
+#include "runtime/os.hpp"
+
+#include "unittest.hpp"
+
+/////////////////////////////////////////////////////////////////////
+// A little mockup to mimick and test the CommitMask in various tests
+
+class TestMap {
+  const size_t _len;
+  char* _arr;
+public:
+  TestMap(size_t len) : _len(len), _arr(NULL) {
+    _arr = NEW_C_HEAP_ARRAY(char, len, mtInternal);
+    memset(_arr, 0, _len);
+  }
+  ~TestMap() { FREE_C_HEAP_ARRAY(char, _arr); }
+
+  int get_num_set(size_t from, size_t to) const {
+    int result = 0;
+    for(size_t i = from; i < to; i++) {
+      if (_arr[i] > 0) {
+        result++;
+      }
+    }
+    return result;
+  }
+
+  size_t get_num_set() const { return get_num_set(0, _len); }
+
+  void set_range(size_t from, size_t to) {
+    memset(_arr + from, 1, to - from);
+  }
+
+  void clear_range(size_t from, size_t to) {
+    memset(_arr + from, 0, to - from);
+  }
+
+  bool at(size_t pos) const {
+    return _arr[pos] == 1;
+  }
+
+};
+
+///////////////////////////////////////////////////////////
+// Helper class for generating random allocation sizes
+class RandSizeGenerator {
+  const size_t _min; // [
+  const size_t _max; // )
+  const float _outlier_chance; // 0.0 -- 1.0
+  const size_t _outlier_min; // [
+  const size_t _outlier_max; // )
+public:
+  RandSizeGenerator(size_t min, size_t max)
+    : _min(min), _max(max), _outlier_chance(0.0), _outlier_min(min), _outlier_max(max)
+  {}
+
+  RandSizeGenerator(size_t min, size_t max, float outlier_chance, size_t outlier_min, size_t outlier_max)
+    : _min(min), _max(max), _outlier_chance(outlier_chance), _outlier_min(outlier_min), _outlier_max(outlier_max)
+  {}
+
+  size_t min() const { return _min; }
+  size_t max() const { return _max; }
+
+  size_t get() const {
+    size_t l1 = _min;
+    size_t l2 = _max;
+    int r = os::random() % 1000;
+    if ((float)r < _outlier_chance * 1000.0) {
+      l1 = _outlier_min;
+      l2 = _outlier_max;
+    }
+    const size_t d = l2 - l1;
+    return l1 + (os::random() % d);
+  }
+
+}; // end RandSizeGenerator
+
+size_t get_random_size(size_t min, size_t max);
+
+///////////////////////////////////////////////////////////
+// Function to test-access a memory range
+
+void zap_range(MetaWord* p, size_t word_size);
+
+// "fill_range_with_pattern" fills a range of heap words with pointers to itself.
+//
+// The idea is to fill a memory range with a pattern which is both marked clearly to the caller
+// and cannot be moved without becoming invalid.
+//
+// The filled range can be checked with check_range_for_pattern. One also can only check
+// a sub range of the original range.
+void fill_range_with_pattern(MetaWord* p, uintx pattern, size_t word_size);
+void check_range_for_pattern(const MetaWord* p, uintx pattern, size_t word_size);
+
+// Writes a uniqe pattern to p
+void mark_address(MetaWord* p, uintx pattern);
+// checks pattern at address
+void check_marked_address(const MetaWord* p, uintx pattern);
+
+// Similar to fill_range_with_pattern, but only marks start and end. This is optimized for cases
+// where fill_range_with_pattern just is too slow.
+// Use check_marked_range to check the range. In contrast to check_range_for_pattern, only the original
+// range can be checked.
+void mark_range(MetaWord* p, uintx pattern, size_t word_size);
+void check_marked_range(const MetaWord* p, uintx pattern, size_t word_size);
+
+void mark_range(MetaWord* p, size_t word_size);
+void check_marked_range(const MetaWord* p, size_t word_size);
+
+//////////////////////////////////////////////////////////
+// Some helpers to avoid typing out those annoying casts for NULL
+
+#define ASSERT_NOT_NULL(ptr)      ASSERT_NE((void*)NULL, (void*)ptr)
+#define ASSERT_NULL(ptr)          ASSERT_EQ((void*)NULL, (void*)ptr)
+#define EXPECT_NOT_NULL(ptr)      EXPECT_NE((void*)NULL, (void*)ptr)
+#define EXPECT_NULL(ptr)          EXPECT_EQ((void*)NULL, (void*)ptr)
+
+#define ASSERT_0(v)               ASSERT_EQ((intptr_t)0, (intptr_t)v)
+#define ASSERT_NOT_0(v)           ASSERT_NE((intptr_t)0, (intptr_t)v)
+#define EXPECT_0(v)               EXPECT_EQ((intptr_t)0, (intptr_t)v)
+#define EXPECT_NOT_0(v)           EXPECT_NE((intptr_t)0, (intptr_t)v)
+#define ASSERT_GT0(v)             ASSERT_GT((intptr_t)v, (intptr_t)0)
+#define EXPECT_GT0(v)             EXPECT_GT((intptr_t)v, (intptr_t)0)
+
+//////////////////////////////////////////////////////////
+// logging
+
+// Define "LOG_PLEASE" to switch on logging for a particular test before inclusion of this header.
+#ifdef LOG_PLEASE
+  #define LOG(...) { printf(__VA_ARGS__); printf("\n"); fflush(stdout); }
+#else
+  #define LOG(...)
+#endif
+
+//////////////////////////////////////////////////////////
+// Helper
+
+size_t get_workingset_size();
+
+// A simple preallocated buffer used to "feed" someone.
+// Mimicks chunk retirement leftover blocks.
+class FeederBuffer {
+
+  MetaWord* _buf;
+
+  // Buffer capacity in size of words.
+  const size_t _cap;
+
+  // Used words.
+  size_t _used;
+
+public:
+
+  FeederBuffer(size_t size) : _buf(NULL), _cap(size), _used(0) {
+    _buf = NEW_C_HEAP_ARRAY(MetaWord, _cap, mtInternal);
+  }
+
+  ~FeederBuffer() {
+    FREE_C_HEAP_ARRAY(MetaWord, _buf);
+  }
+
+  MetaWord* get(size_t word_size) {
+    if (_used + word_size > _cap) {
+      return NULL;
+    }
+    MetaWord* p = _buf + _used;
+    _used += word_size;
+    return p;
+  }
+
+  bool is_valid_pointer(MetaWord* p) const {
+    return p >= _buf && p < _buf + _used;
+  }
+
+  bool is_valid_range(MetaWord* p, size_t word_size) const {
+    return is_valid_pointer(p) &&
+           word_size > 0 ? is_valid_pointer(p + word_size - 1) : true;
+  }
+
+};
+
+#endif // GTEST_METASPACE_METASPACEGTESTCOMMON_HPP
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/test/hotspot/gtest/metaspace/metaspaceGtestContexts.cpp	2020-09-04 13:58:13.657509885 +0200
@@ -0,0 +1,171 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+
+#include "memory/metaspace/msChunkManager.hpp"
+#include "memory/metaspace/msSettings.hpp"
+#include "metaspaceGtestContexts.hpp"
+
+#include "metaspaceGtestCommon.hpp"
+
+using metaspace::Settings;
+
+void ChunkGtestContext::checked_alloc_chunk_0(Metachunk** p_return_value, chunklevel_t preferred_level, chunklevel_t max_level,
+                                                      size_t min_committed_size) {
+
+  *p_return_value = NULL;
+
+  Metachunk* c = cm().get_chunk(preferred_level, max_level, min_committed_size);
+
+  if (c != NULL) {
+
+    ASSERT_LE(c->level(), max_level);
+    ASSERT_GE(c->level(), preferred_level);
+    ASSERT_GE(c->committed_words(), min_committed_size);
+    ASSERT_EQ(c->committed_words(), c->free_below_committed_words());
+    ASSERT_EQ(c->used_words(), (size_t)0);
+    ASSERT_TRUE(c->is_in_use());
+    ASSERT_FALSE(c->is_free());
+    ASSERT_FALSE(c->is_dead());
+    ASSERT_NULL(c->next());
+    ASSERT_NULL(c->prev());
+    if (c->level() == HIGHEST_CHUNK_LEVEL) {
+      ASSERT_TRUE(c->is_leaf_chunk());
+    } else {
+      ASSERT_FALSE(c->is_leaf_chunk());
+    }
+    if (c->level() == LOWEST_CHUNK_LEVEL) {
+      ASSERT_TRUE(c->is_root_chunk());
+    } else {
+      ASSERT_FALSE(c->is_root_chunk());
+    }
+    if (_num_chunks_allocated == 0) { // First chunk? We can make more assumptions
+      ASSERT_EQ(c->level(), preferred_level);
+      // Needs lock EXPECT_NULL(c->next_in_vs());
+      // Needs lock EXPECT_NULL(c->prev_in_vs());
+      ASSERT_TRUE(c->is_root_chunk() || c->is_leader());
+    }
+    _num_chunks_allocated++;
+
+  }
+
+  *p_return_value = c;
+
+}
+
+// Test pattern established when allocating from the chunk with allocate_from_chunk_with_tests().
+void ChunkGtestContext::test_pattern(Metachunk* c, size_t word_size) {
+  check_range_for_pattern(c->base(), word_size, (uintx)c);
+}
+
+void ChunkGtestContext::return_chunk(Metachunk* c) {
+  test_pattern(c);
+  c->set_in_use(); // Forestall assert in cm
+  cm().return_chunk(c);
+}
+
+ void ChunkGtestContext::allocate_from_chunk(MetaWord** p_return_value, Metachunk* c, size_t word_size) {
+
+  size_t used_before = c->used_words();
+  size_t free_before = c->free_words();
+  size_t free_below_committed_before = c->free_below_committed_words();
+  const MetaWord* top_before = c->top();
+
+  MetaWord* p = c->allocate(word_size);
+  EXPECT_NOT_NULL(p);
+  EXPECT_EQ(c->used_words(), used_before + word_size);
+  EXPECT_EQ(c->free_words(), free_before - word_size);
+  EXPECT_EQ(c->free_below_committed_words(), free_below_committed_before - word_size);
+  EXPECT_EQ(c->top(), top_before + word_size);
+
+  // Old content should be preserved
+  test_pattern(c, used_before);
+
+  // Fill newly allocated range too
+  fill_range_with_pattern(p, word_size, (uintx)c);
+
+  *p_return_value = p;
+}
+
+void ChunkGtestContext::commit_chunk_with_test(Metachunk* c, size_t additional_size) {
+
+  size_t used_before = c->used_words();
+  size_t free_before = c->free_words();
+  const MetaWord* top_before = c->top();
+
+  c->set_in_use();
+  bool b = c->ensure_committed_additional(additional_size);
+  EXPECT_TRUE(b);
+
+  // We should have enough committed size now
+  EXPECT_GE(c->free_below_committed_words(), additional_size);
+
+  // used, free, top should be unchanged.
+  EXPECT_EQ(c->used_words(), used_before);
+  EXPECT_EQ(c->free_words(), free_before);
+  EXPECT_EQ(c->top(), top_before);
+
+  test_pattern(c, used_before);
+
+}
+
+void ChunkGtestContext::commit_chunk_expect_failure(Metachunk* c, size_t additional_size) {
+
+  size_t used_before = c->used_words();
+  size_t free_before = c->free_words();
+  size_t free_below_committed_before = c->free_below_committed_words();
+  const MetaWord* top_before = c->top();
+
+  c->set_in_use();
+  bool b = c->ensure_committed_additional(additional_size);
+  EXPECT_FALSE(b);
+
+  // Nothing should have changed
+  EXPECT_EQ(c->used_words(), used_before);
+  EXPECT_EQ(c->free_words(), free_before);
+  EXPECT_EQ(c->free_below_committed_words(), free_below_committed_before);
+  EXPECT_EQ(c->top(), top_before);
+
+  test_pattern(c, used_before);
+
+}
+
+void ChunkGtestContext::uncommit_chunk_with_test(Metachunk* c) {
+  if (c->word_size() >= Settings::commit_granule_words()) {
+    c->set_free();  // Forestall assert in uncommit
+    c->reset_used_words();
+    c->uncommit();
+
+    EXPECT_EQ(c->free_below_committed_words(), (size_t)0);
+    EXPECT_EQ(c->used_words(), (size_t)0);
+    EXPECT_EQ(c->free_words(), c->word_size());
+    EXPECT_EQ(c->top(), c->base());
+    EXPECT_TRUE(c->is_fully_uncommitted());
+  }
+}
+
+/////// SparseArray<T> ////////////////
+
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/test/hotspot/gtest/metaspace/metaspaceGtestContexts.hpp	2020-09-04 13:58:14.209513694 +0200
@@ -0,0 +1,126 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#ifndef GTEST_METASPACE_METASPACE_GTESTCONTEXTS_HPP
+#define GTEST_METASPACE_METASPACE_GTESTCONTEXTS_HPP
+
+#include "memory/allocation.hpp"
+#include "memory/metaspace/msChunklevel.hpp"
+#include "memory/metaspace/msMetachunk.hpp"
+#include "memory/metaspace/msTestHelpers.hpp"
+
+#include "metaspaceGtestCommon.hpp"
+
+using metaspace::Metachunk;
+using metaspace::chunklevel_t;
+using namespace metaspace::chunklevel;
+
+class MetaspaceGtestContext : public metaspace::MetaspaceTestContext {
+public:
+  MetaspaceGtestContext(size_t commit_limit = 0, size_t reserve_limit = 0)
+  : metaspace::MetaspaceTestContext("gtest-metaspace-context", commit_limit, reserve_limit)
+  {}
+};
+
+class ChunkGtestContext : public MetaspaceGtestContext {
+
+  int _num_chunks_allocated;
+
+  void checked_alloc_chunk_0(Metachunk** p_return_value, chunklevel_t preferred_level,
+                             chunklevel_t max_level, size_t min_committed_size);
+
+  // Test pattern established when allocating from the chunk with allocate_from_chunk_with_tests().
+  void test_pattern(Metachunk* c, size_t word_size);
+  void test_pattern(Metachunk* c) { test_pattern(c, c->used_words()); }
+
+public:
+
+  ChunkGtestContext(size_t commit_limit = 0, size_t reserve_limit = 0)
+    : MetaspaceGtestContext(commit_limit, reserve_limit),
+      _num_chunks_allocated(0)
+  {}
+
+  /////
+
+  // Note: all test functions return void and return values are by pointer ref; this is awkward but otherwise we cannot
+  // use gtest ASSERT macros inside those functions.
+
+  // Allocate a chunk (you do not know if it will succeed).
+  void alloc_chunk(Metachunk** p_return_value, chunklevel_t preferred_level, chunklevel_t max_level, size_t min_committed_size) {
+    checked_alloc_chunk_0(p_return_value, preferred_level, max_level, min_committed_size);
+  }
+
+  // Allocate a chunk; do not expect success, but if it succeeds, test the chunk.
+  void alloc_chunk(Metachunk** p_return_value, chunklevel_t level) {
+    alloc_chunk(p_return_value, level, level, word_size_for_level(level));
+  }
+
+  // Allocate a chunk; it must succeed. Test the chunk.
+  void alloc_chunk_expect_success(Metachunk** p_return_value, chunklevel_t preferred_level, chunklevel_t max_level, size_t min_committed_size) {
+    checked_alloc_chunk_0(p_return_value, preferred_level, max_level, min_committed_size);
+    ASSERT_NOT_NULL(*p_return_value);
+  }
+
+  // Allocate a chunk; it must succeed. Test the chunk.
+  void alloc_chunk_expect_success(Metachunk** p_return_value, chunklevel_t level) {
+    alloc_chunk_expect_success(p_return_value, level, level, word_size_for_level(level));
+  }
+
+  // Allocate a chunk but expect it to fail.
+  void alloc_chunk_expect_failure(chunklevel_t preferred_level, chunklevel_t max_level, size_t min_committed_size) {
+    Metachunk* c = NULL;
+    checked_alloc_chunk_0(&c, preferred_level, max_level, min_committed_size);
+    ASSERT_NULL(c);
+  }
+
+  // Allocate a chunk but expect it to fail.
+  void alloc_chunk_expect_failure(chunklevel_t level) {
+    return alloc_chunk_expect_failure(level, level, word_size_for_level(level));
+  }
+
+  /////
+
+  void return_chunk(Metachunk* c);
+
+  /////
+
+  // Allocates from a chunk; also, fills allocated area with test pattern which will be tested with test_pattern().
+  void allocate_from_chunk(MetaWord** p_return_value, Metachunk* c, size_t word_size);
+
+  // Convenience function: allocate from chunk for when you don't care for the result pointer
+  void allocate_from_chunk(Metachunk* c, size_t word_size) {
+    MetaWord* dummy;
+    allocate_from_chunk(&dummy, c, word_size);
+  }
+
+  void commit_chunk_with_test(Metachunk* c, size_t additional_size);
+  void commit_chunk_expect_failure(Metachunk* c, size_t additional_size);
+
+  void uncommit_chunk_with_test(Metachunk* c);
+
+};
+
+#endif // GTEST_METASPACE_METASPACE_GTESTCONTEXTS_HPP
+
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/test/hotspot/gtest/metaspace/metaspaceGtestRangeHelpers.hpp	2020-09-04 13:58:14.757517479 +0200
@@ -0,0 +1,184 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#ifndef GTEST_METASPACE_METASPACEGTESTRANGEHELPERS_HPP
+#define GTEST_METASPACE_METASPACEGTESTRANGEHELPERS_HPP
+
+// We use ranges-of-things in these tests a lot so some helpers help
+// keeping the code small.
+
+#include "memory/allocation.hpp"
+#include "memory/metaspace/msChunklevel.hpp"
+#include "runtime/os.hpp" // For os::random
+#include "utilities/align.hpp"
+#include "utilities/debug.hpp"
+#include "utilities/globalDefinitions.hpp"
+
+using metaspace::chunklevel_t;
+using namespace metaspace::chunklevel;
+
+// A range of numerical values.
+template <typename T, typename Td>
+class Range : public StackObj {
+
+  // start and size of range
+  T   _start;
+  Td  _size;
+
+  static Td random_uncapped_offset() {
+    if (sizeof(Td) > 4) {
+      return (Td)((uint64_t)os::random() * os::random());
+    } else {
+      return (Td)os::random();
+    }
+  }
+
+protected:
+
+  static void swap_if_needed(T& lo, T& hi) {
+    if (lo > hi) {
+      T v = lo;
+      lo = hi;
+      hi = v;
+    }
+  }
+
+public:
+
+  // Lowest value in range
+  T lowest() const      { return _start; }
+
+  // Highest value in range (including)
+  T highest() const     { return _start + (_size - 1); }
+
+  T start() const       { return _start; }
+  T end() const         { return _start + _size; }
+
+  // Number of values in range
+  Td size() const       { return _size; }
+
+  bool is_empty() const { return size() == 0; }
+
+  bool contains(T v) const {
+    return v >= _start && v < end();
+  }
+
+  bool contains(Range<T, Td> r) const {
+    return contains(r.lowest()) && contains(r.highest());
+  }
+
+  // Create a range from [start, end)
+  Range(T start, T end) : _start(start), _size(end - start) {
+    assert(end >= start, "start and end reversed");
+  }
+
+  // a range with a given size, starting at 0
+  Range(Td size) : _start(0), _size(size) {}
+
+  // Return a random offset
+  Td random_offset() const {
+    assert(!is_empty(), "Range too small");
+    Td v = random_uncapped_offset() % size();
+    return v;
+  }
+
+  // Return a random value within the range
+  T random_value() const {
+    assert(!is_empty(), "Range too small");
+    T v = _start + random_offset();
+    assert(contains(v), "Sanity");
+    return v;
+  }
+
+  // Return the head of this range up to but excluding <split_point>
+  Range<T, Td> head(Td split_point) const {
+    assert(_size >= split_point, "Sanity");
+    return Range<T, Td>(_start, _start + split_point);
+  }
+
+  // Return the tail of this range, starting at <split_point>
+  Range<T, Td> tail(Td split_point) const {
+    assert(_size > split_point, "Sanity");
+    return Range<T, Td>(_start + split_point, end());
+  }
+
+  // Return a non-empty random sub range.
+  Range<T, Td> random_subrange() const {
+    assert(size() > 1, "Range too small");
+    Td sz = MAX2((Td)1, random_offset());
+    return random_sized_subrange(sz);
+  }
+
+  // Return a subrange of given size at a random start position
+  Range<T, Td> random_sized_subrange(Td subrange_size) const {
+    assert(subrange_size > 0 && subrange_size < _size, "invalid size");
+    T start = head(_size - subrange_size).random_value();
+    return Range<T, Td>(start, start + subrange_size);
+  }
+
+  //// aligned ranges ////
+
+  bool range_is_aligned(Td alignment) const {
+    return is_aligned(_size, alignment) && is_aligned(_start, alignment);
+  }
+
+  // Return a non-empty aligned random sub range.
+  Range<T, Td> random_aligned_subrange(Td alignment) const {
+    assert(alignment > 0, "Sanity");
+    assert(range_is_aligned(alignment), "Outer range needs to be aligned"); // to keep matters simple
+    assert(_size >= alignment, "Outer range too small.");
+    Td sz = MAX2((Td)1, random_offset());
+    sz = align_up(sz, alignment);
+    return random_aligned_sized_subrange(sz, alignment);
+  }
+
+  // Return a subrange of given size at a random aligned start position
+  Range<T, Td> random_aligned_sized_subrange(Td subrange_size, Td alignment) const {
+    assert(alignment > 0, "Sanity");
+    assert(range_is_aligned(alignment), "Outer range needs to be aligned"); // to keep matters simple
+    assert(subrange_size > 0 && subrange_size <= _size &&
+           is_aligned(subrange_size, alignment), "invalid subrange size");
+    if (_size == subrange_size) {
+      return *this;
+    }
+    T start = head(_size - subrange_size).random_value();
+    start = align_down(start, alignment);
+    return Range<T, Td>(start, start + subrange_size);
+  }
+
+};
+
+typedef Range<int, int> IntRange;
+typedef Range<size_t, size_t> SizeRange;
+typedef Range<chunklevel_t, int> ChunkLevelRange;
+
+struct ChunkLevelRanges : public AllStatic {
+  static ChunkLevelRange small_chunks()  { return ChunkLevelRange(CHUNK_LEVEL_32K, CHUNK_LEVEL_1K + 1); }
+  static ChunkLevelRange medium_chunks() { return ChunkLevelRange(CHUNK_LEVEL_512K, CHUNK_LEVEL_32K + 1); }
+  static ChunkLevelRange large_chunks()  { return ChunkLevelRange(CHUNK_LEVEL_4M, CHUNK_LEVEL_512K + 1); }
+  static ChunkLevelRange all_chunks()    { return ChunkLevelRange(CHUNK_LEVEL_4M, CHUNK_LEVEL_1K + 1); }
+};
+
+#endif // GTEST_METASPACE_METASPACEGTESTRANGEHELPERS_HPP
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/test/hotspot/gtest/metaspace/metaspaceGtestSparseArray.hpp	2020-09-04 13:58:15.309521293 +0200
@@ -0,0 +1,165 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#ifndef GTEST_METASPACE_METASPACEGTESTSPARSEARRAY_HPP
+#define GTEST_METASPACE_METASPACEGTESTSPARSEARRAY_HPP
+
+#include "memory/allocation.hpp"
+#include "runtime/os.hpp"
+#include "utilities/debug.hpp"
+
+#include "metaspaceGtestCommon.hpp"
+#include "metaspaceGtestRangeHelpers.hpp"
+
+/////// SparseArray<T> ////////////////
+
+// Throughout these tests we need to keep track of allocated items (ranges of metaspace memory, metachunks, ..)
+//  and be able to random-access them. Makes sense to have a helper for that.
+template <class T>
+class SparseArray : public StackObj {
+
+  T* const _slots;
+  const int _num;
+
+  // For convenience: a range covering all possible slot indices.
+  const IntRange _index_range;
+
+  bool contains(int index) const {
+    return _index_range.contains(index);
+  }
+
+  // Check slot intex for oob
+  void check_index(int i) const {
+    assert(contains(i), "Sanity");
+  }
+
+  // Swap the content of two slots.
+  void swap(int i1, int i2) {
+    check_index(i1);
+    check_index(i2);
+    T tmp = _slots[i1];
+    _slots[i1] = _slots[i2];
+    _slots[i2] = tmp;
+  }
+
+  enum condition_t { cond_null = 0, cond_non_null = 1, cond_dontcare = 2 };
+
+  // Helper for next_matching_slot
+  bool slot_matches(int slot, condition_t c) const {
+    switch(c) {
+    case cond_null:     return _slots[slot] == NULL;
+    case cond_non_null: return _slots[slot] != NULL;
+    case cond_dontcare: return true;
+    }
+    ShouldNotReachHere();
+    return false;
+  }
+
+  // Starting at (including) index, find the next matching slot. Returns index or -1 if none found.
+  int next_matching_slot(int slot, condition_t c) const {
+    while(slot < _num) {
+      if (slot_matches(slot, c)) {
+        return slot;
+      }
+      slot++;
+    }
+    return -1;
+  }
+
+public:
+
+  SparseArray(int num)
+    : _slots(NEW_C_HEAP_ARRAY(T, num, mtInternal)),
+      _num(num),
+      _index_range(num)
+  {
+    for (int i = 0; i < _num; i++) {
+      _slots[i] = NULL;
+    }
+  }
+
+  T at(int i)              { return _slots[i]; }
+  const T at(int i) const  { return _slots[i]; }
+  void set_at(int i, T e)  { _slots[i] = e; }
+
+  int size() const         { return _num; }
+
+  bool slot_is_null(int i) const                      { check_index(i); return _slots[i] == NULL; }
+
+  DEBUG_ONLY(void check_slot_is_null(int i) const     { assert(slot_is_null(i), "Slot %d is not null", i); })
+  DEBUG_ONLY(void check_slot_is_not_null(int i) const { assert(!slot_is_null(i), "Slot %d is null", i); })
+
+  // Shuffle all elements randomly
+  void shuffle() {
+    for (int i = 0; i < _num; i++) {
+      swap(i, random_slot_index());
+    }
+  }
+
+  // Reverse elements
+  void reverse() {
+    for (int i = 0; i < _num / 2; i++) {
+      swap(i, _num - i);
+    }
+  }
+
+  int first_slot() const            { return 0; }
+  int next_slot(int index) const    { return index == _index_range.highest() ? -1 : index + 1; }
+
+  int first_non_null_slot() const         { return next_matching_slot(0, cond_non_null); }
+  int next_non_null_slot(int index) const { return next_matching_slot(index + 1, cond_non_null); }
+
+  int first_null_slot() const             { return next_matching_slot(0, cond_null); }
+  int next_null_slot(int index) const     { return next_matching_slot(index + 1, cond_null); }
+
+  // Return a random slot index.
+  int random_slot_index() const {
+    return _index_range.random_value();
+  }
+
+  int random_non_null_slot_index() const {
+    int i = next_non_null_slot(_index_range.random_value());
+    if (i == -1) {
+      i = first_non_null_slot();
+    }
+    return i;
+  }
+
+  int random_null_slot_index() const {
+    int i = next_null_slot(_index_range.random_value());
+    if (i == -1) {
+      i = first_null_slot();
+    }
+    return i;
+  }
+
+  IntRange random_slot_range() const {
+    return _index_range.random_subrange();
+  }
+
+};
+
+#endif // GTEST_METASPACE_METASPACEGTESTSPARSEARRAY_HPP
+
--- /dev/null	2020-09-04 12:37:41.765504620 +0200
+++ new/test/hotspot/gtest/metaspace/test_allocationGuard.cpp	2020-09-04 13:58:15.869525164 +0200
@@ -0,0 +1,63 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2020 SAP SE. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ *
+ */
+
+#include "precompiled.hpp"
+
+#include "memory/metaspace/msArena.hpp"
+#include "memory/metaspace/msTestHelpers.hpp"
+#include "memory/metaspace/msSettings.hpp"
+
+//#define LOG_PLEASE
+#include "metaspaceGtestCommon.hpp"
+#include "metaspaceGtestContexts.hpp"
+
+#ifdef ASSERT
+
+using metaspace::MetaspaceArena;
+using metaspace::MetaspaceTestArena;
+using metaspace::Settings;
+
+
+// Test that overwriting memory triggers an assert if allocation guards are enabled.
+//  Note: We use TEST_VM_ASSERT_MSG. However, an assert is only triggered if allocation
+//  guards are enabled; if guards are disabled for the gtests, this test would fail.
+//  So for that case, we trigger a fake assert.
+TEST_VM_ASSERT_MSG(metaspace, test_overwriter, "Corrupt block") {
+
+  if (Settings::use_allocation_guard()) {
+    MetaspaceGtestContext context;
+    MetaspaceTestArena* arena = context.create_arena(Metaspace::StandardMetaspaceType);
+    MetaWord* p = arena->allocate(10);
+    MetaWord* p2 = arena->allocate(10);
+    p[10] = (MetaWord)0x9345; // Overwriter
+    // Checks should run in destructor:
+    delete arena;
+  } else {
+    assert(false, "Corrupt block fake message to satisfy tests");
+  }
+
+}
+
+#endif // ASSERT
--- old/src/hotspot/share/memory/metaspace/allocationGuard.hpp	2020-09-04 13:58:16.685530810 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,120 +0,0 @@
-/*
- * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#ifndef SHARE_MEMORY_METASPACE_ALLOCATION_GUARD_HPP
-#define SHARE_MEMORY_METASPACE_ALLOCATION_GUARD_HPP
-
-#include "memory/allocation.hpp"
-#include "memory/metaspace/chunkLevel.hpp"
-#include "utilities/debug.hpp"
-#include "utilities/globalDefinitions.hpp"
-
-// In Debug builds, Metadata in Metaspace can be optionally guarded - enclosed in canaries -
-// to detect memory overwriters.
-//
-// These canaries are periodically checked, e.g. when the Metaspace is purged in a context
-// of a GC.
-
-// The canaries precede any allocated block...
-//
-// +---------------+
-// |  'METAMETA'   |
-// +---------------+
-// |  block size   |
-// +---------------+
-// |  block...     |
-// .               .
-// .               .
-// .               .
-// |               |
-// +---------------+
-// . <padding>     .
-// +---------------+
-// |  'METAMETA'   |
-// +---------------+
-// |  block size   |
-// +---------------+
-// |  block...     |
-
-// ... and since the blocks are allocated via pointer bump and closely follow each other,
-// one block's prefix is its predecessor's suffix, so apart from the last block all
-// blocks have an overwriter canary on both ends.
-//
-
-// Note: this feature is only available in debug, and is activated using
-//  -XX:+MetaspaceGuardAllocations. When active, it disables deallocation handling - since
-//  freeblock handling in the freeblock lists would get too complex - so one may run leaks
-//  in deallocation-heavvy scenarios (e.g. lots of class redefinitions).
-//
-
-
-namespace metaspace {
-
-#ifdef ASSERT
-
-struct prefix_t {
-  uintx mark;
-  size_t word_size;       // raw word size including prefix
-  // MetaWord payload [0];   // varsized (but unfortunately not all our compilers understand that)
-};
-
-// The prefix structure must be aligned to MetaWord size.
-STATIC_ASSERT((sizeof(prefix_t) & WordAlignmentMask) == 0);
-
-inline prefix_t* prefix_from_payload(MetaWord* p) {
-  return (prefix_t*)((address)p - sizeof(prefix_t));
-}
-
-inline MetaWord* payload_from_prefix(prefix_t* pp) {
-  // return pp->payload;
-  return (MetaWord*)((address)pp + sizeof(prefix_t));
-}
-
-inline size_t prefix_size() {
-  return sizeof(prefix_t);
-}
-
-#define EYECATCHER NOT_LP64(0x77698465) LP64_ONLY(0x7769846577698465ULL) // "META" resp "METAMETA"
-
-// Given a pointer to a memory area, establish the prefix at the start of that area and
-// return the starting pointer to the payload.
-inline MetaWord* establish_prefix(MetaWord* p_raw, size_t raw_word_size) {
-  prefix_t* pp = (prefix_t*)p_raw;
-  pp->mark = EYECATCHER;
-  pp->word_size = raw_word_size;
-  return payload_from_prefix(pp);
-}
-
-inline void check_prefix(const prefix_t* pp) {
-  assert(pp->mark == EYECATCHER, "corrupt block at " PTR_FORMAT ".", p2i(pp));
-  assert(pp->word_size > 0 && pp->word_size < chunklevel::MAX_CHUNK_WORD_SIZE,
-         "Invalid size " SIZE_FORMAT " in block at " PTR_FORMAT ".", pp->word_size, p2i(pp));
-}
-
-#endif
-
-} // namespace metaspace
-
-#endif // SHARE_MEMORY_METASPACE_ALLOCATION_GUARD_HPP
--- old/src/hotspot/share/memory/metaspace/arenaGrowthPolicy.cpp	2020-09-04 13:58:17.093533633 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,128 +0,0 @@
-/*
- * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#include "precompiled.hpp"
-
-#include "memory/metaspace/arenaGrowthPolicy.hpp"
-#include "memory/metaspace/chunkLevel.hpp"
-#include "utilities/globalDefinitions.hpp"
-
-namespace metaspace {
-
-// hard-coded chunk allocation sequences for various space types
-//  (Note: when modifying this, don't add jumps of more than double the
-//   last chunk size. There is a gtest testing this, see test_arenagrowthpolicy.cpp)
-
-static const chunklevel_t g_sequ_standard_non_class[] = {
-    chunklevel::CHUNK_LEVEL_4K,
-    chunklevel::CHUNK_LEVEL_4K,
-    chunklevel::CHUNK_LEVEL_4K,
-    chunklevel::CHUNK_LEVEL_8K,
-    chunklevel::CHUNK_LEVEL_16K
-    // .. repeat last
-};
-
-static const chunklevel_t g_sequ_standard_class[] = {
-    chunklevel::CHUNK_LEVEL_2K,
-    chunklevel::CHUNK_LEVEL_2K,
-    chunklevel::CHUNK_LEVEL_4K,
-    chunklevel::CHUNK_LEVEL_8K,
-    chunklevel::CHUNK_LEVEL_16K
-    // .. repeat last
-};
-
-static const chunklevel_t g_sequ_anon_non_class[] = {
-   chunklevel::CHUNK_LEVEL_1K,
-   // .. repeat last
-};
-
-static const chunklevel_t g_sequ_anon_class[] = {
-    chunklevel::CHUNK_LEVEL_1K,
-    // .. repeat last
-};
-
-static const chunklevel_t g_sequ_refl_non_class[] = {
-    chunklevel::CHUNK_LEVEL_2K,
-    chunklevel::CHUNK_LEVEL_1K
-    // .. repeat last
-};
-
-static const chunklevel_t g_sequ_refl_class[] = {
-    chunklevel::CHUNK_LEVEL_1K,
-    // .. repeat last
-};
-
-// Boot class loader: give it large chunks: beyond commit granule size
-// (typically 64K) the costs for large chunks largely diminishes since
-// they are committed on the fly.
-static const chunklevel_t g_sequ_boot_non_class[] = {
-    chunklevel::CHUNK_LEVEL_4M,
-    chunklevel::CHUNK_LEVEL_1M
-    // .. repeat last
-};
-
-static const chunklevel_t g_sequ_boot_class[] = {
-    chunklevel::CHUNK_LEVEL_256K
-    // .. repeat last
-};
-
-const ArenaGrowthPolicy* ArenaGrowthPolicy::policy_for_space_type(Metaspace::MetaspaceType space_type, bool is_class) {
-
-#define DEFINE_CLASS_FOR_ARRAY(what) \
-  static ArenaGrowthPolicy chunk_alloc_sequence_##what (g_sequ_##what, sizeof(g_sequ_##what)/sizeof(chunklevel_t));
-
-  DEFINE_CLASS_FOR_ARRAY(standard_non_class)
-  DEFINE_CLASS_FOR_ARRAY(standard_class)
-  DEFINE_CLASS_FOR_ARRAY(anon_non_class)
-  DEFINE_CLASS_FOR_ARRAY(anon_class)
-  DEFINE_CLASS_FOR_ARRAY(refl_non_class)
-  DEFINE_CLASS_FOR_ARRAY(refl_class)
-  DEFINE_CLASS_FOR_ARRAY(boot_non_class)
-  DEFINE_CLASS_FOR_ARRAY(boot_class)
-
-  if (is_class) {
-    switch(space_type) {
-    case Metaspace::StandardMetaspaceType:          return &chunk_alloc_sequence_standard_class;
-    case Metaspace::ReflectionMetaspaceType:        return &chunk_alloc_sequence_refl_class;
-    case Metaspace::ClassMirrorHolderMetaspaceType: return &chunk_alloc_sequence_anon_class;
-    case Metaspace::BootMetaspaceType:              return &chunk_alloc_sequence_boot_class;
-    default: ShouldNotReachHere();
-    }
-  } else {
-    switch(space_type) {
-    case Metaspace::StandardMetaspaceType:          return &chunk_alloc_sequence_standard_non_class;
-    case Metaspace::ReflectionMetaspaceType:        return &chunk_alloc_sequence_refl_non_class;
-    case Metaspace::ClassMirrorHolderMetaspaceType: return &chunk_alloc_sequence_anon_non_class;
-    case Metaspace::BootMetaspaceType:              return &chunk_alloc_sequence_boot_non_class;
-    default: ShouldNotReachHere();
-    }
-  }
-
-  return NULL;
-
-}
-
-} // namespace
-
--- old/src/hotspot/share/memory/metaspace/arenaGrowthPolicy.hpp	2020-09-04 13:58:17.501536460 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,79 +0,0 @@
-/*
- * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#ifndef SHARE_MEMORY_METASPACE_CHUNKALLOCSEQUENCE_HPP
-#define SHARE_MEMORY_METASPACE_CHUNKALLOCSEQUENCE_HPP
-
-#include "memory/metaspace.hpp" // For Metaspace::MetaspaceType
-#include "memory/metaspace/chunkLevel.hpp"
-#include "utilities/debug.hpp"
-
-namespace metaspace {
-
-
-// ArenaGrowthPolicy encodes the growth policy of a MetaspaceArena.
-//
-// These arenas grow in steps (by allocating new chunks). The coarseness of growth
-// (chunk size, level) depends on what the arena is used for. Used for a class loader
-// which is expected to load only one or very few classes should grow in tiny steps.
-// For normal classloaders, it can grow in coarser steps, and arenas used by
-// the boot loader will grow in even larger steps since we expect it to load a lot of
-// classes.
-// Note that when growing in large steps (in steps larger than a commit granule,
-// by default 64K), costs diminish somewhat since we do not commit the whole space
-// immediately.
-
-class ArenaGrowthPolicy {
-
-  // const array specifying chunk level allocation progression (growth steps). Last
-  //  chunk is to be an endlessly repeated allocation.
-  const chunklevel_t* const _entries;
-  const int _num_entries;
-
-  ArenaGrowthPolicy(const chunklevel_t* array, int num_entries)
-    : _entries(array), _num_entries(num_entries) {
-    assert(_num_entries > 0, "must not be empty.");
-  }
-
-public:
-
-  chunklevel_t get_level_at_step(int num_allocated) const {
-    if (num_allocated >= _num_entries) {
-      // Caller shall repeat last allocation
-      return _entries[_num_entries - 1];
-    }
-    return _entries[num_allocated];
-  }
-
-  // Given a space type, return the correct policy to use.
-  // The returned object is static and read only.
-  static const ArenaGrowthPolicy* policy_for_space_type(Metaspace::MetaspaceType space_type, bool is_class);
-
-};
-
-
-} // namespace metaspace
-
-#endif // SHARE_MEMORY_METASPACE_CHUNKALLOCSEQUENCE_HPP
--- old/src/hotspot/share/memory/metaspace/binlist.hpp	2020-09-04 13:58:17.917539341 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,224 +0,0 @@
-/*
- * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#ifndef SHARE_MEMORY_METASPACE_BINLIST_HPP
-#define SHARE_MEMORY_METASPACE_BINLIST_HPP
-
-#include "utilities/align.hpp"
-#include "utilities/debug.hpp"
-#include "utilities/globalDefinitions.hpp"
-#include "memory/metaspace/counter.hpp"
-#include "memory/metaspace/metaspaceCommon.hpp"
-
-namespace metaspace {
-
-// BinList is a data structure to manage small to very small memory blocks
-// (only a few words). It is used to manage deallocated blocks - see
-// class FreeBlocks.
-
-// Memory blocks are kept in linked lists. Each list
-// contains blocks of only one size. There is a list for blocks of two words,
-// for blocks of three words, etc. The list heads are kept in a vector,
-// ordered by block size.
-//
-
-// wordsize
-//
-//       +---+   +---+   +---+      +---+
-//  1    |   |-->|   |-->|   |-...->|   |
-//       +---+   +---+   +---+      +---+
-//
-//       +----+   +----+   +----+      +----+
-//  2    |    |-->|    |-->|    |-...->|    |
-//       +----+   +----+   +----+      +----+
-//
-//       +-----+   +-----+   +-----+      +-----+
-//  3    |     |-->|     |-->|     |-...->|     |
-//       +-----+   +-----+   +-----+      +-----+
-//  .
-//  .
-//  .
-//
-//       +----------+   +----------+   +----------+      +----------+
-//  n    |          |-->|          |-->|          |-...->|          |
-//       +----------+   +----------+   +----------+      +----------+
-
-
-// Insertion is of course fast, O(1).
-//
-// On retrieval, we attempt to find the closest fit to a given size, walking the
-// list head vector (a bitmask is used to speed that part up).
-//
-// This structure is a bit expensive in memory costs (we pay one pointer per managed
-// block size) so we only use it for a small number of sizes.
-
-template <size_t smallest_size, int num_lists>
-class BinListImpl {
-
-  struct block_t { block_t* next; size_t size; };
-
-  // a mask to speed up searching for populated lists.
-  // 0 marks an empty list, 1 for a non-empty one.
-  typedef uint32_t mask_t;
-  STATIC_ASSERT(num_lists <= sizeof(mask_t) * 8);
-
-  mask_t _mask;
-
-  // minimal block size must be large enough to hold a block.
-  STATIC_ASSERT(smallest_size * sizeof(MetaWord) >= sizeof(block_t));
-
-public:
-
-  // block sizes this structure can keep are limited by [_min_block_size, _max_block_size)
-  const static size_t minimal_word_size = smallest_size;
-  const static size_t maximal_word_size = minimal_word_size + num_lists;
-
-private:
-
-  block_t* _v[num_lists];
-
-  MemRangeCounter _counter;
-
-  static int index_for_word_size(size_t word_size) {
-    int index = (int)(word_size - minimal_word_size);
-    assert(index >= 0 && index < num_lists, "Invalid index %d", index);
-    return index;
-  }
-
-  static size_t word_size_for_index(int index) {
-    assert(index >= 0 && index < num_lists, "Invalid index %d", index);
-    return minimal_word_size + index;
-  }
-
-  // Search the range [index, _num_lists) for the smallest non-empty list. Returns -1 on fail.
-  int index_for_next_non_empty_list(int index) {
-    assert(index >= 0 && index < num_lists, "Invalid index %d", index);
-    int i2 = index;
-    mask_t m = _mask >> i2;
-    if (m > 0) {
-      // count leading zeros would be helpful.
-      while ((m & 1) == 0) {
-        assert(_v[i2] == NULL, "mask mismatch");
-        i2 ++;
-        m >>= 1;
-      }
-      // We must have found something.
-      assert(i2 < num_lists, "sanity.");
-      assert(_v[i2] != NULL, "mask mismatch");
-      return i2;
-    }
-    return -1;
-  }
-
-  void mask_set_bit(int bit) { _mask |= (((mask_t)1) << bit); }
-  void mask_clr_bit(int bit) { _mask &= ~(((mask_t)1) << bit); }
-
-public:
-
-  BinListImpl() : _mask(0) {
-    for (int i = 0; i < num_lists; i ++) {
-      _v[i] = NULL;
-    }
-  }
-
-  void add_block(MetaWord* p, size_t word_size) {
-    assert(word_size >= minimal_word_size &&
-           word_size < maximal_word_size, "bad block size");
-    const int index = index_for_word_size(word_size);
-    block_t* b = (block_t*)p;
-    b->size = word_size;
-    b->next = _v[index];
-    _v[index] = b;
-    _counter.add(word_size);
-    mask_set_bit(index);
-  }
-
-  // Given a word_size, searches and returns a block of at least that size.
-  // Block may be larger. Real block size is returned in *p_real_word_size.
-  MetaWord* get_block(size_t word_size, size_t* p_real_word_size) {
-    assert(word_size >= minimal_word_size &&
-           word_size < maximal_word_size, "bad block size " SIZE_FORMAT ".", word_size);
-    int index = index_for_word_size(word_size);
-    index = index_for_next_non_empty_list(index);
-    if (index != -1) {
-      assert(_v[index] != NULL &&
-             _v[index]->size >= word_size, "sanity");
-
-      MetaWord* const p = (MetaWord*)_v[index];
-      const size_t real_word_size = word_size_for_index(index);
-
-      _v[index] = _v[index]->next;
-      if (_v[index] == NULL) {
-        mask_clr_bit(index);
-      }
-
-      _counter.sub(real_word_size);
-      *p_real_word_size = real_word_size;
-
-      return p;
-
-    } else {
-
-      *p_real_word_size = 0;
-      return NULL;
-
-    }
-  }
-
-
-  // Returns number of blocks in this structure
-  unsigned count() const { return _counter.count(); }
-
-  // Returns total size, in words, of all elements.
-  size_t total_size() const { return _counter.total_size(); }
-
-  bool is_empty() const { return _mask == 0; }
-
-#ifdef ASSERT
-  void verify() const {
-    MemRangeCounter local_counter;
-    for (int i = 0; i < num_lists; i ++) {
-      assert(((_mask >> i) & 1) == ((_v[i] == 0) ? 0 : 1), "sanity");
-      const size_t s = minimal_word_size + i;
-      for (block_t* b = _v[i]; b != NULL; b = b->next) {
-        assert(b->size == s, "bad block size");
-        local_counter.add(s);
-      }
-    }
-    local_counter.check(_counter);
-  }
-#endif // ASSERT
-
-
-};
-
-typedef BinListImpl<2, 8>  BinList8;
-typedef BinListImpl<2, 16> BinList16;
-typedef BinListImpl<2, 32> BinList32;
-typedef BinListImpl<2, 64> BinList64;
-
-} // namespace metaspace
-
-#endif // SHARE_MEMORY_METASPACE_BINLIST_HPP
--- old/src/hotspot/share/memory/metaspace/blocktree.cpp	2020-09-04 13:58:18.325542170 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,169 +0,0 @@
-/*
- * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#include "precompiled.hpp"
-
-#include "memory/metaspace/blocktree.hpp"
-#include "utilities/debug.hpp"
-#include "utilities/globalDefinitions.hpp"
-#include "utilities/ostream.hpp"
-
-namespace metaspace {
-
-
-#ifdef ASSERT
-
-// Tree verification
-
-// These asserts prints the tree, then asserts
-#define assrt(cond, format, ...) \
-  if (!(cond)) { \
-    print_tree(tty); \
-    assert(cond, format, __VA_ARGS__); \
-  }
-
-  // This assert prints the tree, then stops (generic message)
-#define assrt0(cond) \
-	  if (!(cond)) { \
-	    print_tree(tty); \
-	    assert(cond, "sanity"); \
-	  }
-
-struct BlockTree::veri_data_t {
-  MemRangeCounter counter;
-  int max_edge;
-  size_t largest;
-};
-
-// Given a node, check that all siblings have the same size and that we have no
-// (direct) circularities.
-void BlockTree::verify_node_siblings(node_t* n, veri_data_t* vd) const {
-  const size_t size = n->size;
-  node_t* n2 = n->next;
-  node_t* prev_sib = NULL;
-  while (n2 != NULL) {
-    assrt0(n2->size == size);
-    vd->counter.add(n2->size);
-    if (prev_sib != NULL) {
-      assrt0(prev_sib->next == n2);
-      assrt0(prev_sib != n2);
-    }
-    prev_sib = n2;
-    n2 = n2->next;
-  }
-}
-
-// Given a node and outer bounds applying to it and all children, check it and all children recursively.
-void BlockTree::verify_node(node_t* n, size_t left_limit, size_t right_limit,
-    veri_data_t* vd, int lvl) const {
-
-  if (lvl > vd->max_edge) {
-    vd->max_edge = lvl;
-  }
-
-  if (n->size > vd->largest) {
-    vd->largest = n->size;
-  }
-
-  assrt0((n == _root && n->parent == NULL) || (n != _root && n->parent != NULL));
-
-  // check all siblings
-  if (n->next != NULL) {
-    verify_node_siblings(n, vd);
-  }
-
-  // check order
-  assrt(n->size >= minimal_word_size && n->size <= maximal_word_size,
-      "bad node size " SIZE_FORMAT, n->size);
-  assrt0(n->size < right_limit);
-  assrt0(n->size > left_limit);
-
-  vd->counter.add(n->size);
-
-  if (n->left != NULL) {
-    assrt0(n != n->left);
-    assrt0(n->left->parent == n);
-    assrt0(n->left->size < n->size);
-    assrt0(n->left->size > left_limit);
-    verify_node(n->left, left_limit, n->size, vd, lvl + 1);
-  }
-
-  if (n->right != NULL) {
-    assrt0(n != n->right);
-    assrt0(n->right->parent == n);
-    assrt0(n->right->size < right_limit);
-    assrt0(n->right->size > n->size);
-    verify_node(n->right, n->size, right_limit, vd, lvl + 1);
-  }
-
-}
-
-void BlockTree::verify_tree() const {
-  int num = 0;
-  size_t size = 0;
-  veri_data_t vd;
-  vd.max_edge = 0;
-  vd.largest = 0;
-  if (_root != NULL) {
-    assrt0(_root->parent == NULL);
-    verify_node(_root, 0, maximal_word_size + 1, &vd, 0);
-    assrt0(vd.largest == _largest_size_added);
-    vd.counter.check(_counter);
-    assrt0(vd.counter.count() > 0);
-  }
-}
-
-void BlockTree::zap_range(MetaWord* p, size_t word_size) {
-  memset(p, 0xF3, word_size * sizeof(MetaWord));
-}
-
-#undef assrt
-#undef assrt0
-
-#endif // ASSERT
-
-
-void BlockTree::print_node(outputStream* st, node_t* n, int lvl) {
-  for (int i = 0; i < lvl; i ++) {
-    st->print("---");
-  }
-  st->print_cr("<" PTR_FORMAT " (size " SIZE_FORMAT ")", p2i(n), n->size);
-  if (n->left) {
-    print_node(st, n->left, lvl + 1);
-  }
-  if (n->right) {
-    print_node(st, n->right, lvl + 1);
-  }
-}
-
-void BlockTree::print_tree(outputStream* st) const {
-  if (_root != NULL) {
-    print_node(st, _root, 0);
-  } else {
-    st->print_cr("<no nodes>");
-  }
-}
-
-} // namespace metaspace
--- old/src/hotspot/share/memory/metaspace/blocktree.hpp	2020-09-04 13:58:18.737545026 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,448 +0,0 @@
-/*
- * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#ifndef SHARE_MEMORY_METASPACE_BLOCKTREE_HPP
-#define SHARE_MEMORY_METASPACE_BLOCKTREE_HPP
-
-#include "memory/allocation.hpp"
-#include "memory/metaspace/counter.hpp"
-#include "utilities/debug.hpp"
-#include "utilities/globalDefinitions.hpp"
-
-namespace metaspace {
-
-
-// BlockTree is a rather simple binary search tree. It is used to
-//  manage small to medium free memory blocks (see class FreeBlocks).
-//
-// There is no separation between payload (managed blocks) and nodes: the
-//  memory blocks themselves are the nodes, with the block size being the key.
-//
-// We store node pointer information in these blocks when storing them. That
-//  imposes a minimum size to the managed memory blocks.
-//  See MetaspaceArene::get_raw_allocation_word_size().
-//
-// We want to manage many memory blocks of the same size, but we want
-//  to prevent the tree from blowing up and degenerating into a list. Therefore
-//  there is only one node for each unique block size; subsequent blocks of the
-//  same size are stacked below that first node:
-//
-//                   +-----+
-//                   | 100 |
-//                   +-----+
-//                  /       \
-//           +-----+
-//           | 80  |
-//           +-----+
-//          /   |   \
-//         / +-----+ \
-//  +-----+  | 80  |  +-----+
-//  | 70  |  +-----+  | 85  |
-//  +-----+     |     +-----+
-//           +-----+
-//           | 80  |
-//           +-----+
-//
-//
-// Todo: This tree is unbalanced. It would be a good fit for a red-black tree.
-//  In order to make this a red-black tree, we need an algorithm which can deal
-//  with nodes which are their own payload (most red-black tree implementations
-//  swap payloads of their nodes at some point, see e.g. j.u.TreeSet).
-// A good example is the Linux kernel rbtree, which is a clean, easy-to-read
-//  implementation.
-
-class BlockTree: public CHeapObj<mtMetaspace> {
-
-
-  struct node_t {
-
-    // Normal tree node stuff...
-    node_t* parent;
-    node_t* left;
-    node_t* right;
-
-    // blocks with the same size are put in a list with this node as head.
-    node_t* next;
-
-    // word size of node. Note that size cannot be larger than max metaspace size,
-    // so this could be very well a 32bit value (in case we ever make this a balancing
-    // tree and need additional space for weighting information).
-    size_t size;
-
-  };
-
-public:
-
-  // Largest node size, (bit arbitrarily) capped at 4M since we know this to
-  // be the max possible metaspace allocation size. TODO. Do this better.
-  const static size_t maximal_word_size = 4 * M;
-
-  // We need nodes to be at least large enough to hold a node_t
-  const static size_t minimal_word_size =
-      (sizeof(node_t) + sizeof(MetaWord) - 1) / sizeof(MetaWord);
-
-private:
-
-  node_t* _root;
-
-  // As a performance optimization, we keep the size of the largest node.
-  size_t _largest_size_added;
-
-  MemRangeCounter _counter;
-
-  // given a node n, add it to the list starting at head
-  static void add_to_list(node_t* n, node_t* head) {
-    assert(head->size == n->size, "sanity");
-    n->next = head->next;
-    head->next = n;
-    DEBUG_ONLY(n->left = n->right = n->parent = NULL;)
-  }
-
-  // given a node list starting at head, remove one node from it and return it.
-  // List must contain at least one other node.
-  static node_t* remove_from_list(node_t* head) {
-    assert(head->next != NULL, "sanity");
-    node_t* n = head->next;
-    if (n != NULL) {
-      head->next = n->next;
-    }
-    return n;
-  }
-
-  // Given a node n and a node p, wire up n as left child of p.
-  static void set_left_child(node_t* p, node_t* c) {
-    p->left = c;
-    if (c != NULL) {
-      assert(c->size < p->size, "sanity");
-      c->parent = p;
-    }
-  }
-
-  // Given a node n and a node p, wire up n as right child of p.
-  static void set_right_child(node_t* p, node_t* c) {
-    p->right = c;
-    if (c != NULL) {
-      assert(c->size > p->size, "sanity");
-      c->parent = p;
-    }
-  }
-
-  // Given a node n, return its predecessor in the tree
-  // (node with the next-smaller size).
-  static node_t* predecessor(node_t* n) {
-    node_t* pred = NULL;
-    if (n->left != NULL) {
-      pred = n->left;
-      while (pred->right != NULL) {
-        pred = pred->right;
-      }
-    } else {
-      pred = n->parent;
-      node_t* n2 = n;
-      while (pred != NULL && n2 == pred->left) {
-        n2 = pred;
-        pred = pred->parent;
-      }
-    }
-    return pred;
-  }
-
-  // Given a node n, return its predecessor in the tree
-  // (node with the next-smaller size).
-  static node_t* successor(node_t* n) {
-    node_t* succ = NULL;
-    if (n->right != NULL) {
-      // If there is a right child, search the left-most
-      // child of that child.
-      succ = n->right;
-      while (succ->left != NULL) {
-        succ = succ->left;
-      }
-    } else {
-      succ = n->parent;
-      node_t* n2 = n;
-      // As long as I am the right child of my parent, search upward
-      while (succ != NULL && n2 == succ->right) {
-        n2 = succ;
-        succ = succ->parent;
-      }
-    }
-    return succ;
-  }
-
-  // Given a node, replace it with a replacement node as a child for its parent.
-  // If the node is root and has no parent, sets it as root.
-  void replace_node_in_parent(node_t* child, node_t* replace) {
-    node_t* parent = child->parent;
-    if (parent != NULL) {
-      if (parent->left == child) { // I am a left child
-        set_left_child(parent, replace);
-      } else {
-        set_right_child(parent, replace);
-      }
-    } else {
-      assert(child == _root, "must be root");
-      _root = replace;
-      if (replace != NULL) {
-        replace->parent = NULL;
-      }
-    }
-    return;
-  }
-
-  // Given a node n and a node forebear, insert n under forebear
-  void insert(node_t* forebear, node_t* n) {
-    if (n->size == forebear->size) {
-      add_to_list(n, forebear); // parent stays NULL in this case.
-    } else {
-      if (n->size < forebear->size) {
-        if (forebear->left == NULL) {
-          set_left_child(forebear, n);
-        } else {
-          insert(forebear->left, n);
-        }
-      } else {
-        assert(n->size > forebear->size, "sanity");
-        if (forebear->right == NULL) {
-          set_right_child(forebear, n);
-          if (_largest_size_added < n->size) {
-            _largest_size_added = n->size;
-          }
-        } else {
-          insert(forebear->right, n);
-        }
-      }
-    }
-  }
-
-  // Given a node and a wish size, search this node and all children for
-  // the node closest (equal or larger sized) to the size s.
-  static node_t* find_closest_fit(node_t* n, size_t s) {
-
-    if (n->size == s) {
-      // Perfect fit.
-      return n;
-
-    } else if (n->size < s) {
-      // too small, dive down right side
-      if (n->right != NULL) {
-        return find_closest_fit(n->right, s);
-      } else {
-        return NULL;
-      }
-    } else {
-      // n is a possible fit
-      assert(n->size > s, "Sanity");
-      if (n->left != NULL && n->left->size >= s) {
-        // but not the best - dive down left side.
-        return find_closest_fit(n->left, s);
-      } else {
-        // n is the best fit.
-        return n;
-      }
-    }
-
-  }
-
-  // Given a wish size, search the whole tree for a
-  // node closest (equal or larger sized) to the size s.
-  node_t* find_closest_fit(size_t s) {
-    if (_root != NULL) {
-      return find_closest_fit(_root, s);
-    }
-    return NULL;
-  }
-
-  // Given a node n, remove it from the tree and repair tree.
-  void remove_node_from_tree(node_t* n) {
-
-    assert(n->next == NULL, "do not delete a node which has a non-empty list");
-
-    // Maintain largest size node to speed up lookup
-    if (n->size == _largest_size_added) {
-      node_t* pred = predecessor(n);
-      if (pred != NULL) {
-        _largest_size_added = pred->size;
-      } else {
-        _largest_size_added = 0;
-      }
-    }
-
-    if (n->left == NULL && n->right == NULL) {
-      replace_node_in_parent(n, NULL);
-
-    } else if (n->left == NULL && n->right != NULL) {
-      replace_node_in_parent(n, n->right);
-
-    } else if (n->left != NULL && n->right == NULL) {
-      replace_node_in_parent(n, n->left);
-
-    } else {
-
-      // Node has two children.
-
-      // 1) Find direct successor (the next larger node).
-      node_t* succ = successor(n);
-
-      // There has to be a successor since n->right was != NULL...
-      assert(succ != NULL, "must be");
-
-      // ... and it should not have a left child since successor
-      //     is supposed to be the next larger node, so it must be the mostleft node
-      //     in the sub tree rooted at n->right
-      assert(succ->left == NULL, "must be");
-
-      assert(succ->size > n->size, "sanity");
-
-      node_t* successor_parent = succ->parent;
-      node_t* successor_right_child = succ->right;
-
-      // Remove successor from its parent.
-      if (successor_parent == n) {
-
-        // special case: successor is a direct child of n. Has to be the right child then.
-        assert(n->right == succ, "sanity");
-
-        // Just replace n with this successor.
-        replace_node_in_parent(n, succ);
-
-        // Take over n's old left child, too.
-        // We keep the successor's right child.
-        set_left_child(succ, n->left);
-
-      } else {
-
-        // If the successors parent is not n, we are deeper in the tree,
-        // the successor has to be the left child of its parent.
-        assert(successor_parent->left == succ, "sanity");
-
-        // The right child of the successor (if there was one) replaces the successor at its parent's left child.
-        set_left_child(successor_parent, succ->right);
-
-        // and the successor replaces n at its parent
-        replace_node_in_parent(n, succ);
-
-        // and takes over n's old children
-        set_left_child(succ, n->left);
-        set_right_child(succ, n->right);
-
-      }
-    }
-  }
-
-#ifdef ASSERT
-
-  struct veri_data_t;
-  void verify_node_siblings(node_t* n, veri_data_t* vd) const;
-  void verify_node(node_t* n, size_t left_limit, size_t right_limit, veri_data_t* vd, int lvl) const;
-  void verify_tree() const;
-
-  void zap_range(MetaWord* p, size_t word_size);
-
-#endif // ASSERT
-
-
-  static void print_node(outputStream* st, node_t* n, int lvl);
-
-public:
-
-  BlockTree() : _root(NULL), _largest_size_added(0) {}
-
-  // Add a memory block to the tree. Memory block will be used to store
-  // node information.
-  void add_block(MetaWord* p, size_t word_size) {
-    DEBUG_ONLY(zap_range(p, word_size));
-    assert(word_size >= minimal_word_size && word_size < maximal_word_size,
-           "invalid block size " SIZE_FORMAT, word_size);
-    node_t* n = (node_t*)p;
-    n->size = word_size;
-    n->next = n->left = n->right = n->parent = NULL;
-    if (_root == NULL) {
-      _root = n;
-    } else {
-      insert(_root, n);
-    }
-    _counter.add(word_size);
-
-    // Maintain largest node to speed up lookup
-    if (_largest_size_added < n->size) {
-      _largest_size_added = n->size;
-    }
-
-  }
-
-  // Given a word_size, searches and returns a block of at least that size.
-  // Block may be larger. Real block size is returned in *p_real_word_size.
-  MetaWord* get_block(size_t word_size, size_t* p_real_word_size) {
-    assert(word_size >= minimal_word_size && word_size < maximal_word_size,
-           "invalid block size " SIZE_FORMAT, word_size);
-
-    if (_largest_size_added < word_size) {
-      return NULL;
-    }
-
-    node_t* n = find_closest_fit(word_size);
-
-    if (n != NULL) {
-      assert(n->size >= word_size, "sanity");
-
-      // If the node has siblings, remove one of them,
-      // otherwise remove this node from the tree.
-      if (n->next != NULL) {
-        n = remove_from_list(n);
-      } else {
-        remove_node_from_tree(n);
-      }
-
-      MetaWord* p = (MetaWord*)n;
-      *p_real_word_size = n->size;
-
-      _counter.sub(n->size);
-
-      DEBUG_ONLY(zap_range(p, n->size));
-
-      return p;
-    }
-    return NULL;
-  }
-
-
-  // Returns number of blocks in this structure
-  unsigned count() const { return _counter.count(); }
-
-  // Returns total size, in words, of all elements.
-  size_t total_size() const { return _counter.total_size(); }
-
-  bool is_empty() const { return _root == NULL; }
-
-  void print_tree(outputStream* st) const;
-
-  DEBUG_ONLY(void verify() const { verify_tree(); })
-
-};
-
-} // namespace metaspace
-
-#endif // SHARE_MEMORY_METASPACE_BLOCKTREE_HPP
--- old/src/hotspot/share/memory/metaspace/chunkHeaderPool.cpp	2020-09-04 13:58:19.161547967 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,94 +0,0 @@
-/*
- * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#include "precompiled.hpp"
-#include "memory/metaspace/chunkHeaderPool.hpp"
-#include "runtime/os.hpp"
-#include "utilities/debug.hpp"
-#include "utilities/globalDefinitions.hpp"
-
-namespace metaspace {
-
-
-// Returns reference to the one global chunk header pool.
-ChunkHeaderPool* ChunkHeaderPool::_chunkHeaderPool = NULL;
-
-
-ChunkHeaderPool::ChunkHeaderPool()
-  : _num_slabs(), _first_slab(NULL), _current_slab(NULL)
-{
-}
-
-// Note: the global chunk header pool gets never deleted; so this destructor only
-// exists for the sake of tests.
-ChunkHeaderPool::~ChunkHeaderPool() {
-  slab_t* s = _first_slab;
-  while (s != NULL) {
-    slab_t* next_slab = s->next;
-    os::free(s);
-     s = next_slab;
-  }
-}
-
-void ChunkHeaderPool::allocate_new_slab() {
-  slab_t* slab = new slab_t();
-  if (_current_slab != NULL) {
-    _current_slab->next = slab;
-  }
-  _current_slab = slab;
-  if (_first_slab == NULL) {
-    _first_slab = slab;
-  }
-  _num_slabs.increment();
-}
-
-// Returns size of memory used.
-size_t ChunkHeaderPool::memory_footprint_words() const {
-  return (_num_slabs.get() * sizeof(slab_t)) / BytesPerWord;
-}
-
-void ChunkHeaderPool::initialize() {
-  assert(_chunkHeaderPool == NULL, "only once");
-  _chunkHeaderPool = new ChunkHeaderPool();
-}
-
-#ifdef ASSERT
-void ChunkHeaderPool::verify(bool slow) const {
-  const slab_t* s = _first_slab;
-  int num = 0;
-  while (s != NULL) {
-    assert(s->top >= 0 && s->top <= slab_capacity,
-           "invalid slab at " PTR_FORMAT ", top: %d, slab cap: %d",
-           p2i(s), s->top, slab_capacity );
-    s = s->next;
-    num ++;
-  }
-  _num_slabs.check(num);
-}
-#endif
-
-} // namespace metaspace
-
-
--- old/src/hotspot/share/memory/metaspace/chunkHeaderPool.hpp	2020-09-04 13:58:19.673551520 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,149 +0,0 @@
-/*
- * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#ifndef SHARE_MEMORY_METASPACE_CHUNKHEADERPOOL_HPP
-#define SHARE_MEMORY_METASPACE_CHUNKHEADERPOOL_HPP
-
-#include "memory/allocation.hpp"
-#include "memory/metaspace/metachunk.hpp"
-#include "memory/metaspace/metachunkList.hpp"
-#include "utilities/debug.hpp"
-#include "utilities/globalDefinitions.hpp"
-
-namespace metaspace {
-
-// Chunk headers (Metachunk objects) are separate entities from their payload.
-//  Since they are allocated and released frequently in the course of buddy allocation
-//  (splitting, merging chunks happens often) we want allocation of them fast. Therefore
-//  we keep them in a simple pool (somewhat like a primitive slab allocator).
-
-class ChunkHeaderPool : public CHeapObj<mtMetaspace> {
-
-  static const int slab_capacity = 128;
-
-  struct slab_t : public CHeapObj<mtMetaspace> {
-    slab_t* next;
-    int top;
-    Metachunk elems [slab_capacity];
-    slab_t() : next(NULL), top(0) {
-      for (int i = 0; i < slab_capacity; i++) {
-        elems[i].clear();
-      }
-    }
-  };
-
-  IntCounter _num_slabs;
-  slab_t* _first_slab;
-  slab_t* _current_slab;
-
-  IntCounter _num_handed_out;
-
-  MetachunkList _freelist;
-
-  void allocate_new_slab();
-
-  static ChunkHeaderPool* _chunkHeaderPool;
-
-
-public:
-
-  ChunkHeaderPool();
-
-  ~ChunkHeaderPool();
-
-  // Allocates a Metachunk structure. The structure is uninitialized.
-  Metachunk* allocate_chunk_header() {
-
-    Metachunk* c = NULL;
-
-    DEBUG_ONLY(verify(false));
-
-    c = _freelist.remove_first();
-    assert(c == NULL || c->is_dead(), "Not a freelist chunk header?");
-
-    if (c == NULL) {
-
-      if (_current_slab == NULL ||
-          _current_slab->top == slab_capacity) {
-        allocate_new_slab();
-        assert(_current_slab->top < slab_capacity, "Sanity");
-      }
-
-      c = _current_slab->elems + _current_slab->top;
-      _current_slab->top ++;
-
-    }
-
-    _num_handed_out.increment();
-
-    // By contract, the returned structure is uninitialized.
-    // Zap to make this clear.
-    DEBUG_ONLY(c->zap_header(0xBB);)
-
-    return c;
-
-  }
-
-  void return_chunk_header(Metachunk* c) {
-    // We only ever should return free chunks, since returning chunks
-    // happens only on merging and merging only works with free chunks.
-    assert(c != NULL && c->is_free(), "Sanity");
-#ifdef ASSERT
-    // In debug, fill dead header with pattern.
-    c->zap_header(0xCC);
-    c->set_next(NULL);
-    c->set_prev(NULL);
-#endif
-    c->set_dead();
-    _freelist.add(c);
-    _num_handed_out.decrement();
-
-  }
-
-  // Returns number of allocated elements.
-  int used() const                   { return _num_handed_out.get(); }
-
-  // Returns number of elements in free list.
-  int freelist_size() const          { return _freelist.count(); }
-
-  // Returns size of memory used.
-  size_t memory_footprint_words() const;
-
-  DEBUG_ONLY(void verify(bool slow) const;)
-
-  static void initialize();
-
-  // Returns reference to the one global chunk header pool.
-  static ChunkHeaderPool* pool() { return _chunkHeaderPool; }
-
-};
-
-
-} // namespace metaspace
-
-
-
-
-#endif // SHARE_MEMORY_METASPACE_CHUNKHEADERPOOL_HPP
--- old/src/hotspot/share/memory/metaspace/chunkLevel.cpp	2020-09-04 13:58:20.089554409 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,69 +0,0 @@
-/*
- * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#include "precompiled.hpp"
-#include "memory/metaspace/chunkLevel.hpp"
-#include "utilities/debug.hpp"
-#include "utilities/globalDefinitions.hpp"
-#include "utilities/ostream.hpp"
-#include "utilities/powerOfTwo.hpp"
-
-namespace metaspace {
-
-using namespace chunklevel;
-
-chunklevel_t chunklevel::level_fitting_word_size(size_t word_size) {
-
-  assert(MAX_CHUNK_WORD_SIZE >= word_size,
-         SIZE_FORMAT " - too large allocation size.", word_size * BytesPerWord);
-
-  if (word_size <= MIN_CHUNK_WORD_SIZE) {
-    return HIGHEST_CHUNK_LEVEL;
-  }
-
-  const size_t v_pow2 = round_up_power_of_2(word_size);
-  const chunklevel_t lvl =  (chunklevel_t)(exact_log2(MAX_CHUNK_WORD_SIZE) - exact_log2(v_pow2));
-
-  return lvl;
-
-}
-
-void chunklevel::print_chunk_size(outputStream* st, chunklevel_t lvl) {
-  if (chunklevel::is_valid_level(lvl)) {
-    const size_t s = chunklevel::word_size_for_level(lvl) * BytesPerWord;
-    if (s < 1 * M) {
-      st->print("%3uk", (unsigned)(s / K));
-    } else {
-      st->print("%3um", (unsigned)(s / M));
-    }
-  } else {
-    st->print("?-?");
-  }
-
-}
-
-} // namespace metaspace
-
-
--- old/src/hotspot/share/memory/metaspace/chunkLevel.hpp	2020-09-04 13:58:20.501557271 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,132 +0,0 @@
-/*
- * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#ifndef SHARE_MEMORY_METASPACE_CHUNKLEVEL_HPP
-#define SHARE_MEMORY_METASPACE_CHUNKLEVEL_HPP
-
-#include "utilities/globalDefinitions.hpp"
-
-// Constants for the chunk levels and some utility functions.
-
-class outputStream;
-
-namespace metaspace {
-
-
-// Chunks are managed by a binary buddy allocator.
-
-// Chunk sizes range from 1K to 4MB (64bit).
-//
-
-// Each chunk has a level; the level corresponds to its position in the tree
-// and describes its size.
-//
-// The largest chunks are called root chunks, of 4MB in size, and have level 0.
-// From there on it goes:
-//
-// size    level
-// 4MB     0
-// 2MB     1
-// 1MB     2
-// 512K    3
-// 256K    4
-// 128K    5
-// 64K     6
-// 32K     7
-// 16K     8
-// 8K      9
-// 4K      10
-// 2K      11
-// 1K      12
-
-// Metachunk level (must be signed)
-typedef signed char chunklevel_t;
-
-#define CHKLVL_FORMAT "lv%.2d"
-
-namespace chunklevel {
-
-static const size_t   MAX_CHUNK_BYTE_SIZE    = 4 * M;
-static const int      NUM_CHUNK_LEVELS       = 13;
-static const size_t   MIN_CHUNK_BYTE_SIZE    = (MAX_CHUNK_BYTE_SIZE >> ((size_t)NUM_CHUNK_LEVELS - 1));
-
-static const size_t   MIN_CHUNK_WORD_SIZE    = MIN_CHUNK_BYTE_SIZE / sizeof(MetaWord);
-static const size_t   MAX_CHUNK_WORD_SIZE    = MAX_CHUNK_BYTE_SIZE / sizeof(MetaWord);
-
-static const chunklevel_t ROOT_CHUNK_LEVEL       = 0;
-
-static const chunklevel_t HIGHEST_CHUNK_LEVEL    = NUM_CHUNK_LEVELS - 1;
-static const chunklevel_t LOWEST_CHUNK_LEVEL     = 0;
-
-static const chunklevel_t INVALID_CHUNK_LEVEL    = (chunklevel_t) -1;
-
-inline bool is_valid_level(chunklevel_t level) {
-  return level >= LOWEST_CHUNK_LEVEL &&
-         level <= HIGHEST_CHUNK_LEVEL;
-}
-
-inline void check_valid_level(chunklevel_t lvl) {
-  assert(is_valid_level(lvl), "invalid level (%d)", (int)lvl);
-}
-
-// Given a level return the chunk size, in words.
-inline size_t word_size_for_level(chunklevel_t level) {
-  return (MAX_CHUNK_BYTE_SIZE >> level) / BytesPerWord;
-}
-
-// Given an arbitrary word size smaller than the highest chunk size,
-// return the highest chunk level able to hold this size.
-// Returns INVALID_CHUNK_LEVEL if no fitting level can be found.
-chunklevel_t level_fitting_word_size(size_t word_size);
-
-// Shorthands to refer to exact sizes
-static const chunklevel_t CHUNK_LEVEL_4M =     ROOT_CHUNK_LEVEL;
-static const chunklevel_t CHUNK_LEVEL_2M =    (ROOT_CHUNK_LEVEL + 1);
-static const chunklevel_t CHUNK_LEVEL_1M =    (ROOT_CHUNK_LEVEL + 2);
-static const chunklevel_t CHUNK_LEVEL_512K =  (ROOT_CHUNK_LEVEL + 3);
-static const chunklevel_t CHUNK_LEVEL_256K =  (ROOT_CHUNK_LEVEL + 4);
-static const chunklevel_t CHUNK_LEVEL_128K =  (ROOT_CHUNK_LEVEL + 5);
-static const chunklevel_t CHUNK_LEVEL_64K =   (ROOT_CHUNK_LEVEL + 6);
-static const chunklevel_t CHUNK_LEVEL_32K =   (ROOT_CHUNK_LEVEL + 7);
-static const chunklevel_t CHUNK_LEVEL_16K =   (ROOT_CHUNK_LEVEL + 8);
-static const chunklevel_t CHUNK_LEVEL_8K =    (ROOT_CHUNK_LEVEL + 9);
-static const chunklevel_t CHUNK_LEVEL_4K =    (ROOT_CHUNK_LEVEL + 10);
-static const chunklevel_t CHUNK_LEVEL_2K =    (ROOT_CHUNK_LEVEL + 11);
-static const chunklevel_t CHUNK_LEVEL_1K =    (ROOT_CHUNK_LEVEL + 12);
-
-STATIC_ASSERT(CHUNK_LEVEL_1K == HIGHEST_CHUNK_LEVEL);
-STATIC_ASSERT(CHUNK_LEVEL_4M == LOWEST_CHUNK_LEVEL);
-STATIC_ASSERT(ROOT_CHUNK_LEVEL == LOWEST_CHUNK_LEVEL);
-
-/////////////////////////////////////////////////////////
-// print helpers
-void print_chunk_size(outputStream* st, chunklevel_t lvl);
-
-
-} // namespace chunklevel
-
-} // namespace metaspace
-
-#endif // SHARE_MEMORY_METASPACE_CHUNKLEVEL_HPP
--- old/src/hotspot/share/memory/metaspace/chunkManager.cpp	2020-09-04 13:58:20.913560134 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,479 +0,0 @@
-/*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#include "precompiled.hpp"
-
-
-#include "logging/log.hpp"
-#include "logging/logStream.hpp"
-#include "memory/metaspace/arenaGrowthPolicy.hpp"
-#include "memory/metaspace/chunkLevel.hpp"
-#include "memory/metaspace/chunkManager.hpp"
-#include "memory/metaspace/internStat.hpp"
-#include "memory/metaspace/metachunk.hpp"
-#include "memory/metaspace/metaspaceCommon.hpp"
-#include "memory/metaspace/metaspaceContext.hpp"
-#include "memory/metaspace/metaspaceStatistics.hpp"
-#include "memory/metaspace/settings.hpp"
-#include "memory/metaspace/virtualSpaceNode.hpp"
-#include "memory/metaspace/virtualSpaceList.hpp"
-#include "runtime/mutexLocker.hpp"
-#include "utilities/debug.hpp"
-#include "utilities/globalDefinitions.hpp"
-
-namespace metaspace {
-
-#define LOGFMT         "ChkMgr @" PTR_FORMAT " (%s)"
-#define LOGFMT_ARGS    p2i(this), this->_name
-
-// Return a single chunk to the freelist and adjust accounting. No merge is attempted.
-void ChunkManager::return_chunk_simple_locked(Metachunk* c) {
-
-  assert_lock_strong(MetaspaceExpand_lock);
-
-  DEBUG_ONLY(c->verify(false));
-
-  const chunklevel_t lvl = c->level();
-  _chunks.add(c);
-  c->reset_used_words();
-
-  // Tracing
-  log_debug(metaspace)("ChunkManager %s: returned chunk " METACHUNK_FORMAT ".",
-                       _name, METACHUNK_FORMAT_ARGS(c));
-
-}
-
-// Creates a chunk manager with a given name (which is for debug purposes only)
-// and an associated space list which will be used to request new chunks from
-// (see get_chunk())
-ChunkManager::ChunkManager(const char* name, VirtualSpaceList* space_list)
-  : _vslist(space_list),
-    _name(name),
-    _chunks()
-{
-}
-
-// Given a chunk, split it into a target chunk of a smaller size (higher target level)
-//  and at least one, possible several splinter chunks.
-// The original chunk must be outside of the freelist and its state must be free.
-// The splinter chunks are added to the freelist.
-// The resulting target chunk will be located at the same address as the original
-//  chunk, but it will of course be smaller (of a higher level).
-// The committed areas within the original chunk carry over to the resulting
-//  chunks.
-void ChunkManager::split_chunk_and_add_splinters(Metachunk* c, chunklevel_t target_level) {
-
-  assert_lock_strong(MetaspaceExpand_lock);
-
-  assert(c->is_free(), "chunk to be split must be free.");
-  assert(c->level() < target_level, "Target level must be higher than current level.");
-  assert(c->prev() == NULL && c->next() == NULL, "Chunk must be outside of any list.");
-
-  DEBUG_ONLY(chunklevel::check_valid_level(target_level);)
-  DEBUG_ONLY(c->verify(true);)
-
-  UL2(debug, "splitting chunk " METACHUNK_FORMAT " to " CHKLVL_FORMAT ".",
-      METACHUNK_FORMAT_ARGS(c), target_level);
-
-  DEBUG_ONLY(size_t committed_words_before = c->committed_words();)
-
-  const chunklevel_t orig_level = c->level();
-  c->vsnode()->split(target_level, c, &_chunks);
-
-  // Splitting should never fail.
-  assert(c->level() == target_level, "Sanity");
-
-  // The size of the committed portion should not change (subject to the reduced chunk size of course)
-#ifdef ASSERT
-  if (committed_words_before > c->word_size()) {
-    assert(c->is_fully_committed(), "Sanity");
-  } else {
-    assert(c->committed_words() == committed_words_before, "Sanity");
-  }
-#endif
-
-  DEBUG_ONLY(c->verify(false));
-
-  DEBUG_ONLY(verify_locked(true);)
-
-  SOMETIMES(c->vsnode()->verify_locked(true);)
-
-  InternalStats::inc_num_chunk_splits();
-
-}
-
-// On success, returns a chunk of level of <preferred_level>, but at most <max_level>.
-//  The first first <min_committed_words> of the chunk are guaranteed to be committed.
-// On error, will return NULL.
-//
-// This function may fail for two reasons:
-// - Either we are unable to reserve space for a new chunk (if the underlying VirtualSpaceList
-//   is non-expandable but needs expanding - aka out of compressed class space).
-// - Or, if the necessary space cannot be committed because we hit a commit limit.
-//   This may be either the GC threshold or MaxMetaspaceSize.
-Metachunk* ChunkManager::get_chunk(chunklevel_t preferred_level, chunklevel_t max_level, size_t min_committed_words) {
-
-  assert(preferred_level <= max_level, "Sanity");
-  assert(chunklevel::level_fitting_word_size(min_committed_words) >= max_level, "Sanity");
-
-  MutexLocker fcl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
-
-  DEBUG_ONLY(verify_locked(false);)
-
-  DEBUG_ONLY(chunklevel::check_valid_level(max_level);)
-  DEBUG_ONLY(chunklevel::check_valid_level(preferred_level);)
-  assert(max_level >= preferred_level, "invalid level.");
-
-  UL2(debug, "requested chunk: pref_level: " CHKLVL_FORMAT
-     ", max_level: " CHKLVL_FORMAT ", min committed size: " SIZE_FORMAT ".",
-     preferred_level, max_level, min_committed_words);
-
-  // First, optimistically look for a chunk which is already committed far enough to hold min_word_size.
-
-  // 1) Search best or smaller committed chunks (first attempt):
-  //    Start at the preferred chunk size and work your way down (level up).
-  //    But for now, only consider chunks larger than a certain threshold -
-  //    this is to prevent large loaders (eg boot) from unnecessarily gobbling up
-  //    all the tiny splinter chunks lambdas leave around.
-  Metachunk* c = NULL;
-  c = _chunks.search_chunk_ascending(preferred_level, MIN2((chunklevel_t)(preferred_level + 2), max_level), min_committed_words);
-
-  // 2) Search larger committed chunks:
-  //    If that did not yield anything, look at larger chunks, which may be committed. We would have to split
-  //    them first, of course.
-  if (c == NULL) {
-    c = _chunks.search_chunk_descending(preferred_level, min_committed_words);
-  }
-
-  // 3) Search best or smaller committed chunks (second attempt):
-  //    Repeat (1) but now consider even the tiniest chunks as long as they are large enough to hold the
-  //    committed min size.
-  if (c == NULL) {
-    c = _chunks.search_chunk_ascending(preferred_level, max_level, min_committed_words);
-  }
-
-  // if we did not get anything yet, there are no free chunks commmitted enough. Repeat search but look for uncommitted chunks too:
-
-  // 4) Search best or smaller chunks, can be uncommitted:
-  if (c == NULL) {
-    c = _chunks.search_chunk_ascending(preferred_level, max_level, 0);
-  }
-
-  // 5) Search a larger uncommitted chunk:
-  if (c == NULL) {
-    c = _chunks.search_chunk_descending(preferred_level, 0);
-  }
-
-  if (c != NULL) {
-    UL(trace, "taken from freelist.");
-  }
-
-  // Failing all that, allocate a new root chunk from the connected virtual space.
-  // This may fail if the underlying vslist cannot be expanded (e.g. compressed class space)
-  if (c == NULL) {
-    c = _vslist->allocate_root_chunk();
-    if (c == NULL) {
-      UL(info, "failed to get new root chunk.");
-    } else {
-      assert(c->level() == chunklevel::ROOT_CHUNK_LEVEL, "root chunk expected");
-      UL(debug, "allocated new root chunk.");
-    }
-  }
-
-  if (c == NULL) {
-    // If we end up here, we found no match in the freelists and were unable to get a new
-    // root chunk (so we used up all address space, e.g. out of CompressedClassSpace).
-    UL2(info, "failed to get chunk (preferred level: " CHKLVL_FORMAT
-       ", max level " CHKLVL_FORMAT ".", preferred_level, max_level);
-    c = NULL;
-  }
-
-  if (c != NULL) {
-
-    // Now we have a chunk.
-    //  It may be larger than what the caller wanted, so we may want to split it. This should
-    //  always work.
-    if (c->level() < preferred_level) {
-      split_chunk_and_add_splinters(c, preferred_level);
-      assert(c->level() == preferred_level, "split failed?");
-    }
-
-    // Attempt to commit the chunk (depending on settings, we either fully commit it or just
-    //  commit enough to get the caller going). That may fail if we hit a commit limit. In
-    //  that case put the chunk back to the freelist (re-merging it with its neighbors if we
-    //  did split it) and return NULL.
-    const size_t to_commit = Settings::new_chunks_are_fully_committed() ? c->word_size() : min_committed_words;
-    if (c->committed_words() < to_commit) {
-      if (c->ensure_committed_locked(to_commit) == false) {
-        UL2(info, "failed to commit " SIZE_FORMAT " words on chunk " METACHUNK_FORMAT ".",
-            to_commit,  METACHUNK_FORMAT_ARGS(c));
-        c->set_in_use(); // gets asserted in return_chunk().
-        return_chunk_locked(c);
-        c = NULL;
-      }
-    }
-
-    if (c != NULL) {
-
-      // Still here? We have now a good chunk, all is well.
-      assert(c->committed_words() >= min_committed_words, "Sanity");
-
-      // Any chunk returned from ChunkManager shall be marked as in use.
-      c->set_in_use();
-
-      UL2(debug, "handing out chunk " METACHUNK_FORMAT ".", METACHUNK_FORMAT_ARGS(c));
-
-      InternalStats::inc_num_chunks_taken_from_freelist();
-
-      SOMETIMES(c->vsnode()->verify_locked(true);)
-
-    }
-
-  }
-
-  DEBUG_ONLY(verify_locked(false);)
-
-  return c;
-
-}
-
-
-// Return a single chunk to the ChunkManager and adjust accounting. May merge chunk
-//  with neighbors.
-// As a side effect this removes the chunk from whatever list it has been in previously.
-// Happens after a Classloader was unloaded and releases its metaspace chunks.
-// !! Note: this may invalidate the chunk. Do not access the chunk after
-//    this function returns !!
-void ChunkManager::return_chunk(Metachunk* c) {
-  MutexLocker fcl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
-  return_chunk_locked(c);
-}
-
-// See return_chunk().
-void ChunkManager::return_chunk_locked(Metachunk* c) {
-
-  assert_lock_strong(MetaspaceExpand_lock);
-
-  UL2(debug, ": returning chunk " METACHUNK_FORMAT ".", METACHUNK_FORMAT_ARGS(c));
-
-  DEBUG_ONLY(c->verify(true);)
-
-  assert(contains_chunk(c) == false, "A chunk to be added to the freelist must not be in the freelist already.");
-
-  assert(c->is_in_use(), "Unexpected chunk state");
-  assert(!c->in_list(), "Remove from list first");
-  c->set_free();
-  c->reset_used_words();
-
-  const chunklevel_t orig_lvl = c->level();
-
-  Metachunk* merged = NULL;
-  if (!c->is_root_chunk()) {
-    // Only attempt merging if we are not of the lowest level already.
-    merged = c->vsnode()->merge(c, &_chunks);
-  }
-
-  if (merged != NULL) {
-
-    InternalStats::inc_num_chunk_merges();
-
-    DEBUG_ONLY(merged->verify(false));
-
-    // We did merge our chunk into a different chunk.
-
-    // We did merge chunks and now have a bigger chunk.
-    assert(merged->level() < orig_lvl, "Sanity");
-
-    UL2(debug, "merged into chunk " METACHUNK_FORMAT ".", METACHUNK_FORMAT_ARGS(merged));
-
-    c = merged;
-
-  }
-
-  if (Settings::uncommit_free_chunks() &&
-      c->word_size() >= Settings::commit_granule_words())
-  {
-    UL2(debug, "uncommitting free chunk " METACHUNK_FORMAT ".", METACHUNK_FORMAT_ARGS(c));
-    c->uncommit_locked();
-  }
-
-  return_chunk_simple_locked(c);
-
-  DEBUG_ONLY(verify_locked(false);)
-  SOMETIMES(c->vsnode()->verify_locked(true);)
-
-  InternalStats::inc_num_chunks_returned_to_freelist();
-
-}
-
-// Given a chunk c, whose state must be "in-use" and must not be a root chunk, attempt to
-// enlarge it in place by claiming its trailing buddy.
-//
-// This will only work if c is the leader of the buddy pair and the trailing buddy is free.
-//
-// If successful, the follower chunk will be removed from the freelists, the leader chunk c will
-// double in size (level decreased by one).
-//
-// On success, true is returned, false otherwise.
-bool ChunkManager::attempt_enlarge_chunk(Metachunk* c) {
-  MutexLocker fcl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
-  return c->vsnode()->attempt_enlarge_chunk(c, &_chunks);
-}
-
-static void print_word_size_delta(outputStream* st, size_t word_size_1, size_t word_size_2) {
-  if (word_size_1 == word_size_2) {
-    print_scaled_words(st, word_size_1);
-    st->print (" (no change)");
-  } else {
-    print_scaled_words(st, word_size_1);
-    st->print("->");
-    print_scaled_words(st, word_size_2);
-    st->print(" (");
-    if (word_size_2 <= word_size_1) {
-      st->print("-");
-      print_scaled_words(st, word_size_1 - word_size_2);
-    } else {
-      st->print("+");
-      print_scaled_words(st, word_size_2 - word_size_1);
-    }
-    st->print(")");
-  }
-}
-
-void ChunkManager::purge() {
-
-  MutexLocker fcl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
-
-  UL(info, ": reclaiming memory...");
-
-  const size_t reserved_before = _vslist->reserved_words();
-  const size_t committed_before = _vslist->committed_words();
-  int num_nodes_purged = 0;
-
-  // 1) purge virtual space list
-  num_nodes_purged = _vslist->purge(&_chunks);
-  InternalStats::inc_num_purges();
-
-  // 2) uncommit free chunks
-  if (Settings::uncommit_free_chunks()) {
-    const chunklevel_t max_level =
-        chunklevel::level_fitting_word_size(Settings::commit_granule_words());
-    for (chunklevel_t l = chunklevel::LOWEST_CHUNK_LEVEL;
-         l <= max_level;
-         l ++)
-    {
-      // Since we uncommit all chunks at this level, we do not break the "committed chunks are
-      //  at the front of the list" condition.
-      for (Metachunk* c = _chunks.first_at_level(l); c != NULL; c = c->next()) {
-        c->uncommit_locked();
-      }
-    }
-  }
-
-  const size_t reserved_after = _vslist->reserved_words();
-  const size_t committed_after = _vslist->committed_words();
-
-  // Print a nice report.
-  if (reserved_after == reserved_before && committed_after == committed_before) {
-    UL(info, "nothing reclaimed.");
-  } else {
-    LogTarget(Info, metaspace) lt;
-    if (lt.is_enabled()) {
-      LogStream ls(lt);
-      ls.print_cr(LOGFMT ": finished reclaiming memory: ", LOGFMT_ARGS);
-
-      ls.print("reserved: ");
-      print_word_size_delta(&ls, reserved_before, reserved_after);
-      ls.cr();
-
-      ls.print("committed: ");
-      print_word_size_delta(&ls, committed_before, committed_after);
-      ls.cr();
-
-      ls.print_cr("full nodes purged: %d", num_nodes_purged);
-    }
-  }
-
-  DEBUG_ONLY(_vslist->verify_locked(true));
-  DEBUG_ONLY(verify_locked(true));
-
-}
-
-// Convenience methods to return the global class-space chunkmanager
-//  and non-class chunkmanager, respectively.
-ChunkManager* ChunkManager::chunkmanager_class() {
-  return MetaspaceContext::context_class() == NULL ? NULL : MetaspaceContext::context_class()->cm();
-}
-
-ChunkManager* ChunkManager::chunkmanager_nonclass() {
-  return MetaspaceContext::context_nonclass() == NULL ? NULL : MetaspaceContext::context_nonclass()->cm();
-}
-
-// Update statistics.
-void ChunkManager::add_to_statistics(cm_stats_t* out) const {
-
-  MutexLocker fcl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
-
-  for (chunklevel_t l = chunklevel::ROOT_CHUNK_LEVEL; l <= chunklevel::HIGHEST_CHUNK_LEVEL; l ++) {
-    out->num_chunks[l] += _chunks.num_chunks_at_level(l);
-    out->committed_word_size[l] += _chunks.committed_word_size_at_level(l);
-  }
-
-  DEBUG_ONLY(out->verify();)
-
-}
-
-#ifdef ASSERT
-
-void ChunkManager::verify(bool slow) const {
-  MutexLocker fcl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
-  verify_locked(slow);
-}
-
-void ChunkManager::verify_locked(bool slow) const {
-  assert_lock_strong(MetaspaceExpand_lock);
-  assert(_vslist != NULL, "No vslist");
-  _chunks.verify();
-}
-
-bool ChunkManager::contains_chunk(Metachunk* c) const {
-  return _chunks.contains(c);
-}
-
-#endif // ASSERT
-
-void ChunkManager::print_on(outputStream* st) const {
-  MutexLocker fcl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
-  print_on_locked(st);
-}
-
-void ChunkManager::print_on_locked(outputStream* st) const {
-  assert_lock_strong(MetaspaceExpand_lock);
-  st->print_cr("cm %s: %d chunks, total word size: " SIZE_FORMAT ", committed word size: " SIZE_FORMAT, _name,
-               total_num_chunks(), total_word_size(), _chunks.committed_word_size());
-  _chunks.print_on(st);
-}
-
-} // namespace metaspace
--- old/src/hotspot/share/memory/metaspace/chunkManager.hpp	2020-09-04 13:58:21.325562998 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,192 +0,0 @@
-/*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#ifndef SHARE_MEMORY_METASPACE_CHUNKMANAGER_HPP
-#define SHARE_MEMORY_METASPACE_CHUNKMANAGER_HPP
-
-#include "memory/allocation.hpp"
-#include "memory/metaspace/chunkLevel.hpp"
-#include "memory/metaspace/counter.hpp"
-#include "memory/metaspace/freeChunkList.hpp"
-#include "memory/metaspace/metachunk.hpp"
-
-namespace metaspace {
-
-class VirtualSpaceList;
-struct cm_stats_t;
-
-// ChunkManager has a somewhat central role.
-
-// Arenas request chunks from it and, on death, return chunks back to it.
-//  It keeps freelists for chunks, one per chunk level, sorted by chunk
-//  commit state.
-//  To feed the freelists, it allocates root chunks from the associated
-//  VirtualSpace below it.
-//
-// ChunkManager directs splitting chunks, if a chunk request cannot be
-//  fulfilled directly. It also takes care of merging when chunks are
-//  returned to it, before they are added to the freelist.
-//
-// The freelists are double linked double headed; fully committed chunks
-//  are added to the front, others to the back.
-//
-// Level
-//          +--------------------+   +--------------------+
-//  0  +----|  free root chunk   |---|  free root chunk   |---...
-//     |    +--------------------+   +--------------------+
-//     |
-//     |    +----------+   +----------+
-//  1  +----|          |---|          |---...
-//     |    +----------+   +----------+
-//     |
-//  .
-//  .
-//  .
-//
-//     |    +-+   +-+
-//  12 +----| |---| |---...
-//          +-+   +-+
-
-
-class ChunkManager : public CHeapObj<mtMetaspace> {
-
-  // A chunk manager is connected to a virtual space list which is used
-  // to allocate new root chunks when no free chunks are found.
-  VirtualSpaceList* const _vslist;
-
-  // Name
-  const char* const _name;
-
-  // Freelists
-  FreeChunkListVector _chunks;
-
-  // Returns true if this manager contains the given chunk. Slow (walks free lists) and
-  // only needed for verifications.
-  DEBUG_ONLY(bool contains_chunk(Metachunk* c) const;)
-
-  // Given a chunk, split it into a target chunk of a smaller size (target level)
-  //  at least one, possible more splinter chunks. Splinter chunks are added to the
-  //  freelist.
-  // The original chunk must be outside of the freelist and its state must be free.
-  // The resulting target chunk will be located at the same address as the original
-  //  chunk, but it will of course be smaller (of a higher level).
-  // The committed areas within the original chunk carry over to the resulting
-  //  chunks.
-  void split_chunk_and_add_splinters(Metachunk* c, chunklevel_t target_level);
-
-  // See get_chunk(s,s,s)
-  Metachunk* get_chunk_locked(size_t preferred_word_size, size_t min_word_size, size_t min_committed_words);
-
-  // Uncommit all chunks equal or below the given level.
-  void uncommit_free_chunks(chunklevel_t max_level);
-
-  // Return a single chunk to the freelist without doing any merging, and adjust accounting.
-  void return_chunk_simple_locked(Metachunk* c);
-
-  // See return_chunk().
-  void return_chunk_locked(Metachunk* c);
-
-public:
-
-  // Creates a chunk manager with a given name (which is for debug purposes only)
-  // and an associated space list which will be used to request new chunks from
-  // (see get_chunk())
-  ChunkManager(const char* name, VirtualSpaceList* space_list);
-
-  // On success, returns a chunk of level of <preferred_level>, but at most <max_level>.
-  //  The first first <min_committed_words> of the chunk are guaranteed to be committed.
-  // On error, will return NULL.
-  //
-  // This function may fail for two reasons:
-  // - Either we are unable to reserve space for a new chunk (if the underlying VirtualSpaceList
-  //   is non-expandable but needs expanding - aka out of compressed class space).
-  // - Or, if the necessary space cannot be committed because we hit a commit limit.
-  //   This may be either the GC threshold or MaxMetaspaceSize.
-  Metachunk* get_chunk(chunklevel_t preferred_level, chunklevel_t max_level, size_t min_committed_words);
-
-  // Convenience function - get a chunk of a given level, uncommitted.
-  Metachunk* get_chunk(chunklevel_t lvl) { return get_chunk(lvl, lvl, 0); }
-
-  // Return a single chunk to the ChunkManager and adjust accounting. May merge chunk
-  //  with neighbors.
-  // Happens after a Classloader was unloaded and releases its metaspace chunks.
-  // !! Notes:
-  //    1) After this method returns, c may not be valid anymore. ** Do not access c after this function returns **.
-  //    2) This function will not remove c from its current chunk list. This has to be done by the caller prior to
-  //       calling this method.
-  void return_chunk(Metachunk* c);
-
-  // Given a chunk c, which must be "in use" and must not be a root chunk, attempt to
-  // enlarge it in place by claiming its trailing buddy.
-  //
-  // This will only work if c is the leader of the buddy pair and the trailing buddy is free.
-  //
-  // If successful, the follower chunk will be removed from the freelists, the leader chunk c will
-  // double in size (level decreased by one).
-  //
-  // On success, true is returned, false otherwise.
-  bool attempt_enlarge_chunk(Metachunk* c);
-
-  // Attempt to reclaim free areas in metaspace wholesale:
-  // - first, attempt to purge nodes of the backing virtual space list: nodes which are completely
-  //   unused get unmapped and deleted completely.
-  // - second, it will uncommit free chunks depending on commit granule size.
-  void purge();
-
-  // Run verifications. slow=true: verify chunk-internal integrity too.
-  DEBUG_ONLY(void verify(bool slow) const;)
-  DEBUG_ONLY(void verify_locked(bool slow) const;)
-
-  // Returns the name of this chunk manager.
-  const char* name() const                  { return _name; }
-
-  // Returns total number of chunks
-  int total_num_chunks() const              { return _chunks.num_chunks(); }
-
-  // Returns number of words in all free chunks (regardless of commit state).
-  size_t total_word_size() const            { return _chunks.word_size(); }
-
-  // Returns number of committed words in all free chunks.
-  size_t total_committed_word_size() const  { return _chunks.committed_word_size(); }
-
-  // Update statistics.
-  void add_to_statistics(cm_stats_t* out) const;
-
-  void print_on(outputStream* st) const;
-  void print_on_locked(outputStream* st) const;
-
-public:
-
-  // Convenience methods to return the global class-space chunkmanager
-  //  and non-class chunkmanager, respectively.
-  static ChunkManager* chunkmanager_class();
-  static ChunkManager* chunkmanager_nonclass();
-
-
-};
-
-} // namespace metaspace
-
-#endif // SHARE_MEMORY_METASPACE_CHUNKMANAGER_HPP
--- old/src/hotspot/share/memory/metaspace/classLoaderMetaspace.cpp	2020-09-04 13:58:21.741565891 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,210 +0,0 @@
-/*
- * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#include "precompiled.hpp"
-
-#include "logging/log.hpp"
-#include "memory/metaspace/arenaGrowthPolicy.hpp"
-#include "memory/metaspace.hpp"
-#include "memory/metaspaceTracer.hpp"
-#include "memory/metaspace/chunkManager.hpp"
-#include "memory/metaspace/internStat.hpp"
-#include "memory/metaspace/metaspaceArena.hpp"
-#include "memory/metaspace/metaspaceEnums.hpp"
-#include "memory/metaspace/metaspaceStatistics.hpp"
-#include "memory/metaspace/runningCounters.hpp"
-#include "memory/metaspace/settings.hpp"
-#include "runtime/atomic.hpp"
-#include "utilities/debug.hpp"
-
-using metaspace::clms_stats_t;
-using metaspace::ChunkManager;
-using metaspace::MetaspaceArena;
-using metaspace::ArenaGrowthPolicy;
-using metaspace::RunningCounters;
-using metaspace::InternalStats;
-
-#define LOGFMT         "CLMS @" PTR_FORMAT " "
-#define LOGFMT_ARGS    p2i(this)
-
-static bool use_class_space(bool is_class) {
-  if (Metaspace::using_class_space() && is_class) {
-    return true;
-  }
-  return false;
-}
-
-static bool use_class_space(Metaspace::MetadataType mdType) {
-  return use_class_space(metaspace::is_class(mdType));
-}
-
-ClassLoaderMetaspace::ClassLoaderMetaspace(Mutex* lock, Metaspace::MetaspaceType space_type)
-  : _lock(lock)
-  , _space_type(space_type)
-  , _non_class_space_arena(NULL)
-  , _class_space_arena(NULL)
-{
-  ChunkManager* const non_class_cm =
-          ChunkManager::chunkmanager_nonclass();
-
-  // Initialize non-class Arena
-  _non_class_space_arena = new MetaspaceArena(
-      non_class_cm,
-      ArenaGrowthPolicy::policy_for_space_type(space_type, false),
-      lock,
-      RunningCounters::used_nonclass_counter(),
-      "non-class sm");
-
-  // If needed, initialize class arena
-  if (Metaspace::using_class_space()) {
-    ChunkManager* const class_cm =
-            ChunkManager::chunkmanager_class();
-    _class_space_arena = new MetaspaceArena(
-        class_cm,
-        ArenaGrowthPolicy::policy_for_space_type(space_type, true),
-        lock,
-        RunningCounters::used_class_counter(),
-        "class sm");
-  }
-
-  UL2(debug, "born (SpcMgr nonclass: " PTR_FORMAT ", SpcMgr class: " PTR_FORMAT ".",
-      p2i(_non_class_space_arena), p2i(_class_space_arena));
-}
-
-ClassLoaderMetaspace::~ClassLoaderMetaspace() {
-  Metaspace::assert_not_frozen();
-
-  UL(debug, "dies.");
-
-  delete _non_class_space_arena;
-  delete _class_space_arena;
-
-}
-
-// Allocate word_size words from Metaspace.
-MetaWord* ClassLoaderMetaspace::allocate(size_t word_size, Metaspace::MetadataType mdType) {
-  Metaspace::assert_not_frozen();
-  if (use_class_space(mdType)) {
-    return class_space_arena()->allocate(word_size);
-  } else {
-    return non_class_space_arena()->allocate(word_size);
-  }
-}
-
-// Attempt to expand the GC threshold to be good for at least another word_size words
-// and allocate. Returns NULL if failure. Used during Metaspace GC.
-MetaWord* ClassLoaderMetaspace::expand_and_allocate(size_t word_size, Metaspace::MetadataType mdType) {
-  Metaspace::assert_not_frozen();
-  size_t delta_bytes = MetaspaceGC::delta_capacity_until_GC(word_size * BytesPerWord);
-  assert(delta_bytes > 0, "Must be");
-
-  size_t before = 0;
-  size_t after = 0;
-  bool can_retry = true;
-  MetaWord* res;
-  bool incremented;
-
-  // Each thread increments the HWM at most once. Even if the thread fails to increment
-  // the HWM, an allocation is still attempted. This is because another thread must then
-  // have incremented the HWM and therefore the allocation might still succeed.
-  do {
-    incremented = MetaspaceGC::inc_capacity_until_GC(delta_bytes, &after, &before, &can_retry);
-    res = allocate(word_size, mdType);
-  } while (!incremented && res == NULL && can_retry);
-
-  if (incremented) {
-    Metaspace::tracer()->report_gc_threshold(before, after,
-                                  MetaspaceGCThresholdUpdater::ExpandAndAllocate);
-    // Keeping both for now until I am sure the old variant (gc + metaspace) is not needed anymore
-    log_trace(gc, metaspace)("Increase capacity to GC from " SIZE_FORMAT " to " SIZE_FORMAT, before, after);
-    UL2(info, "GC threshold increased: " SIZE_FORMAT "->" SIZE_FORMAT ".", before, after);
-  }
-
-  return res;
-}
-
-// Prematurely returns a metaspace allocation to the _block_freelists
-// because it is not needed anymore.
-void ClassLoaderMetaspace::deallocate(MetaWord* ptr, size_t word_size, bool is_class) {
-
-  Metaspace::assert_not_frozen();
-
-  if (use_class_space(is_class)) {
-    class_space_arena()->deallocate(ptr, word_size);
-  } else {
-    non_class_space_arena()->deallocate(ptr, word_size);
-  }
-
-  DEBUG_ONLY(InternalStats::inc_num_deallocs();)
-
-}
-
-// Update statistics. This walks all in-use chunks.
-void ClassLoaderMetaspace::add_to_statistics(clms_stats_t* out) const {
-  if (non_class_space_arena() != NULL) {
-    non_class_space_arena()->add_to_statistics(&out->arena_stats_nonclass);
-  }
-  if (class_space_arena() != NULL) {
-    class_space_arena()->add_to_statistics(&out->arena_stats_class);
-  }
-}
-
-#ifdef ASSERT
-void ClassLoaderMetaspace::verify() const {
-  metaspace::check_valid_spacetype(_space_type);
-  if (non_class_space_arena() != NULL) {
-    non_class_space_arena()->verify(false);
-  }
-  if (class_space_arena() != NULL) {
-    class_space_arena()->verify(false);
-  }
-}
-#endif // ASSERT
-
-
-// This only exists for JFR and jcmd VM.classloader_stats. We may want to
-//  change this. Capacity as a stat is of questionable use since it may
-//  contain committed and uncommitted areas. For now we do this to maintain
-//  backward compatibility with JFR.
-void ClassLoaderMetaspace::calculate_jfr_stats(size_t* p_used_bytes, size_t* p_capacity_bytes) const {
-  // Implement this using the standard statistics objects.
-  size_t used_c = 0, cap_c = 0, used_nc = 0, cap_nc = 0;
-  if (non_class_space_arena() != NULL) {
-    non_class_space_arena()->usage_numbers(&used_nc, NULL, &cap_nc);
-  }
-  if (class_space_arena() != NULL) {
-    class_space_arena()->usage_numbers(&used_c, NULL, &cap_c);
-  }
-  if (p_used_bytes != NULL) {
-    *p_used_bytes = used_c + used_nc;
-  }
-  if (p_capacity_bytes != NULL) {
-    *p_capacity_bytes = cap_c + cap_nc;
-  }
-}
-
-
-
-
--- old/src/hotspot/share/memory/metaspace/commitLimiter.cpp	2020-09-04 13:58:22.165568841 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,62 +0,0 @@
-/*
- * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#include "precompiled.hpp"
-
-#include "memory/metaspace/commitLimiter.hpp"
-#include "memory/metaspace.hpp"
-#include "utilities/debug.hpp"
-#include "utilities/globalDefinitions.hpp"
-
-namespace metaspace {
-
-// Returns the size, in words, by which we may expand the metaspace committed area without:
-// - _cap == 0: hitting GC threshold or the MaxMetaspaceSize
-// - _cap > 0: hitting cap (this is just for testing purposes)
-size_t CommitLimiter::possible_expansion_words() const {
-
-  if (_cap > 0) { // Testing.
-    assert(_cnt.get() <= _cap, "Beyond limit?");
-    return _cap - _cnt.get();
-  }
-
-  assert(_cnt.get() * BytesPerWord <= MaxMetaspaceSize, "Beyond limit?");
-  const size_t words_left_below_max = MaxMetaspaceSize / BytesPerWord - _cnt.get();
-
-  const size_t words_left_below_gc_threshold = MetaspaceGC::allowed_expansion();
-
-  return MIN2(words_left_below_max, words_left_below_gc_threshold);
-
-}
-
-static CommitLimiter g_global_limiter(0);
-
-// Returns the global metaspace commit counter
-CommitLimiter* CommitLimiter::globalLimiter() {
-  return &g_global_limiter;
-}
-
-} // namespace metaspace
-
--- old/src/hotspot/share/memory/metaspace/commitLimiter.hpp	2020-09-04 13:58:22.573571681 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,84 +0,0 @@
-/*
- * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#ifndef SHARE_MEMORY_METASPACE_COMMITLIMITER_HPP
-#define SHARE_MEMORY_METASPACE_COMMITLIMITER_HPP
-
-#include "memory/allocation.hpp"
-#include "memory/metaspace/counter.hpp"
-
-namespace metaspace {
-
-// The CommitLimiter encapsulates a limit we may want to impose on how much
-//  memory can be committed. This is a matter of separation of concerns:
-//
-// In metaspace, we have two limits to committing memory: the absolute limit,
-//  MaxMetaspaceSize; and the GC threshold. In both cases an allocation should
-//  fail if it would require committing memory and hit one of these limits.
-//
-// However, the actual Metaspace allocator is a generic one and this
-//  GC- and classloading specific logic should be kept separate. Therefore
-//  it is hidden inside this interface.
-//
-// This allows us to:
-//  - more easily write tests for metaspace, by providing a different implementation
-//    of the commit limiter, thus keeping test logic separate from VM state.
-//  - (potentially) use the metaspace for things other than class metadata,
-//    where different commit rules would apply.
-//
-class CommitLimiter : public CHeapObj<mtMetaspace> {
-
-  // Counts total words committed for metaspace
-  SizeCounter _cnt;
-
-  // Purely for testing purposes: cap, in words.
-  const size_t _cap;
-
-public:
-
-  // Create a commit limiter. This is only useful for testing, with a cap != 0,
-  // since normal code should use the global commit limiter.
-  // If cap != 0 (word size), the cap replaces the internal logic of limiting.
-  CommitLimiter(size_t cap = 0) : _cnt(), _cap(cap) {}
-
-  // Returns the size, in words, by which we may expand the metaspace committed area without:
-  // - _cap == 0: hitting GC threshold or the MaxMetaspaceSize
-  // - _cap > 0: hitting cap (this is just for testing purposes)
-  size_t possible_expansion_words() const;
-
-  void increase_committed(size_t word_size)   { _cnt.increment_by(word_size); }
-  void decrease_committed(size_t word_size)   { _cnt.decrement_by(word_size); }
-
-  size_t committed_words() const              { return _cnt.get(); }
-  size_t cap() const                          { return _cap; }
-
-  // Returns the global metaspace commit counter
-  static CommitLimiter* globalLimiter();
-
-};
-
-} // namespace metaspace
-
-#endif // SHARE_MEMORY_METASPACE_COMMITLIMITER_HPP
--- old/src/hotspot/share/memory/metaspace/commitMask.cpp	2020-09-04 13:58:22.989574577 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,110 +0,0 @@
-/*
- * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#include "precompiled.hpp"
-
-#include "memory/metaspace/commitMask.hpp"
-#include "memory/metaspace/metaspaceCommon.hpp"
-#include "memory/metaspace/settings.hpp"
-#include "runtime/stubRoutines.hpp"
-
-#include "utilities/align.hpp"
-#include "utilities/debug.hpp"
-
-namespace metaspace {
-
-CommitMask::CommitMask(const MetaWord* start, size_t word_size)
-  : CHeapBitMap(mask_size(word_size, Settings::commit_granule_words()))
-  , _base(start)
-  , _word_size(word_size)
-  , _words_per_bit(Settings::commit_granule_words())
-{
-  assert(_word_size > 0 && _words_per_bit > 0 &&
-         is_aligned(_word_size, _words_per_bit), "Sanity");
-}
-
-#ifdef ASSERT
-
-// This is very expensive
-static const bool TEST_UNCOMMITTED_REGION = false;
-
-volatile u1 x;
-
-static void check_range_is_accessible(const MetaWord* p, size_t word_size) {
-  const MetaWord* const p_end = p + word_size;
-  u1 x2 = 0;
-  for (const MetaWord* q = p; q < p_end; q += os::vm_page_size() / BytesPerWord) {
-    x2 += *(u1*)q;
-  }
-  x = x2;
-}
-
-void CommitMask::verify(bool slow) const {
-
-  // Walk the whole commit mask.
-  // For each 1 bit, check if the associated granule is accessible.
-  // For each 0 bit, check if the associated granule is not accessible. Slow mode only.
-
-  assert(_base != NULL && _word_size > 0 && _words_per_bit > 0, "Sanity");
-  assert_is_aligned(_base, _words_per_bit * BytesPerWord);
-  assert_is_aligned(_word_size, _words_per_bit);
-
-  if (slow) {
-    for (idx_t i = 0; i < size(); i ++) {
-      const MetaWord* const p = _base + (i * _words_per_bit);
-      if (at(i)) {
-        // Should be accessible. Just touch it.
-        check_range_is_accessible(p, _words_per_bit);
-      } else {
-        // Note: results may differ between platforms. On Linux, this should be true since
-        // we uncommit memory by setting protection to PROT_NONE. We may have to look if
-        // this works as expected on other platforms.
-        if (TEST_UNCOMMITTED_REGION && CanUseSafeFetch32()) {
-          assert(os::is_readable_pointer(p) == false,
-                 "index %u, pointer " PTR_FORMAT ", should not be accessible.",
-                 (unsigned)i, p2i(p));
-        }
-      }
-    }
-  }
-
-}
-
-#endif // ASSERT
-
-void CommitMask::print_on(outputStream* st) const {
-
-  st->print("commit mask, base " PTR_FORMAT ":", p2i(base()));
-
-  for (idx_t i = 0; i < size(); i ++) {
-    st->print("%c", at(i) ? 'X' : '-');
-  }
-
-  st->cr();
-
-}
-
-} // namespace metaspace
-
--- old/src/hotspot/share/memory/metaspace/commitMask.hpp	2020-09-04 13:58:23.421577587 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,182 +0,0 @@
-/*
- * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#ifndef SHARE_MEMORY_METASPACE_COMMITMASK_HPP
-#define SHARE_MEMORY_METASPACE_COMMITMASK_HPP
-
-#include "utilities/debug.hpp"
-#include "utilities/bitMap.hpp"
-#include "utilities/globalDefinitions.hpp"
-
-class outputStream;
-
-namespace metaspace {
-
-// The CommitMask is a bitmask used to store the commit state of commit granules.
-// It keeps one bit per granule; 1 means committed, 0 means uncommitted.
-
-class CommitMask : public CHeapBitMap {
-
-  const MetaWord* const _base;
-  const size_t _word_size;
-  const size_t _words_per_bit;
-
-  // Given an offset, in words, into the area, return the number of the bit
-  // covering it.
-  static idx_t bitno_for_word_offset(size_t offset, size_t words_per_bit) {
-    return offset / words_per_bit;
-  }
-
-  idx_t bitno_for_address(const MetaWord* p) const {
-    // Note: we allow one-beyond since this is a typical need.
-    assert(p >= _base && p <= _base + _word_size, "Invalid address");
-    const size_t off = p - _base;
-    return bitno_for_word_offset(off, _words_per_bit);
-  }
-
-  static idx_t mask_size(size_t word_size, size_t words_per_bit) {
-    return bitno_for_word_offset(word_size, words_per_bit);
-  }
-
-  struct BitCounterClosure : public BitMapClosure {
-    idx_t cnt;
-    bool do_bit(BitMap::idx_t offset) { cnt ++; return true; }
-  };
-
-#ifdef ASSERT
-  // Given a pointer, check if it points into the range this bitmap covers.
-  bool is_pointer_valid(const MetaWord* p) const {
-    return p >= _base && p < _base + _word_size;
-  }
-
-  // Given a pointer, check if it points into the range this bitmap covers.
-  void check_pointer(const MetaWord* p) const {
-    assert(is_pointer_valid(p),
-           "Pointer " PTR_FORMAT " not in range of this bitmap [" PTR_FORMAT ", " PTR_FORMAT ").",
-           p2i(p), p2i(_base), p2i(_base + _word_size));
-  }
-  // Given a pointer, check if it points into the range this bitmap covers,
-  // and if it is aligned to commit granule border.
-  void check_pointer_aligned(const MetaWord* p) const {
-    check_pointer(p);
-    assert(is_aligned(p, _words_per_bit * BytesPerWord),
-           "Pointer " PTR_FORMAT " should be aligned to commit granule size " SIZE_FORMAT ".",
-           p2i(p), _words_per_bit * BytesPerWord);
-  }
-  // Given a range, check if it points into the range this bitmap covers,
-  // and if its borders are aligned to commit granule border.
-  void check_range(const MetaWord* start, size_t word_size) const {
-    check_pointer_aligned(start);
-    assert(is_aligned(word_size, _words_per_bit),
-           "Range " SIZE_FORMAT " should be aligned to commit granule size " SIZE_FORMAT ".",
-           word_size, _words_per_bit);
-    check_pointer(start + word_size - 1);
-  }
-#endif
-
-  // Marks a single commit granule as committed (value == true)
-  // or uncomitted (value == false) and returns
-  // its prior state.
-  bool mark_granule(idx_t bitno, bool value) {
-    bool b = at(bitno);
-    at_put(bitno, value);
-    return b;
-  }
-
-public:
-
-  // Create a commit mask covering a range [start, start + word_size).
-  CommitMask(const MetaWord* start, size_t word_size);
-
-  const MetaWord* base() const  { return _base; }
-  size_t word_size() const      { return _word_size; }
-  const MetaWord* end() const   { return _base + word_size(); }
-
-  // Given an address, returns true if the address is committed, false if not.
-  bool is_committed_address(const MetaWord* p) const {
-    DEBUG_ONLY(check_pointer(p));
-    const idx_t bitno = bitno_for_address(p);
-    return at(bitno);
-  }
-
-  // Given an address range, return size, in number of words, of committed area within that range.
-  size_t get_committed_size_in_range(const MetaWord* start, size_t word_size) const {
-    DEBUG_ONLY(check_range(start, word_size));
-    assert(word_size > 0, "zero range");
-    const idx_t b1 = bitno_for_address(start);
-    const idx_t b2 = bitno_for_address(start + word_size);
-    const idx_t num_bits = count_one_bits(b1, b2);
-    return num_bits * _words_per_bit;
-  }
-
-  // Return total committed size, in number of words.
-  size_t get_committed_size() const {
-    return count_one_bits() * _words_per_bit;
-  }
-
-  // Mark a whole address range [start, end) as committed.
-  // Return the number of words which had already been committed before this operation.
-  size_t mark_range_as_committed(const MetaWord* start, size_t word_size) {
-    DEBUG_ONLY(check_range(start, word_size));
-    assert(word_size > 0, "zero range");
-    const idx_t b1 = bitno_for_address(start);
-    const idx_t b2 = bitno_for_address(start + word_size);
-    if (b1 == b2) { // Simple case, 1 granule
-      bool was_committed = mark_granule(b1, true);
-      return was_committed ? _words_per_bit : 0;
-    }
-    const idx_t one_bits_in_range_before = count_one_bits(b1, b2);
-    set_range(b1, b2);
-    return one_bits_in_range_before * _words_per_bit;
-  }
-
-  // Mark a whole address range [start, end) as uncommitted.
-  // Return the number of words which had already been uncommitted before this operation.
-  size_t mark_range_as_uncommitted(const MetaWord* start, size_t word_size) {
-    DEBUG_ONLY(check_range(start, word_size));
-    assert(word_size > 0, "zero range");
-    const idx_t b1 = bitno_for_address(start);
-    const idx_t b2 = bitno_for_address(start + word_size);
-    if (b1 == b2) { // Simple case, 1 granule
-      bool was_committed = mark_granule(b1, false);
-      return was_committed ? 0 : _words_per_bit;
-    }
-    const idx_t zero_bits_in_range_before =
-        (b2 - b1) - count_one_bits(b1, b2);
-    clear_range(b1, b2);
-    return zero_bits_in_range_before * _words_per_bit;
-  }
-
-
-  //// Debug stuff ////
-  DEBUG_ONLY(void verify(bool slow) const;)
-
-  void print_on(outputStream* st) const;
-
-};
-
-} // namespace metaspace
-
-#endif // SHARE_MEMORY_METASPACE_COMMITMASK_HPP
--- old/src/hotspot/share/memory/metaspace/counter.hpp	2020-09-04 13:58:23.865580681 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,186 +0,0 @@
-/*
- * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#ifndef SHARE_MEMORY_METASPACE_COUNTER_HPP
-#define SHARE_MEMORY_METASPACE_COUNTER_HPP
-
-#include "metaprogramming/isSigned.hpp"
-#include "runtime/atomic.hpp"
-#include "utilities/debug.hpp"
-#include "utilities/globalDefinitions.hpp"
-
-
-namespace metaspace {
-
-// We seem to be counting a lot of things which makes it worthwhile to
-// make helper classes for all that boilerplate coding.
-
-// AbstractCounter counts something and asserts overflow and underflow.
-template <class T>
-class AbstractCounter {
-
-  T _c;
-
-  // Only allow unsigned values for now
-  STATIC_ASSERT(IsSigned<T>::value == false);
-
-public:
-
-  AbstractCounter() : _c(0) {}
-
-  T get() const           { return _c; }
-
-  void increment() { increment_by(1); }
-  void decrement() { decrement_by(1); }
-
-  void increment_by(T v) {
-#ifdef ASSERT
-    T old = _c;
-    assert(old + v >= old,
-        "overflow (" UINT64_FORMAT "+" UINT64_FORMAT ")", (uint64_t)old, (uint64_t)v);
-#endif
-    _c += v;
-  }
-
-  void decrement_by(T v) {
-    assert(_c >= v,
-           "underflow (" UINT64_FORMAT "-" UINT64_FORMAT ")",
-           (uint64_t)_c, (uint64_t)v);
-    _c -= v;
-  }
-
-  void reset()                { _c = 0; }
-
-#ifdef ASSERT
-  void check(T expected) const {
-    assert(_c == expected, "Counter mismatch: %d, expected: %d.",
-           (int)_c, (int)expected);
-    }
-#endif
-
-};
-
-// Atomic variant of AbstractCounter.
-template <class T>
-class AbstractAtomicCounter {
-
-  volatile T _c;
-
-  // Only allow unsigned values for now
-  STATIC_ASSERT(IsSigned<T>::value == false);
-
-public:
-
-  AbstractAtomicCounter() : _c(0) {}
-
-  T get() const               { return _c; }
-
-  void increment() {
-    Atomic::inc(&_c);
-  }
-
-  void decrement() {
-#ifdef ASSERT
-    T old = Atomic::load_acquire(&_c);
-    assert(old >= 1,
-        "underflow (" UINT64_FORMAT "-1)", (uint64_t)old);
-#endif
-    Atomic::dec(&_c);
-  }
-
-  void increment_by(T v) {
-    Atomic::add(&_c, v);
-  }
-
-  void decrement_by(T v) {
-#ifdef ASSERT
-    T old = Atomic::load_acquire(&_c);
-    assert(old >= v,
-        "underflow (" UINT64_FORMAT "+" UINT64_FORMAT ")", (uint64_t)old, (uint64_t)v);
-#endif
-    Atomic::sub(&_c, v);
-  }
-
-#ifdef ASSERT
-  void check(T expected) const {
-    assert(_c == expected, "Counter mismatch: %d, expected: %d.",
-           (int)_c, (int)expected);
-    }
-#endif
-
-};
-
-typedef AbstractCounter<size_t>   SizeCounter;
-typedef AbstractCounter<unsigned> IntCounter;
-
-typedef AbstractAtomicCounter<size_t> SizeAtomicCounter;
-
-
-// We often count memory ranges (blocks, chunks etc).
-// Make a helper class for that.
-template <class T_num, class T_size>
-class AbstractMemoryRangeCounter {
-
-  AbstractCounter<T_num>  _count;
-  AbstractCounter<T_size> _total_size;
-
-public:
-
-  void add(T_size s) {
-    if(s > 0) {
-      _count.increment();
-      _total_size.increment_by(s);
-    }
-  }
-
-  void sub(T_size s) {
-    if(s > 0) {
-      _count.decrement();
-      _total_size.decrement_by(s);
-    }
-  }
-
-  T_num count() const       { return _count.get(); }
-  T_size total_size() const { return _total_size.get(); }
-
-
-#ifdef ASSERT
-  void check(T_num expected_count, T_size expected_size) const {
-    _count.check(expected_count);
-    _total_size.check(expected_size);
-  }
-  void check(const AbstractMemoryRangeCounter<T_num, T_size>& other) const {
-    check(other.count(), other.total_size());
-  }
-#endif
-
-};
-
-typedef AbstractMemoryRangeCounter<unsigned, size_t> MemRangeCounter;
-
-} // namespace metaspace
-
-#endif // SHARE_MEMORY_METASPACE_WORDSIZECOUNTER_HPP
-
--- old/src/hotspot/share/memory/metaspace/freeBlocks.cpp	2020-09-04 13:58:24.281583582 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,64 +0,0 @@
-/*
- * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#include "precompiled.hpp"
-#include "memory/metaspace/freeBlocks.hpp"
-#include "utilities/globalDefinitions.hpp"
-#include "utilities/debug.hpp"
-
-namespace metaspace {
-
-void FreeBlocks::add_block(MetaWord* p, size_t word_size) {
-  assert(word_size >= minimal_word_size, "sanity (" SIZE_FORMAT ")", word_size);
-  if (word_size >= _small_blocks.maximal_word_size) {
-    _tree.add_block(p, word_size);
-  } else {
-    _small_blocks.add_block(p, word_size);
-  }
-}
-
-MetaWord* FreeBlocks::get_block(size_t requested_word_size) {
-  assert(requested_word_size >= minimal_word_size,
-      "requested_word_size too small (" SIZE_FORMAT ")", requested_word_size);
-  size_t real_size = 0;
-  MetaWord* p = NULL;
-  if (requested_word_size >= _small_blocks.maximal_word_size) {
-    p = _tree.get_block(requested_word_size, &real_size);
-  } else {
-    p = _small_blocks.get_block(requested_word_size, &real_size);
-  }
-  if (p != NULL) {
-    // Blocks which are larger than a certain threshold are split and
-    // the remainder is handed back to the manager.
-    const size_t waste = real_size - requested_word_size;
-    if (waste > MAX2(minimal_word_size, splinter_threshold)) {
-      add_block(p + requested_word_size, waste);
-    }
-  }
-  return p;
-}
-
-} // namespace metaspace
-
--- old/src/hotspot/share/memory/metaspace/freeBlocks.hpp	2020-09-04 13:58:24.721586650 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,117 +0,0 @@
-/*
- * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#ifndef SHARE_MEMORY_METASPACE_LEFTOVERBINS_HPP
-#define SHARE_MEMORY_METASPACE_LEFTOVERBINS_HPP
-
-#include "memory/allocation.hpp"
-
-#include "memory/metaspace/counter.hpp"
-#include "memory/metaspace/binlist.hpp"
-#include "memory/metaspace/blocktree.hpp"
-
-#include "utilities/debug.hpp"
-#include "utilities/globalDefinitions.hpp"
-
-
-class outputStream;
-
-namespace metaspace {
-
-// Class FreeBlocks manages deallocated blocks in Metaspace.
-//
-// In Metaspace, allocated memory blocks may be release prematurely. This is
-//  uncommon (otherwise an arena-based allocation scheme would not make sense).
-//  It can happen e.g. when class loading fails or when bytecode gets rewritten.
-//
-// All these released blocks should be reused, so they are collected. Since these
-//  blocks are embedded into chunks which are still in use by a live arena,
-//  we cannot just give these blocks to anyone; only the owner of this arena can
-//  reuse these blocks. Therefore these blocks are kept at arena-level.
-//
-// The structure to manage these released blocks at arena level is class FreeBlocks.
-//
-// FreeBlocks is optimized toward the typical size and number of deallocated
-//  blocks. The vast majority of them (about 90%) are below 16 words in size,
-//  but there is a significant portion of memory blocks much larger than that,
-//  leftover space from retired chunks, see MetaspaceArena::retire_current_chunk().
-//
-// Since the vast majority of blocks are small or very small, FreeBlocks consists
-//  internally of two separate structures to keep very small blocks and other blocks.
-//  Very small blocks are kept in a bin list (see binlist.hpp) and larger blocks in
-//  a BST (see blocktree.hpp).
-
-class FreeBlocks : public CHeapObj<mtMetaspace> {
-
-  typedef BinList32 SmallBlocksType;
-
-  // _small_blocks takes care of small to very small blocks.
-  SmallBlocksType _small_blocks;
-
-  // A BST for larger blocks.
-  BlockTree _tree;
-
-  static const size_t splinter_threshold = 0;// 0x100;
-
-public:
-
-  const static size_t minimal_word_size = SmallBlocksType::minimal_word_size;
-
-  // Add a block to the deallocation management.
-  void add_block(MetaWord* p, size_t word_size);
-
-  // Retrieve a block of at least requested_word_size.
-  MetaWord* get_block(size_t requested_word_size);
-
-#ifdef ASSERT
-  void verify() const {
-    _tree.verify();
-    _small_blocks.verify();
-  };
-#endif
-
-  // Returns number of blocks.
-  int count() const {
-    return _small_blocks.count() + _tree.count();
-  }
-
-  // Returns total size, in words, of all elements.
-  size_t total_size() const {
-    return _small_blocks.total_size() + _tree.total_size();
-  }
-
-  // Returns true if empty.
-  bool is_empty() const {
-    return _small_blocks.is_empty() && _tree.is_empty();
-  }
-
-};
-
-
-
-
-} // namespace metaspace
-
-#endif // SHARE_MEMORY_METASPACE_CHUNKMANAGER_HPP
--- old/src/hotspot/share/memory/metaspace/freeChunkList.cpp	2020-09-04 13:58:25.153589665 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,183 +0,0 @@
-/*
- * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#include "precompiled.hpp"
-#include "memory/metaspace/chunkLevel.hpp"
-#include "memory/metaspace/freeChunkList.hpp"
-#include "utilities/globalDefinitions.hpp"
-#include "utilities/debug.hpp"
-#include "utilities/ostream.hpp"
-
-
-
-namespace metaspace {
-
-void FreeChunkList::print_on(outputStream* st) const {
-
-  if (_num_chunks.get() > 0) {
-    for (const Metachunk* c = _first; c != NULL; c = c->next()) {
-      st->print(" - <");
-      c->print_on(st);
-      st->print(">");
-    }
-    st->print(" - total : %d chunks.", _num_chunks.get());
-  } else {
-    st->print("empty");
-  }
-
-}
-
-#ifdef ASSERT
-
-bool FreeChunkList::contains(const Metachunk* c) const {
-  for (Metachunk* c2 = _first; c2 != NULL; c2 = c2->next()) {
-    if (c2 == c) {
-      return true;
-    }
-  }
-  return false;
-}
-
-void FreeChunkList::verify() const {
-
-  if (_first == NULL) {
-    assert(_last == NULL, "Sanity");
-  } else {
-    assert(_last != NULL, "Sanity");
-    size_t committed = 0;
-    int num = 0;
-    bool uncommitted = (_first->committed_words() == 0);
-    for (Metachunk* c = _first; c != NULL; c = c->next()) {
-      assert(c->is_free(), "Chunks in freelist should be free");
-      assert(c->used_words() == 0, "Chunk in freelist should have not used words.");
-      assert(c->level() == _first->level(), "wrong level");
-      assert(c->next() == NULL || c->next()->prev() == c, "front link broken");
-      assert(c->prev() == NULL || c->prev()->next() == c, "back link broken");
-      assert(c != c->prev() && c != c->next(), "circle");
-      c->verify(false);
-      committed += c->committed_words();
-      num ++;
-    }
-    _num_chunks.check(num);
-    _committed_word_size.check(committed);
-  }
-
-}
-
-#endif // ASSERT
-
-
-// Returns total size in all lists (regardless of commit state of underlying memory)
-size_t FreeChunkListVector::word_size() const {
-  size_t sum = 0;
-  for (chunklevel_t l = chunklevel::LOWEST_CHUNK_LEVEL; l <= chunklevel::HIGHEST_CHUNK_LEVEL; l ++) {
-    sum += list_for_level(l)->num_chunks() * chunklevel::word_size_for_level(l);
-  }
-  return sum;
-}
-
-// Returns total committed size in all lists
-size_t FreeChunkListVector::committed_word_size() const {
-  size_t sum = 0;
-  for (chunklevel_t l = chunklevel::LOWEST_CHUNK_LEVEL; l <= chunklevel::HIGHEST_CHUNK_LEVEL; l ++) {
-    sum += list_for_level(l)->committed_word_size();
-  }
-  return sum;
-}
-
-// Returns total committed size in all lists
-int FreeChunkListVector::num_chunks() const {
-  int n = 0;
-  for (chunklevel_t l = chunklevel::LOWEST_CHUNK_LEVEL; l <= chunklevel::HIGHEST_CHUNK_LEVEL; l ++) {
-    n += list_for_level(l)->num_chunks();
-  }
-  return n;
-}
-
-
-// Look for a chunk: starting at level, up to and including max_level,
-//  return the first chunk whose committed words >= min_committed_words.
-// Return NULL if no such chunk was found.
-Metachunk* FreeChunkListVector::search_chunk_ascending(chunklevel_t level, chunklevel_t max_level, size_t min_committed_words) {
-  assert(min_committed_words <= chunklevel::word_size_for_level(max_level),
-         "min chunk size too small to hold min_committed_words");
-  for (chunklevel_t l = level; l <= max_level; l ++) {
-    Metachunk* c = list_for_level(l)->first();
-    if (c != NULL && c->committed_words() >= min_committed_words) {
-      list_for_level(l)->remove(c);
-      return c;
-    }
-  }
-  return NULL;
-}
-
-// Look for a chunk: starting at level, down to (including) the root chunk level,
-// return the first chunk whose committed words >= min_committed_words.
-// Return NULL if no such chunk was found.
-Metachunk* FreeChunkListVector::search_chunk_descending(chunklevel_t level, size_t min_committed_words) {
-  for (chunklevel_t l = level; l >= chunklevel::LOWEST_CHUNK_LEVEL; l --) {
-    Metachunk* c = list_for_level(l)->first();
-    if (c != NULL && c->committed_words() >= min_committed_words) {
-      list_for_level(l)->remove(c);
-      return c;
-    }
-  }
-  return NULL;
-}
-
-void FreeChunkListVector::print_on(outputStream* st) const {
-  for (chunklevel_t l = chunklevel::LOWEST_CHUNK_LEVEL; l <= chunklevel::HIGHEST_CHUNK_LEVEL; l ++) {
-    st->print("-- List[" CHKLVL_FORMAT "]: ", l);
-    list_for_level(l)->print_on(st);
-    st->cr();
-  }
-  st->print_cr("total chunks: %d, total word size: " SIZE_FORMAT ", committed word size: " SIZE_FORMAT ".",
-               num_chunks(), word_size(), committed_word_size());
-}
-
-
-#ifdef ASSERT
-
-void FreeChunkListVector::verify() const {
-  for (chunklevel_t l = chunklevel::LOWEST_CHUNK_LEVEL; l <= chunklevel::HIGHEST_CHUNK_LEVEL; l ++) {
-    list_for_level(l)->verify();
-  }
-}
-
-bool FreeChunkListVector::contains(const Metachunk* c) const {
-  for (chunklevel_t l = chunklevel::LOWEST_CHUNK_LEVEL; l <= chunklevel::HIGHEST_CHUNK_LEVEL; l ++) {
-    if (list_for_level(l)->contains(c)) {
-      return true;
-    }
-  }
-  return false;
-}
-
-#endif // ASSERT
-
-
-
-} // namespace metaspace
-
--- old/src/hotspot/share/memory/metaspace/freeChunkList.hpp	2020-09-04 13:58:25.573592597 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,275 +0,0 @@
-/*
- * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#ifndef SHARE_MEMORY_METASPACE_FREECHUNKLIST_HPP
-#define SHARE_MEMORY_METASPACE_FREECHUNKLIST_HPP
-
-#include "memory/allocation.hpp"
-#include "memory/metaspace/chunkLevel.hpp"
-#include "memory/metaspace/counter.hpp"
-#include "memory/metaspace/metachunk.hpp"
-#include "memory/metaspace/metachunkList.hpp"
-
-class outputStream;
-
-namespace metaspace {
-
-
-// This is the free list underlying the ChunkManager.
-//
-// Chunks are kept in a vector of double-linked double-headed lists
-//  (using Metachunk::prev/next). One list per chunk level exists.
-//
-// Chunks in these lists are roughly ordered: uncommitted chunks
-//  are added to the back of the list, fully or partially committed
-//  chunks to the front.
-//
-// (Small caveat: commit state of a chunk may change as a result of
-//  actions on neighboring chunks, if the chunk is smaller than a commit
-//  granule and therefore shares its granule with neighbors. So it may change
-//  after the chunk has been added to the list.
-//  It will never involuntarily uncommit: only chunks >= granule size are uncommitted.
-//  But it may get involuntarily committed if an in-granule neighbor is committed and
-//  causes committing of the whole granule.
-//  In practice this is not a big deal; it has very little consequence.)
-//
-// Beyond adding at either front or at back, we do not sort on insert, since the
-//  insert path is used during Metaspace reclamation which may happen at GC pause.
-//
-// During retrieval (at class loading), we search the list for a chunk of at least
-//  n committed words to satisfy the caller requested committed word size. We stop
-//  searching at the first fully uncommitted chunk.
-//
-// Note that even though this is an O(n) search, in practice this is not a problem:
-//  - in all likelihood the requested commit word size is way smaller than even a single
-//    commit granule, so 99% of all searches would end at the first chunk (which is either
-//    uncommitted or committed to at least one commit granule size).
-//  - in all likelihood chunks, when added to this list, are either fully committed
-//    or fully uncommitted (see Settings::uncommit_on_return_min_word_size()).
-//
-// Should we ever encounter situations where the O(n) search is a bottleneck, this
-//  structure can easily be optimized (e.g. a BST). But for now lets keep this simple.
-
-class FreeChunkList {
-
-  Metachunk* _first;
-  Metachunk* _last;
-
-  IntCounter _num_chunks;
-  SizeCounter _committed_word_size;
-
-  void add_front(Metachunk* c) {
-    if (_first == NULL) {
-      assert(_last == NULL, "Sanity");
-      _first = _last = c;
-      c->set_prev(NULL);
-      c->set_next(NULL);
-    } else {
-      assert(_last != NULL, "Sanity");
-      c->set_next(_first);
-      c->set_prev(NULL);
-      _first->set_prev(c);
-      _first = c;
-    }
-  }
-
-  // Add chunk to the back of the list.
-  void add_back(Metachunk* c) {
-    if (_last == NULL) {
-      assert(_first == NULL, "Sanity");
-      _last = _first = c;
-      c->set_prev(NULL);
-      c->set_next(NULL);
-    } else {
-      assert(_first != NULL, "Sanity");
-      c->set_next(NULL);
-      c->set_prev(_last);
-      _last->set_next(c);
-      _last = c;
-    }
-  }
-
-public:
-
-  FreeChunkList() :
-    _first(NULL),
-    _last(NULL)
-    {}
-
-  // Remove given chunk from anywhere in the list.
-  Metachunk* remove(Metachunk* c) {
-    assert(contains(c), "Must be contained here");
-    Metachunk* pred = c->prev();
-    Metachunk* succ = c->next();
-    if (pred) {
-      pred->set_next(succ);
-    }
-    if (succ) {
-      succ->set_prev(pred);
-    }
-    if (_first == c) {
-      _first = succ;
-    }
-    if (_last == c) {
-      _last = pred;
-    }
-    c->set_next(NULL);
-    c->set_prev(NULL);
-    _committed_word_size.decrement_by(c->committed_words());
-    _num_chunks.decrement();
-    return c;
-  }
-
-  void add(Metachunk* c) {
-    assert(contains(c) == false, "Chunk already in freelist");
-    assert(_first == NULL || _first->level() == c->level(), "wrong level");
-    // Uncomitted chunks go to the back, fully or partially committed to the front.
-    if (c->committed_words() == 0) {
-      add_back(c);
-    } else {
-      add_front(c);
-    }
-    _committed_word_size.increment_by(c->committed_words());
-    _num_chunks.increment();
-  }
-
-  // Removes the first chunk from the list and returns it. Returns NULL if list is empty.
-  Metachunk* remove_first() {
-    Metachunk* c = _first;
-    if (c != NULL) {
-      remove(c);
-    }
-    return c;
-  }
-
-  // Find and removes a chunk in this list which has at least min_committed_words committed words.
-  // Returns NULL if not found.
-  Metachunk* find_matching(size_t min_committed_words) {
-    Metachunk* c = _first;
-    while (c != NULL && c->committed_words() > 0) {
-      if (c->committed_words() <= min_committed_words) {
-        remove(c);
-        return c;
-      }
-      c = c->next();
-    }
-    return NULL;
-  }
-
-  // Returns reference to the first chunk in the list, or NULL
-  Metachunk* first() const { return _first; }
-
-#ifdef ASSERT
-  bool contains(const Metachunk* c) const;
-  void verify() const;
-#endif
-
-  // Returns number of chunks
-  int num_chunks() const { return _num_chunks.get(); }
-
-  // Returns total committed word size
-  size_t committed_word_size() const { return _committed_word_size.get(); }
-
-  void print_on(outputStream* st) const;
-
-};
-
-
-// A vector of free chunk lists, one per chunk level
-class FreeChunkListVector {
-
-  FreeChunkList _lists[chunklevel::NUM_CHUNK_LEVELS];
-
-  const FreeChunkList* list_for_level(chunklevel_t lvl) const         { DEBUG_ONLY(chunklevel::check_valid_level(lvl)); return _lists + lvl; }
-  FreeChunkList* list_for_level(chunklevel_t lvl)                     { DEBUG_ONLY(chunklevel::check_valid_level(lvl)); return _lists + lvl; }
-
-  const FreeChunkList* list_for_chunk(const Metachunk* c) const       { return list_for_level(c->level()); }
-  FreeChunkList* list_for_chunk(const Metachunk* c)                   { return list_for_level(c->level()); }
-
-public:
-
-  // Remove given chunk from its list. List must contain that chunk.
-  void remove(Metachunk* c) {
-    list_for_chunk(c)->remove(c);
-  }
-
-  // Remove first node unless empty. Returns node or NULL.
-  Metachunk* remove_first(chunklevel_t lvl) {
-    Metachunk* c = list_for_level(lvl)->remove_first();
-    return c;
-  }
-
-  void add(Metachunk* c) {
-    list_for_chunk(c)->add(c);
-  }
-
-  // Returns number of chunks for a given level.
-  int num_chunks_at_level(chunklevel_t lvl) const {
-    return list_for_level(lvl)->num_chunks();
-  }
-
-  // Returns number of chunks for a given level.
-  size_t committed_word_size_at_level(chunklevel_t lvl) const {
-    return list_for_level(lvl)->committed_word_size();
-  }
-
-  // Returns reference to first chunk at this level, or NULL if sublist is empty.
-  Metachunk* first_at_level(chunklevel_t lvl) const {
-    return list_for_level(lvl)->first();
-  }
-
-  // Look for a chunk: starting at level, up to and including max_level,
-  //  return the first chunk whose committed words >= min_committed_words.
-  // Return NULL if no such chunk was found.
-  Metachunk* search_chunk_ascending(chunklevel_t level, chunklevel_t max_level,
-                                    size_t min_committed_words);
-
-  // Look for a chunk: starting at level, down to (including) the root chunk level,
-  // return the first chunk whose committed words >= min_committed_words.
-  // Return NULL if no such chunk was found.
-  Metachunk* search_chunk_descending(chunklevel_t level, size_t min_committed_words);
-
-  // Returns total size in all lists (regardless of commit state of underlying memory)
-  size_t word_size() const;
-
-  // Returns total committed size in all lists
-  size_t committed_word_size() const;
-
-  // Returns number of chunks in all lists
-  int num_chunks() const;
-
-#ifdef ASSERT
-  bool contains(const Metachunk* c) const;
-  void verify() const;
-#endif
-
-  void print_on(outputStream* st) const;
-
-};
-
-
-} // namespace metaspace
-
-#endif // SHARE_MEMORY_METASPACE_FREECHUNKLIST_HPP
--- old/src/hotspot/share/memory/metaspace/internStat.cpp	2020-09-04 13:58:25.985595474 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,52 +0,0 @@
-/*
- * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#include "precompiled.hpp"
-#include "memory/metaspace/internStat.hpp"
-#include "utilities/globalDefinitions.hpp"
-#include "utilities/ostream.hpp"
-
-namespace metaspace {
-
-#define MATERIALIZE_COUNTER(name)          uint64_t InternalStats::_##name;
-#define MATERIALIZE_ATOMIC_COUNTER(name)   volatile uint64_t InternalStats::_##name;
-  ALL_MY_COUNTERS(MATERIALIZE_COUNTER, MATERIALIZE_ATOMIC_COUNTER)
-#undef MATERIALIZE_COUNTER
-#undef MATERIALIZE_ATOMIC_COUNTER
-
-
-void InternalStats::print_on(outputStream* st) {
-
-#define xstr(s) str(s)
-#define str(s) #s
-
-#define PRINT_COUNTER(name)  st->print_cr("%s: " UINT64_FORMAT ".", xstr(name), _##name);
-  ALL_MY_COUNTERS(PRINT_COUNTER, PRINT_COUNTER)
-#undef PRINT_COUNTER
-
-}
-
-} // namespace metaspace
-
--- old/src/hotspot/share/memory/metaspace/internStat.hpp	2020-09-04 13:58:26.393598326 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,128 +0,0 @@
-/*
- * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#ifndef SHARE_MEMORY_METASPACE_INTERNSTAT_HPP
-#define SHARE_MEMORY_METASPACE_INTERNSTAT_HPP
-
-#include "memory/allocation.hpp"
-#include "runtime/atomic.hpp"
-#include "utilities/globalDefinitions.hpp"
-
-class outputStream;
-
-namespace metaspace {
-
-
-// These are some counters useful for debugging and analyzing Metaspace problems.
-// They get printed as part of the Metaspace report (e.g. via jcmd VM.metaspace)
-
-class InternalStats : public AllStatic {
-
-  // Note: all counters which are modified on the classloader local allocation path
-  //   (not under ExpandLock protection) have to be atomic.
-
-#define ALL_MY_COUNTERS(x, x_atomic)                \
-                                                    \
-  /* Number of allocations. */                      \
-  DEBUG_ONLY(x_atomic(num_allocs))                  \
-                                                    \
-  /* Number of external deallocations */            \
-  /* (excluding retired chunk remains) */           \
-	DEBUG_ONLY(x_atomic(num_deallocs))                \
-                                                    \
-  /* Number of times an allocation was satisfied */ \
-  /*  from deallocated blocks. */                   \
-  DEBUG_ONLY(x_atomic(num_allocs_from_deallocated_blocks)) \
-                                                    \
-  /* Number of times an arena retired a chunk */    \
-  DEBUG_ONLY(x_atomic(num_chunks_retired))          \
-                                                    \
-  /* Number of times an allocation failed */        \
-  /*  because we hit a limit. */                    \
-  x_atomic(num_allocs_failed_limit)                 \
-                                                    \
-  /* Number of times an arena was born ... */       \
-	x_atomic(num_arena_births)                        \
-  /* ... and died. */                               \
-	x_atomic(num_arena_deaths)                        \
-                                                    \
-  /* Number of times VirtualSpaceNode were */       \
-  /*  born...  */                                   \
-  x(num_vsnodes_births)                             \
-  /* ... and died. */                               \
-  x(num_vsnodes_deaths)                             \
-                                                    \
-  /* Number of times we committed space. */         \
-  x(num_space_committed)                            \
-  /* Number of times we uncommitted space. */       \
-  x(num_space_uncommitted)                          \
-                                                    \
-  /* Number of times a chunk was returned to the */ \
-  /*  freelist (external only). */                  \
-  x(num_chunks_returned_to_freelist)                \
-  /* Number of times a chunk was taken from */      \
-  /*  freelist (external only) */                   \
-  x(num_chunks_taken_from_freelist)                 \
-                                                    \
-  /* Number of successful chunk merges */           \
-  x(num_chunk_merges)                               \
-  /* Number of chunk splits */                      \
-  x(num_chunk_splits)                               \
-  /* Number of chunk in place enlargements */       \
-  x(num_chunks_enlarged)                            \
-                                                    \
-  /* Number of times we did a purge */              \
-  x(num_purges)                                     \
-
-
-#define DEFINE_COUNTER(name)          static uint64_t _##name;
-#define DEFINE_ATOMIC_COUNTER(name)   static volatile uint64_t _##name;
-  ALL_MY_COUNTERS(DEFINE_COUNTER, DEFINE_ATOMIC_COUNTER)
-#undef DEFINE_COUNTER
-#undef DEFINE_ATOMIC_COUNTER
-
-public:
-
-// incrementors
-#define INCREMENTOR(name)           static void inc_##name() { _##name ++; }
-#define INCREMENTOR_ATOMIC(name)    static void inc_##name() { Atomic::inc(&_##name); }
-  ALL_MY_COUNTERS(INCREMENTOR, INCREMENTOR_ATOMIC)
-#undef INCREMENTOR
-#undef INCREMENTOR_ATOMIC
-
-// getters
-#define GETTER(name)                static uint64_t name() { return _##name; }
-  ALL_MY_COUNTERS(GETTER, GETTER)
-#undef GETTER
-
-
-  static void print_on(outputStream* st);
-
-
-};
-
-} // namespace metaspace
-
-#endif // SHARE_MEMORY_METASPACE_INTERNSTAT_HPP
--- old/src/hotspot/share/memory/metaspace/metachunk.cpp	2020-09-04 13:58:26.825601344 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,507 +0,0 @@
-/*
- * Copyright (c) 2012, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2017, 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#include "precompiled.hpp"
-
-#include "logging/log.hpp"
-#include "memory/metaspace/chunkLevel.hpp"
-#include "memory/metaspace/metachunk.hpp"
-#include "memory/metaspace/metaspaceCommon.hpp"
-#include "memory/metaspace/settings.hpp"
-#include "memory/metaspace/virtualSpaceNode.hpp"
-#include "runtime/mutexLocker.hpp"
-
-#include "utilities/align.hpp"
-#include "utilities/copy.hpp"
-#include "utilities/debug.hpp"
-
-namespace metaspace {
-
-// Return a single char presentation of the state ('f', 'u', 'd')
-char Metachunk::get_state_char() const {
-  switch (_state) {
-  case state_free:    return 'f';
-  case state_in_use:  return 'u';
-  case state_dead:    return 'd';
-  }
-  return '?';
-}
-
-#ifdef ASSERT
-void Metachunk::assert_have_expand_lock() {
-  assert_lock_strong(MetaspaceExpand_lock);
-}
-#endif
-
-// Commit uncommitted section of the chunk.
-// Fails if we hit a commit limit.
-bool Metachunk::commit_up_to(size_t new_committed_words) {
-
-  // Please note:
-  //
-  // VirtualSpaceNode::ensure_range_is_committed(), when called over a range containing both committed and uncommitted parts,
-  // will replace the whole range with a new mapping, thus erasing the existing content in the committed parts. Therefore
-  // we must make sure never to call VirtualSpaceNode::ensure_range_is_committed() over a range containing live data.
-  //
-  // Luckily, this cannot happen by design. We have two cases:
-  //
-  // 1) chunks equal or larger than a commit granule.
-  //    In this case, due to chunk geometry, the chunk should cover whole commit granules (in other words, a chunk equal or larger than
-  //    a commit granule will never share a granule with a neighbor). That means whatever we commit or uncommit here does not affect
-  //    neighboring chunks. We only have to take care not to re-commit used parts of ourself. We do this by moving the committed_words
-  //    limit in multiple of commit granules.
-  //
-  // 2) chunks smaller than a commit granule.
-  //    In this case, a chunk shares a single commit granule with its neighbors. But this never can be a problem:
-  //    - Either the commit granule is already committed (and maybe the neighbors contain live data). In that case calling
-  //      ensure_range_is_committed() will do nothing.
-  //    - Or the commit granule is not committed, but in this case, the neighbors are uncommitted too and cannot contain live data.
-
-#ifdef ASSERT
-  if (word_size() >= Settings::commit_granule_words()) {
-    // case (1)
-    assert(is_aligned(base(), Settings::commit_granule_bytes()) &&
-           is_aligned(end(), Settings::commit_granule_bytes()),
-           "Chunks larger than a commit granule must cover whole granules.");
-    assert(is_aligned(_committed_words, Settings::commit_granule_words()),
-           "The commit boundary must be aligned to commit granule size");
-    assert(_used_words <= _committed_words, "Sanity");
-  } else {
-    // case (2)
-    assert(_committed_words == 0 || _committed_words == word_size(), "Sanity");
-  }
-#endif
-
-  // We should hold the expand lock at this point.
-  assert_lock_strong(MetaspaceExpand_lock);
-
-  const size_t commit_from = _committed_words;
-  const size_t commit_to =   MIN2(align_up(new_committed_words, Settings::commit_granule_words()), word_size());
-
-  assert(commit_from >= used_words(), "Sanity");
-  assert(commit_to <= word_size(), "Sanity");
-
-  if (commit_to > commit_from) {
-    log_debug(metaspace)("Chunk " METACHUNK_FORMAT ": attempting to move commit line to "
-                         SIZE_FORMAT " words.", METACHUNK_FORMAT_ARGS(this), commit_to);
-
-    if (!_vsnode->ensure_range_is_committed(base() + commit_from, commit_to - commit_from)) {
-      DEBUG_ONLY(verify(true);)
-      return false;
-    }
-  }
-
-  // Remember how far we have committed.
-  _committed_words = commit_to;
-
-  DEBUG_ONLY(verify(true);)
-
-  return true;
-
-}
-
-
-// Ensure that chunk is committed up to at least new_committed_words words.
-// Fails if we hit a commit limit.
-bool Metachunk::ensure_committed(size_t new_committed_words) {
-
-  bool rc = true;
-
-  if (new_committed_words > committed_words()) {
-    MutexLocker cl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
-    rc = commit_up_to(new_committed_words);
-  }
-
-  return rc;
-
-}
-
-bool Metachunk::ensure_committed_locked(size_t new_committed_words) {
-
-  // the .._locked() variant should be called if we own the lock already.
-  assert_lock_strong(MetaspaceExpand_lock);
-
-  bool rc = true;
-
-  if (new_committed_words > committed_words()) {
-    rc = commit_up_to(new_committed_words);
-  }
-
-  return rc;
-
-}
-
-// Uncommit chunk area. The area must be a common multiple of the
-// commit granule size (in other words, we cannot uncommit chunks smaller than
-// a commit granule size).
-void Metachunk::uncommit() {
-  MutexLocker cl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
-  uncommit_locked();
-}
-
-void Metachunk::uncommit_locked() {
-  // Only uncommit chunks which are free, have no used words set (extra precaution) and are equal or larger in size than a single commit granule.
-  assert_lock_strong(MetaspaceExpand_lock);
-  assert(_state == state_free && _used_words == 0 && word_size() >= Settings::commit_granule_words(),
-         "Only free chunks equal or larger than commit granule size can be uncommitted "
-         "(chunk " METACHUNK_FULL_FORMAT ").", METACHUNK_FULL_FORMAT_ARGS(this));
-  if (word_size() >= Settings::commit_granule_words()) {
-    _vsnode->uncommit_range(base(), word_size());
-    _committed_words = 0;
-  }
-}
-void Metachunk::set_committed_words(size_t v) {
-  // Set committed words. Since we know that we only commit whole commit granules, we can round up v here.
-  v = MIN2(align_up(v, Settings::commit_granule_words()), word_size());
- _committed_words = v;
-}
-
-
-// Allocate word_size words from this chunk (word_size must be aligned to
-//  allocation_alignment_words).
-//
-// Caller must make sure the chunk is both large enough and committed far enough
-// to hold the allocation. Will always work.
-//
-MetaWord* Metachunk::allocate(size_t request_word_size) {
-
-  log_trace(metaspace)("Chunk " METACHUNK_FULL_FORMAT ": allocating " SIZE_FORMAT " words.",
-                       METACHUNK_FULL_FORMAT_ARGS(this), request_word_size);
-
-  // Caller must have made sure this works
-  assert(free_words() >= request_word_size, "Chunk too small.");
-  assert(free_below_committed_words() >= request_word_size, "Chunk not committed.");
-
-  MetaWord* const p = top();
-
-  _used_words += request_word_size;
-
-  SOMETIMES(verify(false);)
-
-  return p;
-
-}
-
-#ifdef ASSERT
-
-// Zap this structure.
-void Metachunk::zap_header(uint8_t c) {
-  memset(this, c, sizeof(Metachunk));
-}
-
-void Metachunk::fill_with_pattern(MetaWord pattern, size_t word_size) {
-  assert(word_size <= committed_words(), "Sanity");
-  for (size_t l = 0; l < word_size; l ++) {
-    _base[l] = pattern;
-  }
-}
-
-void Metachunk::check_pattern(MetaWord pattern, size_t word_size) {
-  assert(word_size <= committed_words(), "Sanity");
-  for (size_t l = 0; l < word_size; l ++) {
-    assert(_base[l] == pattern,
-           "chunk " METACHUNK_FULL_FORMAT ": pattern change at " PTR_FORMAT ": expected " UINTX_FORMAT " but got " UINTX_FORMAT ".",
-           METACHUNK_FULL_FORMAT_ARGS(this), p2i(_base + l), (uintx)pattern, (uintx)_base[l]);
-
-    ////////////////////////////////////////////
-    // A double-headed list of Metachunks.
-
-    class AbstractMetachunkList {
-
-      Metachunk* _first;
-      Metachunk* _last;
-
-      // Number of chunks
-      IntCounter _num;
-
-    protected:
-
-      AbstractMetachunkList() : _first(NULL), _last(NULL), _num() {}
-
-      Metachunk* first() const { return _first; }
-      int count() const { return _num.get(); }
-
-      // Add chunk to the front of the list.
-      void add_front(Metachunk* c) {
-        if (_first == NULL) {
-          assert(_last == NULL && _num.get() == 0, "Sanity");
-          _first = _last = c;
-          c->set_prev(NULL);
-          c->set_next(NULL);
-        } else {
-          assert(_last != NULL && _num.get() > 0, "Sanity");
-          c->set_next(_first);
-          c->set_prev(NULL);
-          _first->set_prev(c);
-          _first = c;
-        }
-        _num.increment();
-      }
-
-      // Add chunk to the back of the list.
-      void add_back(Metachunk* c) {
-        if (_last == NULL) {
-          assert(_first == NULL && _num.get() == 0, "Sanity");
-          _last = _first = c;
-          c->set_prev(NULL);
-          c->set_next(NULL);
-        } else {
-          assert(_first != NULL && _num.get() > 0, "Sanity");
-          c->set_next(NULL);
-          c->set_prev(_last);
-          _last->set_next(c);
-          _last = c;
-        }
-        _num.increment();
-      }
-
-      // Remove chunk from the front of the list. Returns NULL if list is empty.
-      Metachunk* remove_front() {
-        Metachunk* c = NULL;
-        if (_first == NULL) {
-          assert(_last == NULL && _num.get() == 0, "Sanity");
-        } else {
-          c = _first;
-          assert(c->prev() == NULL, "Sanity");
-          if (_first == _last) {
-            assert(_num.get() == 1, "Sanity");
-            _first = _last = NULL;
-          } else {
-            assert(_num.get() > 1, "Sanity");
-            _first = _first->next();
-            _first->set_prev(NULL);
-          }
-          _num.decrement();
-          c->set_next(NULL);
-        }
-        return c;
-      }
-
-      // Remove chunk from the back of the list. Returns NULL if list is empty.
-      Metachunk* remove_back() {
-        Metachunk* c = NULL;
-        if (_last == NULL) {
-          assert(_first == NULL && _num.get() == 0, "Sanity");
-        } else {
-          c = _last;
-          assert(c->next() == NULL, "Sanity");
-          if (_first == _last) {
-            assert(_num.get() == 1, "Sanity");
-            _first = _last = NULL;
-          } else {
-            assert(_num.get() > 1, "Sanity");
-            _last = _last->prev();
-            _last->set_next(NULL);
-          }
-          _num.decrement();
-          c->set_prev(NULL);
-        }
-        return c;
-      }
-
-    public:
-
-    #ifdef ASSERT
-      bool contains(const Metachunk* c) const;
-      void verify() const;
-    #endif
-
-      // Returns size, in words, of committed space of all chunks in this list.
-      // Note: walks list.
-      size_t committed_word_size() const {
-        size_t l = 0;
-        for (const Metachunk* c = _first; c != NULL; c = c->next()) {
-          l += c->committed_words();
-        }
-        return l;
-      }
-
-      void print_on(outputStream* st) const;
-
-    };
-
-    class UnsortedMetachunkList : public AbstractMetachunkList {
-    public:
-
-
-
-
-
-    };
-
-
-  }
-}
-
-
-// Verifies linking with neighbors in virtual space.
-// Can only be done under expand lock protection.
-void Metachunk::verify_neighborhood() const {
-
-  assert_lock_strong(MetaspaceExpand_lock);
-  assert(!is_dead(), "Do not call on dead chunks.");
-
-  if (is_root_chunk()) {
-
-    // Root chunks are all alone in the world.
-    assert(next_in_vs() == NULL || prev_in_vs() == NULL, "Root chunks should have no neighbors");
-
-  } else {
-
-    // Non-root chunks have neighbors, at least one, possibly two.
-
-    assert(next_in_vs() != NULL || prev_in_vs() != NULL,
-           "A non-root chunk should have neighbors (chunk @" PTR_FORMAT
-           ", base " PTR_FORMAT ", level " CHKLVL_FORMAT ".",
-           p2i(this), p2i(base()), level());
-
-    if (prev_in_vs() != NULL) {
-      assert(prev_in_vs()->end() == base(),
-             "Chunk " METACHUNK_FULL_FORMAT ": should be adjacent to predecessor: " METACHUNK_FULL_FORMAT ".",
-             METACHUNK_FULL_FORMAT_ARGS(this), METACHUNK_FULL_FORMAT_ARGS(prev_in_vs()));
-      assert(prev_in_vs()->next_in_vs() == this,
-             "Chunk " METACHUNK_FULL_FORMAT ": broken link to left neighbor: " METACHUNK_FULL_FORMAT " (" PTR_FORMAT ").",
-             METACHUNK_FULL_FORMAT_ARGS(this), METACHUNK_FULL_FORMAT_ARGS(prev_in_vs()), p2i(prev_in_vs()->next_in_vs()));
-    }
-
-    if (next_in_vs() != NULL) {
-      assert(end() == next_in_vs()->base(),
-             "Chunk " METACHUNK_FULL_FORMAT ": should be adjacent to successor: " METACHUNK_FULL_FORMAT ".",
-             METACHUNK_FULL_FORMAT_ARGS(this), METACHUNK_FULL_FORMAT_ARGS(next_in_vs()));
-      assert(next_in_vs()->prev_in_vs() == this,
-             "Chunk " METACHUNK_FULL_FORMAT ": broken link to right neighbor: " METACHUNK_FULL_FORMAT " (" PTR_FORMAT ").",
-             METACHUNK_FULL_FORMAT_ARGS(this), METACHUNK_FULL_FORMAT_ARGS(next_in_vs()), p2i(next_in_vs()->prev_in_vs()));
-    }
-
-    // One of the neighbors must be the buddy. It can be whole or splintered.
-
-    // The chunk following us or preceeding us may be our buddy or a splintered part of it.
-    Metachunk* buddy = is_leader() ? next_in_vs() : prev_in_vs();
-
-    assert(buddy != NULL, "Missing neighbor.");
-    assert(!buddy->is_dead(), "Invalid buddy state.");
-
-    // This neighbor is either or buddy (same level) or a splinter of our buddy - hence
-    // the level can never be smaller (aka the chunk size cannot be larger).
-    assert(buddy->level() >= level(), "Wrong level.");
-
-    if (buddy->level() == level()) {
-
-      // If the buddy is of the same size as us, it is unsplintered.
-      assert(buddy->is_leader() == !is_leader(),
-             "Only one chunk can be leader in a pair");
-
-      // When direct buddies are neighbors, one or both should be in use, otherwise they should
-      // have been merged.
-
-      // But since we call this verification function from internal functions where we are about to merge or just did split,
-      // do not test this. We have RootChunkArea::verify_area_is_ideally_merged() for testing that.
-
-      // assert(buddy->is_in_use() || is_in_use(), "incomplete merging?");
-
-      if (is_leader()) {
-        assert(buddy->base() == end(), "Sanity");
-        assert(is_aligned(base(), word_size() * 2 * BytesPerWord), "Sanity");
-      } else {
-        assert(buddy->end() == base(), "Sanity");
-        assert(is_aligned(buddy->base(), word_size() * 2 * BytesPerWord), "Sanity");
-      }
-
-    } else {
-
-      // Buddy, but splintered, and this is a part of it.
-      if (is_leader()) {
-        assert(buddy->base() == end(), "Sanity");
-      } else {
-        assert(buddy->end() > (base() - word_size()), "Sanity");
-      }
-
-    }
-  }
-}
-
-volatile MetaWord dummy = 0;
-
-void Metachunk::verify(bool slow) const {
-
-  // Note. This should be called under CLD lock protection.
-
-  // We can verify everything except the _prev_in_vs/_next_in_vs pair.
-  // This is because neighbor chunks may be added concurrently, so we cannot rely
-  //  on the content of _next_in_vs/_prev_in_vs unless we have the expand lock.
-
-  assert(!is_dead(), "Do not call on dead chunks.");
-
-  if (is_free()) {
-    assert(used_words() == 0, "free chunks are not used.");
-  }
-
-  // Note: only call this on a life Metachunk.
-  chunklevel::check_valid_level(level());
-
-  assert(base() != NULL, "No base ptr");
-
-  assert(committed_words() >= used_words(),
-         "mismatch: committed: " SIZE_FORMAT ", used: " SIZE_FORMAT ".",
-         committed_words(), used_words());
-
-  assert(word_size() >= committed_words(),
-         "mismatch: word_size: " SIZE_FORMAT ", committed: " SIZE_FORMAT ".",
-         word_size(), committed_words());
-
-  // Test base pointer
-  assert(base() != NULL, "Base pointer NULL");
-  assert(vsnode() != NULL, "No space");
-  vsnode()->check_pointer(base());
-
-  // Starting address shall be aligned to chunk size.
-  const size_t required_alignment = word_size() * sizeof(MetaWord);
-  assert_is_aligned(base(), required_alignment);
-
-  // If slow, test the committed area
-  if (slow && _committed_words > 0) {
-    for (const MetaWord* p = _base; p < _base + _committed_words; p += os::vm_page_size()) {
-      dummy = *p;
-    }
-    dummy = *(_base + _committed_words - 1);
-  }
-
-}
-#endif // ASSERT
-
-void Metachunk::print_on(outputStream* st) const {
-
-  // Note: must also work with invalid/random data. (e.g. do not call word_size())
-  st->print("Chunk @" PTR_FORMAT ", state %c, base " PTR_FORMAT ", "
-            "level " CHKLVL_FORMAT " (" SIZE_FORMAT " words), "
-            "used " SIZE_FORMAT " words, committed " SIZE_FORMAT " words.",
-            p2i(this), get_state_char(), p2i(base()), level(),
-            (chunklevel::is_valid_level(level()) ? chunklevel::word_size_for_level(level()) : (size_t)-1),
-            used_words(), committed_words());
-
-}
-
-} // namespace metaspace
-
--- old/src/hotspot/share/memory/metaspace/metachunk.hpp	2020-09-04 13:58:27.273604476 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,321 +0,0 @@
-/*
- * Copyright (c) 2012, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2017, 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#ifndef SHARE_MEMORY_METASPACE_METACHUNK_HPP
-#define SHARE_MEMORY_METASPACE_METACHUNK_HPP
-
-
-#include "memory/metaspace/counter.hpp"
-#include "memory/metaspace/chunkLevel.hpp"
-#include "utilities/debug.hpp"
-#include "utilities/globalDefinitions.hpp"
-
-
-class outputStream;
-
-namespace metaspace {
-
-class VirtualSpaceNode;
-
-// A Metachunk is a contiguous metaspace memory region. It is part of
-// a MetaspaceArena, which keeps a list of MetaChunk and allocates via
-// pointer bump from the top element in the list.
-//
-// The Metachunk object itself (the "chunk header") is separated from
-//  the memory region (the chunk payload) it describes. It also can have
-//  no payload (a "dead" chunk). In itself it lives in C-heap, managed
-//  as part of a pool of Metachunk headers (ChunkHeaderPool).
-//
-// -- Metachunk state --
-//
-// A Metachunk is "in-use" if it is part of a MetaspaceArena. That means
-//  its memory is used - or will be used shortly - to hold VM metadata
-//  on behalf of a class loader.
-//
-// A Metachunk is "free" if its payload is currently unused. In that
-//  case it is managed by a chunk freelist (the ChunkManager).
-// 
-// A Metachunk is "dead" if it does not have a corresponding payload.
-//  In that case it lives as part of a freelist-of-dead-chunk-headers
-//  in the ChunkHeaderPool.
-//
-// -- Level --
-//
-// Metachunks are managed as part of a buddy style allocation scheme.
-// Sized always in steps of power-of-2, ranging from the smallest chunk size
-// (1Kb) to the largest (4Mb) (see chunklevel.hpp).
-// Its size is encoded as level, with level 0 being the largest chunk
-// size ("root chunk").
-//
-// -- Payload commit state --
-//
-// A Metachunk payload may be committed, partly committed or completely
-// uncommitted. Technically, a payload may be committed "checkered" -
-// i.e. committed and uncommitted parts may interleave - but the
-// important part is how much contiguous space is committed starting
-// at the base of the payload (since that's where we allocate). 
-// 
-// The Metachunk keeps track of how much space is committed starting
-//  at the base of the payload - which is a performace optimization - 
-//  while underlying layers (VirtualSpaceNode->commitmask) keep track
-//  of the "real" commit state, aka which granules are committed,
-//  independent on what chunks reside above those granules.
-
-
-//            +--------------+ <- end    -----------+ ----------+
-//            |              |                      |           |
-//            |              |                      |           |
-//            |              |                      |           |
-//            |              |                      |           |
-//            |              |                      |           |
-//            | -----------  | <- committed_top  -- +           |
-//            |              |                      |           |
-//            |              |                      | "free"    |
-//            |              |                      |           | size 
-//            |              |     "free_below_     |           |
-//            |              |        committed"    |           |
-//            |              |                      |           |
-//            |              |                      |           |
-//            | -----------  | <- top     --------- + --------  |
-//            |              |                      |           |
-//            |              |     "used"           |           |
-//            |              |                      |           |
-//            +--------------+ <- start   ----------+ ----------+
-
-// Note: this is a chunk **descriptor**. The real Payload area lives in metaspace,
-// this class lives somewhere else.
-class Metachunk {
-
-  // start of chunk memory; NULL if dead.
-  MetaWord* _base;
-
-  // Used words.
-  size_t _used_words;
-
-  // Size of the region, starting from base, which is guaranteed to be committed. In words.
-  //  The actual size of committed regions may actually be larger.
-  //
-  //  (This is a performance optimization. The underlying VirtualSpaceNode knows
-  //   which granules are committed; but we want to avoid having to ask.)
-  size_t _committed_words;
-
-  chunklevel_t _level; // aka size.
-
-  // state_free:    free, owned by a ChunkManager
-  // state_in_use:  in-use, owned by a MetaspaceArena
-  // dead:          just a hollow chunk header without associated memory, owned
-  //                 by chunk header pool.
-  enum state_t {
-    state_free = 0,
-    state_in_use = 1,
-    state_dead = 2
-  };
-  state_t _state;
-
-  // We need unfortunately a back link to the virtual space node
-  // for splitting and merging nodes.
-  VirtualSpaceNode* _vsnode;
-
-
-  // A chunk header is kept in a list:
-  // 1 in the list of used chunks inside a MetaspaceArena, if it is in use
-  // 2 in the list of free chunks inside a ChunkManager, if it is free
-  // 3 in the freelist of unused headers inside the ChunkHeaderPool,
-  //   if it is unused (e.g. result of chunk merging) and has no associated
-  //   memory area.
-  Metachunk* _prev;
-  Metachunk* _next;
-
-  // Furthermore, we keep, per chunk, information about the neighboring chunks.
-  // This is needed to split and merge chunks.
-  //
-  // Note: These members can be modified concurrently while a chunk is alive and in use.
-  // This can happen if a neighboring chunk is added or removed.
-  // This means only read or modify these members under expand lock protection.
-  Metachunk* _prev_in_vs;
-  Metachunk* _next_in_vs;
-
-  // Commit uncommitted section of the chunk.
-  // Fails if we hit a commit limit.
-  bool commit_up_to(size_t new_committed_words);
-
-  DEBUG_ONLY(static void assert_have_expand_lock();)
-
-public:
-
-  Metachunk()
-    : _base(NULL),
-      _used_words(0),
-      _committed_words(0),
-      _level(chunklevel::ROOT_CHUNK_LEVEL),
-      _state(state_free),
-      _vsnode(NULL),
-      _prev(NULL), _next(NULL),
-      _prev_in_vs(NULL), _next_in_vs(NULL)
-  {}
-
- void clear() {
-   _base = NULL;
-   _used_words = 0;
-   _committed_words = 0;
-   _level = chunklevel::ROOT_CHUNK_LEVEL;
-   _state = state_free;
-   _vsnode = NULL;
-   _prev = NULL;
-   _next = NULL;
-   _prev_in_vs = NULL;
-   _next_in_vs = NULL;
-  }
-
-
-  size_t word_size() const        { return chunklevel::word_size_for_level(_level); }
-
-  MetaWord* base() const          { return _base; }
-  MetaWord* top() const           { return base() + _used_words; }
-  MetaWord* committed_top() const { return base() + _committed_words; }
-  MetaWord* end() const           { return base() + word_size(); }
-
-  // Chunk list wiring
-  void set_prev(Metachunk* c)     { _prev = c; }
-  Metachunk* prev() const         { return _prev; }
-  void set_next(Metachunk* c)     { _next = c; }
-  Metachunk* next() const         { return _next; }
-
-  DEBUG_ONLY(bool in_list() const { return _prev != NULL || _next != NULL; })
-
-  // Physical neighbors wiring
-  void set_prev_in_vs(Metachunk* c) { DEBUG_ONLY(assert_have_expand_lock()); _prev_in_vs = c; }
-  Metachunk* prev_in_vs() const     { DEBUG_ONLY(assert_have_expand_lock()); return _prev_in_vs; }
-  void set_next_in_vs(Metachunk* c) { DEBUG_ONLY(assert_have_expand_lock()); _next_in_vs = c; }
-  Metachunk* next_in_vs() const     { DEBUG_ONLY(assert_have_expand_lock()); return _next_in_vs; }
-
-  bool is_free() const            { return _state == state_free; }
-  bool is_in_use() const          { return _state == state_in_use; }
-  bool is_dead() const            { return _state == state_dead; }
-  void set_free()                 { _state = state_free; }
-  void set_in_use()               { _state = state_in_use; }
-  void set_dead()                 { _state = state_dead; }
-
-  // Return a single char presentation of the state ('f', 'u', 'd')
-  char get_state_char() const;
-
-  void inc_level()                { _level ++; DEBUG_ONLY(chunklevel::is_valid_level(_level);) }
-  void dec_level()                { _level --; DEBUG_ONLY(chunklevel::is_valid_level(_level);) }
-  chunklevel_t level() const          { return _level; }
-
-  // Convenience functions for extreme levels.
-  bool is_root_chunk() const      { return chunklevel::ROOT_CHUNK_LEVEL == _level; }
-  bool is_leaf_chunk() const      { return chunklevel::HIGHEST_CHUNK_LEVEL == _level; }
-
-  VirtualSpaceNode* vsnode() const        { return _vsnode; }
-
-  size_t used_words() const                   { return _used_words; }
-  size_t free_words() const                   { return word_size() - used_words(); }
-  size_t free_below_committed_words() const   { return committed_words() - used_words(); }
-  void reset_used_words()                     { _used_words = 0; }
-
-  size_t committed_words() const      { return _committed_words; }
-  void set_committed_words(size_t v);
-  bool is_fully_committed() const     { return committed_words() == word_size(); }
-  bool is_fully_uncommitted() const   { return committed_words() == 0; }
-
-  // Ensure that chunk is committed up to at least new_committed_words words.
-  // Fails if we hit a commit limit.
-  bool ensure_committed(size_t new_committed_words);
-  bool ensure_committed_locked(size_t new_committed_words);
-
-  bool ensure_fully_committed()           { return ensure_committed(word_size()); }
-  bool ensure_fully_committed_locked()    { return ensure_committed_locked(word_size()); }
-
-  // Ensure that the chunk is committed far enough to serve an additional allocation of word_size.
-  bool ensure_committed_additional(size_t additional_word_size)   {
-    return ensure_committed(used_words() + additional_word_size);
-  }
-
-  // Uncommit chunk area. The area must be a common multiple of the
-  // commit granule size (in other words, we cannot uncommit chunks smaller than
-  // a commit granule size).
-  void uncommit();
-  void uncommit_locked();
-
-  // Allocation from a chunk
-
-  // Allocate word_size words from this chunk (word_size must be aligned to
-  //  allocation_alignment_words).
-  //
-  // Caller must make sure the chunk is both large enough and committed far enough
-  // to hold the allocation. Will always work.
-  //
-  MetaWord* allocate(size_t request_word_size);
-
-  // Initialize structure for reuse.
-  void initialize(VirtualSpaceNode* node, MetaWord* base, chunklevel_t lvl) {
-    _vsnode = node; _base = base; _level = lvl;
-    _used_words = _committed_words = 0; _state = state_free;
-    _next = _prev = _next_in_vs = _prev_in_vs = NULL;
-  }
-
-  // Returns true if this chunk is the leader in its buddy pair, false if not.
-  // Do not call for root chunks.
-  bool is_leader() const {
-    assert(!is_root_chunk(), "Root chunks have no buddy."); // Bit harsh?
-    return is_aligned(base(), chunklevel::word_size_for_level(level() - 1) * BytesPerWord);
-  }
-
-  //// Debug stuff ////
-#ifdef ASSERT
-  void verify(bool slow) const;
-  // Verifies linking with neighbors in virtual space. Needs expand lock protection.
-  void verify_neighborhood() const;
-  void zap_header(uint8_t c = 0x17);
-  void fill_with_pattern(MetaWord pattern, size_t word_size);
-  void check_pattern(MetaWord pattern, size_t word_size);
-
-  // Returns true if given pointer points into the payload area of this chunk.
-  bool is_valid_pointer(const MetaWord* p) const {
-    return base() <= p && p < top();
-  }
-
-  // Returns true if given pointer points into the commmitted payload area of this chunk.
-  bool is_valid_committed_pointer(const MetaWord* p) const {
-    return base() <= p && p < committed_top();
-  }
-
-#endif // ASSERT
-
-  void print_on(outputStream* st) const;
-
-};
-
-// Little print helpers: since we often print out chunks, here some convenience macros
-#define METACHUNK_FORMAT                "@" PTR_FORMAT ", %c, base " PTR_FORMAT ", level " CHKLVL_FORMAT
-#define METACHUNK_FORMAT_ARGS(chunk)    p2i(chunk), chunk->get_state_char(), p2i(chunk->base()), chunk->level()
-
-#define METACHUNK_FULL_FORMAT                "@" PTR_FORMAT ", %c, base " PTR_FORMAT ", level " CHKLVL_FORMAT " (" SIZE_FORMAT "), used: " SIZE_FORMAT ", committed: " SIZE_FORMAT ", committed-free: " SIZE_FORMAT
-#define METACHUNK_FULL_FORMAT_ARGS(chunk)    p2i(chunk), chunk->get_state_char(), p2i(chunk->base()), chunk->level(), chunk->word_size(), chunk->used_words(), chunk->committed_words(), chunk->free_below_committed_words()
-
-} // namespace metaspace
-
-#endif // SHARE_MEMORY_METASPACE_METACHUNK_HPP
--- old/src/hotspot/share/memory/metaspace/metachunkList.cpp	2020-09-04 13:58:27.713607555 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,113 +0,0 @@
-/*
- * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#include "precompiled.hpp"
-
-#include "memory/metaspace/metachunkList.hpp"
-#include "utilities/debug.hpp"
-#include "utilities/globalDefinitions.hpp"
-#include "utilities/ostream.hpp"
-
-
-namespace metaspace {
-
-#ifdef ASSERT
-
-bool MetachunkList::contains(const Metachunk* c) const {
-  for (Metachunk* c2 = _first; c2 != NULL; c2 = c2->next()) {
-    if (c == c2) {
-      return true;
-    }
-  }
-  return false;
-}
-
-void MetachunkList::verify() const {
-  int num = 0;
-  const Metachunk* last_c = NULL;
-  for (const Metachunk* c = _first; c != NULL; c = c->next()) {
-    num ++;
-    assert(c->prev() != c && c->next() != c, "circularity");
-    assert(c->prev() == last_c,
-           "Broken link to predecessor. Chunk " METACHUNK_FULL_FORMAT ".",
-           METACHUNK_FULL_FORMAT_ARGS(c));
-    c->verify(false);
-    last_c = c;
-  }
-  _num_chunks.check(num);
-}
-
-#endif // ASSERT
-
-
-size_t MetachunkList::calc_committed_word_size() const {
-
-  if (_first != NULL && _first->is_dead()) {
-    // list used for chunk header pool; dead chunks have no size.
-    return 0;
-  }
-
-  size_t s = 0;
-  for (Metachunk* c = _first; c != NULL; c = c->next()) {
-    assert(c->is_dead() == false, "Sanity");
-    s += c->committed_words();
-  }
-  return s;
-}
-
-size_t MetachunkList::calc_word_size() const {
-
-  if (_first != NULL && _first->is_dead()) {
-    // list used for chunk header pool; dead chunks have no size.
-    return 0;
-  }
-
-  size_t s = 0;
-  for (Metachunk* c = _first; c != NULL; c = c->next()) {
-    assert(c->is_dead() == false, "Sanity");
-    s += c->committed_words();
-  }
-  return s;
-
-}
-
-void MetachunkList::print_on(outputStream* st) const {
-
-  if (_num_chunks.get() > 0) {
-    for (const Metachunk* c = _first; c != NULL; c = c->next()) {
-      st->print(" - <");
-      c->print_on(st);
-      st->print(">");
-    }
-    st->print(" - total : %d chunks.", _num_chunks.get());
-  } else {
-    st->print("empty");
-  }
-
-}
-
-
-} // namespace metaspace
-
--- old/src/hotspot/share/memory/metaspace/metachunkList.hpp	2020-09-04 13:58:28.121610410 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,105 +0,0 @@
-/*
- * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#ifndef SHARE_MEMORY_METASPACE_METACHUNKLIST_HPP
-#define SHARE_MEMORY_METASPACE_METACHUNKLIST_HPP
-
-
-#include "memory/metaspace/counter.hpp"
-#include "memory/metaspace/metachunk.hpp"
-#include "memory/metaspace/metaspaceCommon.hpp"
-#include "utilities/debug.hpp"
-#include "utilities/globalDefinitions.hpp"
-
-
-class outputStream;
-
-namespace metaspace {
-
-// A simple single-linked list of chunks, used in MetaspaceArena to keep
-//  a list of retired chunks, as well as in the ChunkHeaderPool to keep
-//  a cache of unused chunk headers.
-
-class MetachunkList {
-
-  Metachunk* _first;
-  IntCounter _num_chunks;
-
-  // Note: The chunks inside this list may be dead (->chunk header pool).
-  // So, do not call c->word size on them or anything else which may not
-  // work with dead chunks.
-
-public:
-
-  MetachunkList() : _first(NULL), _num_chunks() {}
-
-  int count() const { return _num_chunks.get(); }
-
-  void add(Metachunk* c) {
-    // Note: contains is expensive (linear search).
-    ASSERT_SOMETIMES(contains(c) == false, "Chunk already in this list");
-    c->set_next(_first);
-    if (_first) {
-      _first->set_prev(c);
-    }
-    _first = c;
-    _num_chunks.increment();
-  }
-
-  Metachunk* remove_first() {
-    if (_first) {
-      Metachunk* c = _first;
-      _first = _first->next();
-      if (_first) {
-        _first->set_prev(NULL);
-      }
-      _num_chunks.decrement();
-      c->set_prev(NULL);
-      c->set_next(NULL);
-      return c;
-    }
-    return NULL;
-  }
-
-  Metachunk* first()              { return _first; }
-  const Metachunk* first() const  { return _first; }
-
-#ifdef ASSERT
-  // Note: linear search
-  bool contains(const Metachunk* c) const;
-  void verify() const;
-#endif
-
-  size_t calc_committed_word_size() const;
-  size_t calc_word_size() const;
-
-  void print_on(outputStream* st) const;
-
-};
-
-
-} // namespace metaspace
-
-#endif // SHARE_MEMORY_METASPACE_METACHUNKLIST_HPP
--- old/src/hotspot/share/memory/metaspace/metaspaceArena.cpp	2020-09-04 13:58:28.545613379 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,556 +0,0 @@
-/*
- * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#include "precompiled.hpp"
-
-#include "logging/log.hpp"
-#include "logging/logStream.hpp"
-#include "memory/metaspace/allocationGuard.hpp"
-#include "memory/metaspace/arenaGrowthPolicy.hpp"
-#include "memory/metaspace/freeBlocks.hpp"
-#include "memory/metaspace/chunkManager.hpp"
-#include "memory/metaspace/internStat.hpp"
-#include "memory/metaspace/metachunk.hpp"
-#include "memory/metaspace/metaspaceArena.hpp"
-#include "memory/metaspace/metaspaceCommon.hpp"
-#include "memory/metaspace/metaspaceStatistics.hpp"
-#include "memory/metaspace/virtualSpaceList.hpp"
-#include "runtime/atomic.hpp"
-#include "runtime/init.hpp"
-#include "services/memoryService.hpp"
-#include "utilities/align.hpp"
-#include "utilities/debug.hpp"
-#include "utilities/globalDefinitions.hpp"
-
-namespace metaspace {
-
-#define LOGFMT         "Arena @" PTR_FORMAT " (%s)"
-#define LOGFMT_ARGS    p2i(this), this->_name
-
-// Given a net allocation word size, return the raw word size we actually allocate.
-// Note: externally visible for gtests.
-//static
-size_t get_raw_allocation_word_size(size_t net_word_size) {
-
-  size_t byte_size = net_word_size * BytesPerWord;
-
-  // Deallocated metablocks are kept in a binlist which limits their minimal
-  //  size to at least the size of a binlist item (2 words).
-  byte_size = MAX2(byte_size, FreeBlocks::minimal_word_size * BytesPerWord);
-
-  // Metaspace allocations are aligned to word size.
-  byte_size = align_up(byte_size, allocation_alignment_bytes);
-
-  // If we guard allocations, we need additional space for a prefix.
-#ifdef ASSERT
-  if (Settings::use_allocation_guard()) {
-    byte_size += align_up(prefix_size(), allocation_alignment_bytes);
-  }
-#endif
-
-  size_t word_size = byte_size / BytesPerWord;
-
-  assert(word_size * BytesPerWord == byte_size, "Sanity");
-
-  return word_size;
-
-}
-
-// Returns the level of the next chunk to be added, acc to growth policy.
-chunklevel_t MetaspaceArena::next_chunk_level() const {
-  const int growth_step = _chunks.count();
-  return _growth_policy->get_level_at_step(growth_step);
-}
-
-// Given a chunk, add its remaining free committed space to the free block list.
-void MetaspaceArena::salvage_chunk(Metachunk* c) {
-
-  if (Settings::handle_deallocations() == false) {
-    return;
-  }
-
-  assert_lock_strong(lock());
-
-  // If the chunk is completely empty, just return it to the chunk manager.
-  if (c->used_words() == 0) {
-    UL2(trace, "salvage: returning empty chunk " METACHUNK_FORMAT ".", METACHUNK_FORMAT_ARGS(c));
-    _chunk_manager->return_chunk(c);
-    return;
-  }
-
-  size_t remaining_words = c->free_below_committed_words();
-
-  if (remaining_words > FreeBlocks::minimal_word_size) {
-
-    UL2(trace, "salvaging chunk " METACHUNK_FULL_FORMAT ".", METACHUNK_FULL_FORMAT_ARGS(c));
-
-    MetaWord* ptr = c->allocate(remaining_words);
-    assert(ptr != NULL, "Should have worked");
-    _total_used_words_counter->increment_by(remaining_words);
-
-    add_allocation_to_fbl(ptr, remaining_words);
-
-    // After this operation: the chunk should have no free committed space left.
-    assert(c->free_below_committed_words() == 0,
-           "Salvaging chunk failed (chunk " METACHUNK_FULL_FORMAT ").",
-           METACHUNK_FULL_FORMAT_ARGS(c));
-
-  }
-
-}
-
-// Allocate a new chunk from the underlying chunk manager able to hold at least
-// requested word size.
-Metachunk* MetaspaceArena::allocate_new_chunk(size_t requested_word_size) {
-
-  assert_lock_strong(lock());
-
-  // Should this ever happen, we need to increase the maximum possible chunk size.
-  guarantee(requested_word_size <= chunklevel::MAX_CHUNK_WORD_SIZE,
-            "Requested size too large (" SIZE_FORMAT ") - max allowed size per allocation is " SIZE_FORMAT ".",
-            requested_word_size, chunklevel::MAX_CHUNK_WORD_SIZE);
-
-  const int growth_step = _chunks.count();
-  const chunklevel_t max_level = chunklevel::level_fitting_word_size(requested_word_size);
-  const chunklevel_t preferred_level = MIN2(max_level, next_chunk_level());
-
-  Metachunk* c = _chunk_manager->get_chunk(preferred_level, max_level, requested_word_size);
-  if (c == NULL) {
-    return NULL;
-  }
-
-  assert(c->is_in_use(), "Wrong chunk state.");
-  assert(c->free_below_committed_words() >= requested_word_size, "Chunk not committed");
-
-  return c;
-
-}
-
-void MetaspaceArena::add_allocation_to_fbl(MetaWord* p, size_t word_size) {
-  assert(Settings::handle_deallocations(), "Sanity");
-  if (_fbl == NULL) {
-    _fbl = new FreeBlocks(); // Create only on demand
-  }
-  _fbl->add_block(p, word_size);
-}
-
-MetaspaceArena::MetaspaceArena(ChunkManager* chunk_manager,
-             const ArenaGrowthPolicy* growth_policy,
-             Mutex* lock,
-             SizeAtomicCounter* total_used_words_counter,
-             const char* name)
-: _lock(lock),
-  _chunk_manager(chunk_manager),
-  _growth_policy(growth_policy),
-  _chunks(),
-  _fbl(NULL),
-  _total_used_words_counter(total_used_words_counter),
-  _name(name)
-{
-  UL(debug, ": born.");
-
-  // Update statistics
-  InternalStats::inc_num_arena_births();
-}
-
-MetaspaceArena::~MetaspaceArena() {
-
-  DEBUG_ONLY(verify(true);)
-
-  MutexLocker fcl(lock(), Mutex::_no_safepoint_check_flag);
-
-  MemRangeCounter return_counter;
-
-  Metachunk* c = _chunks.first();
-  Metachunk* c2 = NULL;
-
-  while(c) {
-    c2 = c->next();
-    return_counter.add(c->used_words());
-    DEBUG_ONLY(c->set_prev(NULL);)
-    DEBUG_ONLY(c->set_next(NULL);)
-    UL2(debug, "return chunk: " METACHUNK_FORMAT ".", METACHUNK_FORMAT_ARGS(c));
-    _chunk_manager->return_chunk(c);
-    // c may be invalid after return_chunk(c) was called. Don't access anymore.
-    c = c2;
-  }
-
-  UL2(info, "returned %d chunks, total capacity " SIZE_FORMAT " words.",
-      return_counter.count(), return_counter.total_size());
-
-  _total_used_words_counter->decrement_by(return_counter.total_size());
-
-  DEBUG_ONLY(chunk_manager()->verify(true);)
-
-  delete _fbl;
-
-  UL(debug, ": dies.");
-
-  // Update statistics
-  InternalStats::inc_num_arena_deaths();
-
-}
-
-// Attempt to enlarge the current chunk to make it large enough to hold at least
-//  requested_word_size additional words.
-//
-// On success, true is returned, false otherwise.
-bool MetaspaceArena::attempt_enlarge_current_chunk(size_t requested_word_size) {
-
-  assert_lock_strong(lock());
-
-  Metachunk* c = current_chunk();
-  assert(c->free_words() < requested_word_size, "Sanity");
-
-  // Not if chunk enlargment is switched off...
-  if (Settings::enlarge_chunks_in_place() == false) {
-    return false;
-  }
-
-  // ... we also disallow it for very large chunks...
-  if (c->word_size() > Settings::enlarge_chunks_in_place_max_word_size()) {
-    return false;
-  }
-
-  // ... nor if we are already a root chunk ...
-  if (c->is_root_chunk()) {
-    return false;
-  }
-
-  // ... nor if the combined size of chunk content and new content would bring us above the size of a root chunk ...
-  if ((c->used_words() + requested_word_size) > metaspace::chunklevel::MAX_CHUNK_WORD_SIZE) {
-    return false;
-  }
-
-  const chunklevel_t new_level =
-      chunklevel::level_fitting_word_size(c->used_words() + requested_word_size);
-  assert(new_level < c->level(), "Sanity");
-
-  // Atm we only enlarge by one level (so, doubling the chunk in size). So, if the requested enlargement
-  // would require the chunk to more than double in size, we bail. But this covers about 99% of all cases,
-  // so this is good enough.
-  if (new_level < c->level() - 1) {
-    return false;
-  }
-
-  // This only works if chunk is the leader of its buddy pair (and also if buddy
-  // is free and unsplit, but that we cannot check outside of metaspace lock).
-  if (!c->is_leader()) {
-    return false;
-  }
-
-  // If the size added to the chunk would be larger than allowed for the next growth step
-  // dont enlarge.
-  if (next_chunk_level() > c->level()) {
-    return false;
-  }
-
-  bool success = _chunk_manager->attempt_enlarge_chunk(c);
-
-  assert(success == false || c->free_words() >= requested_word_size, "Sanity");
-
-  return success;
-
-}
-
-// Allocate memory from Metaspace.
-// 1) Attempt to allocate from the free block list.
-// 2) Attempt to allocate from the current chunk.
-// 3) Attempt to enlarge the current chunk in place if it is too small.
-// 4) Attempt to get a new chunk and allocate from that chunk.
-// At any point, if we hit a commit limit, we return NULL.
-MetaWord* MetaspaceArena::allocate(size_t requested_word_size) {
-
-  MutexLocker cl(lock(), Mutex::_no_safepoint_check_flag);
-
-  UL2(trace, "requested " SIZE_FORMAT " words.", requested_word_size);
-
-  MetaWord* p = NULL;
-
-  const size_t raw_word_size = get_raw_word_size_for_requested_word_size(requested_word_size);
-
-  // 1) Attempt to allocate from the free blocks list
-  if (Settings::handle_deallocations() && _fbl != NULL && !_fbl->is_empty()) {
-    p = _fbl->get_block(raw_word_size);
-    if (p != NULL) {
-      DEBUG_ONLY(InternalStats::inc_num_allocs_from_deallocated_blocks();)
-      UL2(trace, "taken from fbl (now: %d, " SIZE_FORMAT ").",
-          _fbl->count(), _fbl->total_size());
-      // Note: Space in the freeblock dictionary counts as already used (see retire_current_chunk()) -
-      // that means that we do not modify any counters and therefore can skip the epilog.
-      return p;
-    }
-  }
-
-  bool current_chunk_too_small = false;
-  bool commit_failure = false;
-
-  if (current_chunk() != NULL) {
-
-    // 2) Attempt to satisfy the allocation from the current chunk.
-
-    // If the current chunk is too small to hold the requested size, attempt to enlarge it.
-    // If that fails, retire the chunk.
-    if (current_chunk()->free_words() < raw_word_size) {
-      if (!attempt_enlarge_current_chunk(raw_word_size)) {
-        current_chunk_too_small = true;
-      } else {
-        DEBUG_ONLY(InternalStats::inc_num_chunks_enlarged();)
-        UL(debug, "enlarged chunk.");
-      }
-    }
-
-    // Commit the chunk far enough to hold the requested word size. If that fails, we
-    // hit a limit (either GC threshold or MaxMetaspaceSize). In that case retire the
-    // chunk.
-    if (!current_chunk_too_small) {
-      if (!current_chunk()->ensure_committed_additional(raw_word_size)) {
-        UL2(info, "commit failure (requested size: " SIZE_FORMAT ")", raw_word_size);
-        commit_failure = true;
-      }
-    }
-
-    // Allocate from the current chunk. This should work now.
-    if (!current_chunk_too_small && !commit_failure) {
-      p = current_chunk()->allocate(raw_word_size);
-      assert(p != NULL, "Allocation from chunk failed.");
-    }
-
-  }
-
-  if (p == NULL) {
-
-    // If we are here, we either had no current chunk to begin with or it was deemed insufficient.
-    assert(current_chunk() == NULL ||
-           current_chunk_too_small || commit_failure, "Sanity");
-
-    Metachunk* new_chunk = allocate_new_chunk(raw_word_size);
-
-    if (new_chunk != NULL) {
-
-      UL2(debug, "allocated new chunk " METACHUNK_FORMAT " for requested word size " SIZE_FORMAT ".",
-          METACHUNK_FORMAT_ARGS(new_chunk), requested_word_size);
-
-      assert(new_chunk->free_below_committed_words() >= raw_word_size, "Sanity");
-
-      // We have a new chunk. Before making it the current chunk, retire the old one.
-      if (current_chunk() != NULL) {
-        salvage_chunk(current_chunk());
-        DEBUG_ONLY(InternalStats::inc_num_chunks_retired();)
-      }
-
-      _chunks.add(new_chunk);
-
-      // Now, allocate from that chunk. That should work.
-      p = current_chunk()->allocate(raw_word_size);
-      assert(p != NULL, "Allocation from chunk failed.");
-
-    } else {
-      UL2(info, "failed to allocate new chunk for requested word size " SIZE_FORMAT ".", requested_word_size);
-    }
-
-  }
-
-#ifdef ASSERT
-  // When using allocation guards, establish a prefix.
-  if (p != NULL && Settings::use_allocation_guard()) {
-    p = establish_prefix(p, raw_word_size);
-  }
-#endif
-
-  if (p == NULL) {
-    InternalStats::inc_num_allocs_failed_limit();
-  } else {
-    DEBUG_ONLY(InternalStats::inc_num_allocs();)
-    _total_used_words_counter->increment_by(raw_word_size);
-  }
-
-  SOMETIMES(verify_locked(true);)
-
-  if (p == NULL) {
-    UL(info, "allocation failed, returned NULL.");
-  } else {
-    UL2(trace, "returned " PTR_FORMAT ".", p2i(p));
-  }
-
-  return p;
-
-}
-
-// Prematurely returns a metaspace allocation to the _block_freelists
-// because it is not needed anymore (requires CLD lock to be active).
-void MetaspaceArena::deallocate_locked(MetaWord* p, size_t word_size) {
-
-  if (Settings::handle_deallocations() == false) {
-    return;
-  }
-
-  assert_lock_strong(lock());
-
-  // At this point a current chunk must exist since we only deallocate if we did allocate before.
-  assert(current_chunk() != NULL, "stray deallocation?");
-
-  assert(is_valid_area(p, word_size),
-         "Pointer range not part of this Arena and cannot be deallocated: (" PTR_FORMAT ".." PTR_FORMAT ").",
-         p2i(p), p2i(p + word_size));
-
-  UL2(trace, "deallocating " PTR_FORMAT ", word size: " SIZE_FORMAT ".",
-      p2i(p), word_size);
-
-  size_t raw_word_size = get_raw_word_size_for_requested_word_size(word_size);
-  add_allocation_to_fbl(p, raw_word_size);
-
-  DEBUG_ONLY(verify_locked(false);)
-
-}
-
-// Prematurely returns a metaspace allocation to the _block_freelists because it is not
-// needed anymore.
-void MetaspaceArena::deallocate(MetaWord* p, size_t word_size) {
-  MutexLocker cl(lock(), Mutex::_no_safepoint_check_flag);
-  deallocate_locked(p, word_size);
-}
-
-// Update statistics. This walks all in-use chunks.
-void MetaspaceArena::add_to_statistics(arena_stats_t* out) const {
-
-  MutexLocker cl(lock(), Mutex::_no_safepoint_check_flag);
-
-  for (const Metachunk* c = _chunks.first(); c != NULL; c = c->next()) {
-    in_use_chunk_stats_t& ucs = out->stats[c->level()];
-    ucs.num ++;
-    ucs.word_size += c->word_size();
-    ucs.committed_words += c->committed_words();
-    ucs.used_words += c->used_words();
-    // Note: for free and waste, we only count what's committed.
-    if (c == current_chunk()) {
-      ucs.free_words += c->free_below_committed_words();
-    } else {
-      ucs.waste_words += c->free_below_committed_words();
-    }
-  }
-
-  if (_fbl != NULL) {
-    out->free_blocks_num += _fbl->count();
-    out->free_blocks_word_size += _fbl->total_size();
-  }
-
-  SOMETIMES(out->verify();)
-
-}
-
-// Convenience method to get the most important usage statistics.
-// For deeper analysis use add_to_statistics().
-void MetaspaceArena::usage_numbers(size_t* p_used_words, size_t* p_committed_words, size_t* p_capacity_words) const {
-  MutexLocker cl(lock(), Mutex::_no_safepoint_check_flag);
-  size_t used = 0, comm = 0, cap = 0;
-  for (const Metachunk* c = _chunks.first(); c != NULL; c = c->next()) {
-    used += c->used_words();
-    comm += c->committed_words();
-    cap += c->word_size();
-  }
-  if (p_used_words != NULL) {
-    *p_used_words = used;
-  }
-  if (p_committed_words != NULL) {
-    *p_committed_words = comm;
-  }
-  if (p_capacity_words != NULL) {
-    *p_capacity_words = cap;
-  }
-}
-
-
-#ifdef ASSERT
-
-void MetaspaceArena::verify_locked(bool slow) const {
-
-  assert_lock_strong(lock());
-
-  assert(_growth_policy != NULL && _chunk_manager != NULL, "Sanity");
-
-  _chunks.verify();
-
-  if (_fbl != NULL) {
-    _fbl->verify();
-  }
-
-  // In slow mode, verify guard zones of all allocations
-  if (slow && Settings::use_allocation_guard()) {
-    for (const Metachunk* c = _chunks.first(); c != NULL; c = c->next()) {
-      const MetaWord* p = c->base();
-      while (p < c->top()) {
-        const prefix_t* pp = (const prefix_t*)p;
-        check_prefix(pp);
-        p += pp->word_size;
-      }
-    }
-  }
-
-}
-
-void MetaspaceArena::verify(bool slow) const {
-
-  MutexLocker cl(lock(), Mutex::_no_safepoint_check_flag);
-  verify_locked(slow);
-
-}
-
-// Returns true if the area indicated by pointer and size have actually been allocated
-// from this arena.
-bool MetaspaceArena::is_valid_area(MetaWord* p, size_t word_size) const {
-  assert(p != NULL && word_size > 0, "Sanity");
-  bool found = false;
-  if (!found) {
-    for (const Metachunk* c = _chunks.first(); c != NULL && !found; c = c->next()) {
-      assert(c->is_valid_committed_pointer(p) ==
-             c->is_valid_committed_pointer(p + word_size - 1), "range intersects");
-      found = c->is_valid_committed_pointer(p);
-    }
-  }
-  return found;
-}
-
-#endif // ASSERT
-
-void MetaspaceArena::print_on(outputStream* st) const {
-  MutexLocker fcl(_lock, Mutex::_no_safepoint_check_flag);
-  print_on_locked(st);
-}
-
-void MetaspaceArena::print_on_locked(outputStream* st) const {
-  assert_lock_strong(_lock);
-  st->print_cr("sm %s: %d chunks, total word size: " SIZE_FORMAT ", committed word size: " SIZE_FORMAT, _name,
-               _chunks.count(), _chunks.calc_word_size(), _chunks.calc_committed_word_size());
-  _chunks.print_on(st);
-  st->cr();
-  st->print_cr("growth-policy " PTR_FORMAT ", lock " PTR_FORMAT ", cm " PTR_FORMAT ", fbl " PTR_FORMAT,
-                p2i(_growth_policy), p2i(_lock), p2i(_chunk_manager), p2i(_fbl));
-}
-
-
-
-} // namespace metaspace
-
--- old/src/hotspot/share/memory/metaspace/metaspaceArena.hpp	2020-09-04 13:58:28.961616291 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,164 +0,0 @@
-/*
- * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#ifndef SHARE_MEMORY_METASPACE_METASPACEARENA_HPP
-#define SHARE_MEMORY_METASPACE_METASPACEARENA_HPP
-
-#include "memory/allocation.hpp"
-#include "memory/metaspace.hpp"
-#include "memory/metaspace/chunkManager.hpp"
-#include "memory/metaspace/metachunk.hpp"
-#include "memory/metaspace/metachunkList.hpp"
-#include "memory/metaspace/metaspaceCommon.hpp"
-
-
-class outputStream;
-class Mutex;
-
-namespace metaspace {
-
-
-class ArenaGrowthPolicy;
-class FreeBlocks;
-
-struct arena_stats_t;
-
-
-// The MetaspaceArena is a growable metaspace memory pool belonging to a CLD;
-//  internally it consists of a list of metaspace chunks, of which the head chunk
-//  is the current chunk from which we allocate via pointer bump.
-//
-// When the current chunk is used up, MetaspaceArena requestes a new chunk from
-//  the associated ChunkManager.
-//
-// MetaspaceArena also keeps a FreeBlocks structure to manage memory blocks which
-//  had been deallocated prematurely.
-//
-
-class MetaspaceArena : public CHeapObj<mtClass> {
-
-  // Reference to an outside lock to use for synchronizing access to this arena.
-  //  This lock is normally owned by the CLD which owns the ClassLoaderMetaspace which
-  //  owns this arena.
-  // Todo: This should be changed. Either the CLD should synchronize access to the
-  //       CLMS and its arenas itself, or the arena should have an own lock. The latter
-  //       would allow for more fine granular locking since it would allow access to
-  //       both class- and non-class arena in the CLMS independently.
-  Mutex* const _lock;
-
-  // Reference to the chunk manager to allocate chunks from.
-  ChunkManager* const _chunk_manager;
-
-  // Reference to the growth policy to use.
-  const ArenaGrowthPolicy* const _growth_policy;
-
-  // List of chunks. Head of the list is the current chunk.
-  MetachunkList _chunks;
-
-  // Structure to take care of leftover/deallocated space in used chunks.
-  // Owned by the Arena. Gets allocated on demand only.
-  FreeBlocks* _fbl;
-
-  Metachunk* current_chunk()              { return _chunks.first(); }
-  const Metachunk* current_chunk() const  { return _chunks.first(); }
-
-  // Reference to an outside counter to keep track of used space.
-  SizeAtomicCounter* const _total_used_words_counter;
-
-  // A name for purely debugging/logging purposes.
-  const char* const _name;
-
-  Mutex* lock() const                           { return _lock; }
-  ChunkManager* chunk_manager() const           { return _chunk_manager; }
-
-  // free block list
-  FreeBlocks* fbl() const                       { return _fbl; }
-  void add_allocation_to_fbl(MetaWord* p, size_t word_size);
-
-  // Given a chunk, add its remaining free committed space to the free block list.
-  void salvage_chunk(Metachunk* c);
-
-  // Allocate a new chunk from the underlying chunk manager able to hold at least
-  // requested word size.
-  Metachunk* allocate_new_chunk(size_t requested_word_size);
-
-  // Returns the level of the next chunk to be added, acc to growth policy.
-  chunklevel_t next_chunk_level() const;
-
-  // Attempt to enlarge the current chunk to make it large enough to hold at least
-  //  requested_word_size additional words.
-  //
-  // On success, true is returned, false otherwise.
-  bool attempt_enlarge_current_chunk(size_t requested_word_size);
-
-  // Prematurely returns a metaspace allocation to the _block_freelists
-  // because it is not needed anymore (requires CLD lock to be active).
-  void deallocate_locked(MetaWord* p, size_t word_size);
-
-  // Returns true if the area indicated by pointer and size have actually been allocated
-  // from this arena.
-  DEBUG_ONLY(bool is_valid_area(MetaWord* p, size_t word_size) const;)
-
-public:
-
-  MetaspaceArena(ChunkManager* chunk_manager,
-               const ArenaGrowthPolicy* growth_policy,
-               Mutex* lock,
-               SizeAtomicCounter* total_used_words_counter,
-               const char* name);
-
-  ~MetaspaceArena();
-
-  // Allocate memory from Metaspace.
-  // 1) Attempt to allocate from the dictionary of deallocated blocks.
-  // 2) Attempt to allocate from the current chunk.
-  // 3) Attempt to enlarge the current chunk in place if it is too small.
-  // 4) Attempt to get a new chunk and allocate from that chunk.
-  // At any point, if we hit a commit limit, we return NULL.
-  MetaWord* allocate(size_t word_size);
-
-  // Prematurely returns a metaspace allocation to the _block_freelists because it is not
-  // needed anymore.
-  void deallocate(MetaWord* p, size_t word_size);
-
-  // Update statistics. This walks all in-use chunks.
-  void add_to_statistics(arena_stats_t* out) const;
-
-  // Convenience method to get the most important usage statistics.
-  // For deeper analysis use add_to_statistics().
-  void usage_numbers(size_t* p_used_words, size_t* p_committed_words, size_t* p_capacity_words) const;
-
-  DEBUG_ONLY(void verify(bool slow) const;)
-  DEBUG_ONLY(void verify_locked(bool slow) const;)
-
-  void print_on(outputStream* st) const;
-  void print_on_locked(outputStream* st) const;
-
-};
-
-} // namespace metaspace
-
-#endif // SHARE_MEMORY_METASPACE_METASPACEARENA_HPP
-
--- old/src/hotspot/share/memory/metaspace/metaspaceCommon.cpp	2020-09-04 13:58:29.373619179 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,204 +0,0 @@
-/*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#include "precompiled.hpp"
-
-#include "memory/metaspace/allocationGuard.hpp"
-#include "memory/metaspace/freeBlocks.hpp"
-#include "memory/metaspace/metaspaceCommon.hpp"
-#include "memory/metaspace/virtualSpaceNode.hpp"
-
-#include "utilities/align.hpp"
-#include "utilities/debug.hpp"
-#include "utilities/globalDefinitions.hpp"
-#include "utilities/ostream.hpp"
-
-namespace metaspace {
-
-
-// Print a size, in words, scaled.
-void print_scaled_words(outputStream* st, size_t word_size, size_t scale, int width) {
-  print_human_readable_size(st, word_size * sizeof(MetaWord), scale, width);
-}
-
-// Convenience helper: prints a size value and a percentage.
-void print_scaled_words_and_percentage(outputStream* st, size_t word_size, size_t compare_word_size, size_t scale, int width) {
-  print_scaled_words(st, word_size, scale, width);
-  st->print(" (");
-  print_percentage(st, compare_word_size, word_size);
-  st->print(")");
-}
-
-static const char* display_unit_for_scale(size_t scale) {
-  const char* s = NULL;
-  switch(scale) {
-    case 1: s = "bytes"; break;
-    case BytesPerWord: s = "words"; break;
-    case K: s = "KB"; break;
-    case M: s = "MB"; break;
-    case G: s = "GB"; break;
-    default:
-      ShouldNotReachHere();
-  }
-  return s;
-}
-
-// Print a human readable size.
-// byte_size: size, in bytes, to be printed.
-// scale: one of 1 (byte-wise printing), sizeof(word) (word-size printing), K, M, G (scaled by KB, MB, GB respectively,
-//         or 0, which means the best scale is choosen dynamically.
-// width: printing width.
-void print_human_readable_size(outputStream* st, size_t byte_size, size_t scale, int width)  {
-  if (scale == 0) {
-    // Dynamic mode. Choose scale for this value.
-    if (byte_size == 0) {
-      // Zero values are printed as bytes.
-      scale = 1;
-    } else {
-      if (byte_size >= G) {
-        scale = G;
-      } else if (byte_size >= M) {
-        scale = M;
-      } else if (byte_size >= K) {
-        scale = K;
-      } else {
-        scale = 1;
-      }
-    }
-    return print_human_readable_size(st, byte_size, scale, width);
-  }
-
-#ifdef ASSERT
-  assert(scale == 1 || scale == BytesPerWord ||
-         scale == K || scale == M || scale == G, "Invalid scale");
-  // Special case: printing wordsize should only be done with word-sized values
-  if (scale == BytesPerWord) {
-    assert(byte_size % BytesPerWord == 0, "not word sized");
-  }
-#endif
-
-  if (width == -1) {
-    if (scale == 1) {
-      st->print(SIZE_FORMAT " bytes", byte_size);
-    } else if (scale == BytesPerWord) {
-      st->print(SIZE_FORMAT " words", byte_size / BytesPerWord);
-    } else {
-      const char* display_unit = display_unit_for_scale(scale);
-      float display_value = (float) byte_size / scale;
-      // Prevent very small but non-null values showing up as 0.00.
-      if (byte_size > 0 && display_value < 0.01f) {
-        st->print("<0.01 %s", display_unit);
-      } else {
-        st->print("%.2f %s", display_value, display_unit);
-      }
-    }
-  } else {
-    if (scale == 1) {
-      st->print("%*" PRIuPTR " bytes", width, byte_size);
-    } else if (scale == BytesPerWord) {
-      st->print("%*" PRIuPTR " words", width, byte_size / BytesPerWord);
-    } else {
-      const char* display_unit = display_unit_for_scale(scale);
-      float display_value = (float) byte_size / scale;
-      // Since we use width to display a number with two trailing digits, increase it a bit.
-      width += 3;
-      // Prevent very small but non-null values showing up as 0.00.
-      if (byte_size > 0 && display_value < 0.01f) {
-        st->print("%*s %s", width, "<0.01", display_unit);
-      } else {
-        st->print("%*.2f %s", width, display_value, display_unit);
-      }
-    }
-  }
-}
-
-// Prints a percentage value. Values smaller than 1% but not 0 are displayed as "<1%", values
-// larger than 99% but not 100% are displayed as ">100%".
-void print_percentage(outputStream* st, size_t total, size_t part) {
-  if (total == 0) {
-    st->print("  ?%%");
-  } else if (part == 0) {
-    st->print("  0%%");
-  } else if (part == total) {
-    st->print("100%%");
-  } else {
-    // Note: clearly print very-small-but-not-0% and very-large-but-not-100% percentages.
-    float p = ((float)part / total) * 100.0f;
-    if (p < 1.0f) {
-      st->print(" <1%%");
-    } else if (p > 99.0f){
-      st->print(">99%%");
-    } else {
-      st->print("%3.0f%%", p);
-    }
-  }
-}
-
-const char* loaders_plural(uintx num) {
-  return num == 1 ? "loader" : "loaders";
-}
-
-const char* classes_plural(uintx num) {
-  return num == 1 ? "class" : "classes";
-}
-
-void print_number_of_classes(outputStream* out, uintx classes, uintx classes_shared) {
-  out->print(UINTX_FORMAT " %s", classes, classes_plural(classes));
-  if (classes_shared > 0) {
-    out->print(" (" UINTX_FORMAT " shared)", classes_shared);
-  }
-}
-
-// Given a net allocation word size, return the raw word size we actually allocate.
-// Note: externally visible for gtests.
-//static
-size_t get_raw_word_size_for_requested_word_size(size_t word_size) {
-
-  size_t byte_size = word_size * BytesPerWord;
-
-  // Deallocated metablocks are kept in a binlist which limits their minimal
-  //  size to at least the size of a binlist item (2 words).
-  byte_size = MAX2(byte_size, FreeBlocks::minimal_word_size * BytesPerWord);
-
-  // Metaspace allocations are aligned to word size.
-  byte_size = align_up(byte_size, allocation_alignment_bytes);
-
-  // If we guard allocations, we need additional space for a prefix.
-#ifdef ASSERT
-  if (Settings::use_allocation_guard()) {
-    byte_size += align_up(prefix_size(), allocation_alignment_bytes);
-  }
-#endif
-
-  size_t raw_word_size = byte_size / BytesPerWord;
-
-  assert(raw_word_size * BytesPerWord == byte_size, "Sanity");
-
-  return raw_word_size;
-
-}
-
-} // namespace metaspace
-
--- old/src/hotspot/share/memory/metaspace/metaspaceCommon.hpp	2020-09-04 13:58:29.789622095 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,151 +0,0 @@
-/*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#ifndef SHARE_MEMORY_METASPACE_METASPACECOMMON_HPP
-#define SHARE_MEMORY_METASPACE_METASPACECOMMON_HPP
-
-#include "runtime/globals.hpp"
-#include "utilities/align.hpp"
-#include "utilities/debug.hpp"
-#include "utilities/globalDefinitions.hpp"
-
-class outputStream;
-
-namespace metaspace {
-
-
-// Metaspace allocation alignment:
-
-// 1) Metaspace allocations have to be aligned such that 64bit values are aligned
-//  correctly.
-//
-// 2) Klass* structures allocated from Metaspace have to be aligned to KlassAlignmentInBytes.
-//
-// At the moment LogKlassAlignmentInBytes is 3, so KlassAlignmentInBytes == 8,
-//  so (1) and (2) can both be fulfilled with an alignment of 8. Should we increase
-//  KlassAlignmentInBytes at any time this will increase the necessary alignment as well. In
-//  that case we may think about introducing a separate alignment just for the class space
-//  since that alignment would only be needed for Klass structures.
-
-static const size_t allocation_alignment_bytes = 8;
-STATIC_ASSERT(allocation_alignment_bytes == (size_t)KlassAlignmentInBytes);
-
-static const size_t allocation_alignment_words = allocation_alignment_bytes / BytesPerWord;
-
-// Returns the raw word size allocated for a given net allocation
-size_t get_raw_word_size_for_requested_word_size(size_t word_size);
-
-
-// Utility functions
-
-// Print a size, in words, scaled.
-void print_scaled_words(outputStream* st, size_t word_size, size_t scale = 0, int width = -1);
-
-// Convenience helper: prints a size value and a percentage.
-void print_scaled_words_and_percentage(outputStream* st, size_t word_size, size_t compare_word_size, size_t scale = 0, int width = -1);
-
-// Print a human readable size.
-// byte_size: size, in bytes, to be printed.
-// scale: one of 1 (byte-wise printing), sizeof(word) (word-size printing), K, M, G (scaled by KB, MB, GB respectively,
-//         or 0, which means the best scale is choosen dynamically.
-// width: printing width.
-void print_human_readable_size(outputStream* st, size_t byte_size, size_t scale = 0, int width = -1);
-
-// Prints a percentage value. Values smaller than 1% but not 0 are displayed as "<1%", values
-// larger than 99% but not 100% are displayed as ">100%".
-void print_percentage(outputStream* st, size_t total, size_t part);
-
-
-#ifdef ASSERT
-#define assert_is_aligned(value, alignment)                  \
-  assert(is_aligned((value), (alignment)),                   \
-         SIZE_FORMAT_HEX " is not aligned to "               \
-         SIZE_FORMAT_HEX, (size_t)(uintptr_t)value, (size_t)(alignment))
-#else
-#define assert_is_aligned(value, alignment)
-#endif
-
-
-// Pretty printing helpers
-const char* classes_plural(uintx num);
-const char* loaders_plural(uintx num);
-void print_number_of_classes(outputStream* out, uintx classes, uintx classes_shared);
-
-
-// Since Metaspace verifications are expensive, we want to do them at a reduced rate,
-// but not completely avoiding them.
-// For that we introduce the macros SOMETIMES() and ASSERT_SOMETIMES() which will
-// execute code or assert at intervals controlled via VerifyMetaspaceInterval.
-#ifdef ASSERT
-
-#define EVERY_NTH(n)          \
-{ static int counter_ = 0;    \
-  if (n > 0) {                \
-    counter_ ++;              \
-    if (counter_ > n) {       \
-      counter_ = 0;           \
-
-#define END_EVERY_NTH         } } }
-
-#define SOMETIMES(code) \
-    EVERY_NTH(VerifyMetaspaceInterval) \
-    { code } \
-    END_EVERY_NTH
-
-#define ASSERT_SOMETIMES(condition, ...) \
-    EVERY_NTH(VerifyMetaspaceInterval) \
-    assert( (condition), __VA_ARGS__); \
-    END_EVERY_NTH
-
-#else
-
-#define SOMETIMES(code)
-#define ASSERT_SOMETIMES(condition, ...)
-
-#endif // ASSERT
-
-///////// Logging //////////////
-
-// What we log at which levels:
-
-// "info" : metaspace failed allocation, commit failure, reserve failure, metaspace oom, metaspace gc threshold changed, Arena created, destroyed, metaspace purged
-
-// "debug" : "info" + vslist extended, memory committed/uncommitted, chunk created/split/merged/enlarged, chunk returned
-
-// "trace" : "debug" + every single allocation and deallocation, internals
-
-#define HAVE_UL
-
-#ifdef HAVE_UL
-#define UL(level, message)        log_##level(metaspace)(LOGFMT ": " message, LOGFMT_ARGS);
-#define UL2(level, message, ...)  log_##level(metaspace)(LOGFMT ": " message, LOGFMT_ARGS, __VA_ARGS__);
-#else
-#define UL(level, ...)
-#define UL2(level, ...)
-#endif
-
-} // namespace metaspace
-
-#endif // SHARE_MEMORY_METASPACE_METASPACECOMMON_HPP
--- old/src/hotspot/share/memory/metaspace/metaspaceContext.cpp	2020-09-04 13:58:30.209625040 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,89 +0,0 @@
-/*
- * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#include "precompiled.hpp"
-
-#include "memory/metaspace/chunkManager.hpp"
-#include "memory/metaspace/metaspaceContext.hpp"
-#include "memory/metaspace/virtualSpaceList.hpp"
-#include "utilities/debug.hpp"
-#include "utilities/globalDefinitions.hpp"
-#include "utilities/ostream.hpp"
-
-
-namespace metaspace {
-
-#define LOGFMT         "SpcMgr @" PTR_FORMAT " (%s)"
-#define LOGFMT_ARGS    p2i(this), this->_name
-
-
-MetaspaceContext* MetaspaceContext::_class_space_context = NULL;
-MetaspaceContext* MetaspaceContext::_nonclass_space_context = NULL;
-
-// Destroys the context: deletes chunkmanager and virtualspacelist.
-// If this is a non-expandable context over an existing space, that space remains
-// untouched, otherwise all memory is unmapped.
-MetaspaceContext::~MetaspaceContext() {
-  delete _cm;
-  delete _vslist;
-}
-
-// Create a new, empty, expandable metaspace context.
-MetaspaceContext* MetaspaceContext::create_expandable_context(const char* name, CommitLimiter* commit_limiter) {
-  VirtualSpaceList* vsl = new VirtualSpaceList(name, commit_limiter);
-  ChunkManager* cm = new ChunkManager(name, vsl);
-  return new MetaspaceContext(name, vsl, cm);
-}
-
-// Create a new, empty, non-expandable metaspace context atop of an externally provided space.
-MetaspaceContext* MetaspaceContext::create_nonexpandable_context(const char* name, ReservedSpace rs, CommitLimiter* commit_limiter) {
-  VirtualSpaceList* vsl = new VirtualSpaceList(name, rs, commit_limiter);
-  ChunkManager* cm = new ChunkManager(name, vsl);
-  return new MetaspaceContext(name, vsl, cm);
-}
-
-
-void MetaspaceContext::initialize_class_space_context(ReservedSpace rs) {
-  _class_space_context = create_nonexpandable_context("class-space", rs, CommitLimiter::globalLimiter());
-}
-
-void MetaspaceContext::initialize_nonclass_space_context() {
-  _nonclass_space_context = create_expandable_context("non-class-space", CommitLimiter::globalLimiter());
-}
-
-void MetaspaceContext::print_on(outputStream* st) const {
-  _vslist->print_on(st);
-  _cm->print_on(st);
-}
-
-#ifdef ASSERT
-void MetaspaceContext::verify(bool slow) const {
-  _vslist->verify(slow);
-  _cm->verify(slow);
-}
-#endif // ASSERT
-
-} // namespace metaspace
-
--- old/src/hotspot/share/memory/metaspace/metaspaceContext.hpp	2020-09-04 13:58:30.625627959 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,108 +0,0 @@
-/*
- * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#ifndef SHARE_MEMORY_METASPACE_METASPACECONTEXT_HPP
-#define SHARE_MEMORY_METASPACE_METASPACECONTEXT_HPP
-
-#include "memory/allocation.hpp"
-#include "memory/virtualspace.hpp"
-#include "utilities/debug.hpp"
-
-class outputStream;
-
-namespace metaspace {
-
-class ChunkManager;
-class VirtualSpaceList;
-class CommitLimiter;
-
-// MetaspaceContext is a convenience bracket around:
-//
-// - a VirtualSpaceList managing a memory area used for Metaspace
-// - a ChunkManager sitting atop of that which manages chunk freelists
-//
-// In a normal VM only one or two of these contexts ever exist: one for the metaspace, and
-//  optionally another one for the compressed class space.
-//
-// For tests more contexts may be created, and this would also be a way to use Metaspace
-//  for things other than class metadata. We would have to work on the naming then.
-//
-// - (Future TODO): Context should own a lock to guard it. Currently this stuff is guarded
-//     by one global lock, the slightly misnamed Metaspace_expandlock, but that one
-//     should be split into one per context.
-// - (Future TODO): Context can/should have its own allocation alignment. That way we
-//     can have different alignment between class space and non-class metaspace. That could
-//     help optimize compressed class pointer encoding, see discussion for JDK-8244943).
-
-class MetaspaceContext : public CHeapObj<mtMetaspace> {
-
-  const char* const _name;
-  VirtualSpaceList* const _vslist;
-  ChunkManager* const _cm;
-
-  MetaspaceContext(const char* name, VirtualSpaceList* vslist, ChunkManager* cm)
-    : _name(name), _vslist(vslist), _cm(cm) {}
-
-  static MetaspaceContext* _nonclass_space_context;
-  static MetaspaceContext* _class_space_context;
-
-public:
-
-  // Destroys the context: deletes chunkmanager and virtualspacelist.
-  // If this is a non-expandable context over an existing space, that space remains
-  // untouched, otherwise all memory is unmapped.
-  ~MetaspaceContext();
-
-  VirtualSpaceList* vslist() { return _vslist; }
-  ChunkManager* cm() { return _cm; }
-
-  // Create a new, empty, expandable metaspace context.
-  static MetaspaceContext* create_expandable_context(const char* name, CommitLimiter* commit_limiter);
-
-  // Create a new, empty, non-expandable metaspace context atop of an externally provided space.
-  static MetaspaceContext* create_nonexpandable_context(const char* name, ReservedSpace rs, CommitLimiter* commit_limiter);
-
-  void print_on(outputStream* st) const;
-
-  DEBUG_ONLY(void verify(bool slow) const;)
-
-  static void initialize_class_space_context(ReservedSpace rs);
-  static void initialize_nonclass_space_context();
-
-  // Returns pointer to the global metaspace context.
-  // If compressed class space is active, this contains the non-class-space allocations.
-  // If compressed class space is inactive, this contains all metaspace allocations.
-  static MetaspaceContext* context_nonclass()     { return _nonclass_space_context; }
-
-  // Returns pointer to the global class space context, if compressed class space is active,
-  // NULL otherwise.
-  static MetaspaceContext* context_class()        { return _class_space_context; }
-
-};
-
-} // end namespace
-
-#endif // SHARE_MEMORY_METASPACE_METASPACECONTEXT_HPP
-
--- old/src/hotspot/share/memory/metaspace/metaspaceDCmd.cpp	2020-09-04 13:58:31.033630821 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,102 +0,0 @@
-/*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#include "precompiled.hpp"
-#include "memory/metaspace/metaspaceReport.hpp"
-#include "memory/metaspace/metaspaceDCmd.hpp"
-#include "memory/resourceArea.hpp"
-#include "services/diagnosticCommand.hpp"
-#include "services/nmtCommon.hpp"
-
-namespace metaspace {
-
-MetaspaceDCmd::MetaspaceDCmd(outputStream* output, bool heap)
-  : DCmdWithParser(output, heap)
-  , _basic("basic", "Prints a basic summary (does not need a safepoint).", "BOOLEAN", false, "false")
-  , _show_loaders("show-loaders", "Shows usage by class loader.", "BOOLEAN", false, "false")
-  , _by_spacetype("by-spacetype", "Break down numbers by loader type.", "BOOLEAN", false, "false")
-  , _by_chunktype("by-chunktype", "Break down numbers by chunk type.", "BOOLEAN", false, "false")
-  , _show_vslist("vslist", "Shows details about the underlying virtual space.", "BOOLEAN", false, "false")
-  , _scale("scale", "Memory usage in which to scale. Valid values are: 1, KB, MB or GB (fixed scale) "
-           "or \"dynamic\" for a dynamically choosen scale.",
-           "STRING", false, "dynamic")
-  , _show_classes("show-classes", "If show-loaders is set, shows loaded classes for each loader.", "BOOLEAN", false, "false")
-{
-  _dcmdparser.add_dcmd_option(&_basic);
-  _dcmdparser.add_dcmd_option(&_show_loaders);
-  _dcmdparser.add_dcmd_option(&_show_classes);
-  _dcmdparser.add_dcmd_option(&_by_chunktype);
-  _dcmdparser.add_dcmd_option(&_by_spacetype);
-  _dcmdparser.add_dcmd_option(&_show_vslist);
-  _dcmdparser.add_dcmd_option(&_scale);
-}
-
-int MetaspaceDCmd::num_arguments() {
-  ResourceMark rm;
-  MetaspaceDCmd* dcmd = new MetaspaceDCmd(NULL, false);
-  if (dcmd != NULL) {
-    DCmdMark mark(dcmd);
-    return dcmd->_dcmdparser.num_arguments();
-  } else {
-    return 0;
-  }
-}
-
-void MetaspaceDCmd::execute(DCmdSource source, TRAPS) {
-  // Parse scale value.
-  const char* scale_value = _scale.value();
-  size_t scale = 0;
-  if (scale_value != NULL) {
-    if (strcasecmp("dynamic", scale_value) == 0) {
-      scale = 0;
-    } else {
-      scale = NMT_ONLY(NMTUtil::scale_from_name(scale_value)) NOT_NMT(0);
-      if (scale == 0) {
-        output()->print_cr("Invalid scale: \"%s\". Will use dynamic scaling.", scale_value);
-      }
-    }
-  }
-  if (_basic.value() == true) {
-    if (_show_loaders.value() || _by_chunktype.value() || _by_spacetype.value() ||
-        _show_vslist.value()) {
-      // Basic mode. Just print essentials. Does not need to be at a safepoint.
-      output()->print_cr("In basic mode, additional arguments are ignored.");
-    }
-    MetaspaceUtils::print_basic_report(output(), scale);
-  } else {
-    // Full mode. Requires safepoint.
-    int flags = 0;
-    if (_show_loaders.value())         flags |= MetaspaceReporter::rf_show_loaders;
-    if (_show_classes.value())         flags |= MetaspaceReporter::rf_show_classes;
-    if (_by_chunktype.value())         flags |= MetaspaceReporter::rf_break_down_by_chunktype;
-    if (_by_spacetype.value())         flags |= MetaspaceReporter::rf_break_down_by_spacetype;
-    if (_show_vslist.value())          flags |= MetaspaceReporter::rf_show_vslist;
-    VM_PrintMetadata op(output(), scale, flags);
-    VMThread::execute(&op);
-  }
-}
-
-} // namespace metaspace
-
--- old/src/hotspot/share/memory/metaspace/metaspaceDCmd.hpp	2020-09-04 13:58:31.441633686 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,65 +0,0 @@
-/*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#ifndef SHARE_MEMORY_METASPACE_METASPACEDCMD_HPP
-#define SHARE_MEMORY_METASPACE_METASPACEDCMD_HPP
-
-#include "services/diagnosticCommand.hpp"
-
-class outputStream;
-
-namespace metaspace {
-
-class MetaspaceDCmd : public DCmdWithParser {
-  DCmdArgument<bool> _basic;
-  DCmdArgument<bool> _show_loaders;
-  DCmdArgument<bool> _by_spacetype;
-  DCmdArgument<bool> _by_chunktype;
-  DCmdArgument<bool> _show_vslist;
-  DCmdArgument<char*> _scale;
-  DCmdArgument<bool> _show_classes;
-public:
-  MetaspaceDCmd(outputStream* output, bool heap);
-  static const char* name() {
-    return "VM.metaspace";
-  }
-  static const char* description() {
-    return "Prints the statistics for the metaspace";
-  }
-  static const char* impact() {
-      return "Medium: Depends on number of classes loaded.";
-  }
-  static const JavaPermission permission() {
-    JavaPermission p = {"java.lang.management.ManagementPermission",
-                        "monitor", NULL};
-    return p;
-  }
-  static int num_arguments();
-  virtual void execute(DCmdSource source, TRAPS);
-};
-
-} // namespace metaspace
-
-#endif // SHARE_MEMORY_METASPACE_METASPACEDCMD_HPP
--- old/src/hotspot/share/memory/metaspace/metaspaceEnums.cpp	2020-09-04 13:58:31.849636552 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,55 +0,0 @@
-/*
- * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#include "precompiled.hpp"
-#include "memory/metaspace/metaspaceEnums.hpp"
-#include "utilities/debug.hpp"
-
-namespace metaspace {
-
-const char* describe_spacetype(Metaspace::MetaspaceType st) {
-  const char* s = NULL;
-  switch (st) {
-    case Metaspace::StandardMetaspaceType: s = "Standard"; break;
-    case Metaspace::BootMetaspaceType: s = "Boot"; break;
-    case Metaspace::ClassMirrorHolderMetaspaceType: s = "ClassMirrorHolder"; break;
-    case Metaspace::ReflectionMetaspaceType: s = "Reflection"; break;
-    default: ShouldNotReachHere();
-  }
-  return s;
-}
-
-const char* describe_mdtype(Metaspace::MetadataType md) {
-  const char* s = NULL;
-  switch (md) {
-    case Metaspace::NonClassType: s = "nonclass"; break;
-    case Metaspace::ClassType: s = "class"; break;
-    default: ShouldNotReachHere();
-  }
-  return s;
-}
-
-} // namespace metaspace
-
--- old/src/hotspot/share/memory/metaspace/metaspaceEnums.hpp	2020-09-04 13:58:32.257639419 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,67 +0,0 @@
-/*
- * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#ifndef SHARE_MEMORY_METASPACEENUMS_HPP
-#define SHARE_MEMORY_METASPACEENUMS_HPP
-
-#include "memory/metaspace.hpp"
-#include "utilities/debug.hpp"
-
-
-namespace metaspace {
-
-// A bunch of convenience functions around MetadataType and MetaspaceType
-
-///////////////////////
-
-inline bool is_class(Metaspace::MetadataType md) { return md == Metaspace::ClassType; }
-
-const char* describe_mdtype(Metaspace::MetadataType md);
-
-#ifdef ASSERT
-inline bool is_valid_mdtype(Metaspace::MetadataType md) {
-  return (int)md >= 0 && (int)md < Metaspace::MetadataTypeCount;
-}
-inline void check_valid_mdtype(Metaspace::MetadataType md) {
-  assert(is_valid_mdtype(md), "Wrong value for MetadataType: %d", (int) md);
-}
-#endif // ASSERT
-
-///////////////////////
-
-const char* describe_spacetype(Metaspace::MetaspaceType st);
-
-#ifdef ASSERT
-inline bool is_valid_spacetype(Metaspace::MetaspaceType st) {
-  return (int)st >= 0 && (int)st < Metaspace::MetaspaceTypeCount;
-}
-inline void check_valid_spacetype(Metaspace::MetaspaceType st) {
-  assert(is_valid_spacetype(st), "Wrong value for MetaspaceType: %d", (int) st);
-}
-#endif
-
-} // namespace metaspace
-
-#endif // SHARE_MEMORY_METASPACEENUMS_HPP
--- old/src/hotspot/share/memory/metaspace/metaspaceReport.cpp	2020-09-04 13:58:32.665642287 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,379 +0,0 @@
-/*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#include "precompiled.hpp"
-#include "classfile/classLoaderData.hpp"
-#include "classfile/classLoaderDataGraph.hpp"
-#include "memory/metaspace/chunkHeaderPool.hpp"
-#include "memory/metaspace/chunkManager.hpp"
-#include "memory/metaspace/internStat.hpp"
-#include "memory/metaspace/metaspaceCommon.hpp"
-#include "memory/metaspace/metaspaceEnums.hpp"
-#include "memory/metaspace/metaspaceReport.hpp"
-#include "memory/metaspace/metaspaceStatistics.hpp"
-#include "memory/metaspace/printCLDMetaspaceInfoClosure.hpp"
-#include "memory/metaspace/runningCounters.hpp"
-#include "memory/metaspace/virtualSpaceList.hpp"
-#include "memory/metaspace.hpp"
-#include "runtime/os.hpp"
-
-namespace metaspace {
-
-static void print_vs(outputStream* out, size_t scale) {
-
-  const size_t reserved_nc = RunningCounters::reserved_words_nonclass();
-  const size_t committed_nc = RunningCounters::committed_words_nonclass();
-  const int num_nodes_nc = VirtualSpaceList::vslist_nonclass()->num_nodes();
-
-  if (Metaspace::using_class_space()) {
-
-    const size_t reserved_c = RunningCounters::reserved_words_class();
-    const size_t committed_c = RunningCounters::committed_words_class();
-    const int num_nodes_c = VirtualSpaceList::vslist_class()->num_nodes();
-
-    out->print("  Non-class space:  ");
-    print_scaled_words(out, reserved_nc, scale, 7);
-    out->print(" reserved, ");
-    print_scaled_words_and_percentage(out, committed_nc, reserved_nc, scale, 7);
-    out->print(" committed, ");
-    out->print(" %d nodes.", num_nodes_nc);
-    out->cr();
-    out->print("      Class space:  ");
-    print_scaled_words(out, reserved_c, scale, 7);
-    out->print(" reserved, ");
-    print_scaled_words_and_percentage(out, committed_c, reserved_c, scale, 7);
-    out->print(" committed, ");
-    out->print(" %d nodes.", num_nodes_c);
-    out->cr();
-    out->print("              Both:  ");
-    print_scaled_words(out, reserved_c + reserved_nc, scale, 7);
-    out->print(" reserved, ");
-    print_scaled_words_and_percentage(out, committed_c + committed_nc, reserved_c + reserved_nc, scale, 7);
-    out->print(" committed. ");
-    out->cr();
-
-  } else {
-    print_scaled_words(out, reserved_nc, scale, 7);
-    out->print(" reserved, ");
-    print_scaled_words_and_percentage(out, committed_nc, reserved_nc, scale, 7);
-    out->print(" committed, ");
-    out->print(" %d nodes.", num_nodes_nc);
-    out->cr();
-  }
-}
-
-static void print_settings(outputStream* out, size_t scale) {
-  out->print("MaxMetaspaceSize: ");
-  if (MaxMetaspaceSize >= (max_uintx) - (2 * os::vm_page_size())) {
-    // aka "very big". Default is max_uintx, but due to rounding in arg parsing the real
-    // value is smaller.
-    out->print("unlimited");
-  } else {
-    print_human_readable_size(out, MaxMetaspaceSize, scale);
-  }
-  out->cr();
-  if (Metaspace::using_class_space()) {
-    out->print("CompressedClassSpaceSize: ");
-    print_human_readable_size(out, CompressedClassSpaceSize, scale);
-  }
-  out->cr();
-  Settings::print_on(out);
-}
-
-// This will print out a basic metaspace usage report but
-// unlike print_report() is guaranteed not to lock or to walk the CLDG.
-void MetaspaceReporter::print_basic_report(outputStream* out, size_t scale) {
-
-  if (!Metaspace::initialized()) {
-    out->print_cr("Metaspace not yet initialized.");
-    return;
-  }
-
-  out->cr();
-  out->print_cr("Usage:");
-
-  if (Metaspace::using_class_space()) {
-    out->print("  Non-class:  ");
-  }
-
-  // Note: since we want to purely rely on counters, without any locking or walking the CLDG,
-  // for Usage stats (statistics over in-use chunks) all we can print is the
-  // used words. We cannot print committed areas, or free/waste areas, of in-use chunks require
-  // walking.
-  const size_t used_nc = MetaspaceUtils::used_words(Metaspace::NonClassType);
-
-  print_scaled_words(out, used_nc, scale, 5);
-  out->print(" used.");
-  out->cr();
-
-  if (Metaspace::using_class_space()) {
-    const size_t used_c = MetaspaceUtils::used_words(Metaspace::ClassType);
-    out->print("      Class:  ");
-    print_scaled_words(out, used_c, scale, 5);
-    out->print(" used.");
-    out->cr();
-
-    out->print("       Both:  ");
-    const size_t used = used_nc + used_c;
-    print_scaled_words(out, used, scale, 5);
-    out->print(" used.");
-    out->cr();
-  }
-
-  out->cr();
-  out->print_cr("Virtual space:");
-
-  print_vs(out, scale);
-
-  out->cr();
-  out->print_cr("Chunk freelists:");
-
-  if (Metaspace::using_class_space()) {
-    out->print("   Non-Class:  ");
-  }
-  print_scaled_words(out, ChunkManager::chunkmanager_nonclass()->total_word_size(), scale);
-  out->cr();
-  if (Metaspace::using_class_space()) {
-    out->print("       Class:  ");
-    print_scaled_words(out, ChunkManager::chunkmanager_class()->total_word_size(), scale);
-    out->cr();
-    out->print("        Both:  ");
-    print_scaled_words(out, ChunkManager::chunkmanager_nonclass()->total_word_size() +
-                            ChunkManager::chunkmanager_class()->total_word_size(), scale);
-    out->cr();
-  }
-
-  out->cr();
-
-  // Print basic settings
-  print_settings(out, scale);
-
-  out->cr();
-
-  out->cr();
-  out->print_cr("Internal statistics:");
-  out->cr();
-  InternalStats::print_on(out);
-  out->cr();
-
-}
-
-void MetaspaceReporter::print_report(outputStream* out, size_t scale, int flags) {
-
-  if (!Metaspace::initialized()) {
-    out->print_cr("Metaspace not yet initialized.");
-    return;
-  }
-
-  const bool print_loaders = (flags & rf_show_loaders) > 0;
-  const bool print_classes = (flags & rf_show_classes) > 0;
-  const bool print_by_chunktype = (flags & rf_break_down_by_chunktype) > 0;
-  const bool print_by_spacetype = (flags & rf_break_down_by_spacetype) > 0;
-
-  // Some report options require walking the class loader data graph.
-  metaspace::PrintCLDMetaspaceInfoClosure cl(out, scale, print_loaders, print_classes, print_by_chunktype);
-  if (print_loaders) {
-    out->cr();
-    out->print_cr("Usage per loader:");
-    out->cr();
-  }
-
-  ClassLoaderDataGraph::loaded_cld_do(&cl); // collect data and optionally print
-
-  // Print totals, broken up by space type.
-  if (print_by_spacetype) {
-    out->cr();
-    out->print_cr("Usage per space type:");
-    out->cr();
-    for (int space_type = (int)Metaspace::ZeroMetaspaceType;
-         space_type < (int)Metaspace::MetaspaceTypeCount; space_type ++)
-    {
-      uintx num_loaders = cl._num_loaders_by_spacetype[space_type];
-      uintx num_classes = cl._num_classes_by_spacetype[space_type];
-      out->print("%s - " UINTX_FORMAT " %s",
-        describe_spacetype((Metaspace::MetaspaceType)space_type),
-        num_loaders, loaders_plural(num_loaders));
-      if (num_classes > 0) {
-        out->print(", ");
-
-        print_number_of_classes(out, num_classes, cl._num_classes_shared_by_spacetype[space_type]);
-        out->print(":");
-        cl._stats_by_spacetype[space_type].print_on(out, scale, print_by_chunktype);
-      } else {
-        out->print(".");
-        out->cr();
-      }
-      out->cr();
-    }
-  }
-
-  // Print totals for in-use data:
-  out->cr();
-  {
-    uintx num_loaders = cl._num_loaders;
-    out->print("Total Usage - " UINTX_FORMAT " %s, ",
-      num_loaders, loaders_plural(num_loaders));
-    print_number_of_classes(out, cl._num_classes, cl._num_classes_shared);
-    out->print(":");
-    cl._stats_total.print_on(out, scale, print_by_chunktype);
-    out->cr();
-  }
-
-  /////////////////////////////////////////////////
-  // -- Print Virtual space.
-  out->cr();
-  out->print_cr("Virtual space:");
-
-  print_vs(out, scale);
-
-  // -- Print VirtualSpaceList details.
-  if ((flags & rf_show_vslist) > 0) {
-    out->cr();
-    out->print_cr("Virtual space list%s:", Metaspace::using_class_space() ? "s" : "");
-
-    if (Metaspace::using_class_space()) {
-      out->print_cr("   Non-Class:");
-    }
-    VirtualSpaceList::vslist_nonclass()->print_on(out);
-    out->cr();
-    if (Metaspace::using_class_space()) {
-      out->print_cr("       Class:");
-      VirtualSpaceList::vslist_class()->print_on(out);
-      out->cr();
-    }
-  }
-  out->cr();
-
-  //////////// Freelists (ChunkManager) section ///////////////////////////
-
-  out->cr();
-  out->print_cr("Chunk freelist%s:", Metaspace::using_class_space() ? "s" : "");
-
-  cm_stats_t non_class_cm_stat;
-  cm_stats_t class_cm_stat;
-  cm_stats_t total_cm_stat;
-
-  ChunkManager::chunkmanager_nonclass()->add_to_statistics(&non_class_cm_stat);
-  if (Metaspace::using_class_space()) {
-    ChunkManager::chunkmanager_nonclass()->add_to_statistics(&non_class_cm_stat);
-    ChunkManager::chunkmanager_class()->add_to_statistics(&class_cm_stat);
-    total_cm_stat.add(non_class_cm_stat);
-    total_cm_stat.add(class_cm_stat);
-
-    out->print_cr("   Non-Class:");
-    non_class_cm_stat.print_on(out, scale);
-    out->cr();
-    out->print_cr("       Class:");
-    class_cm_stat.print_on(out, scale);
-    out->cr();
-    out->print_cr("        Both:");
-    total_cm_stat.print_on(out, scale);
-    out->cr();
-  } else {
-    ChunkManager::chunkmanager_nonclass()->add_to_statistics(&non_class_cm_stat);
-    non_class_cm_stat.print_on(out, scale);
-    out->cr();
-  }
-
-  //////////// Waste section ///////////////////////////
-  // As a convenience, print a summary of common waste.
-  out->cr();
-  out->print("Waste (unused committed space):");
-  // For all wastages, print percentages from total. As total use the total size of memory committed for metaspace.
-  const size_t committed_words = RunningCounters::committed_words();
-
-  out->print("(percentages refer to total committed size ");
-  print_scaled_words(out, committed_words, scale);
-  out->print_cr("):");
-
-  // Print waste for in-use chunks.
-  in_use_chunk_stats_t ucs_nonclass = cl._stats_total.arena_stats_nonclass.totals();
-  in_use_chunk_stats_t ucs_class = cl._stats_total.arena_stats_class.totals();
-  const size_t waste_in_chunks_in_use = ucs_nonclass.waste_words + ucs_class.waste_words;
-  const size_t free_in_chunks_in_use = ucs_nonclass.free_words + ucs_class.free_words;
-
-  out->print("        Waste in chunks in use: ");
-  print_scaled_words_and_percentage(out, waste_in_chunks_in_use, committed_words, scale, 6);
-  out->cr();
-  out->print("        Free in chunks in use: ");
-  print_scaled_words_and_percentage(out, free_in_chunks_in_use, committed_words, scale, 6);
-  out->cr();
-
-  // Print waste in free chunks.
-  const size_t committed_in_free_chunks = total_cm_stat.total_committed_word_size();
-  out->print("                In free chunks: ");
-  print_scaled_words_and_percentage(out, committed_in_free_chunks, committed_words, scale, 6);
-  out->cr();
-
-  // Print waste in deallocated blocks.
-  const uintx free_blocks_num =
-      cl._stats_total.arena_stats_nonclass.free_blocks_num +
-      cl._stats_total.arena_stats_class.free_blocks_num;
-  const size_t free_blocks_cap_words =
-      cl._stats_total.arena_stats_nonclass.free_blocks_word_size +
-      cl._stats_total.arena_stats_class.free_blocks_word_size;
-  out->print("Deallocated from chunks in use: ");
-  print_scaled_words_and_percentage(out, free_blocks_cap_words, committed_words, scale, 6);
-  out->print(" (" UINTX_FORMAT " blocks)", free_blocks_num);
-  out->cr();
-
-  // Print total waste.
-  const size_t total_waste =
-      waste_in_chunks_in_use +
-      free_in_chunks_in_use +
-      committed_in_free_chunks +
-      free_blocks_cap_words;
-  out->print("                       -total-: ");
-  print_scaled_words_and_percentage(out, total_waste, committed_words, scale, 6);
-  out->cr();
-
-  // Also print chunk header pool size.
-  out->cr();
-  out->print("chunk header pool: %u items, ", ChunkHeaderPool::pool()->used());
-  print_scaled_words(out, ChunkHeaderPool::pool()->memory_footprint_words(), scale);
-  out->print(".");
-  out->cr();
-
-  // Print internal statistics
-  out->cr();
-  out->print_cr("Internal statistics:");
-  out->cr();
-  InternalStats::print_on(out);
-  out->cr();
-
-  // Print some interesting settings
-  out->cr();
-  out->print_cr("Settings:");
-  print_settings(out, scale);
-
-  out->cr();
-  out->cr();
-
-  DEBUG_ONLY(MetaspaceUtils::verify(true);)
-
-} // MetaspaceUtils::print_report()
-
-} // namespace metaspace
-
--- old/src/hotspot/share/memory/metaspace/metaspaceReport.hpp	2020-09-04 13:58:33.073645156 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,64 +0,0 @@
-/*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#ifndef SHARE_MEMORY_METASPACE_METASPACEREPORT_HPP
-#define SHARE_MEMORY_METASPACE_METASPACEREPORT_HPP
-
-#include "memory/allocation.hpp"
-
-namespace metaspace {
-
-class MetaspaceReporter : public AllStatic {
-public:
-
-  // Flags for print_report().
-  enum ReportFlag {
-    // Show usage by class loader.
-    rf_show_loaders                 = (1 << 0),
-    // Breaks report down by chunk type (small, medium, ...).
-    rf_break_down_by_chunktype      = (1 << 1),
-    // Breaks report down by space type (anonymous, reflection, ...).
-    rf_break_down_by_spacetype      = (1 << 2),
-    // Print details about the underlying virtual spaces.
-    rf_show_vslist                  = (1 << 3),
-    // If show_loaders: show loaded classes for each loader.
-    rf_show_classes                 = (1 << 4)
-  };
-
-  // This will print out a basic metaspace usage report but
-  // unlike print_report() is guaranteed not to lock or to walk the CLDG.
-  static void print_basic_report(outputStream* st, size_t scale);
-
-  // Prints a report about the current metaspace state.
-  // Optional parts can be enabled via flags.
-  // Function will walk the CLDG and will lock the expand lock; if that is not
-  // convenient, use print_basic_report() instead.
-  static void print_report(outputStream* out, size_t scale = 0, int flags = 0);
-
-};
-
-} // namespace metaspace
-
-#endif // SHARE_MEMORY_METASPACE_METASPACEREPORT_HPP
--- old/src/hotspot/share/memory/metaspace/metaspaceStatistics.cpp	2020-09-04 13:58:33.481648026 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,257 +0,0 @@
-/*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#include "precompiled.hpp"
-
-
-#include "memory/metaspace/chunkLevel.hpp"
-#include "memory/metaspace/metaspaceCommon.hpp"
-#include "memory/metaspace/metaspaceStatistics.hpp"
-
-#include "utilities/debug.hpp"
-#include "utilities/globalDefinitions.hpp"
-#include "utilities/ostream.hpp"
-
-namespace metaspace {
-
-
-// Returns total word size of all chunks in this manager.
-void cm_stats_t::add(const cm_stats_t& other) {
-  for (chunklevel_t l = chunklevel::LOWEST_CHUNK_LEVEL; l <= chunklevel::HIGHEST_CHUNK_LEVEL; l ++) {
-    num_chunks[l] += other.num_chunks[l];
-    committed_word_size[l] += other.committed_word_size[l];
-  }
-}
-
-// Returns total word size of all chunks in this manager.
-size_t cm_stats_t::total_word_size() const {
-  size_t s = 0;
-  for (chunklevel_t l = chunklevel::LOWEST_CHUNK_LEVEL; l <= chunklevel::HIGHEST_CHUNK_LEVEL; l ++) {
-    s += num_chunks[l] * chunklevel::word_size_for_level(l);
-  }
-  return s;
-}
-
-// Returns total committed word size of all chunks in this manager.
-size_t cm_stats_t::total_committed_word_size() const {
-  size_t s = 0;
-  for (chunklevel_t l = chunklevel::LOWEST_CHUNK_LEVEL; l <= chunklevel::HIGHEST_CHUNK_LEVEL; l ++) {
-    s += committed_word_size[l];
-  }
-  return s;
-}
-
-
-void cm_stats_t::print_on(outputStream* st, size_t scale) const {
-  // Note: used as part of MetaspaceReport so formatting matters.
-  size_t total_size = 0;
-  size_t total_committed_size = 0;
-  for (chunklevel_t l = chunklevel::LOWEST_CHUNK_LEVEL; l <= chunklevel::HIGHEST_CHUNK_LEVEL; l ++) {
-    st->cr();
-    chunklevel::print_chunk_size(st, l);
-    st->print(": ");
-    if (num_chunks[l] > 0) {
-      const size_t word_size = num_chunks[l] * chunklevel::word_size_for_level(l);
-
-      st->print("%4d, capacity=", num_chunks[l]);
-      print_scaled_words(st, word_size, scale);
-
-      st->print(", committed=");
-      print_scaled_words_and_percentage(st, committed_word_size[l], word_size, scale);
-
-      total_size += word_size;
-      total_committed_size += committed_word_size[l];
-    } else {
-      st->print("(none)");
-    }
-  }
-  st->cr();
-  st->print("Total word size: ");
-  print_scaled_words(st, total_size, scale);
-  st->print(", committed: ");
-  print_scaled_words_and_percentage(st, total_committed_size, total_size, scale);
-  st->cr();
-}
-
-#ifdef ASSERT
-void cm_stats_t::verify() const {
-  assert(total_committed_word_size() <= total_word_size(),
-         "Sanity");
-}
-#endif
-
-
-void in_use_chunk_stats_t::print_on(outputStream* st, size_t scale) const {
-  int col = st->position();
-  st->print("%4d chunk%s, ", num, num != 1 ? "s" : "");
-  if (num > 0) {
-    col += 14; st->fill_to(col);
-
-    print_scaled_words(st, word_size, scale, 5);
-    st->print(" capacity,");
-
-    col += 20; st->fill_to(col);
-    print_scaled_words_and_percentage(st, committed_words, word_size, scale, 5);
-    st->print(" committed, ");
-
-    col += 18; st->fill_to(col);
-    print_scaled_words_and_percentage(st, used_words, word_size, scale, 5);
-    st->print(" used, ");
-
-    col += 20; st->fill_to(col);
-    print_scaled_words_and_percentage(st, free_words, word_size, scale, 5);
-    st->print(" free, ");
-
-    col += 20; st->fill_to(col);
-    print_scaled_words_and_percentage(st, waste_words, word_size, scale, 5);
-    st->print(" waste ");
-
-  }
-}
-
-#ifdef ASSERT
-void in_use_chunk_stats_t::verify() const {
-  assert(word_size >= committed_words &&
-      committed_words == used_words + free_words + waste_words,
-         "Sanity: cap " SIZE_FORMAT ", committed " SIZE_FORMAT ", used " SIZE_FORMAT ", free " SIZE_FORMAT ", waste " SIZE_FORMAT ".",
-         word_size, committed_words, used_words, free_words, waste_words);
-}
-#endif
-
-void arena_stats_t::add(const arena_stats_t& other) {
-  for (chunklevel_t l = chunklevel::LOWEST_CHUNK_LEVEL; l <= chunklevel::HIGHEST_CHUNK_LEVEL; l ++) {
-    stats[l].add(other.stats[l]);
-  }
-  free_blocks_num += other.free_blocks_num;
-  free_blocks_word_size += other.free_blocks_word_size;
-}
-
-
-// Returns total chunk statistics over all chunk types.
-in_use_chunk_stats_t arena_stats_t::totals() const {
-  in_use_chunk_stats_t out;
-  for (chunklevel_t l = chunklevel::LOWEST_CHUNK_LEVEL; l <= chunklevel::HIGHEST_CHUNK_LEVEL; l ++) {
-    out.add(stats[l]);
-  }
-  return out;
-}
-
-void arena_stats_t::print_on(outputStream* st, size_t scale,  bool detailed) const {
-  streamIndentor sti(st);
-  if (detailed) {
-    st->cr_indent();
-    st->print("Usage by chunk level:");
-    {
-      streamIndentor sti2(st);
-      for (chunklevel_t l = chunklevel::LOWEST_CHUNK_LEVEL; l <= chunklevel::HIGHEST_CHUNK_LEVEL; l ++) {
-        st->cr_indent();
-        chunklevel::print_chunk_size(st, l);
-        st->print(" chunks: ");
-        if (stats[l].num == 0) {
-          st->print(" (none)");
-        } else {
-          stats[l].print_on(st, scale);
-        }
-      }
-
-      st->cr_indent();
-      st->print("%15s: ", "-total-");
-      totals().print_on(st, scale);
-    }
-    if (free_blocks_num > 0) {
-      st->cr_indent();
-      st->print("deallocated: " UINTX_FORMAT " blocks with ", free_blocks_num);
-      print_scaled_words(st, free_blocks_word_size, scale);
-    }
-  } else {
-    totals().print_on(st, scale);
-    st->print(", ");
-    st->print("deallocated: " UINTX_FORMAT " blocks with ", free_blocks_num);
-    print_scaled_words(st, free_blocks_word_size, scale);
-  }
-}
-
-#ifdef ASSERT
-
-void arena_stats_t::verify() const {
-  size_t total_used = 0;
-  for (chunklevel_t l = chunklevel::LOWEST_CHUNK_LEVEL; l <= chunklevel::HIGHEST_CHUNK_LEVEL; l ++) {
-    stats[l].verify();
-    total_used += stats[l].used_words;
-  }
-  // Deallocated allocations still count as used
-  assert(total_used >= free_blocks_word_size,
-         "Sanity");
-}
-#endif
-
-
-// Returns total arena statistics for both class and non-class metaspace
-arena_stats_t clms_stats_t::totals() const {
-  arena_stats_t out;
-  out.add(arena_stats_nonclass);
-  out.add(arena_stats_class);
-  return out;
-}
-
-void clms_stats_t::print_on(outputStream* st, size_t scale, bool detailed) const {
-  streamIndentor sti(st);
-  st->cr_indent();
-  if (Metaspace::using_class_space()) {
-    st->print("Non-Class: ");
-  }
-  arena_stats_nonclass.print_on(st, scale, detailed);
-  if (detailed) {
-    st->cr();
-  }
-  if (Metaspace::using_class_space()) {
-    st->cr_indent();
-    st->print("    Class: ");
-    arena_stats_class.print_on(st, scale, detailed);
-    if (detailed) {
-      st->cr();
-    }
-    st->cr_indent();
-    st->print("     Both: ");
-    totals().print_on(st, scale, detailed);
-    if (detailed) {
-      st->cr();
-    }
-  }
-  st->cr();
-}
-
-
-#ifdef ASSERT
-void clms_stats_t::verify() const {
-  arena_stats_nonclass.verify();
-  arena_stats_class.verify();
-}
-#endif
-
-} // end namespace metaspace
-
-
-
--- old/src/hotspot/share/memory/metaspace/metaspaceStatistics.hpp	2020-09-04 13:58:33.893650926 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,166 +0,0 @@
-/*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#ifndef SHARE_MEMORY_METASPACE_METASPACESTATISTICS_HPP
-#define SHARE_MEMORY_METASPACE_METASPACESTATISTICS_HPP
-
-#include "memory/metaspace.hpp"             // for MetadataType enum
-#include "memory/metaspace/chunkLevel.hpp"
-#include "utilities/globalDefinitions.hpp"
-
-class outputStream;
-
-namespace metaspace {
-
-// Contains a number of data output structures:
-//
-// - cm_stats_t
-// - clms_stats_t -> arena_stats_t -> in_use_chunk_stats_t
-//
-// used for the various XXXX::add_to_statistic() methods in MetaspaceArena, ClassLoaderMetaspace
-//  and ChunkManager, respectively.
-
-struct cm_stats_t {
-
-  // How many chunks per level are checked in.
-  int num_chunks[chunklevel::NUM_CHUNK_LEVELS];
-
-  // Size, in words, of the sum of all committed areas in this chunk manager, per level.
-  size_t committed_word_size[chunklevel::NUM_CHUNK_LEVELS];
-
-  cm_stats_t() : num_chunks(), committed_word_size() {}
-
-  void add(const cm_stats_t& other);
-
-  // Returns total word size of all chunks in this manager.
-  size_t total_word_size() const;
-
-  // Returns total committed word size of all chunks in this manager.
-  size_t total_committed_word_size() const;
-
-  void print_on(outputStream* st, size_t scale) const;
-
-  DEBUG_ONLY(void verify() const;)
-
-};
-
-// Contains statistics for one or multiple chunks in use.
-struct in_use_chunk_stats_t {
-
-  // Number of chunks
-  int num;
-
-  // Note:
-  // capacity = committed + uncommitted
-  //            committed = used + free + waste
-
-  // Capacity (total sum of all chunk sizes) in words.
-  // May contain committed and uncommitted space.
-  size_t word_size;
-
-  // Total committed area, in words.
-  size_t committed_words;
-
-  // Total used area, in words.
-  size_t used_words;
-
-  // Total free committed area, in words.
-  size_t free_words;
-
-  // Total waste committed area, in words.
-  size_t waste_words;
-
-  in_use_chunk_stats_t()
-    : num(0), word_size(0), committed_words(0),
-      used_words(0), free_words(0), waste_words(0)
-  {}
-
-  void add(const in_use_chunk_stats_t& other) {
-    num += other.num;
-    word_size += other.word_size;
-    committed_words += other.committed_words;
-    used_words += other.used_words;
-    free_words += other.free_words;
-    waste_words += other.waste_words;
-
-  }
-
-  void print_on(outputStream* st, size_t scale) const;
-
-  DEBUG_ONLY(void verify() const;)
-
-};
-
-// Class containing statistics for one or more MetaspaceArena objects.
-struct  arena_stats_t {
-
-  // chunk statistics by chunk level
-  in_use_chunk_stats_t stats[chunklevel::NUM_CHUNK_LEVELS];
-  uintx free_blocks_num;
-  size_t free_blocks_word_size;
-
-  arena_stats_t()
-    : stats(),
-      free_blocks_num(0),
-      free_blocks_word_size(0)
-  {}
-
-  void add(const arena_stats_t& other);
-
-  void print_on(outputStream* st, size_t scale = K,  bool detailed = true) const;
-
-  in_use_chunk_stats_t totals() const;
-
-  DEBUG_ONLY(void verify() const;)
-
-};
-
-// Statistics for one or multiple ClassLoaderMetaspace objects
-struct clms_stats_t {
-
-  arena_stats_t arena_stats_nonclass;
-  arena_stats_t arena_stats_class;
-
-  clms_stats_t() : arena_stats_nonclass(), arena_stats_class() {}
-
-  void add(const clms_stats_t& other) {
-    arena_stats_nonclass.add(other.arena_stats_nonclass);
-    arena_stats_class.add(other.arena_stats_class);
-  }
-
-  void print_on(outputStream* st, size_t scale, bool detailed) const;
-
-  // Returns total statistics for both class and non-class metaspace
-  arena_stats_t totals() const;
-
-
-  DEBUG_ONLY(void verify() const;)
-
-};
-
-} // namespace metaspace
-
-#endif // SHARE_MEMORY_METASPACE_METASPACESTATISTICS_HPP
-
--- old/src/hotspot/share/memory/metaspace/metaspace_test.cpp	2020-09-04 13:58:34.385654390 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,119 +0,0 @@
-/*
- * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#include "precompiled.hpp"
-
-#include "memory/virtualspace.hpp"
-#include "memory/metaspace/virtualSpaceList.hpp"
-#include "memory/metaspace/chunkManager.hpp"
-#include "memory/metaspace/arenaGrowthPolicy.hpp"
-#include "memory/metaspace/commitLimiter.hpp"
-#include "memory/metaspace/metaspace_test.hpp"
-#include "memory/metaspace/metaspaceArena.hpp"
-#include "memory/metaspace/metaspaceContext.hpp"
-#include "memory/metaspace/runningCounters.hpp"
-#include "runtime/mutexLocker.hpp"
-#include "utilities/debug.hpp"
-#include "utilities/ostream.hpp"
-#include "utilities/globalDefinitions.hpp"
-
-namespace metaspace {
-
-///// MetaspaceTestArena //////
-
-MetaspaceTestArena::MetaspaceTestArena(Mutex* lock, MetaspaceArena* arena)
-  : _lock(lock), _arena(arena) {}
-
-MetaspaceTestArena::~MetaspaceTestArena() {
-  delete _arena;
-  delete _lock;
-}
-
-MetaWord* MetaspaceTestArena::allocate(size_t word_size) {
-  return _arena->allocate(word_size);
-}
-
-void MetaspaceTestArena::deallocate(MetaWord* p, size_t word_size) {
-  return _arena->deallocate(p, word_size);
-}
-
-///// MetaspaceTestArea //////
-
-MetaspaceTestContext::MetaspaceTestContext(const char* name, size_t commit_limit, size_t reserve_limit)
-  : _name(name), _reserve_limit(reserve_limit), _commit_limit(commit_limit),
-    _context(NULL),
-    _commit_limiter(commit_limit == 0 ? max_uintx : commit_limit), // commit_limit == 0 -> no limit
-    _used_words_counter()
-{
-  assert(is_aligned(reserve_limit, Metaspace::reserve_alignment_words()), "reserve_limit (" SIZE_FORMAT ") "
-                    "not aligned to metaspace reserve alignment (" SIZE_FORMAT ")",
-                    reserve_limit, Metaspace::reserve_alignment_words());
-  if (reserve_limit > 0) {
-    // have reserve limit -> non-expandable context
-    ReservedSpace rs(reserve_limit * BytesPerWord, Metaspace::reserve_alignment(), false);
-    _context = MetaspaceContext::create_nonexpandable_context(name, rs, &_commit_limiter);
-  } else {
-    // no reserve limit -> expandable vslist
-    _context = MetaspaceContext::create_expandable_context(name, &_commit_limiter);
-  }
-
-}
-
-MetaspaceTestContext::~MetaspaceTestContext() {
-  DEBUG_ONLY(verify(true);)
-  MutexLocker fcl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
-  delete _context;
-}
-
-// Create an arena, feeding off this area.
-MetaspaceTestArena* MetaspaceTestContext::create_arena(Metaspace::MetaspaceType type) {
-  const ArenaGrowthPolicy* growth_policy = ArenaGrowthPolicy::policy_for_space_type(type, false);
-  Mutex* lock = new Mutex(Monitor::native, "MetaspaceTestArea-lock", false, Monitor::_safepoint_check_never);
-  MetaspaceArena* arena = NULL;
-  {
-    MutexLocker ml(lock,  Mutex::_no_safepoint_check_flag);
-    arena = new MetaspaceArena(_context->cm(), growth_policy, lock, &_used_words_counter, _name);
-  }
-  return new MetaspaceTestArena(lock, arena);
-}
-
-void MetaspaceTestContext::purge_area() {
-  _context->cm()->purge();
-}
-
-#ifdef ASSERT
-void MetaspaceTestContext::verify(bool slow) const {
-  if (_context != NULL) {
-    _context->verify(slow);
-  }
-}
-#endif
-
-void MetaspaceTestContext::print_on(outputStream* st) const {
-  _context->print_on(st);
-}
-
-} // namespace metaspace
-
--- old/src/hotspot/share/memory/metaspace/metaspace_test.hpp	2020-09-04 13:58:34.797657291 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,120 +0,0 @@
-/*
- * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#ifndef SHARE_MEMORY_METASPACE_METASPACE_TEST_HPP
-#define SHARE_MEMORY_METASPACE_METASPACE_TEST_HPP
-
-
-#include "memory/allocation.hpp"
-#include "memory/metaspace.hpp"
-#include "memory/metaspace/commitLimiter.hpp"
-#include "memory/metaspace/counter.hpp"
-#include "memory/metaspace/metaspaceContext.hpp"
-#include "memory/virtualspace.hpp"
-#include "utilities/globalDefinitions.hpp"
-
-// This is just convenience classes for metaspace-related tests
-//  (jtreg, via whitebox API, and gtests)
-
-class ReservedSpace;
-class Mutex;
-class outputStream;
-
-namespace metaspace {
-
-class MetaspaceContext;
-class MetaspaceArena;
-
-
-// Wraps a MetaspaceTestArena with its own lock for testing purposes.
-class MetaspaceTestArena : public CHeapObj<mtInternal> {
-
-  Mutex* const _lock;
-  MetaspaceArena* const _arena;
-
-public:
-
-  const MetaspaceArena* arena() const {
-    return _arena;
-  }
-
-  MetaspaceTestArena(Mutex* lock, MetaspaceArena* arena);
-  ~MetaspaceTestArena();
-
-  MetaWord* allocate(size_t word_size);
-  void deallocate(MetaWord* p, size_t word_size);
-
-};
-
-
-// Wraps an instance of a MetaspaceContext together with some side objects for easy use in test beds (whitebox, gtests)
-class MetaspaceTestContext : public CHeapObj<mtInternal> {
-
-  const char* const _name;
-  const size_t _reserve_limit;
-  const size_t _commit_limit;
-
-  MetaspaceContext* _context;
-  CommitLimiter _commit_limiter;
-  SizeAtomicCounter _used_words_counter;
-
-public:
-
-  // Note: limit == 0 means unlimited
-  // Reserve limit > 0 simulates a non-expandable VirtualSpaceList (like CompressedClassSpace)
-  // Commit limit > 0 simulates a limit to max commitable space (like MaxMetaspaceSize)
-  MetaspaceTestContext(const char* name, size_t commit_limit = 0, size_t reserve_limit = 0);
-  ~MetaspaceTestContext();
-
-  // Create an arena, feeding off this area.
-  MetaspaceTestArena* create_arena(Metaspace::MetaspaceType type);
-
-  void purge_area();
-
-  // Accessors
-  const CommitLimiter& commit_limiter() const { return _commit_limiter; }
-  const VirtualSpaceList& vslist() const      { return *(_context->vslist()); }
-  ChunkManager& cm()                          { return *(_context->cm()); }
-
-  // Returns reserve- and commit limit we run the test with (in the real world,
-  // these would be equivalent to CompressedClassSpaceSize resp MaxMetaspaceSize)
-  size_t reserve_limit() const    { return _reserve_limit == 0 ? max_uintx : 0; }
-  size_t commit_limit() const     { return _commit_limit == 0 ? max_uintx : 0; }
-
-  // Convenience function to retrieve total committed/used words
-  size_t used_words() const       { return _used_words_counter.get(); }
-  size_t committed_words() const  { return _commit_limiter.committed_words(); }
-
-  DEBUG_ONLY(void verify(bool slow = false) const;)
-
-  void print_on(outputStream* st) const;
-
-};
-
-
-} // namespace metaspace
-
-#endif // SHARE_MEMORY_METASPACE_METASPACE_TEST_HPP
-
--- old/src/hotspot/share/memory/metaspace/printCLDMetaspaceInfoClosure.cpp	2020-09-04 13:58:35.213660223 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,173 +0,0 @@
-/*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#include "precompiled.hpp"
-#include "classfile/classLoaderData.inline.hpp"
-#include "classfile/javaClasses.hpp"
-#include "memory/metaspace.hpp"
-#include "memory/metaspace/printCLDMetaspaceInfoClosure.hpp"
-#include "memory/metaspace/printMetaspaceInfoKlassClosure.hpp"
-#include "memory/metaspace/metaspaceCommon.hpp"
-#include "memory/resourceArea.hpp"
-#include "runtime/safepoint.hpp"
-#include "utilities/globalDefinitions.hpp"
-#include "utilities/ostream.hpp"
-
-
-namespace metaspace {
-
-PrintCLDMetaspaceInfoClosure::PrintCLDMetaspaceInfoClosure(outputStream* out, size_t scale, bool do_print,
-    bool do_print_classes, bool break_down_by_chunktype)
-: _out(out), _scale(scale), _do_print(do_print), _do_print_classes(do_print_classes)
-, _break_down_by_chunktype(break_down_by_chunktype)
-, _num_loaders(0), _num_loaders_without_metaspace(0), _num_loaders_unloading(0)
-,  _num_classes(0), _num_classes_shared(0)
-{
-  memset(_num_loaders_by_spacetype, 0, sizeof(_num_loaders_by_spacetype));
-  memset(_num_classes_by_spacetype, 0, sizeof(_num_classes_by_spacetype));
-  memset(_num_classes_shared_by_spacetype, 0, sizeof(_num_classes_shared_by_spacetype));
-}
-
-// A closure just to count classes
-class CountKlassClosure : public KlassClosure {
-public:
-
-  uintx _num_classes;
-  uintx _num_classes_shared;
-
-  CountKlassClosure() : _num_classes(0), _num_classes_shared(0) {}
-  void do_klass(Klass* k) {
-    _num_classes ++;
-    if (k->is_shared()) {
-      _num_classes_shared ++;
-    }
-  }
-
-}; // end: PrintKlassInfoClosure
-
-void PrintCLDMetaspaceInfoClosure::do_cld(ClassLoaderData* cld) {
-
-  assert(SafepointSynchronize::is_at_safepoint(), "Must be at a safepoint");
-
-  if (cld->is_unloading()) {
-    _num_loaders_unloading ++;
-    return;
-  }
-
-  ClassLoaderMetaspace* msp = cld->metaspace_or_null();
-  if (msp == NULL) {
-    _num_loaders_without_metaspace ++;
-    return;
-  }
-
-  // Collect statistics for this class loader metaspace
-  clms_stats_t this_cld_stat;
-  msp->add_to_statistics(&this_cld_stat);
-
-  // And add it to the running totals
-  _stats_total.add(this_cld_stat);
-  _num_loaders ++;
-  _stats_by_spacetype[msp->space_type()].add(this_cld_stat);
-  _num_loaders_by_spacetype[msp->space_type()] ++;
-
-  // Count classes loaded by this CLD.
-  CountKlassClosure ckc;
-  cld->classes_do(&ckc);
-  // accumulate.
-  _num_classes += ckc._num_classes;
-  _num_classes_by_spacetype[msp->space_type()] += ckc._num_classes;
-  _num_classes_shared += ckc._num_classes_shared;
-  _num_classes_shared_by_spacetype[msp->space_type()] += ckc._num_classes_shared;
-
-  // Optionally, print
-  if (_do_print) {
-
-    _out->print(UINTX_FORMAT_W(4) ": ", _num_loaders);
-
-    // Print "CLD for [<loader name>,] instance of <loader class name>"
-    // or    "CLD for <hidden or anonymous class>, loaded by [<loader name>,] instance of <loader class name>"
-
-    ResourceMark rm;
-    const char* name = NULL;
-    const char* class_name = NULL;
-
-    // Note: this should also work if unloading:
-    Klass* k = cld->class_loader_klass();
-    if (k != NULL) {
-      class_name = k->external_name();
-      Symbol* s = cld->name();
-      if (s != NULL) {
-        name = s->as_C_string();
-      }
-    } else {
-      name = "<bootstrap>";
-    }
-
-    // Print
-    _out->print("CLD " PTR_FORMAT, p2i(cld));
-    if (cld->is_unloading()) {
-      _out->print(" (unloading)");
-    }
-    _out->print(":");
-    if (cld->has_class_mirror_holder()) {
-      _out->print(" <hidden or anonymous class>, loaded by");
-    }
-    if (name != NULL) {
-      _out->print(" \"%s\"", name);
-    }
-    if (class_name != NULL) {
-      _out->print(" instance of %s", class_name);
-    }
-
-    if (_do_print_classes) {
-      // Print a detailed description of all loaded classes.
-      streamIndentor sti(_out, 6);
-      _out->cr_indent();
-      _out->print("Loaded classes");
-      if (ckc._num_classes_shared > 0) {
-        _out->print("('s' = shared)");
-      }
-      _out->print(":");
-      PrintMetaspaceInfoKlassClosure pkic(_out, true);
-      cld->classes_do(&pkic);
-      _out->cr_indent();
-      _out->print("-total-: ");
-      print_number_of_classes(_out, ckc._num_classes, ckc._num_classes_shared);
-    } else {
-      // Just print a summary about how many classes have been loaded.
-      _out->print(", ");
-      print_number_of_classes(_out, ckc._num_classes, ckc._num_classes_shared);
-    }
-
-    // Print statistics
-    this_cld_stat.print_on(_out, _scale, _break_down_by_chunktype);
-    _out->cr();
-
-  }
-
-}
-
-} // namespace metaspace
-
--- old/src/hotspot/share/memory/metaspace/printCLDMetaspaceInfoClosure.hpp	2020-09-04 13:58:35.633663183 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,70 +0,0 @@
-/*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#ifndef SHARE_MEMORY_METASPACE_PRINTCLDMETASPACEINFOCLOSURE_HPP
-#define SHARE_MEMORY_METASPACE_PRINTCLDMETASPACEINFOCLOSURE_HPP
-
-#include "memory/iterator.hpp"
-#include "memory/metaspace.hpp"
-#include "memory/metaspace/metaspaceStatistics.hpp"
-#include "memory/metaspace/metaspaceEnums.hpp"
-#include "utilities/globalDefinitions.hpp"
-
-class outputStream;
-
-namespace metaspace {
-
-class PrintCLDMetaspaceInfoClosure : public CLDClosure {
-private:
-  outputStream* const _out;
-  const size_t        _scale;
-  const bool          _do_print;
-  const bool          _do_print_classes;
-  const bool          _break_down_by_chunktype;
-
-public:
-
-  uintx                           _num_loaders;
-  uintx                           _num_loaders_without_metaspace;
-  uintx                           _num_loaders_unloading;
-  clms_stats_t                    _stats_total;
-
-  uintx                           _num_loaders_by_spacetype [Metaspace::MetaspaceTypeCount];
-  clms_stats_t                    _stats_by_spacetype [Metaspace::MetaspaceTypeCount];
-
-  uintx                           _num_classes_by_spacetype [Metaspace::MetaspaceTypeCount];
-  uintx                           _num_classes_shared_by_spacetype [Metaspace::MetaspaceTypeCount];
-  uintx                           _num_classes;
-  uintx                           _num_classes_shared;
-
-  PrintCLDMetaspaceInfoClosure(outputStream* out, size_t scale, bool do_print,
-      bool do_print_classes, bool break_down_by_chunktype);
-  void do_cld(ClassLoaderData* cld);
-
-};
-
-} // namespace metaspace
-
-#endif // SHARE_MEMORY_METASPACE_PRINTCLDMETASPACEINFOCLOSURE_HPP
--- old/src/hotspot/share/memory/metaspace/printMetaspaceInfoKlassClosure.cpp	2020-09-04 13:58:36.049666117 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,60 +0,0 @@
-/*
- * Copyright (c) 2018, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, SAP and/or its affiliates.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-#include "precompiled.hpp"
-
-#include "memory/metaspaceShared.hpp"
-#include "memory/metaspace/printMetaspaceInfoKlassClosure.hpp"
-#include "memory/resourceArea.hpp"
-#include "oops/reflectionAccessorImplKlassHelper.hpp"
-#include "utilities/globalDefinitions.hpp"
-#include "utilities/ostream.hpp"
-
-
-namespace metaspace {
-
-PrintMetaspaceInfoKlassClosure::PrintMetaspaceInfoKlassClosure(outputStream* out, bool do_print)
-: _out(out), _cnt(0)
-{}
-
-void PrintMetaspaceInfoKlassClosure::do_klass(Klass* k) {
-  _cnt ++;
-  _out->cr_indent();
-  _out->print(UINTX_FORMAT_W(4) ": ", _cnt);
-
-  // Print a 's' for shared classes
-  _out->put(k->is_shared() ? 's': ' ');
-
-  ResourceMark rm;
-  _out->print("  %s", k->external_name());
-
-  // Special treatment for generated core reflection accessor classes: print invocation target.
-  if (ReflectionAccessorImplKlassHelper::is_generated_accessor(k)) {
-    _out->print(" (invokes: ");
-    ReflectionAccessorImplKlassHelper::print_invocation_target(_out, k);
-    _out->print(")");
-  }
-}
-
-} // namespace metaspace
--- old/src/hotspot/share/memory/metaspace/printMetaspaceInfoKlassClosure.hpp	2020-09-04 13:58:36.461669023 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,54 +0,0 @@
-/*
- * Copyright (c) 2018, 2019, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, SAP and/or its affiliates.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#ifndef SHARE_MEMORY_METASPACE_PRINTMETASPACEINFOKLASSCLOSURE_HPP
-#define SHARE_MEMORY_METASPACE_PRINTMETASPACEINFOKLASSCLOSURE_HPP
-
-#include "memory/iterator.hpp"
-#include "utilities/globalDefinitions.hpp"
-
-class outputStream;
-class InstanceKlass;
-
-namespace metaspace {
-
-// Helper class for MetaspaceUtils::print_report()
-class PrintMetaspaceInfoKlassClosure : public KlassClosure {
-private:
-  outputStream* const _out;
-  uintx _cnt;
-
-  bool print_reflection_invocation_target(outputStream* out, InstanceKlass* magic_accessor_impl_class);
-
-public:
-
-  PrintMetaspaceInfoKlassClosure(outputStream* out, bool do_print);
-  void do_klass(Klass* k);
-
-}; // end: PrintKlassInfoClosure
-
-} // namespace metaspace
-
-#endif // SHARE_MEMORY_METASPACE_PRINTMETASPACEINFOKLASSCLOSURE_HPP
--- old/src/hotspot/share/memory/metaspace/rootChunkArea.cpp	2020-09-04 13:58:36.869671903 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,565 +0,0 @@
-/*
- * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#include "precompiled.hpp"
-
-#include "logging/log.hpp"
-#include "memory/allocation.hpp"
-#include "memory/metaspace/chunkHeaderPool.hpp"
-#include "memory/metaspace/chunkManager.hpp"
-#include "memory/metaspace/freeChunkList.hpp"
-#include "memory/metaspace/metachunk.hpp"
-#include "memory/metaspace/metaspaceCommon.hpp"
-#include "memory/metaspace/rootChunkArea.hpp"
-#include "runtime/mutexLocker.hpp"
-#include "utilities/debug.hpp"
-#include "utilities/globalDefinitions.hpp"
-
-namespace metaspace {
-
-RootChunkArea::RootChunkArea(const MetaWord* base)
-  : _base(base), _first_chunk(NULL)
-{}
-
-RootChunkArea::~RootChunkArea() {
-  // This is called when a VirtualSpaceNode is destructed (purged).
-  // All chunks should be free of course. In fact, there should only
-  // be one chunk, since all free chunks should have been merged.
-  if (_first_chunk != NULL) {
-    assert(_first_chunk->is_root_chunk() && _first_chunk->is_free(),
-           "Cannot delete root chunk area if not all chunks are free.");
-    ChunkHeaderPool::pool()->return_chunk_header(_first_chunk);
-  }
-}
-
-// Initialize: allocate a root node and a root chunk header; return the
-// root chunk header. It will be partly initialized.
-// Note: this just allocates a memory-less header; memory itself is allocated inside VirtualSpaceNode.
-Metachunk* RootChunkArea::alloc_root_chunk_header(VirtualSpaceNode* node) {
-
-  assert(_first_chunk == 0, "already have a root");
-
-  Metachunk* c = ChunkHeaderPool::pool()->allocate_chunk_header();
-  c->initialize(node, const_cast<MetaWord*>(_base), chunklevel::ROOT_CHUNK_LEVEL);
-
-  _first_chunk = c;
-
-  return c;
-
-}
-
-// Given a chunk c, split it recursively until you get a chunk of the given target_level.
-//
-// The resulting target chunk resides at the same address as the original chunk.
-// The resulting splinters are added to freelists.
-//
-// Returns pointer to the result chunk; the splitted-off chunks are added as
-//  free chunks to the freelists.
-void RootChunkArea::split(chunklevel_t target_level, Metachunk* c, FreeChunkListVector* freelists) {
-
-  // Splitting a chunk once works like this:
-  //
-  // For a given chunk we want to split:
-  // - increase the chunk level (which halves its size)
-  // - (but leave base address as it is since it will be the leader of the newly
-  //    created chunk pair)
-  // - then create a new chunk header of the same level, set its memory range
-  //   to cover the second halfof the old chunk.
-  // - wire them up (prev_in_vs/next_in_vs)
-  // - return the follower chunk as "splinter chunk" in the splinters array.
-
-  // Doing this multiple times will create a new free splinter chunk for every
-  // level we split:
-  //
-  // A  <- original chunk
-  //
-  // B B  <- split into two halves
-  //
-  // C C B  <- first half split again
-  //
-  // D D C B  <- first half split again ...
-  //
-
-  // As an optimization, since we usually do not split once but multiple times,
-  // to not do each split separately, since we would have to wire up prev_in_vs/next_in_vs
-  // on every level just to tear it open in the next level when we reintroduce a new
-  // half chunk splinter.
-  // Instead, just split split split and delay building up the double linked list of the
-  // new chunks at the end of all splits.
-
-  DEBUG_ONLY(check_pointer(c->base());)
-  DEBUG_ONLY(c->verify(false);)
-  assert(c->is_free(), "Can only split free chunks.");
-
-  DEBUG_ONLY(chunklevel::check_valid_level(target_level));
-  assert(target_level > c->level(), "Wrong target level");
-
-  const chunklevel_t starting_level = c->level();
-
-  while (c->level() < target_level) {
-
-    log_trace(metaspace)("Splitting chunk: " METACHUNK_FULL_FORMAT ".", METACHUNK_FULL_FORMAT_ARGS(c));
-
-    c->inc_level();
-    Metachunk* splinter_chunk = ChunkHeaderPool::pool()->allocate_chunk_header();
-    splinter_chunk->initialize(c->vsnode(), c->end(), c->level());
-
-    // Fix committed words info: If over the half of the original chunk was
-    // committed, committed area spills over into the follower chunk.
-    const size_t old_committed_words = c->committed_words();
-    if (old_committed_words > c->word_size()) {
-      c->set_committed_words(c->word_size());
-      splinter_chunk->set_committed_words(old_committed_words - c->word_size());
-    } else {
-      splinter_chunk->set_committed_words(0);
-    }
-
-    // Insert splinter chunk into vs list
-    if (c->next_in_vs() != NULL) {
-      c->next_in_vs()->set_prev_in_vs(splinter_chunk);
-    }
-    splinter_chunk->set_next_in_vs(c->next_in_vs());
-    splinter_chunk->set_prev_in_vs(c);
-    c->set_next_in_vs(splinter_chunk);
-
-    log_trace(metaspace)(".. Result chunk: " METACHUNK_FULL_FORMAT ".", METACHUNK_FULL_FORMAT_ARGS(c));
-    log_trace(metaspace)(".. Splinter chunk: " METACHUNK_FULL_FORMAT ".", METACHUNK_FULL_FORMAT_ARGS(splinter_chunk));
-
-    // Add splinter to free lists
-    freelists->add(splinter_chunk);
-
-  }
-
-  assert(c->level() == target_level, "Sanity");
-
-  DEBUG_ONLY(verify(true);)
-  DEBUG_ONLY(c->verify(true);)
-
-}
-
-
-// Given a chunk, attempt to merge it recursively with its neighboring chunks.
-//
-// If successful (merged at least once), returns address of
-// the merged chunk; NULL otherwise.
-//
-// The merged chunks are removed from the freelists.
-//
-// !!! Please note that if this method returns a non-NULL value, the
-// original chunk will be invalid and should not be accessed anymore! !!!
-Metachunk* RootChunkArea::merge(Metachunk* c, FreeChunkListVector* freelists) {
-
-  // Note rules:
-  //
-  // - a chunk always has a buddy, unless it is a root chunk.
-  // - In that buddy pair, a chunk is either leader or follower.
-  // - a chunk's base address is always aligned at its size.
-  // - if chunk is leader, its base address is also aligned to the size of the next
-  //   lower level, at least. A follower chunk is not.
-
-  // How we merge once:
-  //
-  // For a given chunk c, which has to be free and non-root, we do:
-  // - find out if we are the leader or the follower chunk
-  // - if we are leader, next_in_vs must be the follower; if we are follower,
-  //   prev_in_vs must be the leader. Now we have the buddy chunk.
-  // - However, if the buddy chunk itself is split (of a level higher than us)
-  //   we cannot merge.
-  // - we can only merge if the buddy is of the same level as we are and it is
-  //   free.
-  // - Then we merge by simply removing the follower chunk from the address range
-  //   linked list (returning the now useless header to the pool) and decreasing
-  //   the leader chunk level by one. That makes it double the size.
-
-  // Example:
-  // (lower case chunks are free, the * indicates the chunk we want to merge):
-  //
-  // ........................
-  // d d*c   b       A           <- we return the second (d*) chunk...
-  //
-  // c*  c   b       A           <- we merge it with its predecessor and decrease its level...
-  //
-  // b*      b       A           <- we merge it again, since its new neighbor was free too...
-  //
-  // a*              A           <- we merge it again, since its new neighbor was free too...
-  //
-  // And we are done, since its new neighbor, (A), is not free. We would also be done
-  // if the new neighbor itself is splintered.
-
-  DEBUG_ONLY(check_pointer(c->base());)
-  assert(!c->is_root_chunk(), "Cannot be merged further.");
-  assert(c->is_free(), "Can only merge free chunks.");
-
-  DEBUG_ONLY(c->verify(false);)
-
-  log_trace(metaspace)("Attempting to merge chunk " METACHUNK_FORMAT ".", METACHUNK_FORMAT_ARGS(c));
-
-  const chunklevel_t starting_level = c->level();
-
-  bool stop = false;
-  Metachunk* result = NULL;
-
-  do {
-
-    // First find out if this chunk is the leader of its pair
-    const bool is_leader = c->is_leader();
-
-    // Note: this is either our buddy or a splinter of the buddy.
-    Metachunk* const buddy = c->is_leader() ? c->next_in_vs() : c->prev_in_vs();
-    DEBUG_ONLY(buddy->verify(true);)
-
-    // A buddy chunk must be of the same or higher level (so, same size or smaller)
-    // never be larger.
-    assert(buddy->level() >= c->level(), "Sanity");
-
-    // Is this really my buddy (same level) or a splinter of it (higher level)?
-    // Also, is it free?
-    if (buddy->level() != c->level() || buddy->is_free() == false) {
-
-      log_trace(metaspace)("cannot merge with chunk " METACHUNK_FORMAT ".", METACHUNK_FORMAT_ARGS(buddy));
-
-      stop = true;
-
-    } else {
-
-      log_trace(metaspace)("will merge with chunk " METACHUNK_FORMAT ".", METACHUNK_FORMAT_ARGS(buddy));
-
-      // We can merge with the buddy.
-
-      // First, remove buddy from the chunk manager.
-      assert(buddy->is_free(), "Sanity");
-      freelists->remove(buddy);
-
-      // Determine current leader and follower
-      Metachunk* leader;
-      Metachunk* follower;
-      if (is_leader) {
-        leader = c; follower = buddy;
-      } else {
-        leader = buddy; follower = c;
-      }
-
-      // Last checkpoint
-      assert(leader->end() == follower->base() &&
-             leader->level() == follower->level() &&
-             leader->is_free() && follower->is_free(), "Sanity");
-
-      // The new merged chunk is as far committed as possible (if leader
-      // chunk is fully committed, as far as the follower chunk).
-      size_t merged_committed_words = leader->committed_words();
-      if (merged_committed_words == leader->word_size()) {
-        merged_committed_words += follower->committed_words();
-      }
-
-      // Leader survives, follower chunk is freed. Remove follower from vslist ..
-      leader->set_next_in_vs(follower->next_in_vs());
-      if (follower->next_in_vs() != NULL) {
-        follower->next_in_vs()->set_prev_in_vs(leader);
-      }
-
-      // .. and return follower chunk header to pool for reuse.
-      ChunkHeaderPool::pool()->return_chunk_header(follower);
-
-      // Leader level gets decreased (leader chunk doubles in size) but
-      // base address stays the same.
-      leader->dec_level();
-
-      // set commit boundary
-      leader->set_committed_words(merged_committed_words);
-
-      // If the leader is now of root chunk size, stop merging
-      if (leader->is_root_chunk()) {
-        stop = true;
-      }
-
-      result = c = leader;
-
-      DEBUG_ONLY(leader->verify(true);)
-
-    }
-
-  } while (!stop);
-
-#ifdef ASSERT
-  verify(true);
-  if (result != NULL) {
-    result->verify(true);
-  }
-#endif // ASSERT
-
-  return result;
-
-}
-
-// Given a chunk c, which must be "in use" and must not be a root chunk, attempt to
-// enlarge it in place by claiming its trailing buddy.
-//
-// This will only work if c is the leader of the buddy pair and the trailing buddy is free.
-//
-// If successful, the follower chunk will be removed from the freelists, the leader chunk c will
-// double in size (level decreased by one).
-//
-// On success, true is returned, false otherwise.
-bool RootChunkArea::attempt_enlarge_chunk(Metachunk* c, FreeChunkListVector* freelists) {
-
-  DEBUG_ONLY(check_pointer(c->base());)
-  assert(!c->is_root_chunk(), "Cannot be merged further.");
-
-  // There is no real reason for this limitation other than it is not
-  // needed on free chunks since they should be merged already:
-  assert(c->is_in_use(), "Can only enlarge in use chunks.");
-
-  DEBUG_ONLY(c->verify(false);)
-
-  if (!c->is_leader()) {
-    return false;
-  }
-
-  // We are the leader, so the buddy must follow us.
-  Metachunk* const buddy = c->next_in_vs();
-  DEBUG_ONLY(buddy->verify(true);)
-
-  // Of course buddy cannot be larger than us.
-  assert(buddy->level() >= c->level(), "Sanity");
-
-  // We cannot merge buddy in if it is not free...
-  if (!buddy->is_free()) {
-    return false;
-  }
-
-  // ... nor if it is splintered.
-  if (buddy->level() != c->level()) {
-    return false;
-  }
-
-  // Okay, lets enlarge c.
-
-  log_trace(metaspace)("Enlarging chunk " METACHUNK_FULL_FORMAT " by merging in follower " METACHUNK_FULL_FORMAT ".",
-                       METACHUNK_FULL_FORMAT_ARGS(c), METACHUNK_FULL_FORMAT_ARGS(buddy));
-
-  // the enlarged c is as far committed as possible:
-  size_t merged_committed_words = c->committed_words();
-  if (merged_committed_words == c->word_size()) {
-    merged_committed_words += buddy->committed_words();
-  }
-
-  // Remove buddy from vs list...
-  Metachunk* successor = buddy->next_in_vs();
-  if (successor != NULL) {
-    successor->set_prev_in_vs(c);
-  }
-  c->set_next_in_vs(successor);
-
-  // .. and from freelist ...
-  freelists->remove(buddy);
-
-  // .. and return its empty husk to the pool...
-  ChunkHeaderPool::pool()->return_chunk_header(buddy);
-
-  // Then decrease level of c.
-  c->dec_level();
-
-  // and correct committed words if needed.
-  c->set_committed_words(merged_committed_words);
-
-  log_debug(metaspace)("Enlarged chunk " METACHUNK_FULL_FORMAT ".", METACHUNK_FULL_FORMAT_ARGS(c));
-//  log_debug(metaspace)("Enlarged chunk " METACHUNK_FORMAT ".", METACHUNK_FORMAT_ARGS(c));
-
-  DEBUG_ONLY(verify(true));
-
-  return true;
-
-}
-
-// Returns true if this root chunk area is completely free:
-//  In that case, it should only contain one chunk (maximally merged, so a root chunk)
-//  and it should be free.
-bool RootChunkArea::is_free() const {
-  return _first_chunk == NULL ||
-      (_first_chunk->is_root_chunk() && _first_chunk->is_free());
-}
-
-
-#ifdef ASSERT
-
-#define assrt_(cond, ...) \
-  if (!(cond)) { \
-    fdStream errst(2); \
-    this->print_on(&errst); \
-    vmassert(cond, __VA_ARGS__); \
-  }
-
-void RootChunkArea::verify(bool slow) const {
-
-
-  assert_lock_strong(MetaspaceExpand_lock);
-  assert_is_aligned(_base, chunklevel::MAX_CHUNK_BYTE_SIZE);
-
-  // Iterate thru all chunks in this area. They must be ordered correctly,
-  // being adjacent to each other, and cover the complete area
-  int num_chunk = 0;
-
-  if (_first_chunk != NULL) {
-
-    assrt_(_first_chunk->prev_in_vs() == NULL, "Sanity");
-
-    const Metachunk* c = _first_chunk;
-    const MetaWord* expected_next_base = _base;
-    const MetaWord* const area_end = _base + word_size();
-
-    while (c != NULL) {
-
-      assrt_(c->is_free() || c->is_in_use(),
-          "Chunk No. %d " METACHUNK_FORMAT " - invalid state.",
-          num_chunk, METACHUNK_FORMAT_ARGS(c));
-
-      assrt_(c->base() == expected_next_base,
-             "Chunk No. %d " METACHUNK_FORMAT " - unexpected base.",
-             num_chunk, METACHUNK_FORMAT_ARGS(c));
-
-      assrt_(c->base() >= base() && c->end() <= end(),
-             "chunk %d " METACHUNK_FORMAT " oob for this root area [" PTR_FORMAT ".." PTR_FORMAT ").",
-             num_chunk, METACHUNK_FORMAT_ARGS(c), p2i(base()), p2i(end()));
-
-      assrt_(is_aligned(c->base(), c->word_size()),
-             "misaligned chunk %d " METACHUNK_FORMAT ".", num_chunk, METACHUNK_FORMAT_ARGS(c));
-
-      c->verify_neighborhood();
-      c->verify(slow);
-
-      expected_next_base = c->end();
-      num_chunk ++;
-
-      c = c->next_in_vs();
-
-    }
-    assrt_(expected_next_base == _base + word_size(), "Sanity");
-  }
-
-}
-
-void RootChunkArea::verify_area_is_ideally_merged() const {
-
-  SOMETIMES(assert_lock_strong(MetaspaceExpand_lock);)
-
-  int num_chunk = 0;
-  for (const Metachunk* c = _first_chunk; c != NULL; c = c->next_in_vs()) {
-    if (!c->is_root_chunk() && c->is_free()) {
-      // If a chunk is free, it must not have a buddy which is also free, because
-      // those chunks should have been merged.
-      // In other words, a buddy shall be either in-use or splintered
-      // (which in turn would mean part of it are in use).
-      Metachunk* const buddy = c->is_leader() ? c->next_in_vs() : c->prev_in_vs();
-      assrt_(buddy->is_in_use() || buddy->level() > c->level(),
-             "Chunk No. %d " METACHUNK_FORMAT " : missed merge opportunity with neighbor " METACHUNK_FORMAT ".",
-             num_chunk, METACHUNK_FORMAT_ARGS(c), METACHUNK_FORMAT_ARGS(buddy));
-    }
-    num_chunk ++;
-  }
-}
-
-#endif
-
-void RootChunkArea::print_on(outputStream* st) const {
-
-  st->print(PTR_FORMAT ": ", p2i(base()));
-  if (_first_chunk != NULL) {
-    const Metachunk* c = _first_chunk;
-    //                                    01234567890123
-    const char* letters_for_levels_cap = "ABCDEFGHIJKLMNOPQRSTUVWXYZ";
-    const char* letters_for_levels =     "abcdefghijklmnopqrstuvwxyz";
-    while (c != NULL) {
-      const chunklevel_t l = c->level();
-      if (l >= 0 && (size_t)l < strlen(letters_for_levels)) {
-//        c->print_on(st); st->cr();
-        st->print("%c", c->is_free() ? letters_for_levels[c->level()] : letters_for_levels_cap[c->level()]);
-      } else {
-        // Obviously garbage, but lets not crash.
-        st->print("?");
-      }
-      c = c->next_in_vs();
-    }
-  } else {
-    st->print(" (no chunks)");
-  }
-  st->cr();
-
-}
-
-
-// Create an array of ChunkTree objects, all initialized to NULL, covering
-// a given memory range. Memory range must be a multiple of root chunk size.
-RootChunkAreaLUT::RootChunkAreaLUT(const MetaWord* base, size_t word_size)
-  : _base(base),
-    _num((int)(word_size / chunklevel::MAX_CHUNK_WORD_SIZE)),
-    _arr(NULL)
-{
-  assert_is_aligned(word_size, chunklevel::MAX_CHUNK_WORD_SIZE);
-  _arr = NEW_C_HEAP_ARRAY(RootChunkArea, _num, mtClass);
-  const MetaWord* this_base = _base;
-  for (int i = 0; i < _num; i ++) {
-    RootChunkArea* rca = new(_arr + i) RootChunkArea(this_base);
-    assert(rca == _arr + i, "Sanity");
-    this_base += chunklevel::MAX_CHUNK_WORD_SIZE;
-  }
-}
-
-RootChunkAreaLUT::~RootChunkAreaLUT() {
-  for (int i = 0; i < _num; i ++) {
-    _arr[i].~RootChunkArea();
-  }
-  FREE_C_HEAP_ARRAY(RootChunkArea, _arr);
-}
-
-// Returns true if all areas in this area table are free (only contain free chunks).
-bool RootChunkAreaLUT::is_free() const {
-  for (int i = 0; i < _num; i ++) {
-    if (!_arr[i].is_free()) {
-      return false;
-    }
-  }
-  return true;
-}
-
-#ifdef ASSERT
-
-void RootChunkAreaLUT::verify(bool slow) const {
-  for (int i = 0; i < _num; i ++) {
-    check_pointer(_arr[i].base());
-    _arr[i].verify(slow);
-  }
-}
-
-#endif
-
-void RootChunkAreaLUT::print_on(outputStream* st) const {
-  for (int i = 0; i < _num; i ++) {
-    st->print("%2d:", i);
-    _arr[i].print_on(st);
-  }
-}
-
-
-} // end: namespace metaspace
--- old/src/hotspot/share/memory/metaspace/rootChunkArea.hpp	2020-09-04 13:58:37.277674783 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,211 +0,0 @@
-/*
- * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#ifndef SHARE_MEMORY_METASPACE_ROOTCHUNKAREA_HPP
-#define SHARE_MEMORY_METASPACE_ROOTCHUNKAREA_HPP
-
-#include "memory/allocation.hpp"
-#include "memory/metaspace/chunkLevel.hpp"
-#include "utilities/debug.hpp"
-#include "utilities/globalDefinitions.hpp"
-
-class outputStream;
-
-namespace metaspace {
-
-class Metachunk;
-class MetachunkClosure;
-class FreeChunkListVector;
-class VirtualSpaceNode;
-
-
-// RootChunkArea manages a memory area covering a single root chunk.
-//
-// Such an area may contain a single root chunk, or a number of chunks the
-//  root chunk was split into.
-//
-// RootChunkArea contains the functionality to merge and split chunks in
-//  buddy allocator fashion.
-//
-
-class RootChunkArea {
-
-  // The base address of this area.
-  // Todo: this may be somewhat superfluous since RootChunkArea only exist in the
-  //  context of a series of chunks, so the address is somewhat implicit. Remove?
-  const MetaWord* const _base;
-
-  // The first chunk in this area; if this area is maximally
-  // folded, this is the root chunk covering the whole area size.
-  Metachunk* _first_chunk;
-
-public:
-
-  RootChunkArea(const MetaWord* base);
-  ~RootChunkArea();
-
-  // Initialize: allocate a root node and a root chunk header; return the
-  // root chunk header. It will be partly initialized.
-  // Note: this just allocates a memory-less header; memory itself is allocated inside VirtualSpaceNode.
-  Metachunk* alloc_root_chunk_header(VirtualSpaceNode* node);
-
-
-  // Given a chunk c, split it recursively until you get a chunk of the given target_level.
-  //
-  // The resulting target chunk resides at the same address as the original chunk.
-  // The resulting splinters are added to freelists.
-  //
-  // Returns pointer to the result chunk; the splitted-off chunks are added as
-  //  free chunks to the freelists.
-  void split(chunklevel_t target_level, Metachunk* c, FreeChunkListVector* freelists);
-
-  // Given a chunk, attempt to merge it recursively with its neighboring chunks.
-  //
-  // If successful (merged at least once), returns address of
-  // the merged chunk; NULL otherwise.
-  //
-  // The merged chunks are removed from the freelists.
-  //
-  // !!! Please note that if this method returns a non-NULL value, the
-  // original chunk will be invalid and should not be accessed anymore! !!!
-  Metachunk* merge(Metachunk* c, FreeChunkListVector* freelists);
-
-  // Given a chunk c, which must be "in use" and must not be a root chunk, attempt to
-  // enlarge it in place by claiming its trailing buddy.
-  //
-  // This will only work if c is the leader of the buddy pair and the trailing buddy is free.
-  //
-  // If successful, the follower chunk will be removed from the freelists, the leader chunk c will
-  // double in size (level decreased by one).
-  //
-  // On success, true is returned, false otherwise.
-  bool attempt_enlarge_chunk(Metachunk* c, FreeChunkListVector* freelists);
-
-  /// range ///
-
-  const MetaWord* base() const  { return _base; }
-  size_t word_size() const      { return chunklevel::MAX_CHUNK_WORD_SIZE; }
-  const MetaWord* end() const   { return _base + word_size(); }
-
-  // Direct access to the first chunk (use with care)
-  Metachunk* first_chunk()              { return _first_chunk; }
-  const Metachunk* first_chunk() const  { return _first_chunk; }
-
-  // Returns true if this root chunk area is completely free:
-  //  In that case, it should only contain one chunk (maximally merged, so a root chunk)
-  //  and it should be free.
-  bool is_free() const;
-
-  //// Debug stuff ////
-
-#ifdef ASSERT
-  void check_pointer(const MetaWord* p) const {
-    assert(p >= _base && p < _base + word_size(),
-           "pointer " PTR_FORMAT " oob for this root area [" PTR_FORMAT ".." PTR_FORMAT ")",
-           p2i(p), p2i(_base), p2i(_base + word_size()));
-  }
-  void verify(bool slow) const;
-
-  // This is a separate operation from verify(). We should be able to call verify()
-  // from almost anywhere, regardless of state, but verify_area_is_ideally_merged()
-  // can only be called outside split and merge ops.
-  void verify_area_is_ideally_merged() const;
-#endif // ASSERT
-
-  void print_on(outputStream* st) const;
-
-};
-
-
-// RootChunkAreaLUT (lookup table) manages a series of contiguous root chunk areas
-//  in memory (in the context of a VirtualSpaceNode). It allows finding the containing
-//  root chunk for any given memory address. It allows for easy iteration over all
-//  root chunks.
-// Beyond that it is unexciting.
-class RootChunkAreaLUT {
-
-  // Base address of the whole area.
-  const MetaWord* const _base;
-
-  // Number of root chunk areas.
-  const int _num;
-
-  // Array of RootChunkArea objects.
-  RootChunkArea* _arr;
-
-#ifdef ASSERT
-  void check_pointer(const MetaWord* p) const {
-    assert(p >= base() && p < base() + word_size(), "Invalid pointer");
-  }
-#endif
-
-  // Given an address into this range, return the index into the area array for the
-  // area this address falls into.
-  int index_by_address(const MetaWord* p) const {
-    DEBUG_ONLY(check_pointer(p);)
-    int idx = (int)((p - base()) / chunklevel::MAX_CHUNK_WORD_SIZE);
-    assert(idx >= 0 && idx < _num, "Sanity");
-    return idx;
-  }
-
-public:
-
-  RootChunkAreaLUT(const MetaWord* base, size_t word_size);
-  ~RootChunkAreaLUT();
-
-  // Given a memory address into the range this array covers, return the
-  // corresponding area object. If none existed at this position, create it
-  // on demand.
-  RootChunkArea* get_area_by_address(const MetaWord* p) const {
-    const int idx = index_by_address(p);
-    RootChunkArea* ra = _arr + idx;
-    DEBUG_ONLY(ra->check_pointer(p);)
-    return _arr + idx;
-  }
-
-  // Access area by its index
-  int number_of_areas() const                               { return _num; }
-  RootChunkArea* get_area_by_index(int index)               { assert(index >= 0 && index < _num, "oob"); return _arr + index; }
-  const RootChunkArea* get_area_by_index(int index) const   { assert(index >= 0 && index < _num, "oob"); return _arr + index; }
-
-  /// range ///
-
-  const MetaWord* base() const  { return _base; }
-  size_t word_size() const      { return _num * chunklevel::MAX_CHUNK_WORD_SIZE; }
-  const MetaWord* end() const   { return _base + word_size(); }
-
-  // Returns true if all areas in this area table are free (only contain free chunks).
-  bool is_free() const;
-
-  DEBUG_ONLY(void verify(bool slow) const;)
-
-  void print_on(outputStream* st) const;
-
-};
-
-
-} // namespace metaspace
-
-#endif // SHARE_MEMORY_METASPACE_ROOTCHUNKAREA_HPP
--- old/src/hotspot/share/memory/metaspace/runningCounters.cpp	2020-09-04 13:58:37.689677693 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,99 +0,0 @@
-/*
- * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#include "precompiled.hpp"
-#include "memory/metaspace/counter.hpp"
-#include "memory/metaspace/runningCounters.hpp"
-#include "memory/metaspace/virtualSpaceList.hpp"
-#include "memory/metaspace/chunkManager.hpp"
-
-namespace metaspace {
-
-SizeAtomicCounter RunningCounters::_used_class_counter;
-SizeAtomicCounter RunningCounters::_used_nonclass_counter;
-
-// Return reserved size, in words, for Metaspace
-size_t RunningCounters::reserved_words() {
-  return reserved_words_class() + reserved_words_nonclass();
-}
-
-size_t RunningCounters::reserved_words_class() {
-  VirtualSpaceList* vs = VirtualSpaceList::vslist_class();
-  return vs != NULL ? vs->reserved_words() : 0;
-}
-
-size_t RunningCounters::reserved_words_nonclass() {
-  return VirtualSpaceList::vslist_nonclass()->reserved_words();
-}
-
-// Return total committed size, in words, for Metaspace
-size_t RunningCounters::committed_words() {
-  return committed_words_class() + committed_words_nonclass();
-}
-
-size_t RunningCounters::committed_words_class() {
-  VirtualSpaceList* vs = VirtualSpaceList::vslist_class();
-  return vs != NULL ? vs->committed_words() : 0;
-}
-
-size_t RunningCounters::committed_words_nonclass() {
-  return VirtualSpaceList::vslist_nonclass()->committed_words();
-}
-
-
-// ---- used chunks -----
-
-// Returns size, in words, used for metadata.
-size_t RunningCounters::used_words() {
-  return used_words_class() + used_words_nonclass();
-}
-
-size_t RunningCounters::used_words_class() {
-  return _used_class_counter.get();
-}
-
-size_t RunningCounters::used_words_nonclass() {
-  return _used_nonclass_counter.get();
-}
-
-// ---- free chunks -----
-
-// Returns size, in words, of all chunks in all freelists.
-size_t RunningCounters::free_chunks_words() {
-  return free_chunks_words_class() + free_chunks_words_nonclass();
-}
-
-size_t RunningCounters::free_chunks_words_class() {
-  ChunkManager* cm = ChunkManager::chunkmanager_class();
-  return cm != NULL ? cm->total_word_size() : 0;
-}
-
-size_t RunningCounters::free_chunks_words_nonclass() {
-  return ChunkManager::chunkmanager_nonclass()->total_word_size();
-}
-
-} // namespace metaspace
-
-
--- old/src/hotspot/share/memory/metaspace/runningCounters.hpp	2020-09-04 13:58:38.101680604 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,79 +0,0 @@
-/*
- * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#ifndef SHARE_MEMORY_METASPACE_RUNNINGCOUNTERS_HPP
-#define SHARE_MEMORY_METASPACE_RUNNINGCOUNTERS_HPP
-
-#include "memory/allocation.hpp"
-#include "memory/metaspace/counter.hpp"
-
-namespace metaspace {
-
-// This class is a convenience interface for accessing global metaspace counters.
-class RunningCounters : public AllStatic {
-
-  static SizeAtomicCounter _used_class_counter;
-  static SizeAtomicCounter _used_nonclass_counter;
-
-public:
-
-  // ---- virtual memory -----
-
-  // Return reserved size, in words, for Metaspace
-  static size_t reserved_words();
-  static size_t reserved_words_class();
-  static size_t reserved_words_nonclass();
-
-  // Return total committed size, in words, for Metaspace
-  static size_t committed_words();
-  static size_t committed_words_class();
-  static size_t committed_words_nonclass();
-
-
-  // ---- used chunks -----
-
-  // Returns size, in words, used for metadata.
-  static size_t used_words();
-  static size_t used_words_class();
-  static size_t used_words_nonclass();
-
-  // ---- free chunks -----
-
-  // Returns size, in words, of all chunks in all freelists.
-  static size_t free_chunks_words();
-  static size_t free_chunks_words_class();
-  static size_t free_chunks_words_nonclass();
-
-  // Direct access to the counters.
-  static SizeAtomicCounter* used_nonclass_counter()     { return &_used_nonclass_counter; }
-  static SizeAtomicCounter* used_class_counter()        { return &_used_class_counter; }
-
-};
-
-} // namespace metaspace
-
-#endif // SHARE_MEMORY_METASPACE_RUNNINGCOUNTERS_HPP
-
-
--- old/src/hotspot/share/memory/metaspace/settings.cpp	2020-09-04 13:58:38.517683545 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,140 +0,0 @@
-/*
- * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#include "precompiled.hpp"
-
-#include "logging/log.hpp"
-#include "logging/logStream.hpp"
-
-#include "memory/metaspace/chunkLevel.hpp"
-#include "memory/metaspace/settings.hpp"
-
-#include "utilities/globalDefinitions.hpp"
-#include "utilities/debug.hpp"
-
-namespace metaspace {
-
-size_t Settings::_commit_granule_bytes = 0;
-size_t Settings::_commit_granule_words = 0;
-
-bool Settings::_new_chunks_are_fully_committed = false;
-bool Settings::_uncommit_free_chunks = false;
-
-DEBUG_ONLY(bool Settings::_use_allocation_guard = false;)
-DEBUG_ONLY(bool Settings::_handle_deallocations = true;)
-
-
-void Settings::ergo_initialize() {
-
-  if (strcmp(MetaspaceReclaimPolicy, "none") == 0) {
-
-    log_info(metaspace)("Initialized with strategy: no reclaim.");
-
-    _commit_granule_bytes = MAX2((size_t)os::vm_page_size(), 64 * K);
-    _commit_granule_words = _commit_granule_bytes / BytesPerWord;
-
-    // In "none" reclamation mode, we do not uncommit, and we commit new chunks fully;
-    // that very closely mimicks the behaviour of old Metaspace.
-    _new_chunks_are_fully_committed = true;
-    _uncommit_free_chunks = false;
-
-
-  } else if (strcmp(MetaspaceReclaimPolicy, "aggressive") == 0) {
-
-    log_info(metaspace)("Initialized with strategy: aggressive reclaim.");
-
-    // Set the granule size rather small; may increase
-    // mapping fragmentation but also increase chance to uncommit.
-    _commit_granule_bytes = MAX2((size_t)os::vm_page_size(), 16 * K);
-    _commit_granule_words = _commit_granule_bytes / BytesPerWord;
-
-    _new_chunks_are_fully_committed = false;
-    _uncommit_free_chunks = true;
-
-  } else if (strcmp(MetaspaceReclaimPolicy, "balanced") == 0) {
-
-    log_info(metaspace)("Initialized with strategy: balanced reclaim.");
-
-    _commit_granule_bytes = MAX2((size_t)os::vm_page_size(), 64 * K);
-    _commit_granule_words = _commit_granule_bytes / BytesPerWord;
-
-    _new_chunks_are_fully_committed = false;
-    _uncommit_free_chunks = true;
-
-  } else {
-
-    vm_exit_during_initialization("Invalid value for MetaspaceReclaimPolicy: \"%s\".", MetaspaceReclaimPolicy);
-
-  }
-
-  // Sanity checks.
-  assert(commit_granule_words() <= chunklevel::MAX_CHUNK_WORD_SIZE, "Too large granule size");
-  assert(is_power_of_2(commit_granule_words()), "granule size must be a power of 2");
-
-  // Should always be true since root chunk size should be much larger than alloc granularity
-  assert(is_aligned(_virtual_space_node_reserve_alignment_words * BytesPerWord,
-                    os::vm_allocation_granularity()), "Sanity");
-
-#ifdef ASSERT
-  // Off for release builds, and by default for debug builds, but can be switched on manually to aid
-  // error analysis.
-  _use_allocation_guard = MetaspaceGuardAllocations;
-
-  // Deallocations can be manually switched off to aid error analysis, since this removes one layer of complexity
-  //  from allocation.
-  _handle_deallocations = MetaspaceHandleDeallocations;
-
-  // We also switch it off automatically if we use allocation guards. This is to keep prefix handling in MetaspaceArena simple.
-  if (_use_allocation_guard) {
-    _handle_deallocations = false;
-  }
-#endif
-
-  LogStream ls(Log(metaspace)::info());
-  Settings::print_on(&ls);
-
-}
-
-void Settings::print_on(outputStream* st) {
-
-  st->print_cr(" - commit_granule_bytes: " SIZE_FORMAT ".", commit_granule_bytes());
-  st->print_cr(" - commit_granule_words: " SIZE_FORMAT ".", commit_granule_words());
-
-
-  st->print_cr(" - virtual_space_node_default_size: " SIZE_FORMAT ".", virtual_space_node_default_word_size());
-
-  st->print_cr(" - enlarge_chunks_in_place: %d.", (int)enlarge_chunks_in_place());
-  st->print_cr(" - enlarge_chunks_in_place_max_word_size: " SIZE_FORMAT ".", enlarge_chunks_in_place_max_word_size());
-
-  st->print_cr(" - new_chunks_are_fully_committed: %d.", (int)new_chunks_are_fully_committed());
-  st->print_cr(" - uncommit_free_chunks: %d.", (int)uncommit_free_chunks());
-
-  st->print_cr(" - use_allocation_guard: %d.", (int)use_allocation_guard());
-  st->print_cr(" - handle_deallocations: %d.", (int)handle_deallocations());
-
-}
-
-} // namespace metaspace
-
--- old/src/hotspot/share/memory/metaspace/settings.hpp	2020-09-04 13:58:38.933686486 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,94 +0,0 @@
-/*
- * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#ifndef SHARE_MEMORY_METASPACE_CONSTANTS_HPP
-#define SHARE_MEMORY_METASPACE_CONSTANTS_HPP
-
-#include "memory/allocation.hpp"
-#include "memory/metaspace/chunkLevel.hpp"
-#include "utilities/globalDefinitions.hpp"
-
-namespace metaspace {
-
-class Settings : public AllStatic {
-
-  // Granularity, in bytes, metaspace is committed with.
-  static size_t _commit_granule_bytes;
-
-  // Granularity, in words, metaspace is committed with.
-  static size_t _commit_granule_words;
-
-  // The default size of a non-class VirtualSpaceNode (unless created differently).
-  // Must be a multiple of the root chunk size.
-  static const size_t _virtual_space_node_default_word_size = chunklevel::MAX_CHUNK_WORD_SIZE * 2; // lets go with 8mb virt size. Seems a good compromise betw. virt and mapping fragmentation.
-
-  // Alignment of the base address of a virtual space node
-  static const size_t _virtual_space_node_reserve_alignment_words = chunklevel::MAX_CHUNK_WORD_SIZE;
-
-  // When allocating from a chunk, if the remaining area in the chunk is too small to hold
-  // the requested size, we attempt to double the chunk size in place...
-  static const bool _enlarge_chunks_in_place = true;
-
-  // .. but we do only do this for chunks below a given size to prevent unnecessary memory blowup.
-  static const size_t _enlarge_chunks_in_place_max_word_size = 256 * K;
-
-  // Whether or not chunks handed out to an arena start out fully committed;
-  // if true, this deactivates committing-on-demand (irregardless of whether
-  // we uncommit free chunks).
-  static bool _new_chunks_are_fully_committed;
-
-  // If true, chunks equal or larger than a commit granule are uncommitted
-  // after being returned to the freelist.
-  static bool _uncommit_free_chunks;
-
-  // If true, metablock allocations are guarded and periodically checked.
-  DEBUG_ONLY(static bool _use_allocation_guard;)
-
-  // If true, we handle deallocated blocks (default).
-  DEBUG_ONLY(static bool _handle_deallocations;)
-
-public:
-
-  static size_t commit_granule_bytes()                        { return _commit_granule_bytes; }
-  static size_t commit_granule_words()                        { return _commit_granule_words; }
-  static bool new_chunks_are_fully_committed()                { return _new_chunks_are_fully_committed; }
-  static size_t virtual_space_node_default_word_size()        { return _virtual_space_node_default_word_size; }
-  static size_t virtual_space_node_reserve_alignment_words()  { return _virtual_space_node_reserve_alignment_words; }
-  static bool enlarge_chunks_in_place()                       { return _enlarge_chunks_in_place; }
-  static size_t enlarge_chunks_in_place_max_word_size()       { return _enlarge_chunks_in_place_max_word_size; }
-  static bool uncommit_free_chunks()                          { return _uncommit_free_chunks; }
-
-  static bool use_allocation_guard()                          { return DEBUG_ONLY(_use_allocation_guard) NOT_DEBUG(false); }
-  static bool handle_deallocations()                          { return DEBUG_ONLY(_handle_deallocations) NOT_DEBUG(true); }
-
-  static void ergo_initialize();
-
-  static void print_on(outputStream* st);
-
-};
-
-} // namespace metaspace
-
-#endif // SHARE_MEMORY_METASPACE_BLOCKFREELIST_HPP
--- old/src/hotspot/share/memory/metaspace/virtualSpaceList.cpp	2020-09-04 13:58:39.353689458 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,274 +0,0 @@
-/*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#include "precompiled.hpp"
-#include "logging/log.hpp"
-#include "memory/metaspace.hpp"
-#include "memory/metaspace/chunkManager.hpp"
-#include "memory/metaspace/counter.hpp"
-#include "memory/metaspace/commitLimiter.hpp"
-#include "memory/metaspace/counter.hpp"
-#include "memory/metaspace/freeChunkList.hpp"
-#include "memory/metaspace/metaspaceContext.hpp"
-#include "memory/metaspace/virtualSpaceList.hpp"
-#include "memory/metaspace/virtualSpaceNode.hpp"
-#include "runtime/mutexLocker.hpp"
-
-
-namespace metaspace {
-
-#define LOGFMT         "VsList @" PTR_FORMAT " (%s)"
-#define LOGFMT_ARGS    p2i(this), this->_name
-
-// Create a new, empty, expandable list.
-VirtualSpaceList::VirtualSpaceList(const char* name, CommitLimiter* commit_limiter)
-  : _name(name),
-    _first_node(NULL),
-    _can_expand(true),
-    _can_purge(true),
-    _commit_limiter(commit_limiter),
-    _reserved_words_counter(),
-    _committed_words_counter()
-{
-}
-
-// Create a new list. The list will contain one node only, which uses the given ReservedSpace.
-// It will be not expandable beyond that first node.
-VirtualSpaceList::VirtualSpaceList(const char* name, ReservedSpace rs, CommitLimiter* commit_limiter)
-: _name(name),
-  _first_node(NULL),
-  _can_expand(false),
-  _can_purge(false),
-  _commit_limiter(commit_limiter),
-  _reserved_words_counter(),
-  _committed_words_counter()
-{
-  // Create the first node spanning the existing ReservedSpace. This will be the only node created
-  // for this list since we cannot expand.
-  VirtualSpaceNode* vsn = VirtualSpaceNode::create_node(rs, _commit_limiter,
-                                                        &_reserved_words_counter, &_committed_words_counter);
-  assert(vsn != NULL, "node creation failed");
-  _first_node = vsn;
-  _first_node->set_next(NULL);
-  _nodes_counter.increment();
-}
-
-VirtualSpaceList::~VirtualSpaceList() {
-  assert_lock_strong(MetaspaceExpand_lock);
-  // Note: normally, there is no reason ever to delete a vslist since they are
-  // global objects, but for gtests it makes sense to allow this.
-  VirtualSpaceNode* vsn = _first_node;
-  VirtualSpaceNode* vsn2 = vsn;
-  while (vsn != NULL) {
-    vsn2 = vsn->next();
-    delete vsn;
-    vsn = vsn2;
-  }
-}
-
-// Create a new node and append it to the list. After
-// this function, _current_node shall point to a new empty node.
-// List must be expandable for this to work.
-void VirtualSpaceList::create_new_node() {
-  assert(_can_expand, "List is not expandable");
-  assert_lock_strong(MetaspaceExpand_lock);
-
-  VirtualSpaceNode* vsn = VirtualSpaceNode::create_node(Settings::virtual_space_node_default_word_size(),
-                                                        _commit_limiter,
-                                                        &_reserved_words_counter, &_committed_words_counter);
-  assert(vsn != NULL, "node creation failed");
-  vsn->set_next(_first_node);
-  _first_node = vsn;
-  _nodes_counter.increment();
-}
-
-// Allocate a root chunk from this list.
-// Note: this just returns a chunk whose memory is reserved; no memory is committed yet.
-// Hence, before using this chunk, it must be committed.
-// Also, no limits are checked, since no committing takes place.
-Metachunk*  VirtualSpaceList::allocate_root_chunk() {
-  assert_lock_strong(MetaspaceExpand_lock);
-
-  if (_first_node == NULL ||
-      _first_node->free_words() == 0) {
-
-    // Since all allocations from a VirtualSpaceNode happen in
-    // root-chunk-size units, and the node size must be root-chunk-size aligned,
-    // we should never have left-over space.
-    assert(_first_node == NULL ||
-           _first_node->free_words() == 0, "Sanity");
-
-    if (_can_expand) {
-      create_new_node();
-      UL2(debug, "added new node (now: %d).", num_nodes());
-    } else {
-      UL(debug, "list cannot expand.");
-      return NULL; // We cannot expand this list.
-    }
-  }
-
-  Metachunk* c = _first_node->allocate_root_chunk();
-
-  assert(c != NULL, "This should have worked");
-
-  return c;
-
-}
-
-// Attempts to purge nodes. This will remove and delete nodes which only contain free chunks.
-// The free chunks are removed from the freelists before the nodes are deleted.
-// Return number of purged nodes.
-int VirtualSpaceList::purge(FreeChunkListVector* freelists) {
-
-  assert_lock_strong(MetaspaceExpand_lock);
-
-  if (_can_purge == false) {
-    return 0;
-  }
-
-  UL(debug, "purging.");
-
-  VirtualSpaceNode* vsn = _first_node;
-  VirtualSpaceNode* prev_vsn = NULL;
-  int num = 0, num_purged = 0;
-  while (vsn != NULL) {
-    VirtualSpaceNode* next_vsn = vsn->next();
-    bool purged = vsn->attempt_purge(freelists);
-    if (purged) {
-      // Note: from now on do not dereference vsn!
-      UL2(debug, "purged node @" PTR_FORMAT ".", p2i(vsn));
-      if (_first_node == vsn) {
-        _first_node = next_vsn;
-      }
-      DEBUG_ONLY(vsn = (VirtualSpaceNode*)((uintptr_t)(0xdeadbeef));)
-      if (prev_vsn != NULL) {
-        prev_vsn->set_next(next_vsn);
-      }
-      num_purged ++;
-      _nodes_counter.decrement();
-    } else {
-      prev_vsn = vsn;
-    }
-    vsn = next_vsn;
-    num ++;
-  }
-
-  UL2(debug, "purged %d nodes (now: %d)", num_purged, num_nodes());
-
-  return num_purged;
-
-}
-
-// Print all nodes in this space list.
-void VirtualSpaceList::print_on(outputStream* st) const {
-  MutexLocker fcl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
-
-  st->print_cr("vsl %s:", _name);
-  const VirtualSpaceNode* vsn = _first_node;
-  int n = 0;
-  while (vsn != NULL) {
-    st->print("- node #%d: ", n);
-    vsn->print_on(st);
-    vsn = vsn->next();
-    n ++;
-  }
-  st->print_cr("- total %d nodes, " SIZE_FORMAT " reserved words, " SIZE_FORMAT " committed words.",
-               n, reserved_words(), committed_words());
-}
-
-#ifdef ASSERT
-void VirtualSpaceList::verify_locked(bool slow) const {
-
-  assert_lock_strong(MetaspaceExpand_lock);
-
-  assert(_name != NULL, "Sanity");
-
-  int n = 0;
-
-  if (_first_node != NULL) {
-
-    size_t total_reserved_words = 0;
-    size_t total_committed_words = 0;
-    const VirtualSpaceNode* vsn = _first_node;
-    while (vsn != NULL) {
-      n ++;
-      vsn->verify_locked(slow);
-      total_reserved_words += vsn->word_size();
-      total_committed_words += vsn->committed_words();
-      vsn = vsn->next();
-    }
-
-    _nodes_counter.check(n);
-    _reserved_words_counter.check(total_reserved_words);
-    _committed_words_counter.check(total_committed_words);
-
-  } else {
-
-    _reserved_words_counter.check(0);
-    _committed_words_counter.check(0);
-
-  }
-}
-
-void VirtualSpaceList::verify(bool slow) const {
-  MutexLocker fcl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
-  verify_locked(slow);
-}
-#endif
-
-// Returns true if this pointer is contained in one of our nodes.
-bool VirtualSpaceList::contains(const MetaWord* p) const {
-  const VirtualSpaceNode* vsn = _first_node;
-  while (vsn != NULL) {
-    if (vsn->contains(p)) {
-      return true;
-    }
-    vsn = vsn->next();
-  }
-  return false;
-}
-
-// Returns true if the vslist is not expandable and no more root chunks
-// can be allocated.
-bool VirtualSpaceList::is_full() const {
-  if (!_can_expand && _first_node != NULL && _first_node->free_words() == 0) {
-    return true;
-  }
-  return false;
-}
-
-// Convenience methods to return the global class-space chunkmanager
-//  and non-class chunkmanager, respectively.
-VirtualSpaceList* VirtualSpaceList::vslist_class() {
-  return MetaspaceContext::context_class() == NULL ? NULL : MetaspaceContext::context_class()->vslist();
-}
-
-VirtualSpaceList* VirtualSpaceList::vslist_nonclass() {
-  return MetaspaceContext::context_nonclass() == NULL ? NULL : MetaspaceContext::context_nonclass()->vslist();
-}
-
-
-
-} // namespace metaspace
--- old/src/hotspot/share/memory/metaspace/virtualSpaceList.hpp	2020-09-04 13:58:39.769692402 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,154 +0,0 @@
-/*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#ifndef SHARE_MEMORY_METASPACE_VIRTUALSPACELIST_HPP
-#define SHARE_MEMORY_METASPACE_VIRTUALSPACELIST_HPP
-
-#include "memory/allocation.hpp"
-#include "memory/metaspace/counter.hpp"
-#include "memory/metaspace/commitLimiter.hpp"
-#include "memory/metaspace/virtualSpaceNode.hpp"
-#include "memory/virtualspace.hpp"
-#include "utilities/globalDefinitions.hpp"
-
-class outputStream;
-
-namespace metaspace {
-
-class Metachunk;
-class FreeChunkListVector;
-
-
-// VirtualSpaceList manages a single (if its non-expandable) or
-//  a series of (if its expandable) virtual memory regions used
-//  for metaspace.
-//
-// Internally it holds a list of nodes (VirtualSpaceNode) each
-//  managing a single contiguous memory region. The first node of
-//  this list is the current node and used for allocation of new
-//  root chunks.
-//
-// Beyond access to those nodes and the ability to grow new nodes
-//  (if expandable) it allows for purging: purging this list means
-//  removing and unmapping all memory regions which are unused.
-
-class VirtualSpaceList : public CHeapObj<mtClass> {
-
-  // Name
-  const char* const _name;
-
-  // Head of the list.
-  VirtualSpaceNode* _first_node;
-
-  // Number of nodes (kept for statistics only).
-  IntCounter _nodes_counter;
-
-  // Whether this list can expand by allocating new nodes.
-  const bool _can_expand;
-
-  // Whether this list can be purged.
-  const bool _can_purge;
-
-  // Used to check limits before committing memory.
-  CommitLimiter* const _commit_limiter;
-
-  // Statistics
-
-  // Holds sum of reserved space, in words, over all list nodes.
-  SizeCounter _reserved_words_counter;
-
-  // Holds sum of committed space, in words, over all list nodes.
-  SizeCounter _committed_words_counter;
-
-  // Create a new node and append it to the list. After
-  // this function, _current_node shall point to a new empty node.
-  // List must be expandable for this to work.
-  void create_new_node();
-
-public:
-
-  // Create a new, empty, expandable list.
-  VirtualSpaceList(const char* name, CommitLimiter* commit_limiter);
-
-  // Create a new list. The list will contain one node only, which uses the given ReservedSpace.
-  // It will be not expandable beyond that first node.
-  VirtualSpaceList(const char* name, ReservedSpace rs, CommitLimiter* commit_limiter);
-
-  virtual ~VirtualSpaceList();
-
-  // Allocate a root chunk from this list.
-  // Note: this just returns a chunk whose memory is reserved; no memory is committed yet.
-  // Hence, before using this chunk, it must be committed.
-  // May return NULL if vslist would need to be expanded to hold the new root node but
-  // the list cannot be expanded (in practice this means we reached CompressedClassSpaceSize).
-  Metachunk* allocate_root_chunk();
-
-  // Attempts to purge nodes. This will remove and delete nodes which only contain free chunks.
-  // The free chunks are removed from the freelists before the nodes are deleted.
-  // Return number of purged nodes.
-  int purge(FreeChunkListVector* freelists);
-
-  //// Statistics ////
-
-  // Return sum of reserved words in all nodes.
-  size_t reserved_words() const     { return _reserved_words_counter.get(); }
-
-  // Return sum of committed words in all nodes.
-  size_t committed_words() const    { return _committed_words_counter.get(); }
-
-  // Return number of nodes in this list.
-  int num_nodes() const             { return _nodes_counter.get(); }
-
-  //// Debug stuff ////
-  DEBUG_ONLY(void verify(bool slow) const;)
-  DEBUG_ONLY(void verify_locked(bool slow) const;)
-
-  // Print all nodes in this space list.
-  void print_on(outputStream* st) const;
-
-  // Returns true if this pointer is contained in one of our nodes.
-  bool contains(const MetaWord* p) const;
-
-  // Returns true if the list is not expandable and no more root chunks
-  // can be allocated.
-  bool is_full() const;
-
-  // Convenience methods to return the global class-space vslist
-  //  and non-class vslist, respectively.
-  static VirtualSpaceList* vslist_class();
-  static VirtualSpaceList* vslist_nonclass();
-
-  // These exist purely to print limits of the compressed class space;
-  // if we ever change the ccs to not use a degenerated-list-of-one-node this
-  // will go away.
-  MetaWord* base_of_first_node() const { return _first_node != NULL ? _first_node->base() : NULL; }
-  size_t word_size_of_first_node() const { return _first_node != NULL ? _first_node->word_size() : 0; }
-
-};
-
-} // namespace metaspace
-
-#endif // SHARE_MEMORY_METASPACE_VIRTUALSPACELIST_HPP
-
--- old/src/hotspot/share/memory/metaspace/virtualSpaceNode.cpp	2020-09-04 13:58:40.181695318 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,520 +0,0 @@
-/*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#include "precompiled.hpp"
-
-#include "logging/log.hpp"
-
-#include "memory/metaspace/chunkLevel.hpp"
-#include "memory/metaspace/chunkHeaderPool.hpp"
-#include "memory/metaspace/commitLimiter.hpp"
-#include "memory/metaspace/counter.hpp"
-#include "memory/metaspace/freeChunkList.hpp"
-#include "memory/metaspace/internStat.hpp"
-#include "memory/metaspace/metachunk.hpp"
-#include "memory/metaspace/metaspaceCommon.hpp"
-#include "memory/metaspace/rootChunkArea.hpp"
-#include "memory/metaspace/runningCounters.hpp"
-#include "memory/metaspace/settings.hpp"
-#include "memory/metaspace/virtualSpaceNode.hpp"
-#include "memory/metaspace.hpp"
-
-#include "runtime/globals.hpp"
-#include "runtime/mutexLocker.hpp"
-#include "runtime/os.hpp"
-
-#include "utilities/align.hpp"
-#include "utilities/debug.hpp"
-#include "utilities/globalDefinitions.hpp"
-#include "utilities/ostream.hpp"
-
-namespace metaspace {
-
-#define LOGFMT         "VsListNode @" PTR_FORMAT " base " PTR_FORMAT " "
-#define LOGFMT_ARGS    p2i(this), p2i(_base)
-
-#ifdef ASSERT
-void check_pointer_is_aligned_to_commit_granule(const MetaWord* p) {
-  assert(is_aligned(p, Settings::commit_granule_bytes()),
-         "Pointer not aligned to commit granule size: " PTR_FORMAT ".",
-         p2i(p));
-}
-void check_word_size_is_aligned_to_commit_granule(size_t word_size) {
-  assert(is_aligned(word_size, Settings::commit_granule_words()),
-         "Not aligned to commit granule size: " SIZE_FORMAT ".", word_size);
-}
-#endif
-
-
-// Given an address range, ensure it is committed.
-//
-// The range has to be aligned to granule size.
-//
-// Function will:
-// - check how many granules in that region are uncommitted; If all are committed, it
-//    returns true immediately.
-// - check if committing those uncommitted granules would bring us over the commit limit
-//    (GC threshold, MaxMetaspaceSize). If true, it returns false.
-// - commit the memory.
-// - mark the range as committed in the commit mask
-//
-// Returns true if success, false if it did hit a commit limit.
-bool VirtualSpaceNode::commit_range(MetaWord* p, size_t word_size) {
-
-  DEBUG_ONLY(check_pointer_is_aligned_to_commit_granule(p);)
-  DEBUG_ONLY(check_word_size_is_aligned_to_commit_granule(word_size);)
-  assert_lock_strong(MetaspaceExpand_lock);
-
-  // First calculate how large the committed regions in this range are
-  const size_t committed_words_in_range = _commit_mask.get_committed_size_in_range(p, word_size);
-  DEBUG_ONLY(check_word_size_is_aligned_to_commit_granule(committed_words_in_range);)
-
-  // By how much words we would increase commit charge
-  //  were we to commit the given address range completely.
-  const size_t commit_increase_words = word_size - committed_words_in_range;
-
-  UL2(debug, "committing range " PTR_FORMAT ".." PTR_FORMAT "(" SIZE_FORMAT " words)",
-      p2i(p), p2i(p + word_size), word_size);
-
-  if (commit_increase_words == 0) {
-    UL(debug, "... already fully committed.");
-    return true; // Already fully committed, nothing to do.
-  }
-
-  // Before committing any more memory, check limits.
-  if (_commit_limiter->possible_expansion_words() < commit_increase_words) {
-    UL(debug, "... cannot commit (limit).");
-    return false;
-  }
-
-  // Commit...
-  if (os::commit_memory((char*)p, word_size * BytesPerWord, false) == false) {
-    vm_exit_out_of_memory(word_size * BytesPerWord, OOM_MMAP_ERROR, "Failed to commit metaspace.");
-  }
-
-  if (AlwaysPreTouch) {
-    os::pretouch_memory(p, p + word_size);
-  }
-
-  UL2(debug, "... committed " SIZE_FORMAT " additional words.", commit_increase_words);
-
-  // ... tell commit limiter...
-  _commit_limiter->increase_committed(commit_increase_words);
-
-  // ... update counters in containing vslist ...
-  _total_committed_words_counter->increment_by(commit_increase_words);
-
-  // ... and update the commit mask.
-  _commit_mask.mark_range_as_committed(p, word_size);
-
-#ifdef ASSERT
-  // The commit boundary maintained in the CommitLimiter should be equal the sum of committed words
-  // in both class and non-class vslist (outside gtests).
-  if (_commit_limiter == CommitLimiter::globalLimiter()) {
-    assert(_commit_limiter->committed_words() == RunningCounters::committed_words(), "counter mismatch");
-  }
-#endif
-
-  InternalStats::inc_num_space_committed();
-
-  return true;
-
-}
-
-// Given an address range, ensure it is committed.
-//
-// The range does not have to be aligned to granule size. However, the function will always commit
-// whole granules.
-//
-// Function will:
-// - check how many granules in that region are uncommitted; If all are committed, it
-//    returns true immediately.
-// - check if committing those uncommitted granules would bring us over the commit limit
-//    (GC threshold, MaxMetaspaceSize). If true, it returns false.
-// - commit the memory.
-// - mark the range as committed in the commit mask
-//
-// !! Careful:
-//    calling ensure_range_is_committed on a range which contains both committed and uncommitted
-//    areas will commit the whole area, thus erase the content in the existing committed parts.
-//    Make sure you never call this on an address range containing live data. !!
-//
-// Returns true if success, false if it did hit a commit limit.
-bool VirtualSpaceNode::ensure_range_is_committed(MetaWord* p, size_t word_size) {
-
-  assert_lock_strong(MetaspaceExpand_lock);
-  assert(p != NULL && word_size > 0, "Sanity");
-
-  MetaWord* p_start = align_down(p, Settings::commit_granule_bytes());
-  MetaWord* p_end = align_up(p + word_size, Settings::commit_granule_bytes());
-
-  // Todo: simple for now. Make it more intelligent late
-  return commit_range(p_start, p_end - p_start);
-
-}
-
-// Given an address range (which has to be aligned to commit granule size):
-//  - uncommit it
-//  - mark it as uncommitted in the commit mask
-void VirtualSpaceNode::uncommit_range(MetaWord* p, size_t word_size) {
-
-  DEBUG_ONLY(check_pointer_is_aligned_to_commit_granule(p);)
-  DEBUG_ONLY(check_word_size_is_aligned_to_commit_granule(word_size);)
-  assert_lock_strong(MetaspaceExpand_lock);
-
-  // First calculate how large the committed regions in this range are
-  const size_t committed_words_in_range = _commit_mask.get_committed_size_in_range(p, word_size);
-  DEBUG_ONLY(check_word_size_is_aligned_to_commit_granule(committed_words_in_range);)
-
-  UL2(debug, "uncommitting range " PTR_FORMAT ".." PTR_FORMAT "(" SIZE_FORMAT " words)",
-      p2i(p), p2i(p + word_size), word_size);
-
-  if (committed_words_in_range == 0) {
-    UL(debug, "... already fully uncommitted.");
-    return; // Already fully uncommitted, nothing to do.
-  }
-
-  // Uncommit...
-  if (os::uncommit_memory((char*)p, word_size * BytesPerWord) == false) {
-    // Note: this can actually happen, since uncommit may increase the number of mappings.
-    fatal("Failed to uncommit metaspace.");
-  }
-
-  UL2(debug, "... uncommitted " SIZE_FORMAT " words.", committed_words_in_range);
-
-  // ... tell commit limiter...
-  _commit_limiter->decrease_committed(committed_words_in_range);
-
-  // ... and global counters...
-  _total_committed_words_counter->decrement_by(committed_words_in_range);
-
-   // ... and update the commit mask.
-  _commit_mask.mark_range_as_uncommitted(p, word_size);
-
-#ifdef ASSERT
-  // The commit boundary maintained in the CommitLimiter should be equal the sum of committed words
-  // in both class and non-class vslist (outside gtests).
-  if (_commit_limiter == CommitLimiter::globalLimiter()) { // We are outside a test scenario
-    assert(_commit_limiter->committed_words() == RunningCounters::committed_words(), "counter mismatch");
-  }
-#endif
-
-  InternalStats::inc_num_space_uncommitted();
-
-}
-
-//// creation, destruction ////
-
-VirtualSpaceNode::VirtualSpaceNode(ReservedSpace rs, bool owns_rs, CommitLimiter* limiter,
-                                   SizeCounter* reserve_counter, SizeCounter* commit_counter)
-  : _next(NULL),
-    _rs(rs),
-    _owns_rs(owns_rs),
-    _base((MetaWord*)rs.base()),
-    _word_size(rs.size() / BytesPerWord),
-    _used_words(0),
-    _commit_mask((MetaWord*)rs.base(), rs.size() / BytesPerWord),
-    _root_chunk_area_lut((MetaWord*)rs.base(), rs.size() / BytesPerWord),
-    _commit_limiter(limiter),
-    _total_reserved_words_counter(reserve_counter),
-    _total_committed_words_counter(commit_counter)
-{
-  UL2(debug, "born (word_size " SIZE_FORMAT ").", _word_size);
-
-  // Update reserved counter in vslist
-  _total_reserved_words_counter->increment_by(_word_size);
-
-  assert_is_aligned(_base, chunklevel::MAX_CHUNK_BYTE_SIZE);
-  assert_is_aligned(_word_size, chunklevel::MAX_CHUNK_WORD_SIZE);
-
-}
-
-
-// Create a node of a given size (it will create its own space).
-VirtualSpaceNode* VirtualSpaceNode::create_node(size_t word_size,
-                                                CommitLimiter* limiter, SizeCounter* reserve_words_counter,
-                                                SizeCounter* commit_words_counter)
-{
-
-  DEBUG_ONLY(assert_is_aligned(word_size, chunklevel::MAX_CHUNK_WORD_SIZE);)
-
-  ReservedSpace rs(word_size * BytesPerWord,
-                   Settings::virtual_space_node_reserve_alignment_words() * BytesPerWord,
-                   false // large
-                   );
-
-  if (!rs.is_reserved()) {
-    vm_exit_out_of_memory(word_size * BytesPerWord, OOM_MMAP_ERROR, "Failed to reserve memory for metaspace");
-  }
-
-  assert_is_aligned(rs.base(), chunklevel::MAX_CHUNK_BYTE_SIZE);
-
-  InternalStats::inc_num_vsnodes_births();
-  return new VirtualSpaceNode(rs, true, limiter, reserve_words_counter, commit_words_counter);
-
-}
-
-// Create a node over an existing space
-VirtualSpaceNode* VirtualSpaceNode::create_node(ReservedSpace rs, CommitLimiter* limiter,
-                                                SizeCounter* reserve_words_counter, SizeCounter* commit_words_counter)
-{
-  InternalStats::inc_num_vsnodes_births();
-  return new VirtualSpaceNode(rs, false, limiter, reserve_words_counter, commit_words_counter);
-}
-
-VirtualSpaceNode::~VirtualSpaceNode() {
-
-  DEBUG_ONLY(verify_locked(true);)
-
-  UL(debug, ": dies.");
-
-  if (_owns_rs) {
-    _rs.release();
-  }
-
-  // Update counters in vslist
-  size_t committed = committed_words();
-  _total_committed_words_counter->decrement_by(committed);
-  _total_reserved_words_counter->decrement_by(_word_size);
-
-  // ... and tell commit limiter
-  _commit_limiter->decrease_committed(committed);
-
-  InternalStats::inc_num_vsnodes_deaths();
-
-}
-
-//// Chunk allocation, splitting, merging /////
-
-// Allocate a root chunk from this node. Will fail and return NULL if the node is full
-//  - if we used up the whole address space of this node's memory region.
-//    (in case this node backs compressed class space, this is how we hit
-//     CompressedClassSpaceSize).
-// Note that this just returns reserved memory; caller must take care of committing this
-//  chunk before using it.
-Metachunk* VirtualSpaceNode::allocate_root_chunk() {
-
-  assert_lock_strong(MetaspaceExpand_lock);
-
-  assert_is_aligned(free_words(), chunklevel::MAX_CHUNK_WORD_SIZE);
-
-  if (free_words() >= chunklevel::MAX_CHUNK_WORD_SIZE) {
-
-    MetaWord* loc = _base + _used_words;
-    _used_words += chunklevel::MAX_CHUNK_WORD_SIZE;
-
-    RootChunkArea* rca = _root_chunk_area_lut.get_area_by_address(loc);
-
-    // Create a root chunk header and initialize it;
-    Metachunk* c = rca->alloc_root_chunk_header(this);
-
-    assert(c->base() == loc && c->vsnode() == this &&
-           c->is_free(), "Sanity");
-
-    DEBUG_ONLY(c->verify(true);)
-
-    UL2(debug, "new root chunk " METACHUNK_FORMAT ".", METACHUNK_FORMAT_ARGS(c));
-
-    return c;
-
-  }
-
-  return NULL; // Node is full.
-
-}
-
-// Given a chunk c, split it recursively until you get a chunk of the given target_level.
-//
-// The resulting target chunk resides at the same address as the original chunk.
-// The resulting splinters are added to freelists.
-void VirtualSpaceNode::split(chunklevel_t target_level, Metachunk* c, FreeChunkListVector* freelists) {
-
-  assert_lock_strong(MetaspaceExpand_lock);
-
-  // Get the area associated with this chunk and let it handle the splitting
-  RootChunkArea* rca = _root_chunk_area_lut.get_area_by_address(c->base());
-
-  DEBUG_ONLY(rca->verify_area_is_ideally_merged();)
-
-  rca->split(target_level, c, freelists);
-
-}
-
-// Given a chunk, attempt to merge it recursively with its neighboring chunks.
-//
-// If successful (merged at least once), returns address of
-// the merged chunk; NULL otherwise.
-//
-// The merged chunks are removed from the freelists.
-//
-// !!! Please note that if this method returns a non-NULL value, the
-// original chunk will be invalid and should not be accessed anymore! !!!
-Metachunk* VirtualSpaceNode::merge(Metachunk* c, FreeChunkListVector* freelists) {
-
-  assert(c != NULL && c->is_free(), "Sanity");
-  assert_lock_strong(MetaspaceExpand_lock);
-
-  // Get the rca associated with this chunk and let it handle the merging
-  RootChunkArea* rca = _root_chunk_area_lut.get_area_by_address(c->base());
-
-  Metachunk* c2 = rca->merge(c, freelists);
-
-  DEBUG_ONLY(rca->verify_area_is_ideally_merged();)
-
-  return c2;
-
-}
-
-// Given a chunk c, which must be "in use" and must not be a root chunk, attempt to
-// enlarge it in place by claiming its trailing buddy.
-//
-// This will only work if c is the leader of the buddy pair and the trailing buddy is free.
-//
-// If successful, the follower chunk will be removed from the freelists, the leader chunk c will
-// double in size (level decreased by one).
-//
-// On success, true is returned, false otherwise.
-bool VirtualSpaceNode::attempt_enlarge_chunk(Metachunk* c, FreeChunkListVector* freelists) {
-
-  assert(c != NULL && c->is_in_use() && !c->is_root_chunk(), "Sanity");
-  assert_lock_strong(MetaspaceExpand_lock);
-
-  // Get the rca associated with this chunk and let it handle the merging
-  RootChunkArea* rca = _root_chunk_area_lut.get_area_by_address(c->base());
-
-  bool rc = rca->attempt_enlarge_chunk(c, freelists);
-
-  DEBUG_ONLY(rca->verify_area_is_ideally_merged();)
-
-  if (rc) {
-    InternalStats::inc_num_chunks_enlarged();
-  }
-
-  return rc;
-
-}
-
-// Attempts to purge the node:
-//
-// If all chunks living in this node are free, they will all be removed from
-//  the freelist they currently reside in. Then, the node will be deleted.
-//
-// Returns true if the node has been deleted, false if not.
-// !! If this returns true, do not access the node from this point on. !!
-bool VirtualSpaceNode::attempt_purge(FreeChunkListVector* freelists) {
-
-  assert_lock_strong(MetaspaceExpand_lock);
-
-  if (!_owns_rs) {
-    // We do not allow purging of nodes if we do not own the
-    // underlying ReservedSpace (CompressClassSpace case).
-    return false;
-  }
-
-  // First find out if all areas are empty. Since empty chunks collapse to root chunk
-  // size, if all chunks in this node are free root chunks we are good to go.
-  if (!_root_chunk_area_lut.is_free()) {
-    return false;
-  }
-
-  UL(debug, ": purging.");
-
-  // Okay, we can purge. Before we can do this, we need to remove all chunks from the freelist.
-  for (int narea = 0; narea < _root_chunk_area_lut.number_of_areas(); narea ++) {
-    RootChunkArea* ra = _root_chunk_area_lut.get_area_by_index(narea);
-    Metachunk* c = ra->first_chunk();
-    if (c != NULL) {
-      UL2(trace, "removing chunk from to-be-purged node: "
-          METACHUNK_FULL_FORMAT ".", METACHUNK_FULL_FORMAT_ARGS(c));
-      assert(c->is_free() && c->is_root_chunk(), "Sanity");
-      freelists->remove(c);
-    }
-  }
-
-  // Now, delete the node, then right away return since this object is invalid.
-  delete this;
-
-  return true;
-
-}
-
-
-void VirtualSpaceNode::print_on(outputStream* st) const {
-
-  size_t scale = K;
-
-  st->print("base " PTR_FORMAT ": ", p2i(base()));
-  st->print("reserved=");
-  print_scaled_words(st, word_size(), scale);
-  st->print(", committed=");
-  print_scaled_words_and_percentage(st, committed_words(), word_size(), scale);
-  st->print(", used=");
-  print_scaled_words_and_percentage(st, used_words(), word_size(), scale);
-
-  st->cr();
-  _root_chunk_area_lut.print_on(st);
-  _commit_mask.print_on(st);
-
-}
-
-// Returns size, in words, of committed space in this node alone.
-// Note: iterates over commit mask and hence may be a tad expensive on large nodes.
-size_t VirtualSpaceNode::committed_words() const {
-  return _commit_mask.get_committed_size();
-}
-
-#ifdef ASSERT
-void VirtualSpaceNode::verify(bool slow) const {
-  MutexLocker fcl(MetaspaceExpand_lock, Mutex::_no_safepoint_check_flag);
-  verify_locked(slow);
-}
-
-// Verify counters and basic structure. Slow mode: verify all chunks in depth
-void VirtualSpaceNode::verify_locked(bool slow) const {
-
-  assert_lock_strong(MetaspaceExpand_lock);
-
-  assert(base() != NULL, "Invalid base");
-  assert(base() == (MetaWord*)_rs.base() &&
-         word_size() == _rs.size() / BytesPerWord,
-         "Sanity");
-  assert_is_aligned(base(), chunklevel::MAX_CHUNK_BYTE_SIZE);
-  assert(used_words() <= word_size(), "Sanity");
-
-  // Since we only ever hand out root chunks from a vsnode, top should always be aligned
-  // to root chunk size.
-  assert_is_aligned(used_words(), chunklevel::MAX_CHUNK_WORD_SIZE);
-
-  _commit_mask.verify(slow);
-  assert(committed_words() <= word_size(), "Sanity");
-  assert_is_aligned(committed_words(), Settings::commit_granule_words());
-  _root_chunk_area_lut.verify(slow);
-
-}
-
-#endif
-
-
-} // namespace metaspace
--- old/src/hotspot/share/memory/metaspace/virtualSpaceNode.hpp	2020-09-04 13:58:40.593698236 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,293 +0,0 @@
-/*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#ifndef SHARE_MEMORY_METASPACE_VIRTUALSPACENODE_HPP
-#define SHARE_MEMORY_METASPACE_VIRTUALSPACENODE_HPP
-
-
-#include "memory/allocation.hpp"
-#include "memory/metaspace/counter.hpp"
-#include "memory/metaspace/commitMask.hpp"
-#include "memory/metaspace/rootChunkArea.hpp"
-#include "memory/metaspace/settings.hpp"
-#include "memory/memRegion.hpp"
-#include "memory/virtualspace.hpp"
-#include "utilities/debug.hpp"
-#include "utilities/bitMap.hpp"
-#include "utilities/globalDefinitions.hpp"
-
-
-class outputStream;
-
-namespace metaspace {
-
-class CommitLimiter;
-class FreeChunkListVector;
-
-// VirtualSpaceNode manages a single contiguous address range of metaspace. Logically that memory
-//  region is split up into a sequence of "root chunk areas", each one containing one root chunk
-//  or splinters of a root chunk.
-//
-// The underlying memory is also logically divided into a number of "commit granules", units of memory
-//  which may be committed or uncommitted independently from each other.
-//
-// (Both root chunk areas and commit granules have not much to do with each other - one is a way to
-//   reserve memory for the upper regions, see ChunkManager. One is a way to manage commited memory.)
-//
-// VirtualSpaceNode:
-//  - exposes a function to allocate a new root chunk (see VirtualSpaceNode::allocate_root_chunk()).
-//
-//  - knows about the commit state of the memory region - which commit granule are committed, which
-//    are not. It exposes functions to commit and uncommit regions (without actively committing
-//    itself)
-//
-//  - It has a reference to a "CommitLimiter", an interface to query whether committing is
-//    possible. That interface hides the various ways committing may be limited (GC threshold,
-//    MaxMetaspaceSize, ...)
-//
-//  - It uses ReservedSpace to reserve its memory. It either owns the ReservedSpace or that
-//    space got handed in from outside (ccs).
-//
-//
-//
-//
-// | root chunk area               | root chunk area               | root chunk area               | <-- root chunk areas
-//
-// +-----------------------------------------------------------------------------------------------+
-// |                                                                                               |
-// |                                   `VirtualSpaceNode` memory                                   |
-// |                                                                                               |
-// +-----------------------------------------------------------------------------------------------+
-//
-// |x| |x|x|x| | | | |x|x|x| | | |x|x| | | |x|x|x|x| | | | | | | | |x| | | |x|x|x|x| | | |x| | | |x| <-- commit granules
-//
-// (x = committed)
-//
-
-class VirtualSpaceNode : public CHeapObj<mtClass> {
-
-  // Link to next VirtualSpaceNode
-  VirtualSpaceNode* _next;
-
-  // The underlying space. This has been either created by this node
-  //  and is owned by it, or has been handed in from outside (e.g. in
-  //  case of CompressedClassSpace).
-  ReservedSpace _rs;
-
-  // True if the node owns the reserved space, false if not.
-  const bool _owns_rs;
-
-  // Start pointer of the area.
-  MetaWord* const _base;
-
-  // Size, in words, of the whole node
-  const size_t _word_size;
-
-  // Size, in words, of the range of this node which has been handed out in
-  // the form of root chunks.
-  size_t _used_words;
-
-  // The bitmap describing the commit state of the region:
-  // Each bit covers a region of 64K (see constants::commit_granule_size).
-  CommitMask _commit_mask;
-
-  // An array/lookup table of RootChunkArea objects. Each one describes a root chunk area.
-  RootChunkAreaLUT _root_chunk_area_lut;
-
-  // Limiter object to ask before expanding the committed size of this node.
-  CommitLimiter* const _commit_limiter;
-
-  // Points to outside size counters which we are to increase/decrease when we commit/uncommit
-  // space from this node.
-  SizeCounter* const _total_reserved_words_counter;
-  SizeCounter* const _total_committed_words_counter;
-
-  /// committing, uncommitting ///
-
-  // Given a pointer into this node, calculate the start of the commit granule
-  // the pointer points into.
-  MetaWord* calc_start_of_granule(MetaWord* p) const {
-    DEBUG_ONLY(check_pointer(p));
-    return align_down(p, Settings::commit_granule_bytes());
-  }
-
-  // Given an address range, ensure it is committed.
-  //
-  // The range has to be aligned to granule size.
-  //
-  // Function will:
-  // - check how many granules in that region are uncommitted; If all are committed, it
-  //    returns true immediately.
-  // - check if committing those uncommitted granules would bring us over the commit limit
-  //    (GC threshold, MaxMetaspaceSize). If true, it returns false.
-  // - commit the memory.
-  // - mark the range as committed in the commit mask
-  //
-  // Returns true if success, false if it did hit a commit limit.
-  bool commit_range(MetaWord* p, size_t word_size);
-
-  //// creation ////
-
-  // Create a new empty node spanning the given given reserved space.
-  VirtualSpaceNode(ReservedSpace rs, bool owns_rs, CommitLimiter* limiter,
-                   SizeCounter* reserve_counter, SizeCounter* commit_counter);
-
-public:
-
-  // Create a node of a given size (it will create its own space).
-  static VirtualSpaceNode* create_node(size_t word_size, CommitLimiter* limiter, SizeCounter* reserve_words_counter,
-                                       SizeCounter* commit_words_counter);
-
-  // Create a node over an existing space
-  static VirtualSpaceNode* create_node(ReservedSpace rs, CommitLimiter* limiter, SizeCounter* reserve_words_counter,
-                                       SizeCounter* commit_words_counter);
-
-  ~VirtualSpaceNode();
-
-  // Note: public for gtests only, could be private.
-  MetaWord* base() const        { return _base; }
-
-  // Reserved size of the whole node.
-  size_t word_size() const      { return _word_size; }
-
-  //// Chunk allocation, splitting, merging /////
-
-  // Allocate a root chunk from this node. Will fail and return NULL if the node is full
-  //  - if we used up the whole address space of this node's memory region.
-  //    (in case this node backs compressed class space, this is how we hit
-  //     CompressedClassSpaceSize).
-  // Note that this just returns reserved memory; caller must take care of committing this
-  //  chunk before using it.
-  Metachunk* allocate_root_chunk();
-
-  // Given a chunk c, split it recursively until you get a chunk of the given target_level.
-  //
-  // The resulting target chunk resides at the same address as the original chunk.
-  // The resulting splinters are added to freelists.
-  void split(chunklevel_t target_level, Metachunk* c, FreeChunkListVector* freelists);
-
-  // Given a chunk, attempt to merge it recursively with its neighboring chunks.
-  //
-  // If successful (merged at least once), returns address of
-  // the merged chunk; NULL otherwise.
-  //
-  // The merged chunks are removed from the freelists.
-  //
-  // !!! Please note that if this method returns a non-NULL value, the
-  // original chunk will be invalid and should not be accessed anymore! !!!
-  Metachunk* merge(Metachunk* c, FreeChunkListVector* freelists);
-
-  // Given a chunk c, which must be "in use" and must not be a root chunk, attempt to
-  // enlarge it in place by claiming its trailing buddy.
-  //
-  // This will only work if c is the leader of the buddy pair and the trailing buddy is free.
-  //
-  // If successful, the follower chunk will be removed from the freelists, the leader chunk c will
-  // double in size (level decreased by one).
-  //
-  // On success, true is returned, false otherwise.
-  bool attempt_enlarge_chunk(Metachunk* c, FreeChunkListVector* freelists);
-
-  // Attempts to purge the node:
-  //
-  // If all chunks living in this node are free, they will all be removed from
-  //  the freelist they currently reside in. Then, the node will be deleted.
-  //
-  // Returns true if the node has been deleted, false if not.
-  // !! If this returns true, do not access the node from this point on. !!
-  bool attempt_purge(FreeChunkListVector* freelists);
-
-  // Attempts to uncommit free areas according to the rules set in settings.
-  // Returns number of words uncommitted.
-  size_t uncommit_free_areas();
-
-  /// misc /////
-
-  // Returns size, in words, of the used space in this node alone.
-  // (Notes:
-  //  - This is the space handed out to the ChunkManager, so it is "used" from the viewpoint of this node,
-  //    but not necessarily used for Metadata.
-  //  - This may or may not be committed memory.
-  size_t used_words() const             { return _used_words; }
-
-  // Returns size, in words, of how much space is left in this node alone.
-  size_t free_words() const             { return _word_size - _used_words; }
-
-  // Returns size, in words, of committed space in this node alone.
-  // Note: iterates over commit mask and hence may be a tad expensive on large nodes.
-  size_t committed_words() const;
-
-  //// Committing/uncommitting memory /////
-
-  // Given an address range, ensure it is committed.
-  //
-  // The range does not have to be aligned to granule size. However, the function will always commit
-  // whole granules.
-  //
-  // Function will:
-  // - check how many granules in that region are uncommitted; If all are committed, it
-  //    returns true immediately.
-  // - check if committing those uncommitted granules would bring us over the commit limit
-  //    (GC threshold, MaxMetaspaceSize). If true, it returns false.
-  // - commit the memory.
-  // - mark the range as committed in the commit mask
-  //
-  // Returns true if success, false if it did hit a commit limit.
-  bool ensure_range_is_committed(MetaWord* p, size_t word_size);
-
-  // Given an address range (which has to be aligned to commit granule size):
-  //  - uncommit it
-  //  - mark it as uncommitted in the commit mask
-  void uncommit_range(MetaWord* p, size_t word_size);
-
-  //// List stuff ////
-  VirtualSpaceNode* next() const        { return _next; }
-  void set_next(VirtualSpaceNode* vsn)  { _next = vsn; }
-
-
-  /// Debug stuff ////
-
-  // Print a description about this node.
-  void print_on(outputStream* st) const;
-
-  // Verify counters and basic structure. Slow mode: verify all chunks in depth
-  bool contains(const MetaWord* p) const {
-    return p >= _base && p < _base + _used_words;
-  }
-
-#ifdef ASSERT
-  void check_pointer(const MetaWord* p) const {
-    assert(contains(p), "invalid pointer");
-  }
-  void verify(bool slow) const;
-  void verify_locked(bool slow) const;
-#endif
-
-};
-
-
-} // namespace metaspace
-
-#endif // SHARE_MEMORY_METASPACE_VIRTUALSPACENODE_HPP
--- old/test/hotspot/gtest/metaspace/metaspaceTestContexts.cpp	2020-09-04 13:58:41.005701155 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,173 +0,0 @@
-/*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-
-#include "precompiled.hpp"
-#include "metaspace/metaspaceTestsCommon.hpp"
-#include "metaspace/metaspaceTestContexts.hpp"
-
-using namespace metaspace::chunklevel;
-
-
-void ChunkTestsContext::checked_alloc_chunk_0(Metachunk** p_return_value, chunklevel_t preferred_level, chunklevel_t max_level,
-                                                      size_t min_committed_size) {
-
-  *p_return_value = NULL;
-
-  Metachunk* c = cm().get_chunk(preferred_level, max_level, min_committed_size);
-
-  if (c != NULL) {
-
-    ASSERT_LE(c->level(), max_level);
-    ASSERT_GE(c->level(), preferred_level);
-    ASSERT_GE(c->committed_words(), min_committed_size);
-    ASSERT_EQ(c->committed_words(), c->free_below_committed_words());
-    ASSERT_EQ(c->used_words(), (size_t)0);
-    ASSERT_TRUE(c->is_in_use());
-    ASSERT_FALSE(c->is_free());
-    ASSERT_FALSE(c->is_dead());
-    ASSERT_NULL(c->next());
-    ASSERT_NULL(c->prev());
-    if (c->level() == HIGHEST_CHUNK_LEVEL) {
-      ASSERT_TRUE(c->is_leaf_chunk());
-    } else {
-      ASSERT_FALSE(c->is_leaf_chunk());
-    }
-    if (c->level() == LOWEST_CHUNK_LEVEL) {
-      ASSERT_TRUE(c->is_root_chunk());
-    } else {
-      ASSERT_FALSE(c->is_root_chunk());
-    }
-    if (_num_chunks_allocated == 0) { // First chunk? We can make more assumptions
-      ASSERT_EQ(c->level(), preferred_level);
-      // Needs lock EXPECT_NULL(c->next_in_vs());
-      // Needs lock EXPECT_NULL(c->prev_in_vs());
-      ASSERT_TRUE(c->is_root_chunk() || c->is_leader());
-    }
-    _num_chunks_allocated ++;
-
-  }
-
-  *p_return_value = c;
-
-}
-
-// Test pattern established when allocating from the chunk with allocate_from_chunk_with_tests().
-void ChunkTestsContext::test_pattern(Metachunk* c, size_t word_size) {
-  check_range_for_pattern(c->base(), word_size, (uintx)c);
-}
-
-void ChunkTestsContext::return_chunk(Metachunk* c) {
-  test_pattern(c);
-  c->set_in_use(); // Forestall assert in cm
-  cm().return_chunk(c);
-}
-
- void ChunkTestsContext::allocate_from_chunk(MetaWord** p_return_value, Metachunk* c, size_t word_size) {
-
-  size_t used_before = c->used_words();
-  size_t free_before = c->free_words();
-  size_t free_below_committed_before = c->free_below_committed_words();
-  const MetaWord* top_before = c->top();
-
-  MetaWord* p = c->allocate(word_size);
-  EXPECT_NOT_NULL(p);
-  EXPECT_EQ(c->used_words(), used_before + word_size);
-  EXPECT_EQ(c->free_words(), free_before - word_size);
-  EXPECT_EQ(c->free_below_committed_words(), free_below_committed_before - word_size);
-  EXPECT_EQ(c->top(), top_before + word_size);
-
-  // Old content should be preserved
-  test_pattern(c, used_before);
-
-  // Fill newly allocated range too
-  fill_range_with_pattern(p, word_size, (uintx)c);
-
-  *p_return_value = p;
-}
-
-void ChunkTestsContext::commit_chunk_with_test(Metachunk* c, size_t additional_size) {
-
-  size_t used_before = c->used_words();
-  size_t free_before = c->free_words();
-  const MetaWord* top_before = c->top();
-
-  c->set_in_use();
-  bool b = c->ensure_committed_additional(additional_size);
-  EXPECT_TRUE(b);
-
-  // We should have enough committed size now
-  EXPECT_GE(c->free_below_committed_words(), additional_size);
-
-  // used, free, top should be unchanged.
-  EXPECT_EQ(c->used_words(), used_before);
-  EXPECT_EQ(c->free_words(), free_before);
-  EXPECT_EQ(c->top(), top_before);
-
-  test_pattern(c, used_before);
-
-}
-
-void ChunkTestsContext::commit_chunk_expect_failure(Metachunk* c, size_t additional_size) {
-
-  size_t used_before = c->used_words();
-  size_t free_before = c->free_words();
-  size_t free_below_committed_before = c->free_below_committed_words();
-  const MetaWord* top_before = c->top();
-
-  c->set_in_use();
-  bool b = c->ensure_committed_additional(additional_size);
-  EXPECT_FALSE(b);
-
-  // Nothing should have changed
-  EXPECT_EQ(c->used_words(), used_before);
-  EXPECT_EQ(c->free_words(), free_before);
-  EXPECT_EQ(c->free_below_committed_words(), free_below_committed_before);
-  EXPECT_EQ(c->top(), top_before);
-
-  test_pattern(c, used_before);
-
-}
-
-void ChunkTestsContext::uncommit_chunk_with_test(Metachunk* c) {
-  if (c->word_size() >= Settings::commit_granule_words()) {
-    c->set_free();  // Forestall assert in uncommit
-    c->reset_used_words();
-    c->uncommit();
-
-    EXPECT_EQ(c->free_below_committed_words(), (size_t)0);
-    EXPECT_EQ(c->used_words(), (size_t)0);
-    EXPECT_EQ(c->free_words(), c->word_size());
-    EXPECT_EQ(c->top(), c->base());
-    EXPECT_TRUE(c->is_fully_uncommitted());
-  }
-}
-
-
-
-/////// SparseArray<T> ////////////////
-
-
-
--- old/test/hotspot/gtest/metaspace/metaspaceTestContexts.hpp	2020-09-04 13:58:41.413704047 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,123 +0,0 @@
-/*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#ifndef GTEST_METASPACE_METASPACE_TESTHELPER_HPP
-#define GTEST_METASPACE_METASPACE_TESTHELPER_HPP
-
-#include "memory/allocation.hpp"
-#include "metaspace/metaspaceTestsCommon.hpp"
-
-using namespace metaspace::chunklevel;
-
-class MetaspaceTestContext : public metaspace::MetaspaceTestContext {
-public:
-  MetaspaceTestContext(size_t commit_limit = 0, size_t reserve_limit = 0)
-  : metaspace::MetaspaceTestContext("gtest-metaspace-context", commit_limit, reserve_limit)
-  {}
-};
-
-class ChunkTestsContext : public metaspace::MetaspaceTestContext {
-
-  int _num_chunks_allocated;
-
-  void checked_alloc_chunk_0(Metachunk** p_return_value, chunklevel_t preferred_level,
-                             chunklevel_t max_level, size_t min_committed_size);
-
-  // Test pattern established when allocating from the chunk with allocate_from_chunk_with_tests().
-  void test_pattern(Metachunk* c, size_t word_size);
-  void test_pattern(Metachunk* c) { test_pattern(c, c->used_words()); }
-
-public:
-
-  ChunkTestsContext(size_t commit_limit = 0, size_t reserve_limit = 0)
-    : metaspace::MetaspaceTestContext("metaspace-gtest-chunktestcontext", commit_limit, reserve_limit),
-      _num_chunks_allocated(0)
-  {}
-
-  /////
-
-  // Note: all test functions return void and return values are by pointer ref; this is awkward but otherwise we cannot
-  // use gtest ASSERT macros inside those functions.
-
-  // Allocate a chunk (you do not know if it will succeed).
-  void alloc_chunk(Metachunk** p_return_value, chunklevel_t preferred_level, chunklevel_t max_level, size_t min_committed_size) {
-    checked_alloc_chunk_0(p_return_value, preferred_level, max_level, min_committed_size);
-  }
-
-  // Allocate a chunk; do not expect success, but if it succeeds, test the chunk.
-  void alloc_chunk(Metachunk** p_return_value, chunklevel_t level) {
-    alloc_chunk(p_return_value, level, level, word_size_for_level(level));
-  }
-
-  // Allocate a chunk; it must succeed. Test the chunk.
-  void alloc_chunk_expect_success(Metachunk** p_return_value, chunklevel_t preferred_level, chunklevel_t max_level, size_t min_committed_size) {
-    checked_alloc_chunk_0(p_return_value, preferred_level, max_level, min_committed_size);
-    ASSERT_NOT_NULL(*p_return_value);
-  }
-
-  // Allocate a chunk; it must succeed. Test the chunk.
-  void alloc_chunk_expect_success(Metachunk** p_return_value, chunklevel_t level) {
-    alloc_chunk_expect_success(p_return_value, level, level, word_size_for_level(level));
-  }
-
-  // Allocate a chunk but expect it to fail.
-  void alloc_chunk_expect_failure(chunklevel_t preferred_level, chunklevel_t max_level, size_t min_committed_size) {
-    Metachunk* c = NULL;
-    checked_alloc_chunk_0(&c, preferred_level, max_level, min_committed_size);
-    ASSERT_NULL(c);
-  }
-
-  // Allocate a chunk but expect it to fail.
-  void alloc_chunk_expect_failure(chunklevel_t level) {
-    return alloc_chunk_expect_failure(level, level, word_size_for_level(level));
-  }
-
-  /////
-
-  void return_chunk(Metachunk* c);
-
-  /////
-
-  // Allocates from a chunk; also, fills allocated area with test pattern which will be tested with test_pattern().
-  void allocate_from_chunk(MetaWord** p_return_value, Metachunk* c, size_t word_size);
-
-  // Convenience function: allocate from chunk for when you don't care for the result pointer
-  void allocate_from_chunk(Metachunk* c, size_t word_size) {
-    MetaWord* dummy;
-    allocate_from_chunk(&dummy, c, word_size);
-  }
-
-  void commit_chunk_with_test(Metachunk* c, size_t additional_size);
-  void commit_chunk_expect_failure(Metachunk* c, size_t additional_size);
-
-  void uncommit_chunk_with_test(Metachunk* c);
-
-
-};
-
-
-#endif // GTEST_METASPACE_METASPACE_TESTHELPER_HPP
-
-
--- old/test/hotspot/gtest/metaspace/metaspaceTestsCommon.cpp	2020-09-04 13:58:41.817706911 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,103 +0,0 @@
-/*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#include "precompiled.hpp"
-
-#include "metaspaceTestsCommon.hpp"
-#include "metaspace/metaspace_rangehelpers.hpp"
-
-#include "utilities/debug.hpp"
-#include "utilities/globalDefinitions.hpp"
-
-
-void zap_range(MetaWord* p, size_t word_size) {
-  for (MetaWord* pzap = p; pzap < p + word_size; pzap += os::vm_page_size() / BytesPerWord) {
-    *pzap = (MetaWord)NOT_LP64(0xFEFEFEFE) LP64_ONLY(0xFEFEFEFEEFEFEFEFULL);
-  }
-}
-
-// Writes a uniqe pattern to p
-void mark_address(MetaWord* p, uintx pattern) {
-  MetaWord x = (MetaWord)((uintx) p ^ pattern);
-  *p = x;
-}
-
-// checks pattern at address
-void check_marked_address(const MetaWord* p, uintx pattern) {
-  MetaWord x = (MetaWord)((uintx) p ^ pattern);
-  EXPECT_EQ(*p, x);
-}
-
-// "fill_range_with_pattern" fills a range of heap words with pointers to itself.
-//
-// The idea is to fill a memory range with a pattern which is both marked clearly to the caller
-// and cannot be moved without becoming invalid.
-//
-// The filled range can be checked with check_range_for_pattern. One also can only check
-// a sub range of the original range.
-void fill_range_with_pattern(MetaWord* p, size_t word_size, uintx pattern) {
-  assert(word_size > 0 && p != NULL, "sanity");
-  for (MetaWord* p2 = p; p2 < p + word_size; p2 ++) {
-    mark_address(p2, pattern);
-  }
-}
-
-void check_range_for_pattern(const MetaWord* p, size_t word_size, uintx pattern) {
-  assert(p != NULL, "sanity");
-  const MetaWord* p2 = p;
-  while (p2 < p + word_size) {
-    check_marked_address(p2, pattern);
-    p2 ++;
-  }
-}
-
-
-// Similar to fill_range_with_pattern, but only marks start and end. This is optimized for cases
-// where fill_range_with_pattern just is too slow.
-// Use check_marked_range to check the range. In contrast to check_range_for_pattern, only the original
-// range can be checked.
-void mark_range(MetaWord* p, size_t word_size, uintx pattern) {
-  assert(word_size > 0 && p != NULL, "sanity");
-  mark_address(p, pattern);
-  mark_address(p + word_size - 1, pattern);
-}
-
-void check_marked_range(const MetaWord* p, size_t word_size, uintx pattern) {
-  assert(word_size > 0 && p != NULL, "sanity");
-  check_marked_address(p, pattern);
-  check_marked_address(p + word_size - 1, pattern);
-}
-
-void mark_range(MetaWord* p, size_t word_size) {
-  assert(word_size > 0 && p != NULL, "sanity");
-  uintx pattern = (uintx)p2i(p);
-  mark_range(p, word_size, pattern);
-}
-
-void check_marked_range(const MetaWord* p, size_t word_size) {
-  uintx pattern = (uintx)p2i(p);
-  check_marked_range(p, word_size, pattern);
-}
-
--- old/test/hotspot/gtest/metaspace/metaspaceTestsCommon.hpp	2020-09-04 13:58:42.225709806 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,273 +0,0 @@
-/*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#ifndef GTEST_METASPACE_METASPACETESTCOMMON_HPP
-#define GTEST_METASPACE_METASPACETESTCOMMON_HPP
-
-#include "memory/allocation.hpp"
-
-
-#include "memory/metaspace/arenaGrowthPolicy.hpp"
-#include "memory/metaspace/binlist.hpp"
-#include "memory/metaspace/blocktree.hpp"
-#include "memory/metaspace/chunkHeaderPool.hpp"
-#include "memory/metaspace/chunkLevel.hpp"
-#include "memory/metaspace/chunkManager.hpp"
-#include "memory/metaspace/counter.hpp"
-#include "memory/metaspace/commitLimiter.hpp"
-#include "memory/metaspace/commitMask.hpp"
-#include "memory/metaspace/freeBlocks.hpp"
-#include "memory/metaspace/freeChunkList.hpp"
-#include "memory/metaspace/internStat.hpp"
-#include "memory/metaspace/metachunk.hpp"
-#include "memory/metaspace/metaspaceArena.hpp"
-#include "memory/metaspace/metaspaceCommon.hpp"
-#include "memory/metaspace/metaspaceEnums.hpp"
-#include "memory/metaspace/metaspaceStatistics.hpp"
-#include "memory/metaspace/metaspace_test.hpp"
-#include "memory/metaspace/virtualSpaceList.hpp"
-#include "memory/metaspace/settings.hpp"
-#include "runtime/mutexLocker.hpp"
-#include "runtime/os.hpp"
-
-#include "utilities/align.hpp"
-#include "utilities/debug.hpp"
-#include "utilities/globalDefinitions.hpp"
-
-#include "unittest.hpp"
-
-
-#include <stdio.h>
-
-
-//////////////////////////////////////////////////////////
-// handy aliases
-
-using metaspace::BinListImpl;
-using metaspace::BlockTree;
-using metaspace::ArenaGrowthPolicy;
-using metaspace::ChunkHeaderPool;
-using metaspace::ChunkManager;
-using metaspace::CommitLimiter;
-using metaspace::CommitMask;
-using metaspace::SizeCounter;
-using metaspace::SizeAtomicCounter;
-using metaspace::IntCounter;
-using metaspace::FreeBlocks;
-using metaspace::FreeChunkList;
-using metaspace::FreeChunkListVector;
-using metaspace::MemRangeCounter;
-using metaspace::Metachunk;
-using metaspace::MetachunkList;
-using metaspace::Settings;
-using metaspace::arena_stats_t;
-using metaspace::in_use_chunk_stats_t;
-using metaspace::cm_stats_t;
-using metaspace::SizeCounter;
-using metaspace::MetaspaceArena;
-using metaspace::VirtualSpaceList;
-using metaspace::VirtualSpaceNode;
-
-using metaspace::chunklevel_t;
-using namespace metaspace::chunklevel;
-
-
-/////////////////////////////////////////////////////////////////////
-// A little mockup to mimick and test the CommitMask in various tests
-
-class TestMap {
-  const size_t _len;
-  char* _arr;
-public:
-  TestMap(size_t len) : _len(len), _arr(NULL) {
-    _arr = NEW_C_HEAP_ARRAY(char, len, mtInternal);
-    memset(_arr, 0, _len);
-  }
-  ~TestMap() { FREE_C_HEAP_ARRAY(char, _arr); }
-
-  int get_num_set(size_t from, size_t to) const {
-    int result = 0;
-    for(size_t i = from; i < to; i ++) {
-      if (_arr[i] > 0) {
-        result ++;
-      }
-    }
-    return result;
-  }
-
-  size_t get_num_set() const { return get_num_set(0, _len); }
-
-  void set_range(size_t from, size_t to) {
-    memset(_arr + from, 1, to - from);
-  }
-
-  void clear_range(size_t from, size_t to) {
-    memset(_arr + from, 0, to - from);
-  }
-
-  bool at(size_t pos) const {
-    return _arr[pos] == 1;
-  }
-
-};
-
-
-///////////////////////////////////////////////////////////
-// Helper class for generating random allocation sizes
-class RandSizeGenerator {
-  const size_t _min; // [
-  const size_t _max; // )
-  const float _outlier_chance; // 0.0 -- 1.0
-  const size_t _outlier_min; // [
-  const size_t _outlier_max; // )
-public:
-  RandSizeGenerator(size_t min, size_t max)
-    : _min(min), _max(max), _outlier_chance(0.0), _outlier_min(min), _outlier_max(max)
-  {}
-
-  RandSizeGenerator(size_t min, size_t max, float outlier_chance, size_t outlier_min, size_t outlier_max)
-    : _min(min), _max(max), _outlier_chance(outlier_chance), _outlier_min(outlier_min), _outlier_max(outlier_max)
-  {}
-
-  size_t min() const { return _min; }
-  size_t max() const { return _max; }
-
-  size_t get() const {
-    size_t l1 = _min;
-    size_t l2 = _max;
-    int r = os::random() % 1000;
-    if ((float)r < _outlier_chance * 1000.0) {
-      l1 = _outlier_min;
-      l2 = _outlier_max;
-    }
-    const size_t d = l2 - l1;
-    return l1 + (os::random() % d);
-  }
-
-}; // end RandSizeGenerator
-
-size_t get_random_size(size_t min, size_t max);
-
-///////////////////////////////////////////////////////////
-// Function to test-access a memory range
-
-void zap_range(MetaWord* p, size_t word_size);
-
-// "fill_range_with_pattern" fills a range of heap words with pointers to itself.
-//
-// The idea is to fill a memory range with a pattern which is both marked clearly to the caller
-// and cannot be moved without becoming invalid.
-//
-// The filled range can be checked with check_range_for_pattern. One also can only check
-// a sub range of the original range.
-void fill_range_with_pattern(MetaWord* p, uintx pattern, size_t word_size);
-void check_range_for_pattern(const MetaWord* p, uintx pattern, size_t word_size);
-
-// Writes a uniqe pattern to p
-void mark_address(MetaWord* p, uintx pattern);
-// checks pattern at address
-void check_marked_address(const MetaWord* p, uintx pattern);
-
-// Similar to fill_range_with_pattern, but only marks start and end. This is optimized for cases
-// where fill_range_with_pattern just is too slow.
-// Use check_marked_range to check the range. In contrast to check_range_for_pattern, only the original
-// range can be checked.
-void mark_range(MetaWord* p, uintx pattern, size_t word_size);
-void check_marked_range(const MetaWord* p, uintx pattern, size_t word_size);
-
-void mark_range(MetaWord* p, size_t word_size);
-void check_marked_range(const MetaWord* p, size_t word_size);
-
-//////////////////////////////////////////////////////////
-// Some helpers to avoid typing out those annoying casts for NULL
-
-#define ASSERT_NOT_NULL(ptr)      ASSERT_NE((void*)NULL, (void*)ptr)
-#define ASSERT_NULL(ptr)          ASSERT_EQ((void*)NULL, (void*)ptr)
-#define EXPECT_NOT_NULL(ptr)      EXPECT_NE((void*)NULL, (void*)ptr)
-#define EXPECT_NULL(ptr)          EXPECT_EQ((void*)NULL, (void*)ptr)
-
-#define ASSERT_0(v)               ASSERT_EQ((intptr_t)0, (intptr_t)v)
-#define ASSERT_NOT_0(v)           ASSERT_NE((intptr_t)0, (intptr_t)v)
-#define EXPECT_0(v)               EXPECT_EQ((intptr_t)0, (intptr_t)v)
-#define EXPECT_NOT_0(v)           EXPECT_NE((intptr_t)0, (intptr_t)v)
-
-//////////////////////////////////////////////////////////
-// logging
-
-// Define "LOG_PLEASE" to switch on logging for a particular test before inclusion of this header.
-#ifdef LOG_PLEASE
-  #define LOG(...) { printf(__VA_ARGS__); printf("\n"); fflush(stdout); }
-#else
-  #define LOG(...)
-#endif
-
-//////////////////////////////////////////////////////////
-// Helper
-
-size_t get_workingset_size();
-
-// A simple preallocated buffer used to "feed" someone.
-// Mimicks chunk retirement leftover blocks.
-class FeederBuffer {
-
-  MetaWord* _buf;
-
-  // Buffer capacity in size of words.
-  const size_t _cap;
-
-  // Used words.
-  size_t _used;
-
-public:
-
-  FeederBuffer(size_t size) : _buf(NULL), _cap(size), _used(0) {
-    _buf = NEW_C_HEAP_ARRAY(MetaWord, _cap, mtInternal);
-  }
-
-  ~FeederBuffer() {
-    FREE_C_HEAP_ARRAY(MetaWord, _buf);
-  }
-
-  MetaWord* get(size_t word_size) {
-    if (_used + word_size > _cap) {
-      return NULL;
-    }
-    MetaWord* p = _buf + _used;
-    _used += word_size;
-    return p;
-  }
-
-  bool is_valid_pointer(MetaWord* p) const {
-    return p >= _buf && p < _buf + _used;
-  }
-
-  bool is_valid_range(MetaWord* p, size_t word_size) const {
-    return is_valid_pointer(p) &&
-           word_size > 0 ? is_valid_pointer(p + word_size - 1) : true;
-  }
-
-};
-
-#endif // GTEST_METASPACE_METASPACETESTCOMMON_HPP
--- old/test/hotspot/gtest/metaspace/metaspace_rangehelpers.hpp	2020-09-04 13:58:42.637712730 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,186 +0,0 @@
-/*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#ifndef GTEST_METASPACE_METASPACE_RANGEHELPERS_HPP
-#define GTEST_METASPACE_METASPACE_RANGEHELPERS_HPP
-
-// We use ranges-of-things in these tests a lot so some helpers help
-// keeping the code small.
-
-#include "memory/allocation.hpp"
-#include "memory/metaspace/chunkLevel.hpp"
-#include "runtime/os.hpp"
-#include "utilities/align.hpp"
-#include "utilities/debug.hpp"
-#include "utilities/globalDefinitions.hpp"
-
-
-using metaspace::chunklevel_t;
-using namespace metaspace::chunklevel;
-
-
-// A range of numerical values.
-template <typename T, typename Td>
-class Range : public StackObj {
-
-  // start and size of range
-  T   _start;
-  Td  _size;
-
-  static Td random_uncapped_offset() {
-    if (sizeof(Td) > 4) {
-      return (Td)((uint64_t)os::random() * os::random());
-    } else {
-      return (Td)os::random();
-    }
-  }
-
-protected:
-
-  static void swap_if_needed(T& lo, T& hi) {
-    if (lo > hi) {
-      T v = lo;
-      lo = hi;
-      hi = v;
-    }
-  }
-
-public:
-
-  // Lowest value in range
-  T lowest() const      { return _start; }
-
-  // Highest value in range (including)
-  T highest() const     { return _start + (_size - 1); }
-
-  T start() const       { return _start; }
-  T end() const         { return _start + _size; }
-
-  // Number of values in range
-  Td size() const       { return _size; }
-
-  bool is_empty() const { return size() == 0; }
-
-  bool contains(T v) const {
-    return v >= _start && v < end();
-  }
-
-  bool contains(Range<T, Td> r) const {
-    return contains(r.lowest()) && contains(r.highest());
-  }
-
-  // Create a range from [start, end)
-  Range(T start, T end) : _start(start), _size(end - start) {
-    assert(end >= start, "start and end reversed");
-  }
-
-  // a range with a given size, starting at 0
-  Range(Td size) : _start(0), _size(size) {}
-
-  // Return a random offset
-  Td random_offset() const {
-    assert(!is_empty(), "Range too small");
-    Td v = random_uncapped_offset() % size();
-    return v;
-  }
-
-  // Return a random value within the range
-  T random_value() const {
-    assert(!is_empty(), "Range too small");
-    T v = _start + random_offset();
-    assert(contains(v), "Sanity");
-    return v;
-  }
-
-  // Return the head of this range up to but excluding <split_point>
-  Range<T, Td> head(Td split_point) const {
-    assert(_size >= split_point, "Sanity");
-    return Range<T, Td>(_start, _start + split_point);
-  }
-
-  // Return the tail of this range, starting at <split_point>
-  Range<T, Td> tail(Td split_point) const {
-    assert(_size > split_point, "Sanity");
-    return Range<T, Td>(_start + split_point, end());
-  }
-
-  // Return a non-empty random sub range.
-  Range<T, Td> random_subrange() const {
-    assert(size() > 1, "Range too small");
-    Td sz = MAX2((Td)1, random_offset());
-    return random_sized_subrange(sz);
-  }
-
-  // Return a subrange of given size at a random start position
-  Range<T, Td> random_sized_subrange(Td subrange_size) const {
-    assert(subrange_size > 0 && subrange_size < _size, "invalid size");
-    T start = head(_size - subrange_size).random_value();
-    return Range<T, Td>(start, start + subrange_size);
-  }
-
-  //// aligned ranges ////
-
-  bool range_is_aligned(Td alignment) const {
-    return is_aligned(_size, alignment) && is_aligned(_start, alignment);
-  }
-
-  // Return a non-empty aligned random sub range.
-  Range<T, Td> random_aligned_subrange(Td alignment) const {
-    assert(alignment > 0, "Sanity");
-    assert(range_is_aligned(alignment), "Outer range needs to be aligned"); // to keep matters simple
-    assert(_size >= alignment, "Outer range too small.");
-    Td sz = MAX2((Td)1, random_offset());
-    sz = align_up(sz, alignment);
-    return random_aligned_sized_subrange(sz, alignment);
-  }
-
-  // Return a subrange of given size at a random aligned start position
-  Range<T, Td> random_aligned_sized_subrange(Td subrange_size, Td alignment) const {
-    assert(alignment > 0, "Sanity");
-    assert(range_is_aligned(alignment), "Outer range needs to be aligned"); // to keep matters simple
-    assert(subrange_size > 0 && subrange_size <= _size &&
-           is_aligned(subrange_size, alignment), "invalid subrange size");
-    if (_size == subrange_size) {
-      return *this;
-    }
-    T start = head(_size - subrange_size).random_value();
-    start = align_down(start, alignment);
-    return Range<T, Td>(start, start + subrange_size);
-  }
-
-};
-
-typedef Range<int, int> IntRange;
-typedef Range<size_t, size_t> SizeRange;
-typedef Range<chunklevel_t, int> ChunkLevelRange;
-
-struct ChunkLevelRanges : public AllStatic {
-  static ChunkLevelRange small_chunks()  { return ChunkLevelRange(CHUNK_LEVEL_32K, CHUNK_LEVEL_1K + 1); }
-  static ChunkLevelRange medium_chunks() { return ChunkLevelRange(CHUNK_LEVEL_512K, CHUNK_LEVEL_32K + 1); }
-  static ChunkLevelRange large_chunks()  { return ChunkLevelRange(CHUNK_LEVEL_4M, CHUNK_LEVEL_512K + 1); }
-  static ChunkLevelRange all_chunks()    { return ChunkLevelRange(CHUNK_LEVEL_4M, CHUNK_LEVEL_1K + 1); }
-};
-
-#endif // GTEST_METASPACE_METASPACE_RANGEHELPERS_HPP
--- old/test/hotspot/gtest/metaspace/metaspace_sparsearray.hpp	2020-09-04 13:58:43.049715654 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,166 +0,0 @@
-/*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#ifndef GTEST_METASPACE_SPARSEARRAY_HPP
-#define GTEST_METASPACE_SPARSEARRAY_HPP
-
-#include "memory/allocation.hpp"
-#include "runtime/os.hpp"
-#include "metaspace/metaspaceTestsCommon.hpp"
-#include "metaspace/metaspace_rangehelpers.hpp"
-
-
-/////// SparseArray<T> ////////////////
-
-// Throughout these tests we need to keep track of allocated items (ranges of metaspace memory, metachunks, ..)
-//  and be able to random-access them. Makes sense to have a helper for that.
-template <class T>
-class SparseArray : public StackObj {
-
-  T* const _slots;
-  const int _num;
-
-  // For convenience: a range covering all possible slot indices.
-  const IntRange _index_range;
-
-  bool contains(int index) const {
-    return _index_range.contains(index);
-  }
-
-  // Check slot intex for oob
-  void check_index(int i) const {
-    assert(contains(i), "Sanity");
-  }
-
-  // Swap the content of two slots.
-  void swap(int i1, int i2) {
-    check_index(i1);
-    check_index(i2);
-    T tmp = _slots[i1];
-    _slots[i1] = _slots[i2];
-    _slots[i2] = tmp;
-  }
-
-  enum condition_t { cond_null = 0, cond_non_null = 1, cond_dontcare = 2 };
-
-  // Helper for next_matching_slot
-  bool slot_matches(int slot, condition_t c) const {
-    switch(c) {
-    case cond_null:     return _slots[slot] == NULL;
-    case cond_non_null: return _slots[slot] != NULL;
-    case cond_dontcare: return true;
-    }
-    ShouldNotReachHere();
-    return false;
-  }
-
-  // Starting at (including) index, find the next matching slot. Returns index or -1 if none found.
-  int next_matching_slot(int slot, condition_t c) const {
-    while(slot < _num) {
-      if (slot_matches(slot, c)) {
-        return slot;
-      }
-      slot ++;
-    }
-    return -1;
-  }
-
-public:
-
-  SparseArray(int num)
-    : _slots(NEW_C_HEAP_ARRAY(T, num, mtInternal)),
-      _num(num),
-      _index_range(num)
-  {
-    for (int i = 0; i < _num; i ++) {
-      _slots[i] = NULL;
-    }
-  }
-
-  T at(int i)              { return _slots[i]; }
-  const T at(int i) const  { return _slots[i]; }
-  void set_at(int i, T e)  { _slots[i] = e; }
-
-  int size() const         { return _num; }
-
-  bool slot_is_null(int i) const                      { check_index(i); return _slots[i] == NULL; }
-
-  DEBUG_ONLY(void check_slot_is_null(int i) const     { assert(slot_is_null(i), "Slot %d is not null", i); })
-  DEBUG_ONLY(void check_slot_is_not_null(int i) const { assert(!slot_is_null(i), "Slot %d is null", i); })
-
-  // Shuffle all elements randomly
-  void shuffle() {
-    for (int i = 0; i < _num; i ++) {
-      swap(i, random_slot_index());
-    }
-  }
-
-  // Reverse elements
-  void reverse() {
-    for (int i = 0; i < _num / 2; i ++) {
-      swap(i, _num - i);
-    }
-  }
-
-  int first_slot() const            { return 0; }
-  int next_slot(int index) const    { return index == _index_range.highest() ? -1 : index + 1; }
-
-  int first_non_null_slot() const         { return next_matching_slot(0, cond_non_null); }
-  int next_non_null_slot(int index) const { return next_matching_slot(index + 1, cond_non_null); }
-
-  int first_null_slot() const             { return next_matching_slot(0, cond_null); }
-  int next_null_slot(int index) const     { return next_matching_slot(index + 1, cond_null); }
-
-  // Return a random slot index.
-  int random_slot_index() const {
-    return _index_range.random_value();
-  }
-
-  int random_non_null_slot_index() const {
-    int i = next_non_null_slot(_index_range.random_value());
-    if (i == -1) {
-      i = first_non_null_slot();
-    }
-    return i;
-  }
-
-  int random_null_slot_index() const {
-    int i = next_null_slot(_index_range.random_value());
-    if (i == -1) {
-      i = first_null_slot();
-    }
-    return i;
-  }
-
-  IntRange random_slot_range() const {
-    return _index_range.random_subrange();
-  }
-
-};
-
-
-#endif // GTEST_METASPACE_SPARSEARRAY_HPP
-
-
--- old/test/hotspot/gtest/metaspace/metaspace_testhelper.cpp	2020-09-04 13:58:43.461718580 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,178 +0,0 @@
-/*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#include "precompiled.hpp"
-
-#include "metaspace/metaspace_testhelper.hpp"
-
-using namespace metaspace::chunklevel;
-
-  // No reserve limit, and a commit limit.
-MetaspaceTestHelper::MetaspaceTestHelper(size_t commit_limit, size_t reserve_limit)
-: metaspace::MetaspaceTestContext("metaspace-gtest-context", commit_limit, reserve_limit),
-  _num_chunks_allocated(0)
-{
-}
-
-void MetaspaceTestHelper::checked_alloc_chunk_0(Metachunk** p_return_value, chunklevel_t preferred_level, chunklevel_t max_level,
-                                                      size_t min_committed_size) {
-
-  *p_return_value = NULL;
-
-  Metachunk* c = cm().get_chunk(preferred_level, max_level, min_committed_size);
-
-  if (c != NULL) {
-
-    ASSERT_LE(c->level(), max_level);
-    ASSERT_GE(c->level(), preferred_level);
-    ASSERT_GE(c->committed_words(), min_committed_size);
-    ASSERT_EQ(c->committed_words(), c->free_below_committed_words());
-    ASSERT_EQ(c->used_words(), (size_t)0);
-    ASSERT_TRUE(c->is_in_use());
-    ASSERT_FALSE(c->is_free());
-    ASSERT_FALSE(c->is_dead());
-    ASSERT_NULL(c->next());
-    ASSERT_NULL(c->prev());
-    if (c->level() == HIGHEST_CHUNK_LEVEL) {
-      ASSERT_TRUE(c->is_leaf_chunk());
-    } else {
-      ASSERT_FALSE(c->is_leaf_chunk());
-    }
-    if (c->level() == LOWEST_CHUNK_LEVEL) {
-      ASSERT_TRUE(c->is_root_chunk());
-    } else {
-      ASSERT_FALSE(c->is_root_chunk());
-    }
-    if (_num_chunks_allocated == 0) { // First chunk? We can make more assumptions
-      ASSERT_EQ(c->level(), preferred_level);
-      // Needs lock EXPECT_NULL(c->next_in_vs());
-      // Needs lock EXPECT_NULL(c->prev_in_vs());
-      ASSERT_TRUE(c->is_root_chunk() || c->is_leader());
-    }
-    _num_chunks_allocated ++;
-
-  }
-
-  *p_return_value = c;
-
-}
-
-// Test pattern established when allocating from the chunk with allocate_from_chunk_with_tests().
-void MetaspaceTestHelper::test_pattern(Metachunk* c, size_t word_size) {
-  check_range_for_pattern(c->base(), word_size, (uintx)c);
-}
-
-void MetaspaceTestHelper::return_chunk(Metachunk* c) {
-  test_pattern(c);
-  c->set_in_use(); // Forestall assert in cm
-  cm().return_chunk(c);
-}
-
- void MetaspaceTestHelper::allocate_from_chunk(MetaWord** p_return_value, Metachunk* c, size_t word_size) {
-
-  size_t used_before = c->used_words();
-  size_t free_before = c->free_words();
-  size_t free_below_committed_before = c->free_below_committed_words();
-  const MetaWord* top_before = c->top();
-
-  MetaWord* p = c->allocate(word_size);
-  EXPECT_NOT_NULL(p);
-  EXPECT_EQ(c->used_words(), used_before + word_size);
-  EXPECT_EQ(c->free_words(), free_before - word_size);
-  EXPECT_EQ(c->free_below_committed_words(), free_below_committed_before - word_size);
-  EXPECT_EQ(c->top(), top_before + word_size);
-
-  // Old content should be preserved
-  test_pattern(c, used_before);
-
-  // Fill newly allocated range too
-  fill_range_with_pattern(p, word_size, (uintx)c);
-
-  *p_return_value = p;
-}
-
-void MetaspaceTestHelper::commit_chunk_with_test(Metachunk* c, size_t additional_size) {
-
-  size_t used_before = c->used_words();
-  size_t free_before = c->free_words();
-  const MetaWord* top_before = c->top();
-
-  c->set_in_use();
-  bool b = c->ensure_committed_additional(additional_size);
-  EXPECT_TRUE(b);
-
-  // We should have enough committed size now
-  EXPECT_GE(c->free_below_committed_words(), additional_size);
-
-  // used, free, top should be unchanged.
-  EXPECT_EQ(c->used_words(), used_before);
-  EXPECT_EQ(c->free_words(), free_before);
-  EXPECT_EQ(c->top(), top_before);
-
-  test_pattern(c, used_before);
-
-}
-
-void MetaspaceTestHelper::commit_chunk_expect_failure(Metachunk* c, size_t additional_size) {
-
-  size_t used_before = c->used_words();
-  size_t free_before = c->free_words();
-  size_t free_below_committed_before = c->free_below_committed_words();
-  const MetaWord* top_before = c->top();
-
-  c->set_in_use();
-  bool b = c->ensure_committed_additional(additional_size);
-  EXPECT_FALSE(b);
-
-  // Nothing should have changed
-  EXPECT_EQ(c->used_words(), used_before);
-  EXPECT_EQ(c->free_words(), free_before);
-  EXPECT_EQ(c->free_below_committed_words(), free_below_committed_before);
-  EXPECT_EQ(c->top(), top_before);
-
-  test_pattern(c, used_before);
-
-}
-
-void MetaspaceTestHelper::uncommit_chunk_with_test(Metachunk* c) {
-  if (c->word_size() >= Settings::commit_granule_words()) {
-    c->set_free();  // Forestall assert in uncommit
-    c->reset_used_words();
-    c->uncommit();
-
-    EXPECT_EQ(c->free_below_committed_words(), (size_t)0);
-    EXPECT_EQ(c->used_words(), (size_t)0);
-    EXPECT_EQ(c->free_words(), c->word_size());
-    EXPECT_EQ(c->top(), c->base());
-    EXPECT_TRUE(c->is_fully_uncommitted());
-  }
-}
-
-
-
-/////// SparseArray<T> ////////////////
-
-
-
--- old/test/hotspot/gtest/metaspace/metaspace_testhelper.hpp	2020-09-04 13:58:43.865721450 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,114 +0,0 @@
-/*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#ifndef GTEST_METASPACE_METASPACE_TESTHELPER_HPP
-#define GTEST_METASPACE_METASPACE_TESTHELPER_HPP
-
-#include "memory/allocation.hpp"
-#include "metaspace/metaspaceTestsCommon.hpp"
-
-using namespace metaspace::chunklevel;
-
-class MetaspaceTestHelper : public metaspace::MetaspaceTestContext {
-
-  int _num_chunks_allocated;
-
-  void checked_alloc_chunk_0(Metachunk** p_return_value, chunklevel_t preferred_level,
-                             chunklevel_t max_level, size_t min_committed_size);
-
-public:
-
-  // Note: limit = 0 means unlimited
-  MetaspaceTestHelper(size_t commit_limit = 0, size_t reserve_limit = 0);
-
-  /////
-
-  // Note: all test functions return void and return values are by pointer ref; this is awkward but otherwise we cannot
-  // use gtest ASSERT macros inside those functions.
-
-  // Allocate a chunk (you do not know if it will succeed).
-  void alloc_chunk(Metachunk** p_return_value, chunklevel_t preferred_level, chunklevel_t max_level, size_t min_committed_size) {
-    checked_alloc_chunk_0(p_return_value, preferred_level, max_level, min_committed_size);
-  }
-
-  // Allocate a chunk; do not expect success, but if it succeeds, test the chunk.
-  void alloc_chunk(Metachunk** p_return_value, chunklevel_t level) {
-    alloc_chunk(p_return_value, level, level, word_size_for_level(level));
-  }
-
-  // Allocate a chunk; it must succeed. Test the chunk.
-  void alloc_chunk_expect_success(Metachunk** p_return_value, chunklevel_t preferred_level, chunklevel_t max_level, size_t min_committed_size) {
-    checked_alloc_chunk_0(p_return_value, preferred_level, max_level, min_committed_size);
-    ASSERT_NOT_NULL(*p_return_value);
-  }
-
-  // Allocate a chunk; it must succeed. Test the chunk.
-  void alloc_chunk_expect_success(Metachunk** p_return_value, chunklevel_t level) {
-    alloc_chunk_expect_success(p_return_value, level, level, word_size_for_level(level));
-  }
-
-  // Allocate a chunk but expect it to fail.
-  void alloc_chunk_expect_failure(chunklevel_t preferred_level, chunklevel_t max_level, size_t min_committed_size) {
-    Metachunk* c = NULL;
-    checked_alloc_chunk_0(&c, preferred_level, max_level, min_committed_size);
-    ASSERT_NULL(c);
-  }
-
-  // Allocate a chunk but expect it to fail.
-  void alloc_chunk_expect_failure(chunklevel_t level) {
-    return alloc_chunk_expect_failure(level, level, word_size_for_level(level));
-  }
-
-  /////
-
-  void return_chunk(Metachunk* c);
-
-  /////
-
-  // Allocates from a chunk; also, fills allocated area with test pattern which will be tested with test_pattern().
-  void allocate_from_chunk(MetaWord** p_return_value, Metachunk* c, size_t word_size);
-
-  // Convenience function: allocate from chunk for when you don't care for the result pointer
-  void allocate_from_chunk(Metachunk* c, size_t word_size) {
-    MetaWord* dummy;
-    allocate_from_chunk(&dummy, c, word_size);
-  }
-
-  // Test pattern established when allocating from the chunk with allocate_from_chunk_with_tests().
-  void test_pattern(Metachunk* c, size_t word_size);
-  void test_pattern(Metachunk* c) { test_pattern(c, c->used_words()); }
-
-  void commit_chunk_with_test(Metachunk* c, size_t additional_size);
-  void commit_chunk_expect_failure(Metachunk* c, size_t additional_size);
-
-  void uncommit_chunk_with_test(Metachunk* c);
-
-
-};
-
-
-#endif // GTEST_METASPACE_METASPACE_TESTHELPER_HPP
-
-
--- old/test/hotspot/gtest/metaspace/test_chunkManager.cpp	2020-09-04 13:58:44.277724378 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,294 +0,0 @@
-/*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#include "precompiled.hpp"
-
-//#define LOG_PLEASE
-
-#include "metaspace/metaspace_sparsearray.hpp"
-#include "metaspace/metaspaceTestsCommon.hpp"
-#include "metaspace/metaspaceTestContexts.hpp"
-
-
-
-class ChunkManagerRandomChunkAllocTest {
-
-  static const size_t max_footprint_words = 8 * M;
-
-  ChunkTestsContext _helper;
-
-  // All allocated live chunks
-  typedef SparseArray<Metachunk*> SparseArrayOfChunks;
-  SparseArrayOfChunks _chunks;
-
-  const ChunkLevelRange _chunklevel_range;
-  const float _commit_factor;
-
-  // Depending on a probability pattern, come up with a reasonable limit to number of live chunks
-  static int max_num_live_chunks(ChunkLevelRange r, float commit_factor) {
-    // Assuming we allocate only the largest type of chunk, committed to the fullest commit factor,
-    // how many chunks can we accomodate before hitting max_footprint_words?
-    const size_t largest_chunk_size = word_size_for_level(r.lowest());
-    int max_chunks = (max_footprint_words * commit_factor) / largest_chunk_size;
-    // .. but cap at (min) 50 and (max) 1000
-    max_chunks = MIN2(1000, max_chunks);
-    max_chunks = MAX2(50, max_chunks);
-    return max_chunks;
-  }
-
-  // Return true if, after an allocation error happened, a reserve error seems likely.
-  bool could_be_reserve_error() {
-    return _helper.vslist().is_full();
-  }
-
-  // Return true if, after an allocation error happened, a commit error seems likely.
-  bool could_be_commit_error(size_t additional_word_size) {
-
-    // could it be commit limit hit?
-
-    if (Settings::new_chunks_are_fully_committed()) {
-      // For all we know we may have just failed to fully-commit a new root chunk.
-      additional_word_size = MAX_CHUNK_WORD_SIZE;
-    }
-
-    // Note that this is difficult to verify precisely, since there are
-    // several layers of truth:
-    // a) at the lowest layer (RootChunkArea) we have a bitmap of committed granules;
-    // b) at the vslist layer, we keep running counters of committed/reserved words;
-    // c) at the chunk layer, we keep a commit watermark (committed_words).
-    //
-    // (a) should mirror reality.
-    // (a) and (b) should be precisely in sync. This is tested by
-    // VirtualSpaceList::verify().
-    // (c) can be, by design, imprecise (too low).
-    //
-    // Here, I check (b) and trust it to be correct. We also call vslist::verify().
-    DEBUG_ONLY(_helper.verify();)
-
-    const size_t commit_add = align_up(additional_word_size, Settings::commit_granule_words());
-    if (_helper.commit_limit() <= (commit_add + _helper.vslist().committed_words())) {
-      return true;
-    }
-
-    return false;
-
-  }
-
-  // Given a chunk level and a factor, return a random commit size.
-  static size_t random_committed_words(chunklevel_t lvl, float commit_factor) {
-    const size_t sz = word_size_for_level(lvl) * commit_factor;
-    if (sz < 2) {
-      return 0;
-    }
-    return MIN2(SizeRange(sz).random_value(), sz);
-  }
-
-
-  //// Chunk allocation ////
-
-  // Given an slot index, allocate a random chunk and set it into that slot. Slot must be empty.
-  // Returns false if allocation fails.
-  bool allocate_random_chunk_at(int slot) {
-
-    DEBUG_ONLY(_chunks.check_slot_is_null(slot);)
-
-    const ChunkLevelRange r = _chunklevel_range.random_subrange();
-    const chunklevel_t pref_level = r.lowest();
-    const chunklevel_t max_level = r.highest();
-    const size_t min_committed = random_committed_words(max_level, _commit_factor);
-
-    Metachunk* c = NULL;
-    _helper.alloc_chunk(&c, r.lowest(), r.highest(), min_committed);
-    if (c == NULL) {
-      EXPECT_TRUE(could_be_reserve_error() ||
-                  could_be_commit_error(min_committed));
-      LOG("Alloc chunk at %d failed.", slot);
-      return false;
-    }
-
-    _chunks.set_at(slot, c);
-
-    LOG("Allocated chunk at %d: " METACHUNK_FORMAT ".", slot, METACHUNK_FORMAT_ARGS(c));
-
-    return true;
-
-  }
-
-  // Allocates a random number of random chunks
-  bool allocate_random_chunks() {
-    int to_alloc = 1 + IntRange(MAX2(1, _chunks.size() / 8)).random_value();
-    bool success = true;
-    int slot = _chunks.first_null_slot();
-    while (to_alloc > 0 && slot != -1 && success) {
-      success = allocate_random_chunk_at(slot);
-      slot = _chunks.next_null_slot(slot);
-      to_alloc --;
-    }
-    return success && to_alloc == 0;
-  }
-
-  bool fill_all_slots_with_random_chunks() {
-    bool success = true;
-    for (int slot = _chunks.first_null_slot();
-         slot != -1 && success; slot = _chunks.next_null_slot(slot)) {
-      success = allocate_random_chunk_at(slot);
-    }
-    return success;
-  }
-
-  //// Chunk return ////
-
-  // Given an slot index, return the chunk in that slot to the chunk manager.
-  void return_chunk_at(int slot) {
-    Metachunk* c = _chunks.at(slot);
-    LOG("Returning chunk at %d: " METACHUNK_FORMAT ".", slot, METACHUNK_FORMAT_ARGS(c));
-    _helper.return_chunk(c);
-    _chunks.set_at(slot, NULL);
-  }
-
-  // return a random number of chunks (at most a quarter of the full slot range)
-  void return_random_chunks() {
-    int to_free = 1 + IntRange(MAX2(1, _chunks.size() / 8)).random_value();
-    int index = _chunks.first_non_null_slot();
-    while (to_free > 0 && index != -1) {
-      return_chunk_at(index);
-      index = _chunks.next_non_null_slot(index);
-      to_free --;
-    }
-  }
-
-  void return_all_chunks() {
-    for (int slot = _chunks.first_non_null_slot();
-         slot != -1; slot = _chunks.next_non_null_slot(slot)) {
-      return_chunk_at(slot);
-    }
-  }
-
-  // adjust test if we change levels
-  STATIC_ASSERT(HIGHEST_CHUNK_LEVEL == CHUNK_LEVEL_1K);
-  STATIC_ASSERT(LOWEST_CHUNK_LEVEL == CHUNK_LEVEL_4M);
-
-  void one_test() {
-
-    fill_all_slots_with_random_chunks();
-    _chunks.shuffle();
-
-    IntRange rand(100);
-
-    for (int j = 0; j < 1000; j ++) {
-
-      bool force_alloc = false;
-      bool force_free = true;
-
-      bool do_alloc =
-          force_alloc ? true :
-              (force_free ? false : rand.random_value() >= 50);
-      force_alloc = force_free = false;
-
-      if (do_alloc) {
-        if (!allocate_random_chunks()) {
-          force_free = true;
-        }
-      } else {
-        return_random_chunks();
-      }
-
-      _chunks.shuffle();
-
-    }
-
-    return_all_chunks();
-
-  }
-
-
-public:
-
-  // A test with no limits
-  ChunkManagerRandomChunkAllocTest(ChunkLevelRange r, float commit_factor)
-    : _helper(),
-      _chunks(max_num_live_chunks(r, commit_factor)),
-      _chunklevel_range(r),
-      _commit_factor(commit_factor)
-  {}
-
-  // A test with no reserve limit but commit limit
-  ChunkManagerRandomChunkAllocTest(size_t commit_limit,
-                                   ChunkLevelRange r, float commit_factor)
-    : _helper(commit_limit),
-      _chunks(max_num_live_chunks(r, commit_factor)),
-      _chunklevel_range(r),
-      _commit_factor(commit_factor)
-  {}
-
-  // A test with both reserve and commit limit
-  // ChunkManagerRandomChunkAllocTest(size_t commit_limit, size_t reserve_limit,
-  //                                  ChunkLevelRange r, float commit_factor)
-  // : _helper(commit_limit, reserve_limit),
-  // _chunks(max_num_live_chunks(r, commit_factor)),
-  // _chunklevel_range(r),
-  // _commit_factor(commit_factor)
-  // {}
-
-
-  void do_tests() {
-    const int num_runs = 5;
-    for (int n = 0; n < num_runs; n ++) {
-      one_test();
-    }
-  }
-
-};
-
-#define DEFINE_TEST(name, range, commit_factor) \
-TEST_VM(metaspace, chunkmanager_##name) { \
-	ChunkManagerRandomChunkAllocTest test(range, commit_factor); \
-	test.do_tests(); \
-}
-
-DEFINE_TEST(test_nolimit_1, ChunkLevelRanges::small_chunks(), 0.0f)
-DEFINE_TEST(test_nolimit_2, ChunkLevelRanges::small_chunks(), 0.5f)
-DEFINE_TEST(test_nolimit_3, ChunkLevelRanges::small_chunks(), 1.0f)
-
-DEFINE_TEST(test_nolimit_4, ChunkLevelRanges::all_chunks(), 0.0f)
-DEFINE_TEST(test_nolimit_5, ChunkLevelRanges::all_chunks(), 0.5f)
-DEFINE_TEST(test_nolimit_6, ChunkLevelRanges::all_chunks(), 1.0f)
-
-#define DEFINE_TEST_2(name, range, commit_factor) \
-TEST_VM(metaspace, chunkmanager_##name) { \
-  const size_t commit_limit = 256 * K; \
-  ChunkManagerRandomChunkAllocTest test(commit_limit, range, commit_factor); \
-  test.do_tests(); \
-}
-
-DEFINE_TEST_2(test_with_limit_1, ChunkLevelRanges::small_chunks(), 0.0f)
-DEFINE_TEST_2(test_with_limit_2, ChunkLevelRanges::small_chunks(), 0.5f)
-DEFINE_TEST_2(test_with_limit_3, ChunkLevelRanges::small_chunks(), 1.0f)
-
-DEFINE_TEST_2(test_with_limit_4, ChunkLevelRanges::all_chunks(), 0.0f)
-DEFINE_TEST_2(test_with_limit_5, ChunkLevelRanges::all_chunks(), 0.5f)
-DEFINE_TEST_2(test_with_limit_6, ChunkLevelRanges::all_chunks(), 1.0f)
-
-
--- old/test/hotspot/gtest/metaspace/test_metaspace_counters.cpp	2020-09-04 13:58:44.693727336 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,48 +0,0 @@
-/*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#include "precompiled.hpp"
-
-//#define LOG_PLEASE
-
-#include "classfile/classLoaderData.hpp"
-#include "metaspaceTestsCommon.hpp"
-#include "metaspace_rangehelpers.hpp"
-#include "threadHelper.inline.hpp"
-
-
-TEST_VM(metaspace, counters_basic)   {
-
-  IntCounter cnt;
-  ASSERT_0(cnt.get());
-  cnt.increment();
-  ASSERT_EQ(cnt.get(), (unsigned)1);
-  cnt.increment_by(100);
-  ASSERT_EQ(cnt.get(), (unsigned)101);
-  cnt.decrement_by(101);
-  ASSERT_0(cnt.get());
-
-}
-
--- old/test/hotspot/gtest/metaspace/test_report.cpp	2020-09-04 13:58:45.105730265 +0200
+++ /dev/null	2020-09-04 12:37:41.765504620 +0200
@@ -1,55 +0,0 @@
-/*
- * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2018, 2020 SAP SE. All rights reserved.
- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
- *
- * This code is free software; you can redistribute it and/or modify it
- * under the terms of the GNU General Public License version 2 only, as
- * published by the Free Software Foundation.
- *
- * This code is distributed in the hope that it will be useful, but WITHOUT
- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
- * version 2 for more details (a copy is included in the LICENSE file that
- * accompanied this code).
- *
- * You should have received a copy of the GNU General Public License version
- * 2 along with this work; if not, write to the Free Software Foundation,
- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
- *
- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
- * or visit www.oracle.com if you need additional information or have any
- * questions.
- *
- */
-
-#include "precompiled.hpp"
-
-//#define LOG_PLEASE
-
-#include "metaspaceTestsCommon.hpp"
-#include "utilities/globalDefinitions.hpp"
-#include "utilities/ostream.hpp"
-
-TEST_VM(metaspace, report_basic) {
-
-  stringStream ss;
-  //outputStream* st = tty;
-  outputStream* st = &ss;
-
-  MetaspaceUtils::print_basic_report(st, 0);
-
-  ASSERT_GT(ss.size(), (size_t)0);
-
-}
-
-// Note: full report needs CLDG lock or a safepoint. We test this as part of the
-// metaspace jtreg jcmd tests, lets not test it here.
-//TEST_VM(metaspace, report_full) {
-//
-//  outputStream* st = tty;
-//
-//  metaspace::MetaspaceReporter::print_report(st, 0, 0);
-//
-//}
-
