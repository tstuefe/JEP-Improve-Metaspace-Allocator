<?xml version="1.0"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head><meta charset="utf-8">
<meta http-equiv="cache-control" content="no-cache" />
<meta http-equiv="Pragma" content="no-cache" />
<meta http-equiv="Expires" content="-1" />
<!--
   Note to customizers: the body of the webrev is IDed as SUNWwebrev
   to allow easy overriding by users of webrev via the userContent.css
   mechanism available in some browsers.

   For example, to have all "removed" information be red instead of
   brown, set a rule in your userContent.css file like:

       body#SUNWwebrev span.removed { color: red ! important; }
-->
<style type="text/css" media="screen">
body {
    background-color: #eeeeee;
}
hr {
    border: none 0;
    border-top: 1px solid #aaa;
    height: 1px;
}
div.summary {
    font-size: .8em;
    border-bottom: 1px solid #aaa;
    padding-left: 1em;
    padding-right: 1em;
}
div.summary h2 {
    margin-bottom: 0.3em;
}
div.summary table th {
    text-align: right;
    vertical-align: top;
    white-space: nowrap;
}
span.lineschanged {
    font-size: 0.7em;
}
span.oldmarker {
    color: red;
    font-size: large;
    font-weight: bold;
}
span.newmarker {
    color: green;
    font-size: large;
    font-weight: bold;
}
span.removed {
    color: brown;
}
span.changed {
    color: blue;
}
span.new {
    color: blue;
    font-weight: bold;
}
a.print { font-size: x-small; }

</style>

<style type="text/css" media="print">
pre { font-size: 0.8em; font-family: courier, monospace; }
span.removed { color: #444; font-style: italic }
span.changed { font-weight: bold; }
span.new { font-weight: bold; }
span.newmarker { font-size: 1.2em; font-weight: bold; }
span.oldmarker { font-size: 1.2em; font-weight: bold; }
a.print {display: none}
hr { border: none 0; border-top: 1px solid #aaa; height: 1px; }
</style>

<title>source Sdiff src/hotspot/share/memory/metaspace </title>
</head><body id="SUNWwebrev">
<center><a href='../../../../../src/hotspot/share/memory/metaspace/virtualSpaceList.hpp.sdiff.html' target='_top'>&lt prev</a> <a href='../../../../../index.html' target='_top'>index</a> <a href='../../../../../src/hotspot/share/memory/metaspace/virtualSpaceNode.hpp.sdiff.html' target='_top'>next &gt</a></center>
<h2>src/hotspot/share/memory/metaspace/virtualSpaceNode.cpp</h2>
<a class="print" href="javascript:print()">Print this page</a>
<pre>rev <a href="https://bugs.openjdk.java.net/browse/JDK-60221">60221</a> : imported patch big.patch</pre>

<table><tr valign="top">
<td><pre>
   1 /*
<span class="changed">   2  * Copyright (c) 2018, Oracle and/or its affiliates. All rights reserved.</span>

   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 


  25 #include "precompiled.hpp"
  26 
  27 #include "logging/log.hpp"
<span class="changed">  28 #include "logging/logStream.hpp"</span>






  29 #include "memory/metaspace/metachunk.hpp"
<span class="removed">  30 #include "memory/metaspace.hpp"</span>
<span class="removed">  31 #include "memory/metaspace/chunkManager.hpp"</span>
<span class="removed">  32 #include "memory/metaspace/metaDebug.hpp"</span>
  33 #include "memory/metaspace/metaspaceCommon.hpp"
<span class="changed">  34 #include "memory/metaspace/occupancyMap.hpp"</span>


  35 #include "memory/metaspace/virtualSpaceNode.hpp"
<span class="changed">  36 #include "memory/virtualspace.hpp"</span>
<span class="changed">  37 #include "runtime/atomic.hpp"</span>


  38 #include "runtime/os.hpp"
<span class="changed">  39 #include "services/memTracker.hpp"</span>
<span class="changed">  40 #include "utilities/copy.hpp"</span>
  41 #include "utilities/debug.hpp"
  42 #include "utilities/globalDefinitions.hpp"

  43 
  44 namespace metaspace {
  45 
<span class="changed">  46 // Decide if large pages should be committed when the memory is reserved.</span>
<span class="changed">  47 static bool should_commit_large_pages_when_reserving(size_t bytes) {</span>
<span class="changed">  48   if (UseLargePages &amp;&amp; UseLargePagesInMetaspace &amp;&amp; !os::can_commit_large_page_memory()) {</span>
<span class="changed">  49     size_t words = bytes / BytesPerWord;</span>
<span class="changed">  50     bool is_class = false; // We never reserve large pages for the class space.</span>
<span class="changed">  51     if (MetaspaceGC::can_expand(words, is_class) &amp;&amp;</span>
<span class="changed">  52         MetaspaceGC::allowed_expansion() &gt;= words) {</span>
<span class="changed">  53       return true;</span>
<span class="changed">  54     }</span>
<span class="changed">  55   }</span>
<span class="changed">  56 </span>
<span class="changed">  57   return false;</span>
  58 }

  59 
<span class="changed">  60 // byte_size is the size of the associated virtualspace.</span>
<span class="changed">  61 VirtualSpaceNode::VirtualSpaceNode(bool is_class, size_t bytes) :</span>
<span class="changed">  62     _next(NULL), _is_class(is_class), _rs(), _top(NULL), _container_count(0), _occupancy_map(NULL) {</span>
<span class="changed">  63   assert_is_aligned(bytes, Metaspace::reserve_alignment());</span>
<span class="changed">  64   bool large_pages = should_commit_large_pages_when_reserving(bytes);</span>
<span class="changed">  65   _rs = ReservedSpace(bytes, Metaspace::reserve_alignment(), large_pages);</span>
<span class="changed">  66 </span>
<span class="changed">  67   if (_rs.is_reserved()) {</span>
<span class="changed">  68     assert(_rs.base() != NULL, "Catch if we get a NULL address");</span>
<span class="changed">  69     assert(_rs.size() != 0, "Catch if we get a 0 size");</span>
<span class="changed">  70     assert_is_aligned(_rs.base(), Metaspace::reserve_alignment());</span>
<span class="changed">  71     assert_is_aligned(_rs.size(), Metaspace::reserve_alignment());</span>
<span class="changed">  72 </span>
<span class="changed">  73     MemTracker::record_virtual_memory_type((address)_rs.base(), mtClass);</span>
<span class="changed">  74   }</span>
<span class="changed">  75 }</span>
<span class="changed">  76 </span>
<span class="changed">  77 void VirtualSpaceNode::purge(ChunkManager* chunk_manager) {</span>
<span class="changed">  78   // When a node is purged, lets give it a thorough examination.</span>
<span class="changed">  79   DEBUG_ONLY(verify(true);)</span>
<span class="changed">  80   Metachunk* chunk = first_chunk();</span>
<span class="changed">  81   Metachunk* invalid_chunk = (Metachunk*) top();</span>
<span class="changed">  82   while (chunk &lt; invalid_chunk ) {</span>
<span class="changed">  83     assert(chunk-&gt;is_tagged_free(), "Should be tagged free");</span>
<span class="changed">  84     MetaWord* next = ((MetaWord*)chunk) + chunk-&gt;word_size();</span>
<span class="changed">  85     chunk_manager-&gt;remove_chunk(chunk);</span>
<span class="changed">  86     chunk-&gt;remove_sentinel();</span>
<span class="changed">  87     assert(chunk-&gt;next() == NULL &amp;&amp;</span>
<span class="changed">  88         chunk-&gt;prev() == NULL,</span>
<span class="changed">  89         "Was not removed from its list");</span>
<span class="changed">  90     chunk = (Metachunk*) next;</span>
<span class="changed">  91   }</span>
<span class="changed">  92 }</span>
<span class="changed">  93 </span>
<span class="changed">  94 void VirtualSpaceNode::print_map(outputStream* st, bool is_class) const {</span>
<span class="changed">  95 </span>
<span class="changed">  96   if (bottom() == top()) {</span>
<span class="changed">  97     return;</span>
<span class="changed">  98   }</span>
<span class="changed">  99 </span>
<span class="changed"> 100   const size_t spec_chunk_size = is_class ? ClassSpecializedChunk : SpecializedChunk;</span>
<span class="changed"> 101   const size_t small_chunk_size = is_class ? ClassSmallChunk : SmallChunk;</span>
<span class="changed"> 102   const size_t med_chunk_size = is_class ? ClassMediumChunk : MediumChunk;</span>
<span class="changed"> 103 </span>
<span class="changed"> 104   int line_len = 100;</span>
<span class="changed"> 105   const size_t section_len = align_up(spec_chunk_size * line_len, med_chunk_size);</span>
<span class="changed"> 106   line_len = (int)(section_len / spec_chunk_size);</span>
<span class="changed"> 107 </span>
<span class="changed"> 108   static const int NUM_LINES = 4;</span>
<span class="changed"> 109 </span>
<span class="changed"> 110   char* lines[NUM_LINES];</span>
<span class="changed"> 111   for (int i = 0; i &lt; NUM_LINES; i ++) {</span>
<span class="changed"> 112     lines[i] = (char*)os::malloc(line_len, mtInternal);</span>
<span class="changed"> 113   }</span>
<span class="changed"> 114   int pos = 0;</span>
<span class="changed"> 115   const MetaWord* p = bottom();</span>
<span class="changed"> 116   const Metachunk* chunk = (const Metachunk*)p;</span>
<span class="changed"> 117   const MetaWord* chunk_end = p + chunk-&gt;word_size();</span>
<span class="changed"> 118   while (p &lt; top()) {</span>
<span class="changed"> 119     if (pos == line_len) {</span>
<span class="changed"> 120       pos = 0;</span>
<span class="changed"> 121       for (int i = 0; i &lt; NUM_LINES; i ++) {</span>
<span class="changed"> 122         st-&gt;fill_to(22);</span>
<span class="changed"> 123         st-&gt;print_raw(lines[i], line_len);</span>
<span class="changed"> 124         st-&gt;cr();</span>
<span class="changed"> 125       }</span>
<span class="changed"> 126     }</span>
<span class="changed"> 127     if (pos == 0) {</span>
<span class="changed"> 128       st-&gt;print(PTR_FORMAT ":", p2i(p));</span>
 129     }
<span class="changed"> 130     if (p == chunk_end) {</span>
<span class="changed"> 131       chunk = (Metachunk*)p;</span>
<span class="changed"> 132       chunk_end = p + chunk-&gt;word_size();</span>
<span class="changed"> 133     }</span>
<span class="changed"> 134     // line 1: chunk starting points (a dot if that area is a chunk start).</span>
<span class="changed"> 135     lines[0][pos] = p == (const MetaWord*)chunk ? '.' : ' ';</span>
<span class="changed"> 136 </span>
<span class="changed"> 137     // Line 2: chunk type (x=spec, s=small, m=medium, h=humongous), uppercase if</span>
<span class="changed"> 138     // chunk is in use.</span>
<span class="changed"> 139     const bool chunk_is_free = ((Metachunk*)chunk)-&gt;is_tagged_free();</span>
<span class="changed"> 140     if (chunk-&gt;word_size() == spec_chunk_size) {</span>
<span class="changed"> 141       lines[1][pos] = chunk_is_free ? 'x' : 'X';</span>
<span class="changed"> 142     } else if (chunk-&gt;word_size() == small_chunk_size) {</span>
<span class="changed"> 143       lines[1][pos] = chunk_is_free ? 's' : 'S';</span>
<span class="changed"> 144     } else if (chunk-&gt;word_size() == med_chunk_size) {</span>
<span class="changed"> 145       lines[1][pos] = chunk_is_free ? 'm' : 'M';</span>
<span class="changed"> 146     } else if (chunk-&gt;word_size() &gt; med_chunk_size) {</span>
<span class="changed"> 147       lines[1][pos] = chunk_is_free ? 'h' : 'H';</span>
<span class="changed"> 148     } else {</span>
<span class="changed"> 149       ShouldNotReachHere();</span>
<span class="changed"> 150     }</span>
<span class="changed"> 151 </span>
<span class="changed"> 152     // Line 3: chunk origin</span>
<span class="changed"> 153     const ChunkOrigin origin = chunk-&gt;get_origin();</span>
<span class="changed"> 154     lines[2][pos] = origin == origin_normal ? ' ' : '0' + (int) origin;</span>
<span class="changed"> 155 </span>
<span class="changed"> 156     // Line 4: Virgin chunk? Virgin chunks are chunks created as a byproduct of padding or splitting,</span>
<span class="changed"> 157     //         but were never used.</span>
<span class="changed"> 158     lines[3][pos] = chunk-&gt;get_use_count() &gt; 0 ? ' ' : 'v';</span>
<span class="changed"> 159 </span>
<span class="changed"> 160     p += spec_chunk_size;</span>
<span class="changed"> 161     pos ++;</span>
<span class="changed"> 162   }</span>
<span class="changed"> 163   if (pos &gt; 0) {</span>
<span class="changed"> 164     for (int i = 0; i &lt; NUM_LINES; i ++) {</span>
<span class="changed"> 165       st-&gt;fill_to(22);</span>
<span class="changed"> 166       st-&gt;print_raw(lines[i], line_len);</span>
<span class="changed"> 167       st-&gt;cr();</span>
 168     }




 169   }
<span class="changed"> 170   for (int i = 0; i &lt; NUM_LINES; i ++) {</span>
<span class="changed"> 171     os::free(lines[i]);</span>

 172   }
<span class="removed"> 173 }</span>
 174 


 175 
<span class="changed"> 176 #ifdef ASSERT</span>

 177 
<span class="changed"> 178 // Verify counters, all chunks in this list node and the occupancy map.</span>
<span class="changed"> 179 void VirtualSpaceNode::verify(bool slow) {</span>
<span class="changed"> 180   log_trace(gc, metaspace, freelist)("verifying %s virtual space node (%s).",</span>
<span class="changed"> 181     (is_class() ? "class space" : "metaspace"), (slow ? "slow" : "quick"));</span>
<span class="changed"> 182   // Fast mode: just verify chunk counters and basic geometry</span>
<span class="changed"> 183   // Slow mode: verify chunks and occupancy map</span>
<span class="changed"> 184   uintx num_in_use_chunks = 0;</span>
<span class="changed"> 185   Metachunk* chunk = first_chunk();</span>
<span class="changed"> 186   Metachunk* invalid_chunk = (Metachunk*) top();</span>
<span class="changed"> 187 </span>
<span class="changed"> 188   // Iterate the chunks in this node and verify each chunk.</span>
<span class="changed"> 189   while (chunk &lt; invalid_chunk ) {</span>
<span class="changed"> 190     if (slow) {</span>
<span class="changed"> 191       do_verify_chunk(chunk);</span>
<span class="changed"> 192     }</span>
<span class="changed"> 193     if (!chunk-&gt;is_tagged_free()) {</span>
<span class="changed"> 194       num_in_use_chunks ++;</span>
<span class="changed"> 195     }</span>
<span class="changed"> 196     const size_t s = chunk-&gt;word_size();</span>
<span class="changed"> 197     // Prevent endless loop on invalid chunk size.</span>
<span class="changed"> 198     assert(is_valid_chunksize(is_class(), s), "Invalid chunk size: " SIZE_FORMAT ".", s);</span>
<span class="changed"> 199     MetaWord* next = ((MetaWord*)chunk) + s;</span>
<span class="changed"> 200     chunk = (Metachunk*) next;</span>
<span class="changed"> 201   }</span>
<span class="changed"> 202   assert(_container_count == num_in_use_chunks, "Container count mismatch (real: " UINTX_FORMAT</span>
<span class="changed"> 203       ", counter: " UINTX_FORMAT ".", num_in_use_chunks, _container_count);</span>
<span class="changed"> 204   // Also verify the occupancy map.</span>
<span class="changed"> 205   if (slow) {</span>
<span class="changed"> 206     occupancy_map()-&gt;verify(bottom(), top());</span>
<span class="changed"> 207   }</span>
<span class="changed"> 208 }</span>
<span class="changed"> 209 </span>
<span class="changed"> 210 // Verify that all free chunks in this node are ideally merged</span>
<span class="changed"> 211 // (there not should be multiple small chunks where a large chunk could exist.)</span>
<span class="changed"> 212 void VirtualSpaceNode::verify_free_chunks_are_ideally_merged() {</span>
<span class="changed"> 213   Metachunk* chunk = first_chunk();</span>
<span class="changed"> 214   Metachunk* invalid_chunk = (Metachunk*) top();</span>
<span class="changed"> 215   // Shorthands.</span>
<span class="changed"> 216   const size_t size_med = (is_class() ? ClassMediumChunk : MediumChunk) * BytesPerWord;</span>
<span class="changed"> 217   const size_t size_small = (is_class() ? ClassSmallChunk : SmallChunk) * BytesPerWord;</span>
<span class="changed"> 218   int num_free_chunks_since_last_med_boundary = -1;</span>
<span class="changed"> 219   int num_free_chunks_since_last_small_boundary = -1;</span>
<span class="changed"> 220   bool error = false;</span>
<span class="changed"> 221   char err[256];</span>
<span class="changed"> 222   while (!error &amp;&amp; chunk &lt; invalid_chunk ) {</span>
<span class="changed"> 223     // Test for missed chunk merge opportunities: count number of free chunks since last chunk boundary.</span>
<span class="changed"> 224     // Reset the counter when encountering a non-free chunk.</span>
<span class="changed"> 225     if (chunk-&gt;get_chunk_type() != HumongousIndex) {</span>
<span class="changed"> 226       if (chunk-&gt;is_tagged_free()) {</span>
<span class="changed"> 227         // Count successive free, non-humongous chunks.</span>
<span class="changed"> 228         if (is_aligned(chunk, size_small)) {</span>
<span class="changed"> 229           if (num_free_chunks_since_last_small_boundary &gt; 0) {</span>
<span class="changed"> 230             error = true;</span>
<span class="changed"> 231             jio_snprintf(err, sizeof(err), "Missed chunk merge opportunity to merge a small chunk preceding " PTR_FORMAT ".", p2i(chunk));</span>
<span class="changed"> 232           } else {</span>
<span class="changed"> 233             num_free_chunks_since_last_small_boundary = 0;</span>
<span class="changed"> 234           }</span>
<span class="changed"> 235         } else if (num_free_chunks_since_last_small_boundary != -1) {</span>
<span class="changed"> 236           num_free_chunks_since_last_small_boundary ++;</span>
<span class="changed"> 237         }</span>
<span class="changed"> 238         if (is_aligned(chunk, size_med)) {</span>
<span class="changed"> 239           if (num_free_chunks_since_last_med_boundary &gt; 0) {</span>
<span class="changed"> 240             error = true;</span>
<span class="changed"> 241             jio_snprintf(err, sizeof(err), "Missed chunk merge opportunity to merge a medium chunk preceding " PTR_FORMAT ".", p2i(chunk));</span>
<span class="changed"> 242           } else {</span>
<span class="changed"> 243             num_free_chunks_since_last_med_boundary = 0;</span>
<span class="changed"> 244           }</span>
<span class="changed"> 245         } else if (num_free_chunks_since_last_med_boundary != -1) {</span>
<span class="changed"> 246           num_free_chunks_since_last_med_boundary ++;</span>
<span class="changed"> 247         }</span>
<span class="changed"> 248       } else {</span>
<span class="changed"> 249         // Encountering a non-free chunk, reset counters.</span>
<span class="changed"> 250         num_free_chunks_since_last_med_boundary = -1;</span>
<span class="changed"> 251         num_free_chunks_since_last_small_boundary = -1;</span>
<span class="changed"> 252       }</span>
<span class="changed"> 253     } else {</span>
<span class="changed"> 254       // One cannot merge areas with a humongous chunk in the middle. Reset counters.</span>
<span class="changed"> 255       num_free_chunks_since_last_med_boundary = -1;</span>
<span class="changed"> 256       num_free_chunks_since_last_small_boundary = -1;</span>
<span class="changed"> 257     }</span>
<span class="changed"> 258 </span>
<span class="changed"> 259     if (error) {</span>
<span class="changed"> 260       print_map(tty, is_class());</span>
<span class="changed"> 261       fatal("%s", err);</span>
<span class="changed"> 262     }</span>
 263 
<span class="changed"> 264     MetaWord* next = ((MetaWord*)chunk) + chunk-&gt;word_size();</span>
<span class="changed"> 265     chunk = (Metachunk*) next;</span>






 266   }






 267 }
<span class="removed"> 268 #endif // ASSERT</span>
 269 
<span class="changed"> 270 void VirtualSpaceNode::inc_container_count() {</span>




















 271   assert_lock_strong(MetaspaceExpand_lock);
<span class="changed"> 272   _container_count++;</span>







 273 }
 274 
<span class="changed"> 275 void VirtualSpaceNode::dec_container_count() {</span>






 276   assert_lock_strong(MetaspaceExpand_lock);
<span class="removed"> 277   _container_count--;</span>
<span class="removed"> 278 }</span>
 279 
<span class="changed"> 280 VirtualSpaceNode::~VirtualSpaceNode() {</span>
<span class="changed"> 281   _rs.release();</span>
<span class="changed"> 282   if (_occupancy_map != NULL) {</span>
<span class="changed"> 283     delete _occupancy_map;</span>













 284   }













 285 #ifdef ASSERT
<span class="changed"> 286   size_t word_size = sizeof(*this) / BytesPerWord;</span>
<span class="changed"> 287   Copy::fill_to_words((HeapWord*) this, word_size, 0xf1f1f1f1);</span>



 288 #endif



 289 }
 290 
<span class="changed"> 291 size_t VirtualSpaceNode::used_words_in_vs() const {</span>
<span class="changed"> 292   return pointer_delta(top(), bottom(), sizeof(MetaWord));</span>



























 293 }
 294 
<span class="changed"> 295 // Space committed in the VirtualSpace</span>
<span class="changed"> 296 size_t VirtualSpaceNode::capacity_words_in_vs() const {</span>
<span class="changed"> 297   return pointer_delta(end(), bottom(), sizeof(MetaWord));</span>
<span class="changed"> 298 }</span>
<span class="changed"> 299 </span>
<span class="changed"> 300 size_t VirtualSpaceNode::free_words_in_vs() const {</span>
<span class="changed"> 301   return pointer_delta(end(), top(), sizeof(MetaWord));</span>
<span class="changed"> 302 }</span>
<span class="changed"> 303 </span>
<span class="changed"> 304 // Given an address larger than top(), allocate padding chunks until top is at the given address.</span>
<span class="changed"> 305 void VirtualSpaceNode::allocate_padding_chunks_until_top_is_at(MetaWord* target_top) {</span>
<span class="changed"> 306 </span>
<span class="changed"> 307   assert(target_top &gt; top(), "Sanity");</span>
<span class="changed"> 308 </span>
<span class="changed"> 309   // Padding chunks are added to the freelist.</span>
<span class="changed"> 310   ChunkManager* const chunk_manager = Metaspace::get_chunk_manager(is_class());</span>
<span class="changed"> 311 </span>
<span class="changed"> 312   // shorthands</span>
<span class="changed"> 313   const size_t spec_word_size = chunk_manager-&gt;specialized_chunk_word_size();</span>
<span class="changed"> 314   const size_t small_word_size = chunk_manager-&gt;small_chunk_word_size();</span>
<span class="changed"> 315   const size_t med_word_size = chunk_manager-&gt;medium_chunk_word_size();</span>
<span class="changed"> 316 </span>
<span class="changed"> 317   while (top() &lt; target_top) {</span>
<span class="changed"> 318 </span>
<span class="changed"> 319     // We could make this coding more generic, but right now we only deal with two possible chunk sizes</span>
<span class="changed"> 320     // for padding chunks, so it is not worth it.</span>
<span class="changed"> 321     size_t padding_chunk_word_size = small_word_size;</span>
<span class="changed"> 322     if (is_aligned(top(), small_word_size * sizeof(MetaWord)) == false) {</span>
<span class="changed"> 323       assert_is_aligned(top(), spec_word_size * sizeof(MetaWord)); // Should always hold true.</span>
<span class="changed"> 324       padding_chunk_word_size = spec_word_size;</span>
<span class="changed"> 325     }</span>
<span class="changed"> 326     MetaWord* here = top();</span>
<span class="changed"> 327     assert_is_aligned(here, padding_chunk_word_size * sizeof(MetaWord));</span>
<span class="changed"> 328     inc_top(padding_chunk_word_size);</span>
<span class="changed"> 329 </span>
<span class="changed"> 330     // Create new padding chunk.</span>
<span class="changed"> 331     ChunkIndex padding_chunk_type = get_chunk_type_by_size(padding_chunk_word_size, is_class());</span>
<span class="changed"> 332     assert(padding_chunk_type == SpecializedIndex || padding_chunk_type == SmallIndex, "sanity");</span>
<span class="changed"> 333 </span>
<span class="changed"> 334     Metachunk* const padding_chunk =</span>
<span class="changed"> 335         ::new (here) Metachunk(padding_chunk_type, is_class(), padding_chunk_word_size, this);</span>
<span class="changed"> 336     assert(padding_chunk == (Metachunk*)here, "Sanity");</span>
<span class="changed"> 337     DEBUG_ONLY(padding_chunk-&gt;set_origin(origin_pad);)</span>
<span class="changed"> 338     log_trace(gc, metaspace, freelist)("Created padding chunk in %s at "</span>
<span class="changed"> 339         PTR_FORMAT ", size " SIZE_FORMAT_HEX ".",</span>
<span class="changed"> 340         (is_class() ? "class space " : "metaspace"),</span>
<span class="changed"> 341         p2i(padding_chunk), padding_chunk-&gt;word_size() * sizeof(MetaWord));</span>
<span class="changed"> 342 </span>
<span class="changed"> 343     // Mark chunk start in occupancy map.</span>
<span class="changed"> 344     occupancy_map()-&gt;set_chunk_starts_at_address((MetaWord*)padding_chunk, true);</span>
<span class="changed"> 345 </span>
<span class="changed"> 346     // Chunks are born as in-use (see MetaChunk ctor). So, before returning</span>
<span class="changed"> 347     // the padding chunk to its chunk manager, mark it as in use (ChunkManager</span>
<span class="changed"> 348     // will assert that).</span>
<span class="changed"> 349     do_update_in_use_info_for_chunk(padding_chunk, true);</span>
<span class="changed"> 350 </span>
<span class="changed"> 351     // Return Chunk to freelist.</span>
<span class="changed"> 352     inc_container_count();</span>
<span class="changed"> 353     chunk_manager-&gt;return_single_chunk(padding_chunk);</span>
<span class="changed"> 354     // Please note: at this point, ChunkManager::return_single_chunk()</span>
<span class="changed"> 355     // may already have merged the padding chunk with neighboring chunks, so</span>
<span class="changed"> 356     // it may have vanished at this point. Do not reference the padding</span>
<span class="changed"> 357     // chunk beyond this point.</span>
<span class="changed"> 358   }</span>
<span class="changed"> 359 </span>
<span class="changed"> 360   assert(top() == target_top, "Sanity");</span>
<span class="changed"> 361 </span>
<span class="changed"> 362 } // allocate_padding_chunks_until_top_is_at()</span>
<span class="changed"> 363 </span>
<span class="changed"> 364 // Allocates the chunk from the virtual space only.</span>
<span class="changed"> 365 // This interface is also used internally for debugging.  Not all</span>
<span class="changed"> 366 // chunks removed here are necessarily used for allocation.</span>
<span class="changed"> 367 Metachunk* VirtualSpaceNode::take_from_committed(size_t chunk_word_size) {</span>
<span class="changed"> 368   // Non-humongous chunks are to be allocated aligned to their chunk</span>
<span class="changed"> 369   // size. So, start addresses of medium chunks are aligned to medium</span>
<span class="changed"> 370   // chunk size, those of small chunks to small chunk size and so</span>
<span class="changed"> 371   // forth. This facilitates merging of free chunks and reduces</span>
<span class="changed"> 372   // fragmentation. Chunk sizes are spec &lt; small &lt; medium, with each</span>
<span class="changed"> 373   // larger chunk size being a multiple of the next smaller chunk</span>
<span class="changed"> 374   // size.</span>
<span class="changed"> 375   // Because of this alignment, me may need to create a number of padding</span>
<span class="changed"> 376   // chunks. These chunks are created and added to the freelist.</span>
<span class="changed"> 377 </span>
<span class="changed"> 378   // The chunk manager to which we will give our padding chunks.</span>
<span class="changed"> 379   ChunkManager* const chunk_manager = Metaspace::get_chunk_manager(is_class());</span>
<span class="changed"> 380 </span>
<span class="changed"> 381   // shorthands</span>
<span class="changed"> 382   const size_t spec_word_size = chunk_manager-&gt;specialized_chunk_word_size();</span>
<span class="changed"> 383   const size_t small_word_size = chunk_manager-&gt;small_chunk_word_size();</span>
<span class="changed"> 384   const size_t med_word_size = chunk_manager-&gt;medium_chunk_word_size();</span>
<span class="changed"> 385 </span>
<span class="changed"> 386   assert(chunk_word_size == spec_word_size || chunk_word_size == small_word_size ||</span>
<span class="changed"> 387       chunk_word_size &gt;= med_word_size, "Invalid chunk size requested.");</span>
<span class="changed"> 388 </span>
<span class="changed"> 389   // Chunk alignment (in bytes) == chunk size unless humongous.</span>
<span class="changed"> 390   // Humongous chunks are aligned to the smallest chunk size (spec).</span>
<span class="changed"> 391   const size_t required_chunk_alignment = (chunk_word_size &gt; med_word_size ?</span>
<span class="changed"> 392       spec_word_size : chunk_word_size) * sizeof(MetaWord);</span>
<span class="changed"> 393 </span>
<span class="changed"> 394   // Do we have enough space to create the requested chunk plus</span>
<span class="changed"> 395   // any padding chunks needed?</span>
<span class="changed"> 396   MetaWord* const next_aligned =</span>
<span class="changed"> 397       static_cast&lt;MetaWord*&gt;(align_up(top(), required_chunk_alignment));</span>
<span class="changed"> 398   if (!is_available((next_aligned - top()) + chunk_word_size)) {</span>
<span class="changed"> 399     return NULL;</span>
<span class="changed"> 400   }</span>
<span class="changed"> 401 </span>
<span class="changed"> 402   // Before allocating the requested chunk, allocate padding chunks if necessary.</span>
<span class="changed"> 403   // We only need to do this for small or medium chunks: specialized chunks are the</span>
<span class="changed"> 404   // smallest size, hence always aligned. Homungous chunks are allocated unaligned</span>
<span class="changed"> 405   // (implicitly, also aligned to smallest chunk size).</span>
<span class="changed"> 406   if ((chunk_word_size == med_word_size || chunk_word_size == small_word_size) &amp;&amp; next_aligned &gt; top())  {</span>
<span class="changed"> 407     log_trace(gc, metaspace, freelist)("Creating padding chunks in %s between %p and %p...",</span>
<span class="changed"> 408         (is_class() ? "class space " : "metaspace"),</span>
<span class="changed"> 409         top(), next_aligned);</span>
<span class="changed"> 410     allocate_padding_chunks_until_top_is_at(next_aligned);</span>
<span class="changed"> 411     // Now, top should be aligned correctly.</span>
<span class="changed"> 412     assert_is_aligned(top(), required_chunk_alignment);</span>
<span class="changed"> 413   }</span>
<span class="changed"> 414 </span>
<span class="changed"> 415   // Now, top should be aligned correctly.</span>
<span class="changed"> 416   assert_is_aligned(top(), required_chunk_alignment);</span>
<span class="changed"> 417 </span>
<span class="changed"> 418   // Bottom of the new chunk</span>
<span class="changed"> 419   MetaWord* chunk_limit = top();</span>
<span class="changed"> 420   assert(chunk_limit != NULL, "Not safe to call this method");</span>
<span class="changed"> 421 </span>
<span class="changed"> 422   // The virtual spaces are always expanded by the</span>
<span class="changed"> 423   // commit granularity to enforce the following condition.</span>
<span class="changed"> 424   // Without this the is_available check will not work correctly.</span>
<span class="changed"> 425   assert(_virtual_space.committed_size() == _virtual_space.actual_committed_size(),</span>
<span class="changed"> 426       "The committed memory doesn't match the expanded memory.");</span>
<span class="changed"> 427 </span>
<span class="changed"> 428   if (!is_available(chunk_word_size)) {</span>
<span class="changed"> 429     LogTarget(Trace, gc, metaspace, freelist) lt;</span>
<span class="changed"> 430     if (lt.is_enabled()) {</span>
<span class="changed"> 431       LogStream ls(lt);</span>
<span class="changed"> 432       ls.print("VirtualSpaceNode::take_from_committed() not available " SIZE_FORMAT " words ", chunk_word_size);</span>
<span class="changed"> 433       // Dump some information about the virtual space that is nearly full</span>
<span class="changed"> 434       print_on(&amp;ls);</span>
<span class="changed"> 435     }</span>
<span class="changed"> 436     return NULL;</span>
<span class="changed"> 437   }</span>
<span class="changed"> 438 </span>
<span class="changed"> 439   // Take the space  (bump top on the current virtual space).</span>
<span class="changed"> 440   inc_top(chunk_word_size);</span>
<span class="changed"> 441 </span>
<span class="changed"> 442   // Initialize the chunk</span>
<span class="changed"> 443   ChunkIndex chunk_type = get_chunk_type_by_size(chunk_word_size, is_class());</span>
<span class="changed"> 444   Metachunk* result = ::new (chunk_limit) Metachunk(chunk_type, is_class(), chunk_word_size, this);</span>
<span class="changed"> 445   assert(result == (Metachunk*)chunk_limit, "Sanity");</span>
<span class="changed"> 446   occupancy_map()-&gt;set_chunk_starts_at_address((MetaWord*)result, true);</span>
<span class="changed"> 447   do_update_in_use_info_for_chunk(result, true);</span>
 448 
<span class="changed"> 449   inc_container_count();</span>
 450 
 451 #ifdef ASSERT
<span class="changed"> 452   EVERY_NTH(VerifyMetaspaceInterval)</span>
<span class="changed"> 453     chunk_manager-&gt;locked_verify(true);</span>
<span class="changed"> 454     verify(true);</span>
<span class="changed"> 455   END_EVERY_NTH</span>
<span class="changed"> 456   do_verify_chunk(result);</span>
 457 #endif
 458 
<span class="changed"> 459   result-&gt;inc_use_count();</span>




































 460 
<span class="removed"> 461   return result;</span>
 462 }
 463 
 464 
<span class="removed"> 465 // Expand the virtual space (commit more of the reserved space)</span>
<span class="removed"> 466 bool VirtualSpaceNode::expand_by(size_t min_words, size_t preferred_words) {</span>
<span class="removed"> 467   size_t min_bytes = min_words * BytesPerWord;</span>
<span class="removed"> 468   size_t preferred_bytes = preferred_words * BytesPerWord;</span>
 469 
<span class="changed"> 470   size_t uncommitted = virtual_space()-&gt;reserved_size() - virtual_space()-&gt;actual_committed_size();</span>
 471 
<span class="changed"> 472   if (uncommitted &lt; min_bytes) {</span>
<span class="changed"> 473     return false;</span>

































 474   }
 475 
<span class="changed"> 476   size_t commit = MIN2(preferred_bytes, uncommitted);</span>
<span class="changed"> 477   bool result = virtual_space()-&gt;expand_by(commit, false);</span>
 478 
<span class="removed"> 479   if (result) {</span>
<span class="removed"> 480     log_trace(gc, metaspace, freelist)("Expanded %s virtual space list node by " SIZE_FORMAT " words.",</span>
<span class="removed"> 481         (is_class() ? "class" : "non-class"), commit);</span>
<span class="removed"> 482     DEBUG_ONLY(Atomic::inc(&amp;g_internal_statistics.num_committed_space_expanded));</span>
<span class="removed"> 483   } else {</span>
<span class="removed"> 484     log_trace(gc, metaspace, freelist)("Failed to expand %s virtual space list node by " SIZE_FORMAT " words.",</span>
<span class="removed"> 485         (is_class() ? "class" : "non-class"), commit);</span>
 486   }
 487 
<span class="changed"> 488   assert(result, "Failed to commit memory");</span>
 489 
<span class="removed"> 490   return result;</span>
 491 }
 492 
<span class="changed"> 493 Metachunk* VirtualSpaceNode::get_chunk_vs(size_t chunk_word_size) {</span>





 494   assert_lock_strong(MetaspaceExpand_lock);
<span class="changed"> 495   Metachunk* result = take_from_committed(chunk_word_size);</span>
<span class="changed"> 496   return result;</span>






 497 }
 498 
<span class="changed"> 499 bool VirtualSpaceNode::initialize() {</span>









 500 
<span class="changed"> 501   if (!_rs.is_reserved()) {</span>
<span class="changed"> 502     return false;</span>
<span class="changed"> 503   }</span>





















 504 
<span class="changed"> 505   // These are necessary restriction to make sure that the virtual space always</span>
<span class="changed"> 506   // grows in steps of Metaspace::commit_alignment(). If both base and size are</span>
<span class="changed"> 507   // aligned only the middle alignment of the VirtualSpace is used.</span>
<span class="changed"> 508   assert_is_aligned(_rs.base(), Metaspace::commit_alignment());</span>
<span class="changed"> 509   assert_is_aligned(_rs.size(), Metaspace::commit_alignment());</span>


 510 
<span class="changed"> 511   // ReservedSpaces marked as special will have the entire memory</span>
<span class="changed"> 512   // pre-committed. Setting a committed size will make sure that</span>
<span class="changed"> 513   // committed_size and actual_committed_size agrees.</span>
<span class="changed"> 514   size_t pre_committed_size = _rs.special() ? _rs.size() : 0;</span>
 515 
<span class="changed"> 516   bool result = virtual_space()-&gt;initialize_with_granularity(_rs, pre_committed_size,</span>
<span class="changed"> 517       Metaspace::commit_alignment());</span>
<span class="changed"> 518   if (result) {</span>
<span class="changed"> 519     assert(virtual_space()-&gt;committed_size() == virtual_space()-&gt;actual_committed_size(),</span>
<span class="changed"> 520         "Checking that the pre-committed memory was registered by the VirtualSpace");</span>
 521 
<span class="changed"> 522     set_top((MetaWord*)virtual_space()-&gt;low());</span>


































 523   }
 524 
<span class="changed"> 525   // Initialize Occupancy Map.</span>
<span class="changed"> 526   const size_t smallest_chunk_size = is_class() ? ClassSpecializedChunk : SpecializedChunk;</span>
<span class="changed"> 527   _occupancy_map = new OccupancyMap(bottom(), reserved_words(), smallest_chunk_size);</span>

 528 
<span class="removed"> 529   return result;</span>
 530 }
 531 
<span class="removed"> 532 void VirtualSpaceNode::print_on(outputStream* st, size_t scale) const {</span>
<span class="removed"> 533   size_t used_words = used_words_in_vs();</span>
<span class="removed"> 534   size_t commit_words = committed_words();</span>
<span class="removed"> 535   size_t res_words = reserved_words();</span>
<span class="removed"> 536   VirtualSpace* vs = virtual_space();</span>
 537 
<span class="changed"> 538   st-&gt;print("node @" PTR_FORMAT ": ", p2i(this));</span>




 539   st-&gt;print("reserved=");
<span class="changed"> 540   print_scaled_words(st, res_words, scale);</span>
 541   st-&gt;print(", committed=");
<span class="changed"> 542   print_scaled_words_and_percentage(st, commit_words, res_words, scale);</span>
 543   st-&gt;print(", used=");
<span class="changed"> 544   print_scaled_words_and_percentage(st, used_words, res_words, scale);</span>

 545   st-&gt;cr();
<span class="changed"> 546   st-&gt;print("   [" PTR_FORMAT ", " PTR_FORMAT ", "</span>
<span class="changed"> 547       PTR_FORMAT ", " PTR_FORMAT ")",</span>
<span class="changed"> 548       p2i(bottom()), p2i(top()), p2i(end()),</span>
<span class="changed"> 549       p2i(vs-&gt;high_boundary()));</span>
 550 }
 551 
<span class="changed"> 552 #ifdef ASSERT</span>
<span class="changed"> 553 void VirtualSpaceNode::mangle() {</span>
<span class="changed"> 554   size_t word_size = capacity_words_in_vs();</span>
<span class="changed"> 555   Copy::fill_to_words((HeapWord*) low(), word_size, 0xf1f1f1f1);</span>
 556 }
<span class="removed"> 557 #endif // ASSERT</span>
 558 
<span class="removed"> 559 void VirtualSpaceNode::retire(ChunkManager* chunk_manager) {</span>
<span class="removed"> 560   assert(is_class() == chunk_manager-&gt;is_class(), "Wrong ChunkManager?");</span>
 561 #ifdef ASSERT
<span class="changed"> 562   verify(false);</span>
<span class="changed"> 563   EVERY_NTH(VerifyMetaspaceInterval)</span>
<span class="changed"> 564     verify(true);</span>
<span class="changed"> 565   END_EVERY_NTH</span>
<span class="changed"> 566 #endif</span>
<span class="changed"> 567   for (int i = (int)MediumIndex; i &gt;= (int)ZeroIndex; --i) {</span>
<span class="changed"> 568     ChunkIndex index = (ChunkIndex)i;</span>
<span class="changed"> 569     size_t chunk_size = chunk_manager-&gt;size_by_index(index);</span>
<span class="changed"> 570 </span>
<span class="changed"> 571     while (free_words_in_vs() &gt;= chunk_size) {</span>
<span class="changed"> 572       Metachunk* chunk = get_chunk_vs(chunk_size);</span>
<span class="changed"> 573       // Chunk will be allocated aligned, so allocation may require</span>
<span class="changed"> 574       // additional padding chunks. That may cause above allocation to</span>
<span class="changed"> 575       // fail. Just ignore the failed allocation and continue with the</span>
<span class="changed"> 576       // next smaller chunk size. As the VirtualSpaceNode comitted</span>
<span class="changed"> 577       // size should be a multiple of the smallest chunk size, we</span>
<span class="changed"> 578       // should always be able to fill the VirtualSpace completely.</span>
<span class="changed"> 579       if (chunk == NULL) {</span>
<span class="changed"> 580         break;</span>
<span class="changed"> 581       }</span>
<span class="changed"> 582       chunk_manager-&gt;return_single_chunk(chunk);</span>
<span class="changed"> 583     }</span>
<span class="changed"> 584   }</span>
<span class="changed"> 585   assert(free_words_in_vs() == 0, "should be empty now");</span>
 586 }



 587 
 588 } // namespace metaspace
</pre></td><td><pre>
   1 /*
<span class="changed">   2  * Copyright (c) 2018, 2019, Oracle and/or its affiliates. All rights reserved.</span>
<span class="changed">   3  * Copyright (c) 2018, 2019 SAP SE. All rights reserved.</span>
   4  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   5  *
   6  * This code is free software; you can redistribute it and/or modify it
   7  * under the terms of the GNU General Public License version 2 only, as
   8  * published by the Free Software Foundation.
   9  *
  10  * This code is distributed in the hope that it will be useful, but WITHOUT
  11  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  12  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  13  * version 2 for more details (a copy is included in the LICENSE file that
  14  * accompanied this code).
  15  *
  16  * You should have received a copy of the GNU General Public License version
  17  * 2 along with this work; if not, write to the Free Software Foundation,
  18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  19  *
  20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  21  * or visit www.oracle.com if you need additional information or have any
  22  * questions.
  23  *
  24  */
  25 
<span class="new">  26 </span>
<span class="new">  27 </span>
  28 #include "precompiled.hpp"
  29 
  30 #include "logging/log.hpp"
<span class="changed">  31 </span>
<span class="changed">  32 #include "memory/metaspace/chunkLevel.hpp"</span>
<span class="changed">  33 #include "memory/metaspace/chunkHeaderPool.hpp"</span>
<span class="changed">  34 #include "memory/metaspace/commitLimiter.hpp"</span>
<span class="changed">  35 #include "memory/metaspace/counter.hpp"</span>
<span class="changed">  36 #include "memory/metaspace/freeChunkList.hpp"</span>
<span class="changed">  37 #include "memory/metaspace/internStat.hpp"</span>
  38 #include "memory/metaspace/metachunk.hpp"



  39 #include "memory/metaspace/metaspaceCommon.hpp"
<span class="changed">  40 #include "memory/metaspace/rootChunkArea.hpp"</span>
<span class="changed">  41 #include "memory/metaspace/runningCounters.hpp"</span>
<span class="changed">  42 #include "memory/metaspace/settings.hpp"</span>
  43 #include "memory/metaspace/virtualSpaceNode.hpp"
<span class="changed">  44 #include "memory/metaspace.hpp"</span>
<span class="changed">  45 </span>
<span class="changed">  46 #include "runtime/globals.hpp"</span>
<span class="changed">  47 #include "runtime/mutexLocker.hpp"</span>
  48 #include "runtime/os.hpp"
<span class="changed">  49 </span>
<span class="changed">  50 #include "utilities/align.hpp"</span>
  51 #include "utilities/debug.hpp"
  52 #include "utilities/globalDefinitions.hpp"
<span class="new">  53 #include "utilities/ostream.hpp"</span>
  54 
  55 namespace metaspace {
  56 
<span class="changed">  57 #ifdef ASSERT</span>
<span class="changed">  58 void check_pointer_is_aligned_to_commit_granule(const MetaWord* p) {</span>
<span class="changed">  59   assert(is_aligned(p, Settings::commit_granule_bytes()),</span>
<span class="changed">  60          "Pointer not aligned to commit granule size: " PTR_FORMAT ".",</span>
<span class="changed">  61          p2i(p));</span>
<span class="changed">  62 }</span>
<span class="changed">  63 void check_word_size_is_aligned_to_commit_granule(size_t word_size) {</span>
<span class="changed">  64   assert(is_aligned(word_size, Settings::commit_granule_words()),</span>
<span class="changed">  65          "Not aligned to commit granule size: " SIZE_FORMAT ".", word_size);</span>



  66 }
<span class="new">  67 #endif</span>
  68 
<span class="changed">  69 </span>
<span class="changed">  70 // Given an address range, ensure it is committed.</span>
<span class="changed">  71 //</span>
<span class="changed">  72 // The range has to be aligned to granule size.</span>
<span class="changed">  73 //</span>
<span class="changed">  74 // Function will:</span>
<span class="changed">  75 // - check how many granules in that region are uncommitted; If all are committed, it</span>
<span class="changed">  76 //    returns true immediately.</span>
<span class="changed">  77 // - check if committing those uncommitted granules would bring us over the commit limit</span>
<span class="changed">  78 //    (GC threshold, MaxMetaspaceSize). If true, it returns false.</span>
<span class="changed">  79 // - commit the memory.</span>
<span class="changed">  80 // - mark the range as committed in the commit mask</span>
<span class="changed">  81 //</span>
<span class="changed">  82 // Returns true if success, false if it did hit a commit limit.</span>
<span class="changed">  83 bool VirtualSpaceNode::commit_range(MetaWord* p, size_t word_size) {</span>
<span class="changed">  84 </span>
<span class="changed">  85   DEBUG_ONLY(check_pointer_is_aligned_to_commit_granule(p);)</span>
<span class="changed">  86   DEBUG_ONLY(check_word_size_is_aligned_to_commit_granule(word_size);)</span>
<span class="changed">  87   assert_lock_strong(MetaspaceExpand_lock);</span>
<span class="changed">  88 </span>
<span class="changed">  89   // First calculate how large the committed regions in this range are</span>
<span class="changed">  90   const size_t committed_words_in_range = _commit_mask.get_committed_size_in_range(p, word_size);</span>
<span class="changed">  91   DEBUG_ONLY(check_word_size_is_aligned_to_commit_granule(committed_words_in_range);)</span>
<span class="changed">  92 </span>
<span class="changed">  93   // By how much words we would increase commit charge</span>
<span class="changed">  94   //  were we to commit the given address range completely.</span>
<span class="changed">  95   const size_t commit_increase_words = word_size - committed_words_in_range;</span>
<span class="changed">  96 </span>
<span class="changed">  97   log_debug(metaspace)("VirtualSpaceNode %d, base " PTR_FORMAT ": committing range " PTR_FORMAT ".." PTR_FORMAT "(" SIZE_FORMAT " words)",</span>
<span class="changed">  98                        _node_id, p2i(_base), p2i(p), p2i(p + word_size), word_size);</span>
<span class="changed">  99 </span>
<span class="changed"> 100   if (commit_increase_words == 0) {</span>
<span class="changed"> 101     log_debug(metaspace)("VirtualSpaceNode %d, base " PTR_FORMAT ": ... already fully committed.",</span>
<span class="changed"> 102                          _node_id, p2i(_base));</span>
<span class="changed"> 103     return true; // Already fully committed, nothing to do.</span>


































 104   }
<span class="changed"> 105 </span>
<span class="changed"> 106   // Before committing any more memory, check limits.</span>
<span class="changed"> 107   if (_commit_limiter-&gt;possible_expansion_words() &lt; commit_increase_words) {</span>
<span class="changed"> 108     return false;</span>


































 109   }
<span class="new"> 110 </span>
<span class="new"> 111   // Commit...</span>
<span class="new"> 112   if (os::commit_memory((char*)p, word_size * BytesPerWord, false) == false) {</span>
<span class="new"> 113     vm_exit_out_of_memory(word_size * BytesPerWord, OOM_MMAP_ERROR, "Failed to commit metaspace.");</span>
 114   }
<span class="changed"> 115 </span>
<span class="changed"> 116   if (AlwaysPreTouch) {</span>
<span class="changed"> 117     os::pretouch_memory(p, p + word_size);</span>
 118   }

 119 
<span class="new"> 120   log_debug(gc, metaspace)("Increased metaspace by " SIZE_FORMAT " bytes.",</span>
<span class="new"> 121                            commit_increase_words * BytesPerWord);</span>
 122 
<span class="changed"> 123   // ... tell commit limiter...</span>
<span class="changed"> 124   _commit_limiter-&gt;increase_committed(commit_increase_words);</span>
 125 
<span class="changed"> 126   // ... update counters in containing vslist ...</span>
<span class="changed"> 127   _total_committed_words_counter-&gt;increment_by(commit_increase_words);</span>



















































































 128 
<span class="changed"> 129   // ... and update the commit mask.</span>
<span class="changed"> 130   _commit_mask.mark_range_as_committed(p, word_size);</span>
<span class="changed"> 131 </span>
<span class="changed"> 132 #ifdef ASSERT</span>
<span class="changed"> 133   // The commit boundary maintained in the CommitLimiter should be equal the sum of committed words</span>
<span class="changed"> 134   // in both class and non-class vslist (outside gtests).</span>
<span class="changed"> 135   if (_commit_limiter == CommitLimiter::globalLimiter()) {</span>
<span class="changed"> 136     assert(_commit_limiter-&gt;committed_words() == RunningCounters::committed_words(), "counter mismatch");</span>
 137   }
<span class="new"> 138 #endif</span>
<span class="new"> 139 </span>
<span class="new"> 140   DEBUG_ONLY(InternalStats::inc_num_space_committed();)</span>
<span class="new"> 141 </span>
<span class="new"> 142   return true;</span>
<span class="new"> 143 </span>
 144 }

 145 
<span class="changed"> 146 // Given an address range, ensure it is committed.</span>
<span class="changed"> 147 //</span>
<span class="changed"> 148 // The range does not have to be aligned to granule size. However, the function will always commit</span>
<span class="changed"> 149 // whole granules.</span>
<span class="changed"> 150 //</span>
<span class="changed"> 151 // Function will:</span>
<span class="changed"> 152 // - check how many granules in that region are uncommitted; If all are committed, it</span>
<span class="changed"> 153 //    returns true immediately.</span>
<span class="changed"> 154 // - check if committing those uncommitted granules would bring us over the commit limit</span>
<span class="changed"> 155 //    (GC threshold, MaxMetaspaceSize). If true, it returns false.</span>
<span class="changed"> 156 // - commit the memory.</span>
<span class="changed"> 157 // - mark the range as committed in the commit mask</span>
<span class="changed"> 158 //</span>
<span class="changed"> 159 // !! Careful:</span>
<span class="changed"> 160 //    calling ensure_range_is_committed on a range which contains both committed and uncommitted</span>
<span class="changed"> 161 //    areas will commit the whole area, thus erase the content in the existing committed parts.</span>
<span class="changed"> 162 //    Make sure you never call this on an address range containing live data. !!</span>
<span class="changed"> 163 //</span>
<span class="changed"> 164 // Returns true if success, false if it did hit a commit limit.</span>
<span class="changed"> 165 bool VirtualSpaceNode::ensure_range_is_committed(MetaWord* p, size_t word_size) {</span>
<span class="changed"> 166 </span>
 167   assert_lock_strong(MetaspaceExpand_lock);
<span class="changed"> 168   assert(p != NULL &amp;&amp; word_size &gt; 0, "Sanity");</span>
<span class="changed"> 169 </span>
<span class="changed"> 170   MetaWord* p_start = align_down(p, Settings::commit_granule_bytes());</span>
<span class="changed"> 171   MetaWord* p_end = align_up(p + word_size, Settings::commit_granule_bytes());</span>
<span class="changed"> 172 </span>
<span class="changed"> 173   // Todo: simple for now. Make it more intelligent late</span>
<span class="changed"> 174   return commit_range(p_start, p_end - p_start);</span>
<span class="changed"> 175 </span>
 176 }
 177 
<span class="changed"> 178 // Given an address range (which has to be aligned to commit granule size):</span>
<span class="changed"> 179 //  - uncommit it</span>
<span class="changed"> 180 //  - mark it as uncommitted in the commit mask</span>
<span class="changed"> 181 void VirtualSpaceNode::uncommit_range(MetaWord* p, size_t word_size) {</span>
<span class="changed"> 182 </span>
<span class="changed"> 183   DEBUG_ONLY(check_pointer_is_aligned_to_commit_granule(p);)</span>
<span class="changed"> 184   DEBUG_ONLY(check_word_size_is_aligned_to_commit_granule(word_size);)</span>
 185   assert_lock_strong(MetaspaceExpand_lock);


 186 
<span class="changed"> 187   // First calculate how large the committed regions in this range are</span>
<span class="changed"> 188   const size_t committed_words_in_range = _commit_mask.get_committed_size_in_range(p, word_size);</span>
<span class="changed"> 189   DEBUG_ONLY(check_word_size_is_aligned_to_commit_granule(committed_words_in_range);)</span>
<span class="changed"> 190 </span>
<span class="changed"> 191   log_debug(metaspace)("VirtualSpaceNode %d, base " PTR_FORMAT ": uncommitting range " PTR_FORMAT ".." PTR_FORMAT "(" SIZE_FORMAT " words)",</span>
<span class="changed"> 192                        _node_id, p2i(_base), p2i(p), p2i(p + word_size), word_size);</span>
<span class="changed"> 193 </span>
<span class="changed"> 194   if (committed_words_in_range == 0) {</span>
<span class="changed"> 195     log_debug(metaspace)("VirtualSpaceNode %d, base " PTR_FORMAT ": ... already fully uncommitted.",</span>
<span class="changed"> 196                          _node_id, p2i(_base));</span>
<span class="changed"> 197     return; // Already fully uncommitted, nothing to do.</span>
<span class="changed"> 198   }</span>
<span class="changed"> 199 </span>
<span class="changed"> 200   // Uncommit...</span>
<span class="changed"> 201   if (os::uncommit_memory((char*)p, word_size * BytesPerWord) == false) {</span>
<span class="changed"> 202     // Note: this can actually happen, since uncommit may increase the number of mappings.</span>
<span class="changed"> 203     fatal("Failed to uncommit metaspace.");</span>
 204   }
<span class="new"> 205 </span>
<span class="new"> 206   log_debug(metaspace)("Decreased metaspace by " SIZE_FORMAT " bytes.",</span>
<span class="new"> 207                         committed_words_in_range * BytesPerWord);</span>
<span class="new"> 208 </span>
<span class="new"> 209   // ... tell commit limiter...</span>
<span class="new"> 210   _commit_limiter-&gt;decrease_committed(committed_words_in_range);</span>
<span class="new"> 211 </span>
<span class="new"> 212   // ... and global counters...</span>
<span class="new"> 213   _total_committed_words_counter-&gt;decrement_by(committed_words_in_range);</span>
<span class="new"> 214 </span>
<span class="new"> 215    // ... and update the commit mask.</span>
<span class="new"> 216   _commit_mask.mark_range_as_uncommitted(p, word_size);</span>
<span class="new"> 217 </span>
 218 #ifdef ASSERT
<span class="changed"> 219   // The commit boundary maintained in the CommitLimiter should be equal the sum of committed words</span>
<span class="changed"> 220   // in both class and non-class vslist (outside gtests).</span>
<span class="changed"> 221   if (_commit_limiter == CommitLimiter::globalLimiter()) { // We are outside a test scenario</span>
<span class="changed"> 222     assert(_commit_limiter-&gt;committed_words() == RunningCounters::committed_words(), "counter mismatch");</span>
<span class="changed"> 223   }</span>
 224 #endif
<span class="new"> 225 </span>
<span class="new"> 226   DEBUG_ONLY(InternalStats::inc_num_space_uncommitted();)</span>
<span class="new"> 227 </span>
 228 }
 229 
<span class="changed"> 230 //// creation, destruction ////</span>
<span class="changed"> 231 </span>
<span class="changed"> 232 VirtualSpaceNode::VirtualSpaceNode(int node_id,</span>
<span class="changed"> 233                                    ReservedSpace rs,</span>
<span class="changed"> 234                                    CommitLimiter* limiter,</span>
<span class="changed"> 235                                    SizeCounter* reserve_words_counter,</span>
<span class="changed"> 236                                    SizeCounter* commit_words_counter)</span>
<span class="changed"> 237   : _next(NULL),</span>
<span class="changed"> 238     _rs(rs),</span>
<span class="changed"> 239     _base((MetaWord*)rs.base()),</span>
<span class="changed"> 240     _word_size(rs.size() / BytesPerWord),</span>
<span class="changed"> 241     _used_words(0),</span>
<span class="changed"> 242     _commit_mask((MetaWord*)rs.base(), rs.size() / BytesPerWord),</span>
<span class="changed"> 243     _root_chunk_area_lut((MetaWord*)rs.base(), rs.size() / BytesPerWord),</span>
<span class="changed"> 244     _commit_limiter(limiter),</span>
<span class="changed"> 245     _total_reserved_words_counter(reserve_words_counter),</span>
<span class="changed"> 246     _total_committed_words_counter(commit_words_counter),</span>
<span class="changed"> 247     _node_id(node_id)</span>
<span class="changed"> 248 {</span>
<span class="changed"> 249 </span>
<span class="changed"> 250   log_debug(metaspace)("Create new VirtualSpaceNode %d, base " PTR_FORMAT ", word size " SIZE_FORMAT ".",</span>
<span class="changed"> 251                        _node_id, p2i(_base), _word_size);</span>
<span class="changed"> 252 </span>
<span class="changed"> 253   // Update reserved counter in vslist</span>
<span class="changed"> 254   _total_reserved_words_counter-&gt;increment_by(_word_size);</span>
<span class="changed"> 255 </span>
<span class="changed"> 256   assert_is_aligned(_base, chunklevel::MAX_CHUNK_BYTE_SIZE);</span>
<span class="changed"> 257   assert_is_aligned(_word_size, chunklevel::MAX_CHUNK_WORD_SIZE);</span>
<span class="changed"> 258 </span>
 259 }
 260 
<span class="changed"> 261 // Create a node of a given size</span>
<span class="changed"> 262 VirtualSpaceNode* VirtualSpaceNode::create_node(int node_id,</span>
<span class="changed"> 263                                                 size_t word_size,</span>
<span class="changed"> 264                                                 CommitLimiter* limiter,</span>
<span class="changed"> 265                                                 SizeCounter* reserve_words_counter,</span>
<span class="changed"> 266                                                 SizeCounter* commit_words_counter)</span>
<span class="changed"> 267 {</span>


















































































































































 268 
<span class="changed"> 269   DEBUG_ONLY(assert_is_aligned(word_size, chunklevel::MAX_CHUNK_WORD_SIZE);)</span>
 270 
 271 #ifdef ASSERT
<span class="changed"> 272   size_t alignment = chunklevel::MAX_CHUNK_BYTE_SIZE;</span>




 273 #endif
 274 
<span class="changed"> 275   ReservedSpace rs(word_size * BytesPerWord,</span>
<span class="changed"> 276                    Metaspace::reserve_alignment(),</span>
<span class="changed"> 277                    false // large</span>
<span class="changed"> 278                    );</span>
<span class="changed"> 279 </span>
<span class="changed"> 280   if (!rs.is_reserved()) {</span>
<span class="changed"> 281     vm_exit_out_of_memory(word_size * BytesPerWord, OOM_MMAP_ERROR, "Failed to reserve memory for metaspace");</span>
<span class="changed"> 282   }</span>
<span class="changed"> 283 </span>
<span class="changed"> 284   assert_is_aligned(rs.base(), chunklevel::MAX_CHUNK_BYTE_SIZE);</span>
<span class="changed"> 285 </span>
<span class="changed"> 286   return create_node(node_id, rs, limiter, reserve_words_counter, commit_words_counter);</span>
<span class="changed"> 287 </span>
<span class="changed"> 288 }</span>
<span class="changed"> 289 </span>
<span class="changed"> 290 // Create a node over an existing space</span>
<span class="changed"> 291 VirtualSpaceNode* VirtualSpaceNode::create_node(int node_id,</span>
<span class="changed"> 292                                                 ReservedSpace rs,</span>
<span class="changed"> 293                                                 CommitLimiter* limiter,</span>
<span class="changed"> 294                                                 SizeCounter* reserve_words_counter,</span>
<span class="changed"> 295                                                 SizeCounter* commit_words_counter)</span>
<span class="changed"> 296 {</span>
<span class="changed"> 297   DEBUG_ONLY(InternalStats::inc_num_vsnodes_created();)</span>
<span class="changed"> 298   return new VirtualSpaceNode(node_id, rs, limiter, reserve_words_counter, commit_words_counter);</span>
<span class="changed"> 299 }</span>
<span class="changed"> 300 </span>
<span class="changed"> 301 VirtualSpaceNode::~VirtualSpaceNode() {</span>
<span class="changed"> 302   _rs.release();</span>
<span class="changed"> 303 </span>
<span class="changed"> 304   log_debug(metaspace)("Destroying VirtualSpaceNode %d, base " PTR_FORMAT ", word size " SIZE_FORMAT ".",</span>
<span class="changed"> 305                        _node_id, p2i(_base), _word_size);</span>
<span class="changed"> 306 </span>
<span class="changed"> 307   // Update counters in vslist</span>
<span class="changed"> 308   _total_committed_words_counter-&gt;decrement_by(committed_words());</span>
<span class="changed"> 309   _total_reserved_words_counter-&gt;decrement_by(_word_size);</span>
<span class="changed"> 310 </span>
<span class="changed"> 311   DEBUG_ONLY(InternalStats::inc_num_vsnodes_destroyed();)</span>
 312 

 313 }
 314 
 315 




 316 
<span class="changed"> 317 //// Chunk allocation, splitting, merging /////</span>
 318 
<span class="changed"> 319 // Allocate a root chunk from this node. Will fail and return NULL</span>
<span class="changed"> 320 // if the node is full.</span>
<span class="changed"> 321 // Note: this just returns a chunk whose memory is reserved; no memory is committed yet.</span>
<span class="changed"> 322 // Hence, before using this chunk, it must be committed.</span>
<span class="changed"> 323 // Also, no limits are checked, since no committing takes place.</span>
<span class="changed"> 324 Metachunk* VirtualSpaceNode::allocate_root_chunk() {</span>
<span class="changed"> 325 </span>
<span class="changed"> 326   assert_lock_strong(MetaspaceExpand_lock);</span>
<span class="changed"> 327 </span>
<span class="changed"> 328   assert_is_aligned(free_words(), chunklevel::MAX_CHUNK_WORD_SIZE);</span>
<span class="changed"> 329 </span>
<span class="changed"> 330   if (free_words() &gt;= chunklevel::MAX_CHUNK_WORD_SIZE) {</span>
<span class="changed"> 331 </span>
<span class="changed"> 332     MetaWord* loc = _base + _used_words;</span>
<span class="changed"> 333     _used_words += chunklevel::MAX_CHUNK_WORD_SIZE;</span>
<span class="changed"> 334 </span>
<span class="changed"> 335     RootChunkArea* rca = _root_chunk_area_lut.get_area_by_address(loc);</span>
<span class="changed"> 336 </span>
<span class="changed"> 337     // Create a root chunk header and initialize it;</span>
<span class="changed"> 338     Metachunk* c = rca-&gt;alloc_root_chunk_header(this);</span>
<span class="changed"> 339 </span>
<span class="changed"> 340     assert(c-&gt;base() == loc &amp;&amp; c-&gt;vsnode() == this &amp;&amp;</span>
<span class="changed"> 341            c-&gt;is_free(), "Sanity");</span>
<span class="changed"> 342 </span>
<span class="changed"> 343     DEBUG_ONLY(c-&gt;verify(true);)</span>
<span class="changed"> 344 </span>
<span class="changed"> 345     log_debug(metaspace)("VirtualSpaceNode %d, base " PTR_FORMAT ": newborn root chunk " METACHUNK_FORMAT ".",</span>
<span class="changed"> 346                          _node_id, p2i(_base), METACHUNK_FORMAT_ARGS(c));</span>
<span class="changed"> 347 </span>
<span class="changed"> 348     if (Settings::newborn_root_chunks_are_fully_committed()) {</span>
<span class="changed"> 349       log_trace(metaspace)("VirtualSpaceNode %d, base " PTR_FORMAT ": committing newborn root chunk.",</span>
<span class="changed"> 350                            _node_id, p2i(_base));</span>
<span class="changed"> 351       // Note: use Metachunk::ensure_commit, do not commit directly. This makes sure the chunk knows</span>
<span class="changed"> 352       // its commit range and does not ask needlessly.</span>
<span class="changed"> 353       c-&gt;ensure_fully_committed_locked();</span>
 354     }
 355 
<span class="changed"> 356     return c;</span>

 357 







 358   }
 359 
<span class="changed"> 360   return NULL; // Node is full.</span>
 361 

 362 }
 363 
<span class="changed"> 364 // Given a chunk c, split it recursively until you get a chunk of the given target_level.</span>
<span class="changed"> 365 //</span>
<span class="changed"> 366 // The resulting target chunk resides at the same address as the original chunk.</span>
<span class="changed"> 367 // The resulting splinters are added to freelists.</span>
<span class="changed"> 368 void VirtualSpaceNode::split(chunklevel_t target_level, Metachunk* c, FreeChunkListVector* freelists) {</span>
<span class="changed"> 369 </span>
 370   assert_lock_strong(MetaspaceExpand_lock);
<span class="changed"> 371 </span>
<span class="changed"> 372   // Get the area associated with this chunk and let it handle the splitting</span>
<span class="changed"> 373   RootChunkArea* rca = _root_chunk_area_lut.get_area_by_address(c-&gt;base());</span>
<span class="changed"> 374 </span>
<span class="changed"> 375   DEBUG_ONLY(rca-&gt;verify_area_is_ideally_merged();)</span>
<span class="changed"> 376 </span>
<span class="changed"> 377   rca-&gt;split(target_level, c, freelists);</span>
<span class="changed"> 378 </span>
 379 }
 380 
<span class="changed"> 381 // Given a chunk, attempt to merge it recursively with its neighboring chunks.</span>
<span class="changed"> 382 //</span>
<span class="changed"> 383 // If successful (merged at least once), returns address of</span>
<span class="changed"> 384 // the merged chunk; NULL otherwise.</span>
<span class="changed"> 385 //</span>
<span class="changed"> 386 // The merged chunks are removed from the freelists.</span>
<span class="changed"> 387 //</span>
<span class="changed"> 388 // !!! Please note that if this method returns a non-NULL value, the</span>
<span class="changed"> 389 // original chunk will be invalid and should not be accessed anymore! !!!</span>
<span class="changed"> 390 Metachunk* VirtualSpaceNode::merge(Metachunk* c, FreeChunkListVector* freelists) {</span>
 391 
<span class="changed"> 392   assert(c != NULL &amp;&amp; c-&gt;is_free(), "Sanity");</span>
<span class="changed"> 393   assert_lock_strong(MetaspaceExpand_lock);</span>
<span class="changed"> 394 </span>
<span class="changed"> 395   // Get the rca associated with this chunk and let it handle the merging</span>
<span class="changed"> 396   RootChunkArea* rca = _root_chunk_area_lut.get_area_by_address(c-&gt;base());</span>
<span class="changed"> 397 </span>
<span class="changed"> 398   Metachunk* c2 = rca-&gt;merge(c, freelists);</span>
<span class="changed"> 399 </span>
<span class="changed"> 400   DEBUG_ONLY(rca-&gt;verify_area_is_ideally_merged();)</span>
<span class="changed"> 401 </span>
<span class="changed"> 402   return c2;</span>
<span class="changed"> 403 </span>
<span class="changed"> 404 }</span>
<span class="changed"> 405 </span>
<span class="changed"> 406 // Given a chunk c, which must be "in use" and must not be a root chunk, attempt to</span>
<span class="changed"> 407 // enlarge it in place by claiming its trailing buddy.</span>
<span class="changed"> 408 //</span>
<span class="changed"> 409 // This will only work if c is the leader of the buddy pair and the trailing buddy is free.</span>
<span class="changed"> 410 //</span>
<span class="changed"> 411 // If successful, the follower chunk will be removed from the freelists, the leader chunk c will</span>
<span class="changed"> 412 // double in size (level decreased by one).</span>
<span class="changed"> 413 //</span>
<span class="changed"> 414 // On success, true is returned, false otherwise.</span>
<span class="changed"> 415 bool VirtualSpaceNode::attempt_enlarge_chunk(Metachunk* c, FreeChunkListVector* freelists) {</span>
 416 
<span class="changed"> 417   assert(c != NULL &amp;&amp; c-&gt;is_in_use() &amp;&amp; !c-&gt;is_root_chunk(), "Sanity");</span>
<span class="changed"> 418   assert_lock_strong(MetaspaceExpand_lock);</span>
<span class="changed"> 419 </span>
<span class="changed"> 420   // Get the rca associated with this chunk and let it handle the merging</span>
<span class="changed"> 421   RootChunkArea* rca = _root_chunk_area_lut.get_area_by_address(c-&gt;base());</span>
<span class="changed"> 422 </span>
<span class="changed"> 423   bool rc = rca-&gt;attempt_enlarge_chunk(c, freelists);</span>
 424 
<span class="changed"> 425   DEBUG_ONLY(rca-&gt;verify_area_is_ideally_merged();)</span>



 426 
<span class="changed"> 427   return rc;</span>
<span class="changed"> 428 </span>
<span class="changed"> 429 }</span>


 430 
<span class="changed"> 431 // Attempts to purge the node:</span>
<span class="changed"> 432 //</span>
<span class="changed"> 433 // If all chunks living in this node are free, they will all be removed from their freelists</span>
<span class="changed"> 434 //   and deletes the node.</span>
<span class="changed"> 435 //</span>
<span class="changed"> 436 // Returns true if the node has been deleted, false if not.</span>
<span class="changed"> 437 // !! If this returns true, do not access the node from this point on. !!</span>
<span class="changed"> 438 bool VirtualSpaceNode::attempt_purge(FreeChunkListVector* freelists) {</span>
<span class="changed"> 439 </span>
<span class="changed"> 440   assert_lock_strong(MetaspaceExpand_lock);</span>
<span class="changed"> 441 </span>
<span class="changed"> 442   // First find out if all areas are empty. Since empty chunks collapse to root chunk</span>
<span class="changed"> 443   // size, if all chunks in this node are free root chunks we are good to go.</span>
<span class="changed"> 444   for (int narea = 0; narea &lt; _root_chunk_area_lut.number_of_areas(); narea ++) {</span>
<span class="changed"> 445     const RootChunkArea* ra = _root_chunk_area_lut.get_area_by_index(narea);</span>
<span class="changed"> 446     const Metachunk* c = ra-&gt;first_chunk();</span>
<span class="changed"> 447     if (c != NULL) {</span>
<span class="changed"> 448       if (!(c-&gt;is_root_chunk() &amp;&amp; c-&gt;is_free())) {</span>
<span class="changed"> 449         return false;</span>
<span class="changed"> 450       }</span>
<span class="changed"> 451     }</span>
<span class="changed"> 452   }</span>
<span class="changed"> 453 </span>
<span class="changed"> 454   log_debug(metaspace)("VirtualSpaceNode %d, base " PTR_FORMAT ": purging.", _node_id, p2i(_base));</span>
<span class="changed"> 455 </span>
<span class="changed"> 456   // Okay, we can purge. Before we can do this, we need to remove all chunks from the freelist.</span>
<span class="changed"> 457   for (int narea = 0; narea &lt; _root_chunk_area_lut.number_of_areas(); narea ++) {</span>
<span class="changed"> 458     RootChunkArea* ra = _root_chunk_area_lut.get_area_by_index(narea);</span>
<span class="changed"> 459     Metachunk* c = ra-&gt;first_chunk();</span>
<span class="changed"> 460     if (c != NULL) {</span>
<span class="changed"> 461       log_trace(metaspace)("VirtualSpaceNode %d, base " PTR_FORMAT ": removing chunk " METACHUNK_FULL_FORMAT ".",</span>
<span class="changed"> 462                            _node_id, p2i(_base), METACHUNK_FULL_FORMAT_ARGS(c));</span>
<span class="changed"> 463       assert(c-&gt;is_free() &amp;&amp; c-&gt;is_root_chunk(), "Sanity");</span>
<span class="changed"> 464       freelists-&gt;remove(c);</span>
<span class="changed"> 465     }</span>
 466   }
 467 
<span class="changed"> 468   // Now, delete the node, then right away return since this object is invalid.</span>
<span class="changed"> 469   delete this;</span>
<span class="changed"> 470 </span>
<span class="changed"> 471   return true;</span>
 472 

 473 }
 474 





 475 
<span class="changed"> 476 void VirtualSpaceNode::print_on(outputStream* st) const {</span>
<span class="changed"> 477 </span>
<span class="changed"> 478   size_t scale = K;</span>
<span class="changed"> 479 </span>
<span class="changed"> 480   st-&gt;print("id: %d, base " PTR_FORMAT ": ", _node_id, p2i(base()));</span>
 481   st-&gt;print("reserved=");
<span class="changed"> 482   print_scaled_words(st, word_size(), scale);</span>
 483   st-&gt;print(", committed=");
<span class="changed"> 484   print_scaled_words_and_percentage(st, committed_words(), word_size(), scale);</span>
 485   st-&gt;print(", used=");
<span class="changed"> 486   print_scaled_words_and_percentage(st, used_words(), word_size(), scale);</span>
<span class="changed"> 487 </span>
 488   st-&gt;cr();
<span class="changed"> 489 </span>
<span class="changed"> 490   _root_chunk_area_lut.print_on(st);</span>
<span class="changed"> 491   _commit_mask.print_on(st);</span>
<span class="changed"> 492 </span>
 493 }
 494 
<span class="changed"> 495 // Returns size, in words, of committed space in this node alone.</span>
<span class="changed"> 496 // Note: iterates over commit mask and hence may be a tad expensive on large nodes.</span>
<span class="changed"> 497 size_t VirtualSpaceNode::committed_words() const {</span>
<span class="changed"> 498   return _commit_mask.get_committed_size();</span>
 499 }

 500 


 501 #ifdef ASSERT
<span class="changed"> 502 // Verify counters and basic structure. Slow mode: verify all chunks in depth</span>
<span class="changed"> 503 void VirtualSpaceNode::verify(bool slow) const {</span>
<span class="changed"> 504 </span>
<span class="changed"> 505   assert_lock_strong(MetaspaceExpand_lock);</span>
<span class="changed"> 506 </span>
<span class="changed"> 507   assert(base() != NULL, "Invalid base");</span>
<span class="changed"> 508   assert(base() == (MetaWord*)_rs.base() &amp;&amp;</span>
<span class="changed"> 509          word_size() == _rs.size() / BytesPerWord,</span>
<span class="changed"> 510          "Sanity");</span>
<span class="changed"> 511   assert_is_aligned(base(), chunklevel::MAX_CHUNK_BYTE_SIZE);</span>
<span class="changed"> 512   assert(used_words() &lt;= word_size(), "Sanity");</span>
<span class="changed"> 513 </span>
<span class="changed"> 514   // Since we only ever hand out root chunks from a vsnode, top should always be aligned</span>
<span class="changed"> 515   // to root chunk size.</span>
<span class="changed"> 516   assert_is_aligned(used_words(), chunklevel::MAX_CHUNK_WORD_SIZE);</span>
<span class="changed"> 517 </span>
<span class="changed"> 518   _commit_mask.verify(slow);</span>
<span class="changed"> 519   assert(committed_words() &lt;= word_size(), "Sanity");</span>
<span class="changed"> 520   assert_is_aligned(committed_words(), Settings::commit_granule_words());</span>
<span class="changed"> 521   _root_chunk_area_lut.verify(slow);</span>
<span class="changed"> 522 </span>



 523 }
<span class="new"> 524 </span>
<span class="new"> 525 #endif</span>
<span class="new"> 526 </span>
 527 
 528 } // namespace metaspace
</pre></td>
</tr></table>
<center><a href='../../../../../src/hotspot/share/memory/metaspace/virtualSpaceList.hpp.sdiff.html' target='_top'>&lt prev</a> <a href='../../../../../index.html' target='_top'>index</a> <a href='../../../../../src/hotspot/share/memory/metaspace/virtualSpaceNode.hpp.sdiff.html' target='_top'>next &gt</a></center>
</body></html>
