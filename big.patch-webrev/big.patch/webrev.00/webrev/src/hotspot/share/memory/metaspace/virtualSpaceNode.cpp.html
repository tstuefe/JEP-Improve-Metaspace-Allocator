<?xml version="1.0"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head><meta charset="utf-8">
<meta http-equiv="cache-control" content="no-cache" />
<meta http-equiv="Pragma" content="no-cache" />
<meta http-equiv="Expires" content="-1" />
<!--
   Note to customizers: the body of the webrev is IDed as SUNWwebrev
   to allow easy overriding by users of webrev via the userContent.css
   mechanism available in some browsers.

   For example, to have all "removed" information be red instead of
   brown, set a rule in your userContent.css file like:

       body#SUNWwebrev span.removed { color: red ! important; }
-->
<style type="text/css" media="screen">
body {
    background-color: #eeeeee;
}
hr {
    border: none 0;
    border-top: 1px solid #aaa;
    height: 1px;
}
div.summary {
    font-size: .8em;
    border-bottom: 1px solid #aaa;
    padding-left: 1em;
    padding-right: 1em;
}
div.summary h2 {
    margin-bottom: 0.3em;
}
div.summary table th {
    text-align: right;
    vertical-align: top;
    white-space: nowrap;
}
span.lineschanged {
    font-size: 0.7em;
}
span.oldmarker {
    color: red;
    font-size: large;
    font-weight: bold;
}
span.newmarker {
    color: green;
    font-size: large;
    font-weight: bold;
}
span.removed {
    color: brown;
}
span.changed {
    color: blue;
}
span.new {
    color: blue;
    font-weight: bold;
}
a.print { font-size: x-small; }

</style>

<style type="text/css" media="print">
pre { font-size: 0.8em; font-family: courier, monospace; }
span.removed { color: #444; font-style: italic }
span.changed { font-weight: bold; }
span.new { font-weight: bold; }
span.newmarker { font-size: 1.2em; font-weight: bold; }
span.oldmarker { font-size: 1.2em; font-weight: bold; }
a.print {display: none}
hr { border: none 0; border-top: 1px solid #aaa; height: 1px; }
</style>

<title>New src/hotspot/share/memory/metaspace/virtualSpaceNode.cpp</title>
<body id="SUNWwebrev">
<pre>
   1 /*
   2  * Copyright (c) 2018, 2019, Oracle and/or its affiliates. All rights reserved.
   3  * Copyright (c) 2018, 2019 SAP SE. All rights reserved.
   4  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   5  *
   6  * This code is free software; you can redistribute it and/or modify it
   7  * under the terms of the GNU General Public License version 2 only, as
   8  * published by the Free Software Foundation.
   9  *
  10  * This code is distributed in the hope that it will be useful, but WITHOUT
  11  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  12  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  13  * version 2 for more details (a copy is included in the LICENSE file that
  14  * accompanied this code).
  15  *
  16  * You should have received a copy of the GNU General Public License version
  17  * 2 along with this work; if not, write to the Free Software Foundation,
  18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  19  *
  20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  21  * or visit www.oracle.com if you need additional information or have any
  22  * questions.
  23  *
  24  */
  25 
  26 
  27 
  28 #include "precompiled.hpp"
  29 
  30 #include "logging/log.hpp"
  31 
  32 #include "memory/metaspace/chunkLevel.hpp"
  33 #include "memory/metaspace/chunkHeaderPool.hpp"
  34 #include "memory/metaspace/commitLimiter.hpp"
  35 #include "memory/metaspace/counter.hpp"
  36 #include "memory/metaspace/freeChunkList.hpp"
  37 #include "memory/metaspace/internStat.hpp"
  38 #include "memory/metaspace/metachunk.hpp"
  39 #include "memory/metaspace/metaspaceCommon.hpp"
  40 #include "memory/metaspace/rootChunkArea.hpp"
  41 #include "memory/metaspace/runningCounters.hpp"
  42 #include "memory/metaspace/settings.hpp"
  43 #include "memory/metaspace/virtualSpaceNode.hpp"
  44 #include "memory/metaspace.hpp"
  45 
  46 #include "runtime/globals.hpp"
  47 #include "runtime/mutexLocker.hpp"
  48 #include "runtime/os.hpp"
  49 
  50 #include "utilities/align.hpp"
  51 #include "utilities/debug.hpp"
  52 #include "utilities/globalDefinitions.hpp"
  53 #include "utilities/ostream.hpp"
  54 
  55 namespace metaspace {
  56 
  57 #ifdef ASSERT
  58 void check_pointer_is_aligned_to_commit_granule(const MetaWord* p) {
  59   assert(is_aligned(p, Settings::commit_granule_bytes()),
  60          "Pointer not aligned to commit granule size: " PTR_FORMAT ".",
  61          p2i(p));
  62 }
  63 void check_word_size_is_aligned_to_commit_granule(size_t word_size) {
  64   assert(is_aligned(word_size, Settings::commit_granule_words()),
  65          "Not aligned to commit granule size: " SIZE_FORMAT ".", word_size);
  66 }
  67 #endif
  68 
  69 
  70 // Given an address range, ensure it is committed.
  71 //
  72 // The range has to be aligned to granule size.
  73 //
  74 // Function will:
  75 // - check how many granules in that region are uncommitted; If all are committed, it
  76 //    returns true immediately.
  77 // - check if committing those uncommitted granules would bring us over the commit limit
  78 //    (GC threshold, MaxMetaspaceSize). If true, it returns false.
  79 // - commit the memory.
  80 // - mark the range as committed in the commit mask
  81 //
  82 // Returns true if success, false if it did hit a commit limit.
  83 bool VirtualSpaceNode::commit_range(MetaWord* p, size_t word_size) {
  84 
  85   DEBUG_ONLY(check_pointer_is_aligned_to_commit_granule(p);)
  86   DEBUG_ONLY(check_word_size_is_aligned_to_commit_granule(word_size);)
  87   assert_lock_strong(MetaspaceExpand_lock);
  88 
  89   // First calculate how large the committed regions in this range are
  90   const size_t committed_words_in_range = _commit_mask.get_committed_size_in_range(p, word_size);
  91   DEBUG_ONLY(check_word_size_is_aligned_to_commit_granule(committed_words_in_range);)
  92 
  93   // By how much words we would increase commit charge
  94   //  were we to commit the given address range completely.
  95   const size_t commit_increase_words = word_size - committed_words_in_range;
  96 
  97   log_debug(metaspace)("VirtualSpaceNode %d, base " PTR_FORMAT ": committing range " PTR_FORMAT ".." PTR_FORMAT "(" SIZE_FORMAT " words)",
  98                        _node_id, p2i(_base), p2i(p), p2i(p + word_size), word_size);
  99 
 100   if (commit_increase_words == 0) {
 101     log_debug(metaspace)("VirtualSpaceNode %d, base " PTR_FORMAT ": ... already fully committed.",
 102                          _node_id, p2i(_base));
 103     return true; // Already fully committed, nothing to do.
 104   }
 105 
 106   // Before committing any more memory, check limits.
 107   if (_commit_limiter-&gt;possible_expansion_words() &lt; commit_increase_words) {
 108     return false;
 109   }
 110 
 111   // Commit...
 112   if (os::commit_memory((char*)p, word_size * BytesPerWord, false) == false) {
 113     vm_exit_out_of_memory(word_size * BytesPerWord, OOM_MMAP_ERROR, "Failed to commit metaspace.");
 114   }
 115 
 116   if (AlwaysPreTouch) {
 117     os::pretouch_memory(p, p + word_size);
 118   }
 119 
 120   log_debug(gc, metaspace)("Increased metaspace by " SIZE_FORMAT " bytes.",
 121                            commit_increase_words * BytesPerWord);
 122 
 123   // ... tell commit limiter...
 124   _commit_limiter-&gt;increase_committed(commit_increase_words);
 125 
 126   // ... update counters in containing vslist ...
 127   _total_committed_words_counter-&gt;increment_by(commit_increase_words);
 128 
 129   // ... and update the commit mask.
 130   _commit_mask.mark_range_as_committed(p, word_size);
 131 
 132 #ifdef ASSERT
 133   // The commit boundary maintained in the CommitLimiter should be equal the sum of committed words
 134   // in both class and non-class vslist (outside gtests).
 135   if (_commit_limiter == CommitLimiter::globalLimiter()) {
 136     assert(_commit_limiter-&gt;committed_words() == RunningCounters::committed_words(), "counter mismatch");
 137   }
 138 #endif
 139 
 140   DEBUG_ONLY(InternalStats::inc_num_space_committed();)
 141 
 142   return true;
 143 
 144 }
 145 
 146 // Given an address range, ensure it is committed.
 147 //
 148 // The range does not have to be aligned to granule size. However, the function will always commit
 149 // whole granules.
 150 //
 151 // Function will:
 152 // - check how many granules in that region are uncommitted; If all are committed, it
 153 //    returns true immediately.
 154 // - check if committing those uncommitted granules would bring us over the commit limit
 155 //    (GC threshold, MaxMetaspaceSize). If true, it returns false.
 156 // - commit the memory.
 157 // - mark the range as committed in the commit mask
 158 //
 159 // !! Careful:
 160 //    calling ensure_range_is_committed on a range which contains both committed and uncommitted
 161 //    areas will commit the whole area, thus erase the content in the existing committed parts.
 162 //    Make sure you never call this on an address range containing live data. !!
 163 //
 164 // Returns true if success, false if it did hit a commit limit.
 165 bool VirtualSpaceNode::ensure_range_is_committed(MetaWord* p, size_t word_size) {
 166 
 167   assert_lock_strong(MetaspaceExpand_lock);
 168   assert(p != NULL &amp;&amp; word_size &gt; 0, "Sanity");
 169 
 170   MetaWord* p_start = align_down(p, Settings::commit_granule_bytes());
 171   MetaWord* p_end = align_up(p + word_size, Settings::commit_granule_bytes());
 172 
 173   // Todo: simple for now. Make it more intelligent late
 174   return commit_range(p_start, p_end - p_start);
 175 
 176 }
 177 
 178 // Given an address range (which has to be aligned to commit granule size):
 179 //  - uncommit it
 180 //  - mark it as uncommitted in the commit mask
 181 void VirtualSpaceNode::uncommit_range(MetaWord* p, size_t word_size) {
 182 
 183   DEBUG_ONLY(check_pointer_is_aligned_to_commit_granule(p);)
 184   DEBUG_ONLY(check_word_size_is_aligned_to_commit_granule(word_size);)
 185   assert_lock_strong(MetaspaceExpand_lock);
 186 
 187   // First calculate how large the committed regions in this range are
 188   const size_t committed_words_in_range = _commit_mask.get_committed_size_in_range(p, word_size);
 189   DEBUG_ONLY(check_word_size_is_aligned_to_commit_granule(committed_words_in_range);)
 190 
 191   log_debug(metaspace)("VirtualSpaceNode %d, base " PTR_FORMAT ": uncommitting range " PTR_FORMAT ".." PTR_FORMAT "(" SIZE_FORMAT " words)",
 192                        _node_id, p2i(_base), p2i(p), p2i(p + word_size), word_size);
 193 
 194   if (committed_words_in_range == 0) {
 195     log_debug(metaspace)("VirtualSpaceNode %d, base " PTR_FORMAT ": ... already fully uncommitted.",
 196                          _node_id, p2i(_base));
 197     return; // Already fully uncommitted, nothing to do.
 198   }
 199 
 200   // Uncommit...
 201   if (os::uncommit_memory((char*)p, word_size * BytesPerWord) == false) {
 202     // Note: this can actually happen, since uncommit may increase the number of mappings.
 203     fatal("Failed to uncommit metaspace.");
 204   }
 205 
 206   log_debug(metaspace)("Decreased metaspace by " SIZE_FORMAT " bytes.",
 207                         committed_words_in_range * BytesPerWord);
 208 
 209   // ... tell commit limiter...
 210   _commit_limiter-&gt;decrease_committed(committed_words_in_range);
 211 
 212   // ... and global counters...
 213   _total_committed_words_counter-&gt;decrement_by(committed_words_in_range);
 214 
 215    // ... and update the commit mask.
 216   _commit_mask.mark_range_as_uncommitted(p, word_size);
 217 
 218 #ifdef ASSERT
 219   // The commit boundary maintained in the CommitLimiter should be equal the sum of committed words
 220   // in both class and non-class vslist (outside gtests).
 221   if (_commit_limiter == CommitLimiter::globalLimiter()) { // We are outside a test scenario
 222     assert(_commit_limiter-&gt;committed_words() == RunningCounters::committed_words(), "counter mismatch");
 223   }
 224 #endif
 225 
 226   DEBUG_ONLY(InternalStats::inc_num_space_uncommitted();)
 227 
 228 }
 229 
 230 //// creation, destruction ////
 231 
 232 VirtualSpaceNode::VirtualSpaceNode(int node_id,
 233                                    ReservedSpace rs,
 234                                    CommitLimiter* limiter,
 235                                    SizeCounter* reserve_words_counter,
 236                                    SizeCounter* commit_words_counter)
 237   : _next(NULL),
 238     _rs(rs),
 239     _base((MetaWord*)rs.base()),
 240     _word_size(rs.size() / BytesPerWord),
 241     _used_words(0),
 242     _commit_mask((MetaWord*)rs.base(), rs.size() / BytesPerWord),
 243     _root_chunk_area_lut((MetaWord*)rs.base(), rs.size() / BytesPerWord),
 244     _commit_limiter(limiter),
 245     _total_reserved_words_counter(reserve_words_counter),
 246     _total_committed_words_counter(commit_words_counter),
 247     _node_id(node_id)
 248 {
 249 
 250   log_debug(metaspace)("Create new VirtualSpaceNode %d, base " PTR_FORMAT ", word size " SIZE_FORMAT ".",
 251                        _node_id, p2i(_base), _word_size);
 252 
 253   // Update reserved counter in vslist
 254   _total_reserved_words_counter-&gt;increment_by(_word_size);
 255 
 256   assert_is_aligned(_base, chunklevel::MAX_CHUNK_BYTE_SIZE);
 257   assert_is_aligned(_word_size, chunklevel::MAX_CHUNK_WORD_SIZE);
 258 
 259 }
 260 
 261 // Create a node of a given size
 262 VirtualSpaceNode* VirtualSpaceNode::create_node(int node_id,
 263                                                 size_t word_size,
 264                                                 CommitLimiter* limiter,
 265                                                 SizeCounter* reserve_words_counter,
 266                                                 SizeCounter* commit_words_counter)
 267 {
 268 
 269   DEBUG_ONLY(assert_is_aligned(word_size, chunklevel::MAX_CHUNK_WORD_SIZE);)
 270 
 271 #ifdef ASSERT
 272   size_t alignment = chunklevel::MAX_CHUNK_BYTE_SIZE;
 273 #endif
 274 
 275   ReservedSpace rs(word_size * BytesPerWord,
 276                    Metaspace::reserve_alignment(),
 277                    false // large
 278                    );
 279 
 280   if (!rs.is_reserved()) {
 281     vm_exit_out_of_memory(word_size * BytesPerWord, OOM_MMAP_ERROR, "Failed to reserve memory for metaspace");
 282   }
 283 
 284   assert_is_aligned(rs.base(), chunklevel::MAX_CHUNK_BYTE_SIZE);
 285 
 286   return create_node(node_id, rs, limiter, reserve_words_counter, commit_words_counter);
 287 
 288 }
 289 
 290 // Create a node over an existing space
 291 VirtualSpaceNode* VirtualSpaceNode::create_node(int node_id,
 292                                                 ReservedSpace rs,
 293                                                 CommitLimiter* limiter,
 294                                                 SizeCounter* reserve_words_counter,
 295                                                 SizeCounter* commit_words_counter)
 296 {
 297   DEBUG_ONLY(InternalStats::inc_num_vsnodes_created();)
 298   return new VirtualSpaceNode(node_id, rs, limiter, reserve_words_counter, commit_words_counter);
 299 }
 300 
 301 VirtualSpaceNode::~VirtualSpaceNode() {
 302   _rs.release();
 303 
 304   log_debug(metaspace)("Destroying VirtualSpaceNode %d, base " PTR_FORMAT ", word size " SIZE_FORMAT ".",
 305                        _node_id, p2i(_base), _word_size);
 306 
 307   // Update counters in vslist
 308   _total_committed_words_counter-&gt;decrement_by(committed_words());
 309   _total_reserved_words_counter-&gt;decrement_by(_word_size);
 310 
 311   DEBUG_ONLY(InternalStats::inc_num_vsnodes_destroyed();)
 312 
 313 }
 314 
 315 
 316 
 317 //// Chunk allocation, splitting, merging /////
 318 
 319 // Allocate a root chunk from this node. Will fail and return NULL
 320 // if the node is full.
 321 // Note: this just returns a chunk whose memory is reserved; no memory is committed yet.
 322 // Hence, before using this chunk, it must be committed.
 323 // Also, no limits are checked, since no committing takes place.
 324 Metachunk* VirtualSpaceNode::allocate_root_chunk() {
 325 
 326   assert_lock_strong(MetaspaceExpand_lock);
 327 
 328   assert_is_aligned(free_words(), chunklevel::MAX_CHUNK_WORD_SIZE);
 329 
 330   if (free_words() &gt;= chunklevel::MAX_CHUNK_WORD_SIZE) {
 331 
 332     MetaWord* loc = _base + _used_words;
 333     _used_words += chunklevel::MAX_CHUNK_WORD_SIZE;
 334 
 335     RootChunkArea* rca = _root_chunk_area_lut.get_area_by_address(loc);
 336 
 337     // Create a root chunk header and initialize it;
 338     Metachunk* c = rca-&gt;alloc_root_chunk_header(this);
 339 
 340     assert(c-&gt;base() == loc &amp;&amp; c-&gt;vsnode() == this &amp;&amp;
 341            c-&gt;is_free(), "Sanity");
 342 
 343     DEBUG_ONLY(c-&gt;verify(true);)
 344 
 345     log_debug(metaspace)("VirtualSpaceNode %d, base " PTR_FORMAT ": newborn root chunk " METACHUNK_FORMAT ".",
 346                          _node_id, p2i(_base), METACHUNK_FORMAT_ARGS(c));
 347 
 348     if (Settings::newborn_root_chunks_are_fully_committed()) {
 349       log_trace(metaspace)("VirtualSpaceNode %d, base " PTR_FORMAT ": committing newborn root chunk.",
 350                            _node_id, p2i(_base));
 351       // Note: use Metachunk::ensure_commit, do not commit directly. This makes sure the chunk knows
 352       // its commit range and does not ask needlessly.
 353       c-&gt;ensure_fully_committed_locked();
 354     }
 355 
 356     return c;
 357 
 358   }
 359 
 360   return NULL; // Node is full.
 361 
 362 }
 363 
 364 // Given a chunk c, split it recursively until you get a chunk of the given target_level.
 365 //
 366 // The resulting target chunk resides at the same address as the original chunk.
 367 // The resulting splinters are added to freelists.
 368 void VirtualSpaceNode::split(chunklevel_t target_level, Metachunk* c, FreeChunkListVector* freelists) {
 369 
 370   assert_lock_strong(MetaspaceExpand_lock);
 371 
 372   // Get the area associated with this chunk and let it handle the splitting
 373   RootChunkArea* rca = _root_chunk_area_lut.get_area_by_address(c-&gt;base());
 374 
 375   DEBUG_ONLY(rca-&gt;verify_area_is_ideally_merged();)
 376 
 377   rca-&gt;split(target_level, c, freelists);
 378 
 379 }
 380 
 381 // Given a chunk, attempt to merge it recursively with its neighboring chunks.
 382 //
 383 // If successful (merged at least once), returns address of
 384 // the merged chunk; NULL otherwise.
 385 //
 386 // The merged chunks are removed from the freelists.
 387 //
 388 // !!! Please note that if this method returns a non-NULL value, the
 389 // original chunk will be invalid and should not be accessed anymore! !!!
 390 Metachunk* VirtualSpaceNode::merge(Metachunk* c, FreeChunkListVector* freelists) {
 391 
 392   assert(c != NULL &amp;&amp; c-&gt;is_free(), "Sanity");
 393   assert_lock_strong(MetaspaceExpand_lock);
 394 
 395   // Get the rca associated with this chunk and let it handle the merging
 396   RootChunkArea* rca = _root_chunk_area_lut.get_area_by_address(c-&gt;base());
 397 
 398   Metachunk* c2 = rca-&gt;merge(c, freelists);
 399 
 400   DEBUG_ONLY(rca-&gt;verify_area_is_ideally_merged();)
 401 
 402   return c2;
 403 
 404 }
 405 
 406 // Given a chunk c, which must be "in use" and must not be a root chunk, attempt to
 407 // enlarge it in place by claiming its trailing buddy.
 408 //
 409 // This will only work if c is the leader of the buddy pair and the trailing buddy is free.
 410 //
 411 // If successful, the follower chunk will be removed from the freelists, the leader chunk c will
 412 // double in size (level decreased by one).
 413 //
 414 // On success, true is returned, false otherwise.
 415 bool VirtualSpaceNode::attempt_enlarge_chunk(Metachunk* c, FreeChunkListVector* freelists) {
 416 
 417   assert(c != NULL &amp;&amp; c-&gt;is_in_use() &amp;&amp; !c-&gt;is_root_chunk(), "Sanity");
 418   assert_lock_strong(MetaspaceExpand_lock);
 419 
 420   // Get the rca associated with this chunk and let it handle the merging
 421   RootChunkArea* rca = _root_chunk_area_lut.get_area_by_address(c-&gt;base());
 422 
 423   bool rc = rca-&gt;attempt_enlarge_chunk(c, freelists);
 424 
 425   DEBUG_ONLY(rca-&gt;verify_area_is_ideally_merged();)
 426 
 427   return rc;
 428 
 429 }
 430 
 431 // Attempts to purge the node:
 432 //
 433 // If all chunks living in this node are free, they will all be removed from their freelists
 434 //   and deletes the node.
 435 //
 436 // Returns true if the node has been deleted, false if not.
 437 // !! If this returns true, do not access the node from this point on. !!
 438 bool VirtualSpaceNode::attempt_purge(FreeChunkListVector* freelists) {
 439 
 440   assert_lock_strong(MetaspaceExpand_lock);
 441 
 442   // First find out if all areas are empty. Since empty chunks collapse to root chunk
 443   // size, if all chunks in this node are free root chunks we are good to go.
 444   for (int narea = 0; narea &lt; _root_chunk_area_lut.number_of_areas(); narea ++) {
 445     const RootChunkArea* ra = _root_chunk_area_lut.get_area_by_index(narea);
 446     const Metachunk* c = ra-&gt;first_chunk();
 447     if (c != NULL) {
 448       if (!(c-&gt;is_root_chunk() &amp;&amp; c-&gt;is_free())) {
 449         return false;
 450       }
 451     }
 452   }
 453 
 454   log_debug(metaspace)("VirtualSpaceNode %d, base " PTR_FORMAT ": purging.", _node_id, p2i(_base));
 455 
 456   // Okay, we can purge. Before we can do this, we need to remove all chunks from the freelist.
 457   for (int narea = 0; narea &lt; _root_chunk_area_lut.number_of_areas(); narea ++) {
 458     RootChunkArea* ra = _root_chunk_area_lut.get_area_by_index(narea);
 459     Metachunk* c = ra-&gt;first_chunk();
 460     if (c != NULL) {
 461       log_trace(metaspace)("VirtualSpaceNode %d, base " PTR_FORMAT ": removing chunk " METACHUNK_FULL_FORMAT ".",
 462                            _node_id, p2i(_base), METACHUNK_FULL_FORMAT_ARGS(c));
 463       assert(c-&gt;is_free() &amp;&amp; c-&gt;is_root_chunk(), "Sanity");
 464       freelists-&gt;remove(c);
 465     }
 466   }
 467 
 468   // Now, delete the node, then right away return since this object is invalid.
 469   delete this;
 470 
 471   return true;
 472 
 473 }
 474 
 475 
 476 void VirtualSpaceNode::print_on(outputStream* st) const {
 477 
 478   size_t scale = K;
 479 
 480   st-&gt;print("id: %d, base " PTR_FORMAT ": ", _node_id, p2i(base()));
 481   st-&gt;print("reserved=");
 482   print_scaled_words(st, word_size(), scale);
 483   st-&gt;print(", committed=");
 484   print_scaled_words_and_percentage(st, committed_words(), word_size(), scale);
 485   st-&gt;print(", used=");
 486   print_scaled_words_and_percentage(st, used_words(), word_size(), scale);
 487 
 488   st-&gt;cr();
 489 
 490   _root_chunk_area_lut.print_on(st);
 491   _commit_mask.print_on(st);
 492 
 493 }
 494 
 495 // Returns size, in words, of committed space in this node alone.
 496 // Note: iterates over commit mask and hence may be a tad expensive on large nodes.
 497 size_t VirtualSpaceNode::committed_words() const {
 498   return _commit_mask.get_committed_size();
 499 }
 500 
 501 #ifdef ASSERT
 502 // Verify counters and basic structure. Slow mode: verify all chunks in depth
 503 void VirtualSpaceNode::verify(bool slow) const {
 504 
 505   assert_lock_strong(MetaspaceExpand_lock);
 506 
 507   assert(base() != NULL, "Invalid base");
 508   assert(base() == (MetaWord*)_rs.base() &amp;&amp;
 509          word_size() == _rs.size() / BytesPerWord,
 510          "Sanity");
 511   assert_is_aligned(base(), chunklevel::MAX_CHUNK_BYTE_SIZE);
 512   assert(used_words() &lt;= word_size(), "Sanity");
 513 
 514   // Since we only ever hand out root chunks from a vsnode, top should always be aligned
 515   // to root chunk size.
 516   assert_is_aligned(used_words(), chunklevel::MAX_CHUNK_WORD_SIZE);
 517 
 518   _commit_mask.verify(slow);
 519   assert(committed_words() &lt;= word_size(), "Sanity");
 520   assert_is_aligned(committed_words(), Settings::commit_granule_words());
 521   _root_chunk_area_lut.verify(slow);
 522 
 523 }
 524 
 525 #endif
 526 
 527 
 528 } // namespace metaspace
</pre></body></html>
